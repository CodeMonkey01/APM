{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9fbf13a",
   "metadata": {},
   "source": [
    "# Fig. 4 calculation - except BOA, HC & LED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a419a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from replearn.eventlog import EventLog\n",
    "\n",
    "from replearn.embedding_predict import EmbeddingPredict\n",
    "from replearn.autoencoder import AutoencoderRepresentation\n",
    "from replearn.doc2vec import Doc2VecRepresentation\n",
    "\n",
    "from replearn.clustering import Clustering\n",
    "from replearn.evaluation import Evaluation\n",
    "import os\n",
    "    \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e0aa40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getFilePaths(path_of_the_directory, noiselevel):\n",
    "    filepaths = []\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        f = os.path.join(path_of_the_directory,filename)\n",
    "        if os.path.isfile(f) and str(noiselevel) + \"-1.json.gz\" in f: \n",
    "            filepaths.append(f)\n",
    "    return filepaths\n",
    "\n",
    "\n",
    "# method def: Autoencoder = 1, Trace2Vec = 2, Case2Vec(event) = 3, Case2Vec(event+case) = 4, LSTMClust = 5, GRUClust = 6\n",
    "def getMetrics_for_Method_and_Noise(noiselevel, method):\n",
    "    \n",
    "    filepaths = getFilePaths('../logs/multi-perspective_02', noiselevel)\n",
    "\n",
    "    case_attributes = None # auto-detect attributes\n",
    "    event_attributes = ['concept:name', 'user'] # use activity name and user\n",
    "    true_cluster_label = 'cluster'\n",
    "\n",
    "    # hyperparameters\n",
    "    n_epochs = 25\n",
    "    n_batch_size = 64\n",
    "    n_clusters = 5\n",
    "\n",
    "    vector_size = 32\n",
    "\n",
    "    data = []\n",
    "    \n",
    "    for file in filepaths:\n",
    "\n",
    "        # load file\n",
    "        event_log = EventLog(file, case_attributes=case_attributes, event_attributes=event_attributes, true_cluster_label=true_cluster_label)\n",
    "        event_log.load(file, False)\n",
    "        event_log.preprocess()\n",
    "        \n",
    "        \n",
    "        if method == 1:\n",
    "\n",
    "            # get sequences from event log as one-hot feature vector\n",
    "            sequences = event_log.event_attributes_flat_onehot_features_2d\n",
    "\n",
    "            # init and train autoencoder\n",
    "            autoencoder = AutoencoderRepresentation(event_log)\n",
    "            autoencoder.build_model(sequences.shape[1], encoder_dim=vector_size)\n",
    "            autoencoder.fit(batch_size=n_batch_size, epochs=n_epochs, verbose=True)\n",
    "\n",
    "            # get feature vector\n",
    "            feature_vector = autoencoder.predict()\n",
    "        \n",
    "        elif method == 2:\n",
    "            \n",
    "            doc2vec = Doc2VecRepresentation(event_log)\n",
    "            doc2vec.build_model(append_case_attr=False, append_event_attr=False, vector_size=vector_size, concat=True, epochs=n_epochs)\n",
    "            doc2vec.fit()\n",
    "            \n",
    "            # infer the vector from the model\n",
    "            feature_vector = doc2vec.predict(epochs=50)\n",
    "            \n",
    "        elif method == 3:\n",
    "            \n",
    "            # train doc2vec model\n",
    "            doc2vec = Doc2VecRepresentation(event_log)\n",
    "            doc2vec.build_model(append_case_attr=False, append_event_attr=True, vector_size=vector_size, concat=True, epochs=n_epochs)\n",
    "            doc2vec.fit()\n",
    "            \n",
    "            # infer the vector from the model\n",
    "            feature_vector = doc2vec.predict(epochs=50)\n",
    "            \n",
    "        elif method == 4:\n",
    "            \n",
    "            doc2vec = Doc2VecRepresentation(event_log)\n",
    "            doc2vec.build_model(append_case_attr=True, append_event_attr=True, vector_size=vector_size, concat=True, epochs=n_epochs)\n",
    "            doc2vec.fit()\n",
    "\n",
    "            # infer the vector from the model\n",
    "            feature_vector = doc2vec.predict(epochs=50)\n",
    "            \n",
    "        elif method == 5:\n",
    "            \n",
    "            # init and train LSTM\n",
    "            predictor = EmbeddingPredict(event_log)\n",
    "            predictor.build_model(embedding_dim=vector_size, gru_dim=vector_size, rnn='LSTM')\n",
    "            predictor.fit(epochs=n_epochs, batch_size=n_batch_size, verbose=True)\n",
    "\n",
    "            # get feature vector\n",
    "            pred_model, feature_vector, embedding_vector = predictor.predict()\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # init and train LSTM\n",
    "            predictor = EmbeddingPredict(event_log)\n",
    "            predictor.build_model(embedding_dim=vector_size, gru_dim=vector_size, rnn='gru')\n",
    "            predictor.fit(epochs=n_epochs, batch_size=n_batch_size, verbose=True)\n",
    "\n",
    "            # get feature vector\n",
    "            pred_model, feature_vector, embedding_vector = predictor.predict()\n",
    "            \n",
    "        \n",
    "        # cluster feature vector\n",
    "        cluster_analysis = Clustering(event_log)\n",
    "        cluster_analysis.cluster(feature_vector, 'agglomerative', n_clusters, 'cosine')\n",
    "\n",
    "        evaluation_a = Evaluation(event_log)\n",
    "        results = evaluation_a.evaluate_clusters(n_clusters,cluster_analysis._pred_labels)\n",
    "        cluster_result = cluster_analysis.evaluate()\n",
    "        \n",
    "        # get results\n",
    "        data.append({'avgFitness': results[0], 'avgPrecision': results[1], 'avgSimp': results[2], 'avgF1-BCubed': cluster_result[2], 'Noise': noiselevel, 'Method': method})\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a52c76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResults_all_Noise_levels(method):\n",
    "    list = []\n",
    "    noiseLevels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] # 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0\n",
    "    for level in noiseLevels:\n",
    "        list.append(getMetrics_for_Method_and_Noise(level, method))\n",
    "    return list\n",
    "\n",
    "def getCombinedMeanResults(method):\n",
    "    allResults = getResults_all_Noise_levels(method)\n",
    "    means = [pd.DataFrame(df.mean()).transpose() for df in allResults]\n",
    "    df = pd.DataFrame({'avgFitness': [], 'avgPrecision': [], 'avgSimp': [], 'avgF1-BCubed': [], 'Noise': [], 'Method': []})\n",
    "    for meanResults in means:\n",
    "        df = df.append(meanResults, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d424cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Results and write into csv\n",
    "resultsAutoencoder = getCombinedMeanResults(1)\n",
    "resultsTrace2Vec = getCombinedMeanResults(2)\n",
    "resultsCase2Vec_event = getCombinedMeanResults(3)\n",
    "resultsCase2Vec_event_case = getCombinedMeanResults(4)\n",
    "resultsLSTMClust = getCombinedMeanResults(5)\n",
    "resultsGRUClust = getCombinedMeanResults(6)\n",
    "\n",
    "resultsAutoencoder.to_csv('fig4_resultsAutoencoder.csv', encoding='utf-8', index=False, sep=';')\n",
    "resultsTrace2Vec.to_csv('fig4_resultsTrace2Vec.csv', encoding='utf-8', index=False, sep=';')\n",
    "resultsCase2Vec_event.to_csv('fig4_resultsCase2Vec_event.csv', encoding='utf-8', index=False, sep=';')\n",
    "resultsCase2Vec_event_case.to_csv('fig4_resultsCase2Vec_event_case.csv', encoding='utf-8', index=False, sep=';')\n",
    "resultsLSTMClust.to_csv('fig4_resultsLSTMClust.csv', encoding='utf-8', index=False, sep=';')\n",
    "resultsGRUClust.to_csv('fig4_resultsGRUClust.csv', encoding='utf-8', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afcb602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_size(w,h, ax=None):\n",
    "    \"\"\" w, h: width, height in inches \"\"\"\n",
    "    if not ax: ax=plt.gca()\n",
    "    l = ax.figure.subplotpars.left\n",
    "    r = ax.figure.subplotpars.right\n",
    "    t = ax.figure.subplotpars.top\n",
    "    b = ax.figure.subplotpars.bottom\n",
    "    figw = float(w)/(r-l)\n",
    "    figh = float(h)/(t-b)\n",
    "    ax.figure.set_size_inches(figw, figh)\n",
    "    \n",
    "\n",
    "def plotResults(results):\n",
    "    \n",
    "        \n",
    "    plt_1 = plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    for res in results:\n",
    "        axs[0, 0].plot(res['Noise'], res['avgF1-BCubed'])\n",
    "        axs[0, 1].plot(res['Noise'], res['avgSimp'])\n",
    "        axs[1, 0].plot(res['Noise'], res['avgFitness'])\n",
    "        axs[1, 1].plot(res['Noise'], res['avgPrecision'])\n",
    "    \n",
    "\n",
    "    axs[0, 0].set_xticks(np.arange(min(results[0]['Noise']), max(results[0]['Noise'])+1, 0.1))\n",
    "    axs[0, 1].set_yticks(np.arange(min(results[0]['Noise']), max(results[0]['Noise'])+1, 0.2))\n",
    "    axs[0, 0].set_ylim([0.38,1])\n",
    "    axs[0, 0].set_xlim([0,1])\n",
    "    axs[0, 0].set_ylabel('F1-BCubed')\n",
    "    axs[0, 0].set_xlabel('noise')\n",
    "    \n",
    "\n",
    "    axs[0, 1].set_xticks(np.arange(min(results[0]['Noise']), max(results[0]['Noise'])+1, 0.1))\n",
    "    axs[0, 1].set_yticks(np.arange(min(results[0]['Noise']), max(results[0]['Noise'])+1, 0.2))\n",
    "    axs[0, 1].set_ylim([0.3,1])\n",
    "    axs[0, 1].set_xlim([0,1])\n",
    "    axs[0, 1].set_ylabel('Simplicity')\n",
    "    axs[0, 1].set_xlabel('noise')\n",
    "    \n",
    "\n",
    "    axs[1, 0].set_xticks(np.arange(min(results[0]['Noise']), max(results[0]['Noise'])+1, 0.1))\n",
    "    axs[1, 0].set_yticks(np.arange(min(results[0]['Noise']), max(results[0]['Noise'])+1, 0.2))\n",
    "    axs[1, 0].set_ylim([0.3,1])\n",
    "    axs[1, 0].set_xlim([0,1])\n",
    "    axs[1, 0].set_ylabel('Fitness')\n",
    "    axs[1, 0].set_xlabel('noise')\n",
    "    \n",
    "    axs[1, 1].set_xticks(np.arange(min(results[0]['Noise']), max(results[0]['Noise'])+1, 0.1))\n",
    "    axs[1, 1].set_yticks(np.arange(min(results[0]['Noise']), max(results[0]['Noise'])+1, 0.2))\n",
    "    axs[1, 1].set_ylim([0.21, 1])\n",
    "    axs[1, 1].set_xlim([0,1])\n",
    "    axs[1, 1].set_ylabel('Precision')\n",
    "    axs[1, 1].set_xlabel('noise')\n",
    "    \n",
    "    \n",
    "\n",
    "    #plt.savefig('foo.pdf')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0236e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read in all the results\n",
    "def readInResults():\n",
    "    data = []\n",
    "    data.append(pd.read_csv('fig4_resultsAutoencoder.csv', sep = ';'))\n",
    "    data.append(pd.read_csv('fig4_resultsTrace2Vec.csv', sep = ';'))\n",
    "    data.append(pd.read_csv('fig4_resultsCase2Vec_event.csv', sep = ';'))\n",
    "    data.append(pd.read_csv('fig4_resultsCase2Vec_event_case.csv', sep = ';'))\n",
    "    data.append(pd.read_csv('fig4_resultsLSTMClust.csv', sep = ';'))\n",
    "    data.append(pd.read_csv('fig4_resultsGRUClust.csv', sep = ';'))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5c81bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in and plot the Results\n",
    "plotResults(readInResults())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85998b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a68eec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import git\n",
    "from pm4py.objects.log.importer.xes import factory as xes_import_factory\n",
    "from replearn.eventlog import EventLog\n",
    "from log_iteration import Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D46BDB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D46BDB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 4s 40ms/step - loss: 0.1795\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.0101\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0056\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.0052\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.0050\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.0047\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.0042\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0037\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0034\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.0031\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D46BDCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D46BDCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 13s 19ms/step - loss: 19.2276 - dense_3_loss: 1.8025 - dense_4_loss: 2.1887 - dense_5_loss: 1.7936 - dense_6_loss: 1.8567 - dense_7_loss: 2.1878 - dense_8_loss: 2.1876 - dense_9_loss: 1.8243 - dense_10_loss: 1.8528 - dense_11_loss: 1.8192 - dense_12_loss: 1.7143 - dense_3_accuracy: 0.2572 - dense_4_accuracy: 0.1716 - dense_5_accuracy: 0.2700 - dense_6_accuracy: 0.2334 - dense_7_accuracy: 0.1706 - dense_8_accuracy: 0.1688 - dense_9_accuracy: 0.3022 - dense_10_accuracy: 0.2756 - dense_11_accuracy: 0.2864 - dense_12_accuracy: 0.3150\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 14.7733 - dense_3_loss: 1.4036 - dense_4_loss: 1.6443 - dense_5_loss: 1.4067 - dense_6_loss: 1.5166 - dense_7_loss: 1.6538 - dense_8_loss: 1.6313 - dense_9_loss: 1.4207 - dense_10_loss: 1.3724 - dense_11_loss: 1.3721 - dense_12_loss: 1.3517 - dense_3_accuracy: 0.3482 - dense_4_accuracy: 0.2354 - dense_5_accuracy: 0.3430 - dense_6_accuracy: 0.2718 - dense_7_accuracy: 0.2316 - dense_8_accuracy: 0.2308 - dense_9_accuracy: 0.3612 - dense_10_accuracy: 0.3656 - dense_11_accuracy: 0.3582 - dense_12_accuracy: 0.3686\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 14.1044 - dense_3_loss: 1.3463 - dense_4_loss: 1.5648 - dense_5_loss: 1.3581 - dense_6_loss: 1.4638 - dense_7_loss: 1.5737 - dense_8_loss: 1.5523 - dense_9_loss: 1.3556 - dense_10_loss: 1.2808 - dense_11_loss: 1.3065 - dense_12_loss: 1.3024 - dense_3_accuracy: 0.3642 - dense_4_accuracy: 0.2528 - dense_5_accuracy: 0.3606 - dense_6_accuracy: 0.2846 - dense_7_accuracy: 0.2494 - dense_8_accuracy: 0.2574 - dense_9_accuracy: 0.3560 - dense_10_accuracy: 0.3820 - dense_11_accuracy: 0.3616 - dense_12_accuracy: 0.3740\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 13.8457 - dense_3_loss: 1.3264 - dense_4_loss: 1.5366 - dense_5_loss: 1.3339 - dense_6_loss: 1.4459 - dense_7_loss: 1.5449 - dense_8_loss: 1.5222 - dense_9_loss: 1.3303 - dense_10_loss: 1.2506 - dense_11_loss: 1.2771 - dense_12_loss: 1.2778 - dense_3_accuracy: 0.3580 - dense_4_accuracy: 0.2486 - dense_5_accuracy: 0.3690 - dense_6_accuracy: 0.2878 - dense_7_accuracy: 0.2522 - dense_8_accuracy: 0.2518 - dense_9_accuracy: 0.3710 - dense_10_accuracy: 0.3798 - dense_11_accuracy: 0.3682 - dense_12_accuracy: 0.3766\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 13.6961 - dense_3_loss: 1.3101 - dense_4_loss: 1.5175 - dense_5_loss: 1.3253 - dense_6_loss: 1.4329 - dense_7_loss: 1.5242 - dense_8_loss: 1.5081 - dense_9_loss: 1.3105 - dense_10_loss: 1.2399 - dense_11_loss: 1.2639 - dense_12_loss: 1.2636 - dense_3_accuracy: 0.3614 - dense_4_accuracy: 0.2536 - dense_5_accuracy: 0.3670 - dense_6_accuracy: 0.2868 - dense_7_accuracy: 0.2546 - dense_8_accuracy: 0.2520 - dense_9_accuracy: 0.3820 - dense_10_accuracy: 0.3828 - dense_11_accuracy: 0.3754 - dense_12_accuracy: 0.3778\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 13.7210 - dense_3_loss: 1.3126 - dense_4_loss: 1.5207 - dense_5_loss: 1.3227 - dense_6_loss: 1.4394 - dense_7_loss: 1.5292 - dense_8_loss: 1.5114 - dense_9_loss: 1.3162 - dense_10_loss: 1.2399 - dense_11_loss: 1.2664 - dense_12_loss: 1.2624 - dense_3_accuracy: 0.3650 - dense_4_accuracy: 0.2496 - dense_5_accuracy: 0.3718 - dense_6_accuracy: 0.2918 - dense_7_accuracy: 0.2552 - dense_8_accuracy: 0.2442 - dense_9_accuracy: 0.3686 - dense_10_accuracy: 0.3812 - dense_11_accuracy: 0.3700 - dense_12_accuracy: 0.3786\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 13.6820 - dense_3_loss: 1.3101 - dense_4_loss: 1.5118 - dense_5_loss: 1.3206 - dense_6_loss: 1.4338 - dense_7_loss: 1.5206 - dense_8_loss: 1.5065 - dense_9_loss: 1.3158 - dense_10_loss: 1.2372 - dense_11_loss: 1.2594 - dense_12_loss: 1.2661 - dense_3_accuracy: 0.3578 - dense_4_accuracy: 0.2470 - dense_5_accuracy: 0.3662 - dense_6_accuracy: 0.2784 - dense_7_accuracy: 0.2438 - dense_8_accuracy: 0.2482 - dense_9_accuracy: 0.3710 - dense_10_accuracy: 0.3772 - dense_11_accuracy: 0.3726 - dense_12_accuracy: 0.3726\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 13.5655 - dense_3_loss: 1.3045 - dense_4_loss: 1.4986 - dense_5_loss: 1.3026 - dense_6_loss: 1.4242 - dense_7_loss: 1.5095 - dense_8_loss: 1.4930 - dense_9_loss: 1.2985 - dense_10_loss: 1.2249 - dense_11_loss: 1.2519 - dense_12_loss: 1.2579 - dense_3_accuracy: 0.3516 - dense_4_accuracy: 0.2578 - dense_5_accuracy: 0.3684 - dense_6_accuracy: 0.2812 - dense_7_accuracy: 0.2518 - dense_8_accuracy: 0.2592 - dense_9_accuracy: 0.3750 - dense_10_accuracy: 0.3824 - dense_11_accuracy: 0.3614 - dense_12_accuracy: 0.3710\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 13.5911 - dense_3_loss: 1.3060 - dense_4_loss: 1.5034 - dense_5_loss: 1.3108 - dense_6_loss: 1.4225 - dense_7_loss: 1.5121 - dense_8_loss: 1.4979 - dense_9_loss: 1.3011 - dense_10_loss: 1.2315 - dense_11_loss: 1.2511 - dense_12_loss: 1.2548 - dense_3_accuracy: 0.3654 - dense_4_accuracy: 0.2490 - dense_5_accuracy: 0.3700 - dense_6_accuracy: 0.2854 - dense_7_accuracy: 0.2468 - dense_8_accuracy: 0.2458 - dense_9_accuracy: 0.3776 - dense_10_accuracy: 0.3786 - dense_11_accuracy: 0.3716 - dense_12_accuracy: 0.3794\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 13.5559 - dense_3_loss: 1.2988 - dense_4_loss: 1.5010 - dense_5_loss: 1.3067 - dense_6_loss: 1.4202 - dense_7_loss: 1.5081 - dense_8_loss: 1.4957 - dense_9_loss: 1.2979 - dense_10_loss: 1.2224 - dense_11_loss: 1.2513 - dense_12_loss: 1.2537 - dense_3_accuracy: 0.3654 - dense_4_accuracy: 0.2480 - dense_5_accuracy: 0.3756 - dense_6_accuracy: 0.2872 - dense_7_accuracy: 0.2482 - dense_8_accuracy: 0.2514 - dense_9_accuracy: 0.3820 - dense_10_accuracy: 0.3850 - dense_11_accuracy: 0.3714 - dense_12_accuracy: 0.3746\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D34F31F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D34F31F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D2AD6048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D2AD6048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 13s 18ms/step - loss: 19.8077 - dense_13_loss: 1.9114 - dense_14_loss: 2.2576 - dense_15_loss: 1.8398 - dense_16_loss: 1.9098 - dense_17_loss: 2.2719 - dense_18_loss: 2.2659 - dense_19_loss: 1.8657 - dense_20_loss: 1.8746 - dense_21_loss: 1.8565 - dense_22_loss: 1.7546 - dense_13_accuracy: 0.2166 - dense_14_accuracy: 0.1498 - dense_15_accuracy: 0.2576 - dense_16_accuracy: 0.1998 - dense_17_accuracy: 0.1562 - dense_18_accuracy: 0.1502 - dense_19_accuracy: 0.2744 - dense_20_accuracy: 0.2790 - dense_21_accuracy: 0.3020 - dense_22_accuracy: 0.3154\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 15.9617 - dense_13_loss: 1.5311 - dense_14_loss: 1.7918 - dense_15_loss: 1.5084 - dense_16_loss: 1.5750 - dense_17_loss: 1.8006 - dense_18_loss: 1.7927 - dense_19_loss: 1.5244 - dense_20_loss: 1.4750 - dense_21_loss: 1.4945 - dense_22_loss: 1.4681 - dense_13_accuracy: 0.3200 - dense_14_accuracy: 0.2132 - dense_15_accuracy: 0.3374 - dense_16_accuracy: 0.2716 - dense_17_accuracy: 0.2200 - dense_18_accuracy: 0.2158 - dense_19_accuracy: 0.3324 - dense_20_accuracy: 0.3392 - dense_21_accuracy: 0.3398 - dense_22_accuracy: 0.3518\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 14.5479 - dense_13_loss: 1.3857 - dense_14_loss: 1.6180 - dense_15_loss: 1.3963 - dense_16_loss: 1.4923 - dense_17_loss: 1.6277 - dense_18_loss: 1.6121 - dense_19_loss: 1.4049 - dense_20_loss: 1.3280 - dense_21_loss: 1.3535 - dense_22_loss: 1.3295 - dense_13_accuracy: 0.3462 - dense_14_accuracy: 0.2362 - dense_15_accuracy: 0.3560 - dense_16_accuracy: 0.2716 - dense_17_accuracy: 0.2386 - dense_18_accuracy: 0.2342 - dense_19_accuracy: 0.3598 - dense_20_accuracy: 0.3650 - dense_21_accuracy: 0.3450 - dense_22_accuracy: 0.3650\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 14.0374 - dense_13_loss: 1.3305 - dense_14_loss: 1.5595 - dense_15_loss: 1.3556 - dense_16_loss: 1.4596 - dense_17_loss: 1.5661 - dense_18_loss: 1.5481 - dense_19_loss: 1.3517 - dense_20_loss: 1.2765 - dense_21_loss: 1.3012 - dense_22_loss: 1.2885 - dense_13_accuracy: 0.3482 - dense_14_accuracy: 0.2444 - dense_15_accuracy: 0.3580 - dense_16_accuracy: 0.2814 - dense_17_accuracy: 0.2386 - dense_18_accuracy: 0.2428 - dense_19_accuracy: 0.3602 - dense_20_accuracy: 0.3684 - dense_21_accuracy: 0.3560 - dense_22_accuracy: 0.3638\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 13.7919 - dense_13_loss: 1.3153 - dense_14_loss: 1.5323 - dense_15_loss: 1.3287 - dense_16_loss: 1.4425 - dense_17_loss: 1.5357 - dense_18_loss: 1.5211 - dense_19_loss: 1.3209 - dense_20_loss: 1.2494 - dense_21_loss: 1.2747 - dense_22_loss: 1.2714 - dense_13_accuracy: 0.3700 - dense_14_accuracy: 0.2446 - dense_15_accuracy: 0.3726 - dense_16_accuracy: 0.2852 - dense_17_accuracy: 0.2514 - dense_18_accuracy: 0.2476 - dense_19_accuracy: 0.3634 - dense_20_accuracy: 0.3700 - dense_21_accuracy: 0.3642 - dense_22_accuracy: 0.3748\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 13.6706 - dense_13_loss: 1.3075 - dense_14_loss: 1.5137 - dense_15_loss: 1.3220 - dense_16_loss: 1.4320 - dense_17_loss: 1.5217 - dense_18_loss: 1.5061 - dense_19_loss: 1.3098 - dense_20_loss: 1.2363 - dense_21_loss: 1.2625 - dense_22_loss: 1.2589 - dense_13_accuracy: 0.3582 - dense_14_accuracy: 0.2514 - dense_15_accuracy: 0.3672 - dense_16_accuracy: 0.2806 - dense_17_accuracy: 0.2484 - dense_18_accuracy: 0.2468 - dense_19_accuracy: 0.3688 - dense_20_accuracy: 0.3840 - dense_21_accuracy: 0.3650 - dense_22_accuracy: 0.3630\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 13.5905 - dense_13_loss: 1.3016 - dense_14_loss: 1.5035 - dense_15_loss: 1.3129 - dense_16_loss: 1.4251 - dense_17_loss: 1.5119 - dense_18_loss: 1.4979 - dense_19_loss: 1.3004 - dense_20_loss: 1.2265 - dense_21_loss: 1.2559 - dense_22_loss: 1.2548 - dense_13_accuracy: 0.3606 - dense_14_accuracy: 0.2550 - dense_15_accuracy: 0.3694 - dense_16_accuracy: 0.2806 - dense_17_accuracy: 0.2558 - dense_18_accuracy: 0.2586 - dense_19_accuracy: 0.3768 - dense_20_accuracy: 0.3844 - dense_21_accuracy: 0.3752 - dense_22_accuracy: 0.3764\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 13.5864 - dense_13_loss: 1.3030 - dense_14_loss: 1.5022 - dense_15_loss: 1.3126 - dense_16_loss: 1.4208 - dense_17_loss: 1.5113 - dense_18_loss: 1.4968 - dense_19_loss: 1.3021 - dense_20_loss: 1.2300 - dense_21_loss: 1.2531 - dense_22_loss: 1.2546 - dense_13_accuracy: 0.3658 - dense_14_accuracy: 0.2394 - dense_15_accuracy: 0.3748 - dense_16_accuracy: 0.2862 - dense_17_accuracy: 0.2424 - dense_18_accuracy: 0.2448 - dense_19_accuracy: 0.3674 - dense_20_accuracy: 0.3712 - dense_21_accuracy: 0.3616 - dense_22_accuracy: 0.3824\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 13.5851 - dense_13_loss: 1.3048 - dense_14_loss: 1.5050 - dense_15_loss: 1.3106 - dense_16_loss: 1.4189 - dense_17_loss: 1.5128 - dense_18_loss: 1.4961 - dense_19_loss: 1.3003 - dense_20_loss: 1.2279 - dense_21_loss: 1.2541 - dense_22_loss: 1.2546 - dense_13_accuracy: 0.3516 - dense_14_accuracy: 0.2594 - dense_15_accuracy: 0.3760 - dense_16_accuracy: 0.2910 - dense_17_accuracy: 0.2596 - dense_18_accuracy: 0.2594 - dense_19_accuracy: 0.3714 - dense_20_accuracy: 0.3836 - dense_21_accuracy: 0.3786 - dense_22_accuracy: 0.3786\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 13.4826 - dense_13_loss: 1.2946 - dense_14_loss: 1.4926 - dense_15_loss: 1.3007 - dense_16_loss: 1.4138 - dense_17_loss: 1.4998 - dense_18_loss: 1.4858 - dense_19_loss: 1.2866 - dense_20_loss: 1.2173 - dense_21_loss: 1.2431 - dense_22_loss: 1.2481 - dense_13_accuracy: 0.3632 - dense_14_accuracy: 0.2558 - dense_15_accuracy: 0.3722 - dense_16_accuracy: 0.2862 - dense_17_accuracy: 0.2588 - dense_18_accuracy: 0.2578 - dense_19_accuracy: 0.3804 - dense_20_accuracy: 0.3816 - dense_21_accuracy: 0.3720 - dense_22_accuracy: 0.3770\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D2AB74C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D2AB74C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D46BD948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D46BD948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - 2s 19ms/step - loss: 0.2484\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2430\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.2317\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2103\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1763\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1286\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0769\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0412\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0222\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0152\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D34F3A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D34F3A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - 9s 15ms/step - loss: 23.5884 - dense_26_loss: 2.0674 - dense_27_loss: 2.7791 - dense_28_loss: 2.2842 - dense_29_loss: 2.2233 - dense_30_loss: 2.7558 - dense_31_loss: 2.8136 - dense_32_loss: 2.3116 - dense_33_loss: 2.3253 - dense_34_loss: 2.1573 - dense_35_loss: 1.8706 - dense_26_accuracy: 0.2520 - dense_27_accuracy: 0.0920 - dense_28_accuracy: 0.1840 - dense_29_accuracy: 0.1360 - dense_30_accuracy: 0.1040 - dense_31_accuracy: 0.0910 - dense_32_accuracy: 0.1650 - dense_33_accuracy: 0.1760 - dense_34_accuracy: 0.2800 - dense_35_accuracy: 0.4080\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 19.7955 - dense_26_loss: 1.7312 - dense_27_loss: 2.2542 - dense_28_loss: 1.9388 - dense_29_loss: 1.9495 - dense_30_loss: 2.3308 - dense_31_loss: 2.3113 - dense_32_loss: 2.0410 - dense_33_loss: 2.0773 - dense_34_loss: 1.6625 - dense_35_loss: 1.4988 - dense_26_accuracy: 0.3190 - dense_27_accuracy: 0.1730 - dense_28_accuracy: 0.2860 - dense_29_accuracy: 0.2140 - dense_30_accuracy: 0.1590 - dense_31_accuracy: 0.1720 - dense_32_accuracy: 0.2370 - dense_33_accuracy: 0.2120 - dense_34_accuracy: 0.3830 - dense_35_accuracy: 0.4400\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 16.4621 - dense_26_loss: 1.5935 - dense_27_loss: 1.8357 - dense_28_loss: 1.5498 - dense_29_loss: 1.6805 - dense_30_loss: 1.8746 - dense_31_loss: 1.9027 - dense_32_loss: 1.6636 - dense_33_loss: 1.7974 - dense_34_loss: 1.2944 - dense_35_loss: 1.2700 - dense_26_accuracy: 0.3620 - dense_27_accuracy: 0.2350 - dense_28_accuracy: 0.3730 - dense_29_accuracy: 0.2400 - dense_30_accuracy: 0.2320 - dense_31_accuracy: 0.2320 - dense_32_accuracy: 0.2610 - dense_33_accuracy: 0.2270 - dense_34_accuracy: 0.4910 - dense_35_accuracy: 0.5180\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 15.6548 - dense_26_loss: 1.4926 - dense_27_loss: 1.7440 - dense_28_loss: 1.5080 - dense_29_loss: 1.6322 - dense_30_loss: 1.7814 - dense_31_loss: 1.8049 - dense_32_loss: 1.5931 - dense_33_loss: 1.6659 - dense_34_loss: 1.2134 - dense_35_loss: 1.2193 - dense_26_accuracy: 0.3610 - dense_27_accuracy: 0.2230 - dense_28_accuracy: 0.3830 - dense_29_accuracy: 0.2380 - dense_30_accuracy: 0.2450 - dense_31_accuracy: 0.2350 - dense_32_accuracy: 0.2680 - dense_33_accuracy: 0.2340 - dense_34_accuracy: 0.5130 - dense_35_accuracy: 0.5160\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 15.3073 - dense_26_loss: 1.4566 - dense_27_loss: 1.6866 - dense_28_loss: 1.4556 - dense_29_loss: 1.6118 - dense_30_loss: 1.7447 - dense_31_loss: 1.7607 - dense_32_loss: 1.5743 - dense_33_loss: 1.6278 - dense_34_loss: 1.1894 - dense_35_loss: 1.1998 - dense_26_accuracy: 0.3650 - dense_27_accuracy: 0.2360 - dense_28_accuracy: 0.3620 - dense_29_accuracy: 0.2440 - dense_30_accuracy: 0.2270 - dense_31_accuracy: 0.2310 - dense_32_accuracy: 0.2660 - dense_33_accuracy: 0.2510 - dense_34_accuracy: 0.5140 - dense_35_accuracy: 0.5310\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 14.8950 - dense_26_loss: 1.4109 - dense_27_loss: 1.6302 - dense_28_loss: 1.4283 - dense_29_loss: 1.5973 - dense_30_loss: 1.6906 - dense_31_loss: 1.7057 - dense_32_loss: 1.5207 - dense_33_loss: 1.5837 - dense_34_loss: 1.1546 - dense_35_loss: 1.1731 - dense_26_accuracy: 0.3780 - dense_27_accuracy: 0.2710 - dense_28_accuracy: 0.3660 - dense_29_accuracy: 0.2410 - dense_30_accuracy: 0.2630 - dense_31_accuracy: 0.2560 - dense_32_accuracy: 0.3130 - dense_33_accuracy: 0.2510 - dense_34_accuracy: 0.5210 - dense_35_accuracy: 0.5430\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 14.7730 - dense_26_loss: 1.4023 - dense_27_loss: 1.6148 - dense_28_loss: 1.4217 - dense_29_loss: 1.5766 - dense_30_loss: 1.6788 - dense_31_loss: 1.6921 - dense_32_loss: 1.5110 - dense_33_loss: 1.5792 - dense_34_loss: 1.1506 - dense_35_loss: 1.1458 - dense_26_accuracy: 0.3740 - dense_27_accuracy: 0.2530 - dense_28_accuracy: 0.3880 - dense_29_accuracy: 0.2670 - dense_30_accuracy: 0.2450 - dense_31_accuracy: 0.2420 - dense_32_accuracy: 0.3110 - dense_33_accuracy: 0.2530 - dense_34_accuracy: 0.4860 - dense_35_accuracy: 0.5540\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 14.5241 - dense_26_loss: 1.3919 - dense_27_loss: 1.5809 - dense_28_loss: 1.4102 - dense_29_loss: 1.5406 - dense_30_loss: 1.6501 - dense_31_loss: 1.6599 - dense_32_loss: 1.4875 - dense_33_loss: 1.5505 - dense_34_loss: 1.1206 - dense_35_loss: 1.1320 - dense_26_accuracy: 0.3910 - dense_27_accuracy: 0.2920 - dense_28_accuracy: 0.3950 - dense_29_accuracy: 0.3090 - dense_30_accuracy: 0.2630 - dense_31_accuracy: 0.2760 - dense_32_accuracy: 0.3560 - dense_33_accuracy: 0.2960 - dense_34_accuracy: 0.5310 - dense_35_accuracy: 0.5500\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 14.3695 - dense_26_loss: 1.3686 - dense_27_loss: 1.5710 - dense_28_loss: 1.3998 - dense_29_loss: 1.5263 - dense_30_loss: 1.6352 - dense_31_loss: 1.6464 - dense_32_loss: 1.4629 - dense_33_loss: 1.5351 - dense_34_loss: 1.1191 - dense_35_loss: 1.1049 - dense_26_accuracy: 0.4070 - dense_27_accuracy: 0.2790 - dense_28_accuracy: 0.4080 - dense_29_accuracy: 0.3010 - dense_30_accuracy: 0.2830 - dense_31_accuracy: 0.2860 - dense_32_accuracy: 0.3390 - dense_33_accuracy: 0.2910 - dense_34_accuracy: 0.5100 - dense_35_accuracy: 0.5600\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 14.3198 - dense_26_loss: 1.3765 - dense_27_loss: 1.5628 - dense_28_loss: 1.3960 - dense_29_loss: 1.5193 - dense_30_loss: 1.6313 - dense_31_loss: 1.6346 - dense_32_loss: 1.4583 - dense_33_loss: 1.5296 - dense_34_loss: 1.1135 - dense_35_loss: 1.0978 - dense_26_accuracy: 0.4080 - dense_27_accuracy: 0.2960 - dense_28_accuracy: 0.4080 - dense_29_accuracy: 0.3120 - dense_30_accuracy: 0.2880 - dense_31_accuracy: 0.2900 - dense_32_accuracy: 0.3530 - dense_33_accuracy: 0.3160 - dense_34_accuracy: 0.5170 - dense_35_accuracy: 0.5550\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D3AEAE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D3AEAE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D45A4F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D45A4F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - 11s 30ms/step - loss: 22.9050 - dense_36_loss: 2.0426 - dense_37_loss: 2.6783 - dense_38_loss: 2.1518 - dense_39_loss: 2.1685 - dense_40_loss: 2.7012 - dense_41_loss: 2.7144 - dense_42_loss: 2.2686 - dense_43_loss: 2.2859 - dense_44_loss: 2.0448 - dense_45_loss: 1.8487 - dense_36_accuracy: 0.2340 - dense_37_accuracy: 0.1290 - dense_38_accuracy: 0.2170 - dense_39_accuracy: 0.1650 - dense_40_accuracy: 0.1120 - dense_41_accuracy: 0.1170 - dense_42_accuracy: 0.1370 - dense_43_accuracy: 0.1870 - dense_44_accuracy: 0.3520 - dense_45_accuracy: 0.4010\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 17.3094 - dense_36_loss: 1.6398 - dense_37_loss: 1.9713 - dense_38_loss: 1.6250 - dense_39_loss: 1.7559 - dense_40_loss: 2.0125 - dense_41_loss: 2.0088 - dense_42_loss: 1.7328 - dense_43_loss: 1.8477 - dense_44_loss: 1.3806 - dense_45_loss: 1.3347 - dense_36_accuracy: 0.3500 - dense_37_accuracy: 0.2120 - dense_38_accuracy: 0.3710 - dense_39_accuracy: 0.2130 - dense_40_accuracy: 0.1970 - dense_41_accuracy: 0.2180 - dense_42_accuracy: 0.2220 - dense_43_accuracy: 0.2370 - dense_44_accuracy: 0.4770 - dense_45_accuracy: 0.5190\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 15.8683 - dense_36_loss: 1.5192 - dense_37_loss: 1.7607 - dense_38_loss: 1.5063 - dense_39_loss: 1.6715 - dense_40_loss: 1.8068 - dense_41_loss: 1.8256 - dense_42_loss: 1.6144 - dense_43_loss: 1.7139 - dense_44_loss: 1.2276 - dense_45_loss: 1.2223 - dense_36_accuracy: 0.3530 - dense_37_accuracy: 0.2050 - dense_38_accuracy: 0.3690 - dense_39_accuracy: 0.2150 - dense_40_accuracy: 0.2090 - dense_41_accuracy: 0.2210 - dense_42_accuracy: 0.2690 - dense_43_accuracy: 0.2180 - dense_44_accuracy: 0.4890 - dense_45_accuracy: 0.5210\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 15.2419 - dense_36_loss: 1.4569 - dense_37_loss: 1.6786 - dense_38_loss: 1.4654 - dense_39_loss: 1.6120 - dense_40_loss: 1.7276 - dense_41_loss: 1.7393 - dense_42_loss: 1.5476 - dense_43_loss: 1.6275 - dense_44_loss: 1.1873 - dense_45_loss: 1.1998 - dense_36_accuracy: 0.3540 - dense_37_accuracy: 0.2500 - dense_38_accuracy: 0.3840 - dense_39_accuracy: 0.2580 - dense_40_accuracy: 0.2540 - dense_41_accuracy: 0.2430 - dense_42_accuracy: 0.2910 - dense_43_accuracy: 0.2540 - dense_44_accuracy: 0.5120 - dense_45_accuracy: 0.5370\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 14.9219 - dense_36_loss: 1.4161 - dense_37_loss: 1.6296 - dense_38_loss: 1.4392 - dense_39_loss: 1.5877 - dense_40_loss: 1.6967 - dense_41_loss: 1.6965 - dense_42_loss: 1.5368 - dense_43_loss: 1.5944 - dense_44_loss: 1.1497 - dense_45_loss: 1.1751 - dense_36_accuracy: 0.3620 - dense_37_accuracy: 0.2460 - dense_38_accuracy: 0.3920 - dense_39_accuracy: 0.2560 - dense_40_accuracy: 0.2430 - dense_41_accuracy: 0.2610 - dense_42_accuracy: 0.2810 - dense_43_accuracy: 0.2290 - dense_44_accuracy: 0.5150 - dense_45_accuracy: 0.5280\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 14.7199 - dense_36_loss: 1.3993 - dense_37_loss: 1.6081 - dense_38_loss: 1.4310 - dense_39_loss: 1.5701 - dense_40_loss: 1.6710 - dense_41_loss: 1.6816 - dense_42_loss: 1.5004 - dense_43_loss: 1.5680 - dense_44_loss: 1.1360 - dense_45_loss: 1.1545 - dense_36_accuracy: 0.3730 - dense_37_accuracy: 0.2560 - dense_38_accuracy: 0.3770 - dense_39_accuracy: 0.2470 - dense_40_accuracy: 0.2380 - dense_41_accuracy: 0.2510 - dense_42_accuracy: 0.3080 - dense_43_accuracy: 0.2560 - dense_44_accuracy: 0.5060 - dense_45_accuracy: 0.5250\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 14.7587 - dense_36_loss: 1.4082 - dense_37_loss: 1.6089 - dense_38_loss: 1.4376 - dense_39_loss: 1.5669 - dense_40_loss: 1.6711 - dense_41_loss: 1.6922 - dense_42_loss: 1.5080 - dense_43_loss: 1.5723 - dense_44_loss: 1.1394 - dense_45_loss: 1.1541 - dense_36_accuracy: 0.3820 - dense_37_accuracy: 0.2460 - dense_38_accuracy: 0.3720 - dense_39_accuracy: 0.2430 - dense_40_accuracy: 0.2500 - dense_41_accuracy: 0.2470 - dense_42_accuracy: 0.3040 - dense_43_accuracy: 0.2440 - dense_44_accuracy: 0.5140 - dense_45_accuracy: 0.5270\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 14.7425 - dense_36_loss: 1.4085 - dense_37_loss: 1.6165 - dense_38_loss: 1.4294 - dense_39_loss: 1.5711 - dense_40_loss: 1.6765 - dense_41_loss: 1.6850 - dense_42_loss: 1.5075 - dense_43_loss: 1.5708 - dense_44_loss: 1.1348 - dense_45_loss: 1.1424 - dense_36_accuracy: 0.3600 - dense_37_accuracy: 0.2260 - dense_38_accuracy: 0.3650 - dense_39_accuracy: 0.2520 - dense_40_accuracy: 0.2440 - dense_41_accuracy: 0.2400 - dense_42_accuracy: 0.2710 - dense_43_accuracy: 0.2360 - dense_44_accuracy: 0.5050 - dense_45_accuracy: 0.5330\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 14.6713 - dense_36_loss: 1.4049 - dense_37_loss: 1.6146 - dense_38_loss: 1.4194 - dense_39_loss: 1.5552 - dense_40_loss: 1.6667 - dense_41_loss: 1.6704 - dense_42_loss: 1.5045 - dense_43_loss: 1.5708 - dense_44_loss: 1.1412 - dense_45_loss: 1.1236 - dense_36_accuracy: 0.3790 - dense_37_accuracy: 0.2350 - dense_38_accuracy: 0.3750 - dense_39_accuracy: 0.2490 - dense_40_accuracy: 0.2430 - dense_41_accuracy: 0.2550 - dense_42_accuracy: 0.2930 - dense_43_accuracy: 0.2610 - dense_44_accuracy: 0.4900 - dense_45_accuracy: 0.5520\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 14.4993 - dense_36_loss: 1.3852 - dense_37_loss: 1.5894 - dense_38_loss: 1.4045 - dense_39_loss: 1.5433 - dense_40_loss: 1.6512 - dense_41_loss: 1.6552 - dense_42_loss: 1.4920 - dense_43_loss: 1.5502 - dense_44_loss: 1.1172 - dense_45_loss: 1.1112 - dense_36_accuracy: 0.3920 - dense_37_accuracy: 0.2710 - dense_38_accuracy: 0.4000 - dense_39_accuracy: 0.2730 - dense_40_accuracy: 0.2660 - dense_41_accuracy: 0.2810 - dense_42_accuracy: 0.3130 - dense_43_accuracy: 0.2740 - dense_44_accuracy: 0.5210 - dense_45_accuracy: 0.5540\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D46408B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D46408B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4B57708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4B57708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 19ms/step - loss: 0.2485\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2428\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2308\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2082\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1686\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1161\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0656\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0329\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0192\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0131\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3AEADC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3AEADC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - 9s 18ms/step - loss: 23.6119 - dense_49_loss: 2.0029 - dense_50_loss: 2.7771 - dense_51_loss: 2.2845 - dense_52_loss: 2.2705 - dense_53_loss: 2.7686 - dense_54_loss: 2.7927 - dense_55_loss: 2.3880 - dense_56_loss: 2.3282 - dense_57_loss: 2.0957 - dense_58_loss: 1.9037 - dense_49_accuracy: 0.2680 - dense_50_accuracy: 0.0970 - dense_51_accuracy: 0.2300 - dense_52_accuracy: 0.1460 - dense_53_accuracy: 0.1110 - dense_54_accuracy: 0.1110 - dense_55_accuracy: 0.1740 - dense_56_accuracy: 0.1850 - dense_57_accuracy: 0.3210 - dense_58_accuracy: 0.4070\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 18.7521 - dense_49_loss: 1.7011 - dense_50_loss: 2.1662 - dense_51_loss: 1.7388 - dense_52_loss: 1.9313 - dense_53_loss: 2.1620 - dense_54_loss: 2.2385 - dense_55_loss: 1.9305 - dense_56_loss: 1.9990 - dense_57_loss: 1.4576 - dense_58_loss: 1.4270 - dense_49_accuracy: 0.2940 - dense_50_accuracy: 0.1910 - dense_51_accuracy: 0.3570 - dense_52_accuracy: 0.2140 - dense_53_accuracy: 0.2020 - dense_54_accuracy: 0.1890 - dense_55_accuracy: 0.2080 - dense_56_accuracy: 0.1880 - dense_57_accuracy: 0.4720 - dense_58_accuracy: 0.4850\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 16.5563 - dense_49_loss: 1.5094 - dense_50_loss: 1.8490 - dense_51_loss: 1.5973 - dense_52_loss: 1.7505 - dense_53_loss: 1.8276 - dense_54_loss: 1.9818 - dense_55_loss: 1.7151 - dense_56_loss: 1.7678 - dense_57_loss: 1.2928 - dense_58_loss: 1.2651 - dense_49_accuracy: 0.3590 - dense_50_accuracy: 0.2070 - dense_51_accuracy: 0.3570 - dense_52_accuracy: 0.2590 - dense_53_accuracy: 0.2270 - dense_54_accuracy: 0.2170 - dense_55_accuracy: 0.2310 - dense_56_accuracy: 0.2570 - dense_57_accuracy: 0.4930 - dense_58_accuracy: 0.5030\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 15.7144 - dense_49_loss: 1.4211 - dense_50_loss: 1.7594 - dense_51_loss: 1.5218 - dense_52_loss: 1.6492 - dense_53_loss: 1.7195 - dense_54_loss: 1.8972 - dense_55_loss: 1.6593 - dense_56_loss: 1.6636 - dense_57_loss: 1.2026 - dense_58_loss: 1.2207 - dense_49_accuracy: 0.3860 - dense_50_accuracy: 0.2210 - dense_51_accuracy: 0.3600 - dense_52_accuracy: 0.2680 - dense_53_accuracy: 0.2420 - dense_54_accuracy: 0.2300 - dense_55_accuracy: 0.2540 - dense_56_accuracy: 0.2460 - dense_57_accuracy: 0.5050 - dense_58_accuracy: 0.5010\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 15.4513 - dense_49_loss: 1.3925 - dense_50_loss: 1.7198 - dense_51_loss: 1.4966 - dense_52_loss: 1.6573 - dense_53_loss: 1.6799 - dense_54_loss: 1.8609 - dense_55_loss: 1.6305 - dense_56_loss: 1.6404 - dense_57_loss: 1.1781 - dense_58_loss: 1.1953 - dense_49_accuracy: 0.3750 - dense_50_accuracy: 0.2340 - dense_51_accuracy: 0.3510 - dense_52_accuracy: 0.2510 - dense_53_accuracy: 0.2440 - dense_54_accuracy: 0.2210 - dense_55_accuracy: 0.2650 - dense_56_accuracy: 0.2420 - dense_57_accuracy: 0.5040 - dense_58_accuracy: 0.5390\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 15.2055 - dense_49_loss: 1.3751 - dense_50_loss: 1.6910 - dense_51_loss: 1.4704 - dense_52_loss: 1.6235 - dense_53_loss: 1.6681 - dense_54_loss: 1.8295 - dense_55_loss: 1.6057 - dense_56_loss: 1.6121 - dense_57_loss: 1.1628 - dense_58_loss: 1.1673 - dense_49_accuracy: 0.3890 - dense_50_accuracy: 0.2470 - dense_51_accuracy: 0.3650 - dense_52_accuracy: 0.2700 - dense_53_accuracy: 0.2210 - dense_54_accuracy: 0.2130 - dense_55_accuracy: 0.2740 - dense_56_accuracy: 0.2420 - dense_57_accuracy: 0.4930 - dense_58_accuracy: 0.5270\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 15.0386 - dense_49_loss: 1.3598 - dense_50_loss: 1.6787 - dense_51_loss: 1.4595 - dense_52_loss: 1.6005 - dense_53_loss: 1.6472 - dense_54_loss: 1.8139 - dense_55_loss: 1.5797 - dense_56_loss: 1.5916 - dense_57_loss: 1.1495 - dense_58_loss: 1.1582 - dense_49_accuracy: 0.3970 - dense_50_accuracy: 0.2530 - dense_51_accuracy: 0.3860 - dense_52_accuracy: 0.2540 - dense_53_accuracy: 0.2670 - dense_54_accuracy: 0.2340 - dense_55_accuracy: 0.2960 - dense_56_accuracy: 0.2720 - dense_57_accuracy: 0.4990 - dense_58_accuracy: 0.5330\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 14.9388 - dense_49_loss: 1.3679 - dense_50_loss: 1.6633 - dense_51_loss: 1.4502 - dense_52_loss: 1.5892 - dense_53_loss: 1.6368 - dense_54_loss: 1.7968 - dense_55_loss: 1.5734 - dense_56_loss: 1.5808 - dense_57_loss: 1.1421 - dense_58_loss: 1.1385 - dense_49_accuracy: 0.3830 - dense_50_accuracy: 0.2480 - dense_51_accuracy: 0.3680 - dense_52_accuracy: 0.2800 - dense_53_accuracy: 0.2430 - dense_54_accuracy: 0.2200 - dense_55_accuracy: 0.2930 - dense_56_accuracy: 0.2540 - dense_57_accuracy: 0.5000 - dense_58_accuracy: 0.5350\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 14.8202 - dense_49_loss: 1.3562 - dense_50_loss: 1.6547 - dense_51_loss: 1.4344 - dense_52_loss: 1.5821 - dense_53_loss: 1.6107 - dense_54_loss: 1.7892 - dense_55_loss: 1.5675 - dense_56_loss: 1.5646 - dense_57_loss: 1.1352 - dense_58_loss: 1.1255 - dense_49_accuracy: 0.3870 - dense_50_accuracy: 0.2500 - dense_51_accuracy: 0.3820 - dense_52_accuracy: 0.3010 - dense_53_accuracy: 0.2710 - dense_54_accuracy: 0.2420 - dense_55_accuracy: 0.3250 - dense_56_accuracy: 0.2850 - dense_57_accuracy: 0.5270 - dense_58_accuracy: 0.5280\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 14.7175 - dense_49_loss: 1.3609 - dense_50_loss: 1.6374 - dense_51_loss: 1.4151 - dense_52_loss: 1.5687 - dense_53_loss: 1.6114 - dense_54_loss: 1.7691 - dense_55_loss: 1.5499 - dense_56_loss: 1.5574 - dense_57_loss: 1.1211 - dense_58_loss: 1.1264 - dense_49_accuracy: 0.4000 - dense_50_accuracy: 0.2590 - dense_51_accuracy: 0.3920 - dense_52_accuracy: 0.2930 - dense_53_accuracy: 0.2720 - dense_54_accuracy: 0.2650 - dense_55_accuracy: 0.3240 - dense_56_accuracy: 0.2870 - dense_57_accuracy: 0.5180 - dense_58_accuracy: 0.5300\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D3212D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D3212D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D2D375E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D2D375E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - 10s 27ms/step - loss: 23.1878 - dense_59_loss: 2.0482 - dense_60_loss: 2.6822 - dense_61_loss: 2.2261 - dense_62_loss: 2.2222 - dense_63_loss: 2.6912 - dense_64_loss: 2.7421 - dense_65_loss: 2.3012 - dense_66_loss: 2.3028 - dense_67_loss: 2.1427 - dense_68_loss: 1.8289 - dense_59_accuracy: 0.2560 - dense_60_accuracy: 0.1210 - dense_61_accuracy: 0.2470 - dense_62_accuracy: 0.1490 - dense_63_accuracy: 0.1020 - dense_64_accuracy: 0.1240 - dense_65_accuracy: 0.1560 - dense_66_accuracy: 0.1700 - dense_67_accuracy: 0.3340 - dense_68_accuracy: 0.3840\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 17.9618 - dense_59_loss: 1.6061 - dense_60_loss: 2.0592 - dense_61_loss: 1.7128 - dense_62_loss: 1.8402 - dense_63_loss: 2.0443 - dense_64_loss: 2.1987 - dense_65_loss: 1.8462 - dense_66_loss: 1.9128 - dense_67_loss: 1.4143 - dense_68_loss: 1.3273 - dense_59_accuracy: 0.3370 - dense_60_accuracy: 0.1780 - dense_61_accuracy: 0.3080 - dense_62_accuracy: 0.2200 - dense_63_accuracy: 0.2010 - dense_64_accuracy: 0.2000 - dense_65_accuracy: 0.2520 - dense_66_accuracy: 0.2150 - dense_67_accuracy: 0.4790 - dense_68_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 16.4389 - dense_59_loss: 1.4842 - dense_60_loss: 1.8489 - dense_61_loss: 1.5853 - dense_62_loss: 1.7184 - dense_63_loss: 1.8111 - dense_64_loss: 1.9905 - dense_65_loss: 1.7146 - dense_66_loss: 1.7490 - dense_67_loss: 1.2871 - dense_68_loss: 1.2498 - dense_59_accuracy: 0.3540 - dense_60_accuracy: 0.2160 - dense_61_accuracy: 0.3610 - dense_62_accuracy: 0.2310 - dense_63_accuracy: 0.2290 - dense_64_accuracy: 0.1890 - dense_65_accuracy: 0.2120 - dense_66_accuracy: 0.2360 - dense_67_accuracy: 0.4970 - dense_68_accuracy: 0.5120\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 15.9041 - dense_59_loss: 1.4459 - dense_60_loss: 1.7909 - dense_61_loss: 1.5418 - dense_62_loss: 1.6610 - dense_63_loss: 1.7524 - dense_64_loss: 1.9100 - dense_65_loss: 1.6569 - dense_66_loss: 1.6865 - dense_67_loss: 1.2325 - dense_68_loss: 1.2263 - dense_59_accuracy: 0.3830 - dense_60_accuracy: 0.2320 - dense_61_accuracy: 0.3680 - dense_62_accuracy: 0.2660 - dense_63_accuracy: 0.2140 - dense_64_accuracy: 0.2220 - dense_65_accuracy: 0.2650 - dense_66_accuracy: 0.2300 - dense_67_accuracy: 0.4930 - dense_68_accuracy: 0.5080\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 15.5733 - dense_59_loss: 1.4084 - dense_60_loss: 1.7483 - dense_61_loss: 1.5039 - dense_62_loss: 1.6519 - dense_63_loss: 1.6999 - dense_64_loss: 1.8736 - dense_65_loss: 1.6413 - dense_66_loss: 1.6463 - dense_67_loss: 1.2030 - dense_68_loss: 1.1968 - dense_59_accuracy: 0.3880 - dense_60_accuracy: 0.2360 - dense_61_accuracy: 0.3580 - dense_62_accuracy: 0.2500 - dense_63_accuracy: 0.2440 - dense_64_accuracy: 0.2300 - dense_65_accuracy: 0.2620 - dense_66_accuracy: 0.2230 - dense_67_accuracy: 0.4810 - dense_68_accuracy: 0.4960\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 15.3493 - dense_59_loss: 1.3859 - dense_60_loss: 1.7067 - dense_61_loss: 1.4842 - dense_62_loss: 1.6342 - dense_63_loss: 1.6844 - dense_64_loss: 1.8506 - dense_65_loss: 1.6128 - dense_66_loss: 1.6271 - dense_67_loss: 1.1843 - dense_68_loss: 1.1791 - dense_59_accuracy: 0.3830 - dense_60_accuracy: 0.2410 - dense_61_accuracy: 0.3690 - dense_62_accuracy: 0.2600 - dense_63_accuracy: 0.2560 - dense_64_accuracy: 0.2230 - dense_65_accuracy: 0.2700 - dense_66_accuracy: 0.2600 - dense_67_accuracy: 0.5070 - dense_68_accuracy: 0.5250\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 15.2051 - dense_59_loss: 1.3773 - dense_60_loss: 1.6964 - dense_61_loss: 1.4613 - dense_62_loss: 1.6306 - dense_63_loss: 1.6654 - dense_64_loss: 1.8297 - dense_65_loss: 1.6044 - dense_66_loss: 1.6143 - dense_67_loss: 1.1639 - dense_68_loss: 1.1619 - dense_59_accuracy: 0.3660 - dense_60_accuracy: 0.2170 - dense_61_accuracy: 0.3590 - dense_62_accuracy: 0.2230 - dense_63_accuracy: 0.2270 - dense_64_accuracy: 0.2020 - dense_65_accuracy: 0.2590 - dense_66_accuracy: 0.2120 - dense_67_accuracy: 0.4960 - dense_68_accuracy: 0.5270\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 15.1382 - dense_59_loss: 1.3694 - dense_60_loss: 1.6834 - dense_61_loss: 1.4601 - dense_62_loss: 1.6225 - dense_63_loss: 1.6571 - dense_64_loss: 1.8161 - dense_65_loss: 1.5951 - dense_66_loss: 1.6185 - dense_67_loss: 1.1589 - dense_68_loss: 1.1570 - dense_59_accuracy: 0.3740 - dense_60_accuracy: 0.2350 - dense_61_accuracy: 0.3630 - dense_62_accuracy: 0.2330 - dense_63_accuracy: 0.2370 - dense_64_accuracy: 0.2310 - dense_65_accuracy: 0.2570 - dense_66_accuracy: 0.2410 - dense_67_accuracy: 0.4860 - dense_68_accuracy: 0.5190\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 15.1421 - dense_59_loss: 1.3719 - dense_60_loss: 1.6891 - dense_61_loss: 1.4733 - dense_62_loss: 1.6144 - dense_63_loss: 1.6473 - dense_64_loss: 1.8210 - dense_65_loss: 1.6067 - dense_66_loss: 1.6150 - dense_67_loss: 1.1661 - dense_68_loss: 1.1372 - dense_59_accuracy: 0.3790 - dense_60_accuracy: 0.2310 - dense_61_accuracy: 0.3600 - dense_62_accuracy: 0.2540 - dense_63_accuracy: 0.2590 - dense_64_accuracy: 0.2200 - dense_65_accuracy: 0.2700 - dense_66_accuracy: 0.2240 - dense_67_accuracy: 0.4950 - dense_68_accuracy: 0.5240\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 14.9522 - dense_59_loss: 1.3590 - dense_60_loss: 1.6615 - dense_61_loss: 1.4498 - dense_62_loss: 1.5948 - dense_63_loss: 1.6367 - dense_64_loss: 1.8009 - dense_65_loss: 1.5750 - dense_66_loss: 1.5940 - dense_67_loss: 1.1458 - dense_68_loss: 1.1348 - dense_59_accuracy: 0.3920 - dense_60_accuracy: 0.2290 - dense_61_accuracy: 0.3690 - dense_62_accuracy: 0.2360 - dense_63_accuracy: 0.2600 - dense_64_accuracy: 0.2130 - dense_65_accuracy: 0.2770 - dense_66_accuracy: 0.2320 - dense_67_accuracy: 0.5000 - dense_68_accuracy: 0.5270\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D3B12048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D3B12048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D2F198B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D2F198B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 21ms/step - loss: 0.2493\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2473\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2445\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2402\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.2335\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.2253\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2121\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1954\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1739\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1480\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D2758B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D2758B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "8/8 [==============================] - 9s 19ms/step - loss: 24.9159 - dense_72_loss: 2.4878 - dense_73_loss: 2.4099 - dense_74_loss: 2.4368 - dense_75_loss: 2.3667 - dense_76_loss: 2.9408 - dense_77_loss: 2.5555 - dense_78_loss: 2.5782 - dense_79_loss: 2.4005 - dense_80_loss: 2.2047 - dense_81_loss: 2.5350 - dense_72_accuracy: 0.1320 - dense_73_accuracy: 0.1040 - dense_74_accuracy: 0.1420 - dense_75_accuracy: 0.2100 - dense_76_accuracy: 0.1120 - dense_77_accuracy: 0.0700 - dense_78_accuracy: 0.0880 - dense_79_accuracy: 0.1780 - dense_80_accuracy: 0.1620 - dense_81_accuracy: 0.1200\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 23.4580 - dense_72_loss: 2.3044 - dense_73_loss: 2.2707 - dense_74_loss: 2.2788 - dense_75_loss: 2.2033 - dense_76_loss: 2.8167 - dense_77_loss: 2.4703 - dense_78_loss: 2.4202 - dense_79_loss: 2.2538 - dense_80_loss: 2.0209 - dense_81_loss: 2.4190 - dense_72_accuracy: 0.1740 - dense_73_accuracy: 0.2060 - dense_74_accuracy: 0.1680 - dense_75_accuracy: 0.2260 - dense_76_accuracy: 0.0920 - dense_77_accuracy: 0.1640 - dense_78_accuracy: 0.1600 - dense_79_accuracy: 0.1700 - dense_80_accuracy: 0.1900 - dense_81_accuracy: 0.1400\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 22.1136 - dense_72_loss: 2.1399 - dense_73_loss: 2.1269 - dense_74_loss: 2.1695 - dense_75_loss: 2.0821 - dense_76_loss: 2.6165 - dense_77_loss: 2.3612 - dense_78_loss: 2.2821 - dense_79_loss: 2.1153 - dense_80_loss: 1.8831 - dense_81_loss: 2.3370 - dense_72_accuracy: 0.2440 - dense_73_accuracy: 0.2360 - dense_74_accuracy: 0.1900 - dense_75_accuracy: 0.2620 - dense_76_accuracy: 0.1480 - dense_77_accuracy: 0.1460 - dense_78_accuracy: 0.1600 - dense_79_accuracy: 0.2520 - dense_80_accuracy: 0.2380 - dense_81_accuracy: 0.1360\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 20.6908 - dense_72_loss: 2.0060 - dense_73_loss: 1.9950 - dense_74_loss: 2.0212 - dense_75_loss: 1.9358 - dense_76_loss: 2.4381 - dense_77_loss: 2.2111 - dense_78_loss: 2.1885 - dense_79_loss: 1.9618 - dense_80_loss: 1.7781 - dense_81_loss: 2.1553 - dense_72_accuracy: 0.3280 - dense_73_accuracy: 0.2520 - dense_74_accuracy: 0.2560 - dense_75_accuracy: 0.3360 - dense_76_accuracy: 0.1600 - dense_77_accuracy: 0.1520 - dense_78_accuracy: 0.1780 - dense_79_accuracy: 0.3020 - dense_80_accuracy: 0.3540 - dense_81_accuracy: 0.2320\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 19.8102 - dense_72_loss: 1.9150 - dense_73_loss: 1.9093 - dense_74_loss: 1.9560 - dense_75_loss: 1.8548 - dense_76_loss: 2.3002 - dense_77_loss: 2.0956 - dense_78_loss: 2.1101 - dense_79_loss: 1.8595 - dense_80_loss: 1.7379 - dense_81_loss: 2.0717 - dense_72_accuracy: 0.3140 - dense_73_accuracy: 0.2960 - dense_74_accuracy: 0.2400 - dense_75_accuracy: 0.3120 - dense_76_accuracy: 0.2220 - dense_77_accuracy: 0.1880 - dense_78_accuracy: 0.2100 - dense_79_accuracy: 0.2980 - dense_80_accuracy: 0.3560 - dense_81_accuracy: 0.2240\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 19.2422 - dense_72_loss: 1.8430 - dense_73_loss: 1.8553 - dense_74_loss: 1.8958 - dense_75_loss: 1.8117 - dense_76_loss: 2.2162 - dense_77_loss: 2.0436 - dense_78_loss: 2.0657 - dense_79_loss: 1.7959 - dense_80_loss: 1.7105 - dense_81_loss: 2.0045 - dense_72_accuracy: 0.3600 - dense_73_accuracy: 0.2980 - dense_74_accuracy: 0.3020 - dense_75_accuracy: 0.3300 - dense_76_accuracy: 0.2160 - dense_77_accuracy: 0.2020 - dense_78_accuracy: 0.2300 - dense_79_accuracy: 0.2900 - dense_80_accuracy: 0.3480 - dense_81_accuracy: 0.2540\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 18.6520 - dense_72_loss: 1.7542 - dense_73_loss: 1.7810 - dense_74_loss: 1.8635 - dense_75_loss: 1.7664 - dense_76_loss: 2.1220 - dense_77_loss: 1.9792 - dense_78_loss: 2.0206 - dense_79_loss: 1.7404 - dense_80_loss: 1.6727 - dense_81_loss: 1.9521 - dense_72_accuracy: 0.3680 - dense_73_accuracy: 0.3340 - dense_74_accuracy: 0.2700 - dense_75_accuracy: 0.3340 - dense_76_accuracy: 0.2380 - dense_77_accuracy: 0.1980 - dense_78_accuracy: 0.2140 - dense_79_accuracy: 0.3220 - dense_80_accuracy: 0.3500 - dense_81_accuracy: 0.2740\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 17.8231 - dense_72_loss: 1.6585 - dense_73_loss: 1.6739 - dense_74_loss: 1.7994 - dense_75_loss: 1.7081 - dense_76_loss: 2.0036 - dense_77_loss: 1.8940 - dense_78_loss: 1.9284 - dense_79_loss: 1.6904 - dense_80_loss: 1.6225 - dense_81_loss: 1.8444 - dense_72_accuracy: 0.3700 - dense_73_accuracy: 0.3180 - dense_74_accuracy: 0.2900 - dense_75_accuracy: 0.3300 - dense_76_accuracy: 0.2660 - dense_77_accuracy: 0.2800 - dense_78_accuracy: 0.2560 - dense_79_accuracy: 0.3300 - dense_80_accuracy: 0.3680 - dense_81_accuracy: 0.3160\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 16.9198 - dense_72_loss: 1.5459 - dense_73_loss: 1.5849 - dense_74_loss: 1.7251 - dense_75_loss: 1.6198 - dense_76_loss: 1.8958 - dense_77_loss: 1.7858 - dense_78_loss: 1.8079 - dense_79_loss: 1.6361 - dense_80_loss: 1.5620 - dense_81_loss: 1.7565 - dense_72_accuracy: 0.3500 - dense_73_accuracy: 0.3740 - dense_74_accuracy: 0.3120 - dense_75_accuracy: 0.3200 - dense_76_accuracy: 0.2780 - dense_77_accuracy: 0.2780 - dense_78_accuracy: 0.3020 - dense_79_accuracy: 0.3200 - dense_80_accuracy: 0.3520 - dense_81_accuracy: 0.3100\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 16.4096 - dense_72_loss: 1.5088 - dense_73_loss: 1.5281 - dense_74_loss: 1.6774 - dense_75_loss: 1.5753 - dense_76_loss: 1.8580 - dense_77_loss: 1.7307 - dense_78_loss: 1.7367 - dense_79_loss: 1.5975 - dense_80_loss: 1.5152 - dense_81_loss: 1.6818 - dense_72_accuracy: 0.3600 - dense_73_accuracy: 0.3680 - dense_74_accuracy: 0.3280 - dense_75_accuracy: 0.3320 - dense_76_accuracy: 0.2960 - dense_77_accuracy: 0.2840 - dense_78_accuracy: 0.3200 - dense_79_accuracy: 0.3380 - dense_80_accuracy: 0.3880 - dense_81_accuracy: 0.3140\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D48B2A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D48B2A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D34F3AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D34F3AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "8/8 [==============================] - 9s 23ms/step - loss: 24.6153 - dense_82_loss: 2.4809 - dense_83_loss: 2.3879 - dense_84_loss: 2.4358 - dense_85_loss: 2.3217 - dense_86_loss: 2.9223 - dense_87_loss: 2.5468 - dense_88_loss: 2.5334 - dense_89_loss: 2.3647 - dense_90_loss: 2.1181 - dense_91_loss: 2.5036 - dense_82_accuracy: 0.1520 - dense_83_accuracy: 0.1420 - dense_84_accuracy: 0.1200 - dense_85_accuracy: 0.1960 - dense_86_accuracy: 0.1120 - dense_87_accuracy: 0.1080 - dense_88_accuracy: 0.1520 - dense_89_accuracy: 0.1700 - dense_90_accuracy: 0.1940 - dense_91_accuracy: 0.0800\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 22.6239 - dense_82_loss: 2.2260 - dense_83_loss: 2.2066 - dense_84_loss: 2.2487 - dense_85_loss: 2.1022 - dense_86_loss: 2.6522 - dense_87_loss: 2.3917 - dense_88_loss: 2.3233 - dense_89_loss: 2.1652 - dense_90_loss: 1.9669 - dense_91_loss: 2.3411 - dense_82_accuracy: 0.1800 - dense_83_accuracy: 0.2060 - dense_84_accuracy: 0.1860 - dense_85_accuracy: 0.2480 - dense_86_accuracy: 0.1400 - dense_87_accuracy: 0.1760 - dense_88_accuracy: 0.1620 - dense_89_accuracy: 0.1840 - dense_90_accuracy: 0.2200 - dense_91_accuracy: 0.2220\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 21.2401 - dense_82_loss: 2.1091 - dense_83_loss: 2.0729 - dense_84_loss: 2.1264 - dense_85_loss: 1.9582 - dense_86_loss: 2.4864 - dense_87_loss: 2.2693 - dense_88_loss: 2.1773 - dense_89_loss: 2.0428 - dense_90_loss: 1.8234 - dense_91_loss: 2.1744 - dense_82_accuracy: 0.2420 - dense_83_accuracy: 0.2220 - dense_84_accuracy: 0.2380 - dense_85_accuracy: 0.3260 - dense_86_accuracy: 0.1740 - dense_87_accuracy: 0.1760 - dense_88_accuracy: 0.1800 - dense_89_accuracy: 0.2580 - dense_90_accuracy: 0.3440 - dense_91_accuracy: 0.2520\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 19.9983 - dense_82_loss: 1.9483 - dense_83_loss: 1.9259 - dense_84_loss: 1.9696 - dense_85_loss: 1.8607 - dense_86_loss: 2.3211 - dense_87_loss: 2.1165 - dense_88_loss: 2.0538 - dense_89_loss: 1.9539 - dense_90_loss: 1.7697 - dense_91_loss: 2.0788 - dense_82_accuracy: 0.3100 - dense_83_accuracy: 0.2540 - dense_84_accuracy: 0.2540 - dense_85_accuracy: 0.3420 - dense_86_accuracy: 0.1660 - dense_87_accuracy: 0.2060 - dense_88_accuracy: 0.2380 - dense_89_accuracy: 0.2860 - dense_90_accuracy: 0.3520 - dense_91_accuracy: 0.2400\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 18.8589 - dense_82_loss: 1.8091 - dense_83_loss: 1.7836 - dense_84_loss: 1.8807 - dense_85_loss: 1.7694 - dense_86_loss: 2.1764 - dense_87_loss: 1.9943 - dense_88_loss: 1.9617 - dense_89_loss: 1.8254 - dense_90_loss: 1.6668 - dense_91_loss: 1.9914 - dense_82_accuracy: 0.3260 - dense_83_accuracy: 0.3200 - dense_84_accuracy: 0.2920 - dense_85_accuracy: 0.3160 - dense_86_accuracy: 0.2240 - dense_87_accuracy: 0.2320 - dense_88_accuracy: 0.2480 - dense_89_accuracy: 0.2780 - dense_90_accuracy: 0.3560 - dense_91_accuracy: 0.3080\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 17.7665 - dense_82_loss: 1.6637 - dense_83_loss: 1.6758 - dense_84_loss: 1.8195 - dense_85_loss: 1.6931 - dense_86_loss: 2.0394 - dense_87_loss: 1.8673 - dense_88_loss: 1.8885 - dense_89_loss: 1.6977 - dense_90_loss: 1.5905 - dense_91_loss: 1.8309 - dense_82_accuracy: 0.3540 - dense_83_accuracy: 0.3100 - dense_84_accuracy: 0.2900 - dense_85_accuracy: 0.3100 - dense_86_accuracy: 0.2380 - dense_87_accuracy: 0.2400 - dense_88_accuracy: 0.2420 - dense_89_accuracy: 0.2900 - dense_90_accuracy: 0.3440 - dense_91_accuracy: 0.2980\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 17.1094 - dense_82_loss: 1.5891 - dense_83_loss: 1.5972 - dense_84_loss: 1.7569 - dense_85_loss: 1.6503 - dense_86_loss: 1.9838 - dense_87_loss: 1.7887 - dense_88_loss: 1.7965 - dense_89_loss: 1.6493 - dense_90_loss: 1.5390 - dense_91_loss: 1.7586 - dense_82_accuracy: 0.3660 - dense_83_accuracy: 0.3440 - dense_84_accuracy: 0.3100 - dense_85_accuracy: 0.3160 - dense_86_accuracy: 0.2560 - dense_87_accuracy: 0.2740 - dense_88_accuracy: 0.2420 - dense_89_accuracy: 0.3340 - dense_90_accuracy: 0.3840 - dense_91_accuracy: 0.3100\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 16.5487 - dense_82_loss: 1.5197 - dense_83_loss: 1.5363 - dense_84_loss: 1.7079 - dense_85_loss: 1.5903 - dense_86_loss: 1.9028 - dense_87_loss: 1.7385 - dense_88_loss: 1.7550 - dense_89_loss: 1.6092 - dense_90_loss: 1.4947 - dense_91_loss: 1.6942 - dense_82_accuracy: 0.3760 - dense_83_accuracy: 0.3700 - dense_84_accuracy: 0.3140 - dense_85_accuracy: 0.3340 - dense_86_accuracy: 0.2520 - dense_87_accuracy: 0.2860 - dense_88_accuracy: 0.2520 - dense_89_accuracy: 0.3400 - dense_90_accuracy: 0.3740 - dense_91_accuracy: 0.3000\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 16.2739 - dense_82_loss: 1.4900 - dense_83_loss: 1.5176 - dense_84_loss: 1.6748 - dense_85_loss: 1.5632 - dense_86_loss: 1.8621 - dense_87_loss: 1.7222 - dense_88_loss: 1.7197 - dense_89_loss: 1.5845 - dense_90_loss: 1.4761 - dense_91_loss: 1.6638 - dense_82_accuracy: 0.3840 - dense_83_accuracy: 0.3740 - dense_84_accuracy: 0.3100 - dense_85_accuracy: 0.3360 - dense_86_accuracy: 0.2840 - dense_87_accuracy: 0.2940 - dense_88_accuracy: 0.2880 - dense_89_accuracy: 0.3460 - dense_90_accuracy: 0.3920 - dense_91_accuracy: 0.3100\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 16.2966 - dense_82_loss: 1.5058 - dense_83_loss: 1.5188 - dense_84_loss: 1.6656 - dense_85_loss: 1.5749 - dense_86_loss: 1.8554 - dense_87_loss: 1.7219 - dense_88_loss: 1.7111 - dense_89_loss: 1.5955 - dense_90_loss: 1.4857 - dense_91_loss: 1.6620 - dense_82_accuracy: 0.3760 - dense_83_accuracy: 0.3640 - dense_84_accuracy: 0.3120 - dense_85_accuracy: 0.3320 - dense_86_accuracy: 0.2660 - dense_87_accuracy: 0.2680 - dense_88_accuracy: 0.2840 - dense_89_accuracy: 0.3120 - dense_90_accuracy: 0.3800 - dense_91_accuracy: 0.3220\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4F6EDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4F6EDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D38B1708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D38B1708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 3s 25ms/step - loss: 0.2015\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0212\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 0.0057\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0050\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0048\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 0.0047\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0047\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0046\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0046\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0046\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D427E0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D427E0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 9s 17ms/step - loss: 17.6563 - dense_95_loss: 1.5834 - dense_96_loss: 1.7707 - dense_97_loss: 1.8808 - dense_98_loss: 1.7207 - dense_99_loss: 1.9918 - dense_100_loss: 1.7669 - dense_101_loss: 1.7170 - dense_102_loss: 1.7190 - dense_103_loss: 1.6339 - dense_104_loss: 1.8720 - dense_95_accuracy: 0.4126 - dense_96_accuracy: 0.2580 - dense_97_accuracy: 0.2026 - dense_98_accuracy: 0.2676 - dense_99_accuracy: 0.2066 - dense_100_accuracy: 0.2692 - dense_101_accuracy: 0.3190 - dense_102_accuracy: 0.2740 - dense_103_accuracy: 0.3614 - dense_104_accuracy: 0.2228\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 15.3349 - dense_95_loss: 1.3138 - dense_96_loss: 1.5460 - dense_97_loss: 1.6390 - dense_98_loss: 1.5178 - dense_99_loss: 1.7075 - dense_100_loss: 1.5459 - dense_101_loss: 1.4840 - dense_102_loss: 1.5501 - dense_103_loss: 1.4114 - dense_104_loss: 1.6193 - dense_95_accuracy: 0.4704 - dense_96_accuracy: 0.2982 - dense_97_accuracy: 0.2408 - dense_98_accuracy: 0.2986 - dense_99_accuracy: 0.2374 - dense_100_accuracy: 0.2976 - dense_101_accuracy: 0.3570 - dense_102_accuracy: 0.3060 - dense_103_accuracy: 0.4002 - dense_104_accuracy: 0.2466\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 15.3231 - dense_95_loss: 1.3119 - dense_96_loss: 1.5462 - dense_97_loss: 1.6384 - dense_98_loss: 1.5140 - dense_99_loss: 1.7029 - dense_100_loss: 1.5428 - dense_101_loss: 1.4860 - dense_102_loss: 1.5510 - dense_103_loss: 1.4080 - dense_104_loss: 1.6219 - dense_95_accuracy: 0.4734 - dense_96_accuracy: 0.2990 - dense_97_accuracy: 0.2342 - dense_98_accuracy: 0.2960 - dense_99_accuracy: 0.2362 - dense_100_accuracy: 0.2992 - dense_101_accuracy: 0.3560 - dense_102_accuracy: 0.2996 - dense_103_accuracy: 0.4000 - dense_104_accuracy: 0.2414\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 15.2514 - dense_95_loss: 1.3074 - dense_96_loss: 1.5379 - dense_97_loss: 1.6286 - dense_98_loss: 1.5041 - dense_99_loss: 1.6966 - dense_100_loss: 1.5344 - dense_101_loss: 1.4770 - dense_102_loss: 1.5472 - dense_103_loss: 1.4032 - dense_104_loss: 1.6151 - dense_95_accuracy: 0.4764 - dense_96_accuracy: 0.3026 - dense_97_accuracy: 0.2386 - dense_98_accuracy: 0.3104 - dense_99_accuracy: 0.2394 - dense_100_accuracy: 0.2978 - dense_101_accuracy: 0.3636 - dense_102_accuracy: 0.3062 - dense_103_accuracy: 0.4074 - dense_104_accuracy: 0.2518\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 15.2862 - dense_95_loss: 1.3085 - dense_96_loss: 1.5402 - dense_97_loss: 1.6323 - dense_98_loss: 1.5104 - dense_99_loss: 1.7034 - dense_100_loss: 1.5395 - dense_101_loss: 1.4801 - dense_102_loss: 1.5484 - dense_103_loss: 1.4065 - dense_104_loss: 1.6170 - dense_95_accuracy: 0.4762 - dense_96_accuracy: 0.2992 - dense_97_accuracy: 0.2424 - dense_98_accuracy: 0.2962 - dense_99_accuracy: 0.2320 - dense_100_accuracy: 0.2958 - dense_101_accuracy: 0.3562 - dense_102_accuracy: 0.3034 - dense_103_accuracy: 0.4000 - dense_104_accuracy: 0.2520\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 15.2545 - dense_95_loss: 1.3079 - dense_96_loss: 1.5382 - dense_97_loss: 1.6335 - dense_98_loss: 1.5059 - dense_99_loss: 1.6967 - dense_100_loss: 1.5344 - dense_101_loss: 1.4768 - dense_102_loss: 1.5439 - dense_103_loss: 1.4036 - dense_104_loss: 1.6135 - dense_95_accuracy: 0.4758 - dense_96_accuracy: 0.3080 - dense_97_accuracy: 0.2444 - dense_98_accuracy: 0.2950 - dense_99_accuracy: 0.2398 - dense_100_accuracy: 0.2956 - dense_101_accuracy: 0.3578 - dense_102_accuracy: 0.2990 - dense_103_accuracy: 0.4084 - dense_104_accuracy: 0.2524\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 15.2067 - dense_95_loss: 1.3059 - dense_96_loss: 1.5347 - dense_97_loss: 1.6252 - dense_98_loss: 1.4986 - dense_99_loss: 1.6903 - dense_100_loss: 1.5310 - dense_101_loss: 1.4772 - dense_102_loss: 1.5363 - dense_103_loss: 1.4008 - dense_104_loss: 1.6068 - dense_95_accuracy: 0.4778 - dense_96_accuracy: 0.3130 - dense_97_accuracy: 0.2560 - dense_98_accuracy: 0.3200 - dense_99_accuracy: 0.2530 - dense_100_accuracy: 0.3100 - dense_101_accuracy: 0.3690 - dense_102_accuracy: 0.3140 - dense_103_accuracy: 0.4040 - dense_104_accuracy: 0.2668\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 15.1322 - dense_95_loss: 1.3001 - dense_96_loss: 1.5270 - dense_97_loss: 1.6167 - dense_98_loss: 1.4921 - dense_99_loss: 1.6838 - dense_100_loss: 1.5198 - dense_101_loss: 1.4693 - dense_102_loss: 1.5290 - dense_103_loss: 1.3959 - dense_104_loss: 1.5985 - dense_95_accuracy: 0.4768 - dense_96_accuracy: 0.3224 - dense_97_accuracy: 0.2622 - dense_98_accuracy: 0.3266 - dense_99_accuracy: 0.2624 - dense_100_accuracy: 0.3158 - dense_101_accuracy: 0.3694 - dense_102_accuracy: 0.3274 - dense_103_accuracy: 0.4148 - dense_104_accuracy: 0.2718\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 15.0652 - dense_95_loss: 1.2963 - dense_96_loss: 1.5177 - dense_97_loss: 1.6062 - dense_98_loss: 1.4876 - dense_99_loss: 1.6712 - dense_100_loss: 1.5137 - dense_101_loss: 1.4648 - dense_102_loss: 1.5214 - dense_103_loss: 1.3929 - dense_104_loss: 1.5935 - dense_95_accuracy: 0.4762 - dense_96_accuracy: 0.3272 - dense_97_accuracy: 0.2710 - dense_98_accuracy: 0.3228 - dense_99_accuracy: 0.2756 - dense_100_accuracy: 0.3242 - dense_101_accuracy: 0.3704 - dense_102_accuracy: 0.3366 - dense_103_accuracy: 0.4126 - dense_104_accuracy: 0.2736\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 14.9461 - dense_95_loss: 1.2889 - dense_96_loss: 1.5065 - dense_97_loss: 1.5962 - dense_98_loss: 1.4727 - dense_99_loss: 1.6602 - dense_100_loss: 1.4976 - dense_101_loss: 1.4572 - dense_102_loss: 1.5078 - dense_103_loss: 1.3833 - dense_104_loss: 1.5757 - dense_95_accuracy: 0.4900 - dense_96_accuracy: 0.3292 - dense_97_accuracy: 0.2678 - dense_98_accuracy: 0.3318 - dense_99_accuracy: 0.2678 - dense_100_accuracy: 0.3360 - dense_101_accuracy: 0.3756 - dense_102_accuracy: 0.3324 - dense_103_accuracy: 0.4138 - dense_104_accuracy: 0.2760\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D1737798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D1737798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D0031438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D0031438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 10s 17ms/step - loss: 17.0161 - dense_105_loss: 1.5000 - dense_106_loss: 1.6902 - dense_107_loss: 1.8108 - dense_108_loss: 1.6839 - dense_109_loss: 1.9169 - dense_110_loss: 1.7074 - dense_111_loss: 1.6543 - dense_112_loss: 1.7178 - dense_113_loss: 1.5490 - dense_114_loss: 1.7857 - dense_105_accuracy: 0.4374 - dense_106_accuracy: 0.2736 - dense_107_accuracy: 0.2252 - dense_108_accuracy: 0.2626 - dense_109_accuracy: 0.2058 - dense_110_accuracy: 0.2628 - dense_111_accuracy: 0.3234 - dense_112_accuracy: 0.2584 - dense_113_accuracy: 0.3702 - dense_114_accuracy: 0.2214\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 15.3438 - dense_105_loss: 1.3079 - dense_106_loss: 1.5467 - dense_107_loss: 1.6396 - dense_108_loss: 1.5174 - dense_109_loss: 1.7078 - dense_110_loss: 1.5481 - dense_111_loss: 1.4816 - dense_112_loss: 1.5559 - dense_113_loss: 1.4106 - dense_114_loss: 1.6282 - dense_105_accuracy: 0.4758 - dense_106_accuracy: 0.2966 - dense_107_accuracy: 0.2316 - dense_108_accuracy: 0.3004 - dense_109_accuracy: 0.2294 - dense_110_accuracy: 0.2930 - dense_111_accuracy: 0.3520 - dense_112_accuracy: 0.2960 - dense_113_accuracy: 0.3984 - dense_114_accuracy: 0.2280\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 15.2872 - dense_105_loss: 1.3089 - dense_106_loss: 1.5392 - dense_107_loss: 1.6328 - dense_108_loss: 1.5066 - dense_109_loss: 1.7030 - dense_110_loss: 1.5412 - dense_111_loss: 1.4821 - dense_112_loss: 1.5481 - dense_113_loss: 1.4060 - dense_114_loss: 1.6193 - dense_105_accuracy: 0.4760 - dense_106_accuracy: 0.3022 - dense_107_accuracy: 0.2302 - dense_108_accuracy: 0.3102 - dense_109_accuracy: 0.2314 - dense_110_accuracy: 0.2882 - dense_111_accuracy: 0.3510 - dense_112_accuracy: 0.2938 - dense_113_accuracy: 0.4018 - dense_114_accuracy: 0.2380\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 15.3055 - dense_105_loss: 1.3122 - dense_106_loss: 1.5407 - dense_107_loss: 1.6364 - dense_108_loss: 1.5093 - dense_109_loss: 1.7019 - dense_110_loss: 1.5413 - dense_111_loss: 1.4830 - dense_112_loss: 1.5500 - dense_113_loss: 1.4097 - dense_114_loss: 1.6209 - dense_105_accuracy: 0.4728 - dense_106_accuracy: 0.3048 - dense_107_accuracy: 0.2364 - dense_108_accuracy: 0.3094 - dense_109_accuracy: 0.2352 - dense_110_accuracy: 0.2946 - dense_111_accuracy: 0.3530 - dense_112_accuracy: 0.2988 - dense_113_accuracy: 0.4028 - dense_114_accuracy: 0.2354\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 15.2867 - dense_105_loss: 1.3081 - dense_106_loss: 1.5414 - dense_107_loss: 1.6338 - dense_108_loss: 1.5068 - dense_109_loss: 1.7029 - dense_110_loss: 1.5400 - dense_111_loss: 1.4799 - dense_112_loss: 1.5489 - dense_113_loss: 1.4051 - dense_114_loss: 1.6198 - dense_105_accuracy: 0.4758 - dense_106_accuracy: 0.3056 - dense_107_accuracy: 0.2382 - dense_108_accuracy: 0.3094 - dense_109_accuracy: 0.2298 - dense_110_accuracy: 0.2898 - dense_111_accuracy: 0.3504 - dense_112_accuracy: 0.3026 - dense_113_accuracy: 0.3996 - dense_114_accuracy: 0.2348\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 15.2696 - dense_105_loss: 1.3075 - dense_106_loss: 1.5390 - dense_107_loss: 1.6295 - dense_108_loss: 1.5081 - dense_109_loss: 1.7003 - dense_110_loss: 1.5382 - dense_111_loss: 1.4772 - dense_112_loss: 1.5468 - dense_113_loss: 1.4067 - dense_114_loss: 1.6164 - dense_105_accuracy: 0.4714 - dense_106_accuracy: 0.3048 - dense_107_accuracy: 0.2422 - dense_108_accuracy: 0.2966 - dense_109_accuracy: 0.2334 - dense_110_accuracy: 0.2930 - dense_111_accuracy: 0.3544 - dense_112_accuracy: 0.3016 - dense_113_accuracy: 0.4028 - dense_114_accuracy: 0.2372\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 15.2813 - dense_105_loss: 1.3094 - dense_106_loss: 1.5426 - dense_107_loss: 1.6326 - dense_108_loss: 1.5073 - dense_109_loss: 1.7018 - dense_110_loss: 1.5371 - dense_111_loss: 1.4810 - dense_112_loss: 1.5480 - dense_113_loss: 1.4052 - dense_114_loss: 1.6163 - dense_105_accuracy: 0.4728 - dense_106_accuracy: 0.2958 - dense_107_accuracy: 0.2314 - dense_108_accuracy: 0.2974 - dense_109_accuracy: 0.2232 - dense_110_accuracy: 0.2930 - dense_111_accuracy: 0.3520 - dense_112_accuracy: 0.2968 - dense_113_accuracy: 0.4002 - dense_114_accuracy: 0.2292\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 15.2312 - dense_105_loss: 1.3037 - dense_106_loss: 1.5390 - dense_107_loss: 1.6246 - dense_108_loss: 1.5028 - dense_109_loss: 1.6972 - dense_110_loss: 1.5325 - dense_111_loss: 1.4756 - dense_112_loss: 1.5422 - dense_113_loss: 1.4016 - dense_114_loss: 1.6119 - dense_105_accuracy: 0.4762 - dense_106_accuracy: 0.2972 - dense_107_accuracy: 0.2322 - dense_108_accuracy: 0.2972 - dense_109_accuracy: 0.2328 - dense_110_accuracy: 0.2954 - dense_111_accuracy: 0.3566 - dense_112_accuracy: 0.2950 - dense_113_accuracy: 0.4020 - dense_114_accuracy: 0.2408\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 15.2570 - dense_105_loss: 1.3074 - dense_106_loss: 1.5381 - dense_107_loss: 1.6285 - dense_108_loss: 1.5058 - dense_109_loss: 1.6994 - dense_110_loss: 1.5344 - dense_111_loss: 1.4792 - dense_112_loss: 1.5444 - dense_113_loss: 1.4035 - dense_114_loss: 1.6162 - dense_105_accuracy: 0.4762 - dense_106_accuracy: 0.3034 - dense_107_accuracy: 0.2360 - dense_108_accuracy: 0.3046 - dense_109_accuracy: 0.2328 - dense_110_accuracy: 0.2964 - dense_111_accuracy: 0.3544 - dense_112_accuracy: 0.2992 - dense_113_accuracy: 0.4054 - dense_114_accuracy: 0.2388\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 15.2378 - dense_105_loss: 1.3056 - dense_106_loss: 1.5385 - dense_107_loss: 1.6229 - dense_108_loss: 1.5040 - dense_109_loss: 1.6949 - dense_110_loss: 1.5331 - dense_111_loss: 1.4776 - dense_112_loss: 1.5453 - dense_113_loss: 1.4024 - dense_114_loss: 1.6135 - dense_105_accuracy: 0.4752 - dense_106_accuracy: 0.3054 - dense_107_accuracy: 0.2388 - dense_108_accuracy: 0.3016 - dense_109_accuracy: 0.2432 - dense_110_accuracy: 0.2994 - dense_111_accuracy: 0.3610 - dense_112_accuracy: 0.2944 - dense_113_accuracy: 0.4050 - dense_114_accuracy: 0.2480\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D152A798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D152A798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D2758F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D2758F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "157/157 [==============================] - 4s 22ms/step - loss: 0.1312\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 3s 22ms/step - loss: 0.0062\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 3s 21ms/step - loss: 0.0051\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 3s 22ms/step - loss: 0.0049\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 3s 21ms/step - loss: 0.0048\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 3s 22ms/step - loss: 0.0045\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 3s 22ms/step - loss: 0.0039\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 4s 27ms/step - loss: 0.0036\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 4s 25ms/step - loss: 0.0034\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 4s 26ms/step - loss: 0.0033\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D49809D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D49809D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "157/157 [==============================] - 11s 15ms/step - loss: 16.6144 - dense_118_loss: 1.5101 - dense_119_loss: 1.9087 - dense_120_loss: 1.5112 - dense_121_loss: 1.6376 - dense_122_loss: 1.9114 - dense_123_loss: 1.9203 - dense_124_loss: 1.6843 - dense_125_loss: 1.5849 - dense_126_loss: 1.4909 - dense_127_loss: 1.4551 - dense_118_accuracy: 0.3736 - dense_119_accuracy: 0.2077 - dense_120_accuracy: 0.3963 - dense_121_accuracy: 0.2917 - dense_122_accuracy: 0.2154 - dense_123_accuracy: 0.2130 - dense_124_accuracy: 0.2826 - dense_125_accuracy: 0.2911 - dense_126_accuracy: 0.3737 - dense_127_accuracy: 0.3674\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 14.3663 - dense_118_loss: 1.3180 - dense_119_loss: 1.6292 - dense_120_loss: 1.3073 - dense_121_loss: 1.4564 - dense_122_loss: 1.6311 - dense_123_loss: 1.6382 - dense_124_loss: 1.4732 - dense_125_loss: 1.3692 - dense_126_loss: 1.2555 - dense_127_loss: 1.2880 - dense_118_accuracy: 0.4211 - dense_119_accuracy: 0.2304 - dense_120_accuracy: 0.4325 - dense_121_accuracy: 0.3162 - dense_122_accuracy: 0.2342 - dense_123_accuracy: 0.2351 - dense_124_accuracy: 0.3042 - dense_125_accuracy: 0.3106 - dense_126_accuracy: 0.4005 - dense_127_accuracy: 0.3956\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 14.2779 - dense_118_loss: 1.3069 - dense_119_loss: 1.6162 - dense_120_loss: 1.3016 - dense_121_loss: 1.4513 - dense_122_loss: 1.6222 - dense_123_loss: 1.6283 - dense_124_loss: 1.4631 - dense_125_loss: 1.3588 - dense_126_loss: 1.2477 - dense_127_loss: 1.2818 - dense_118_accuracy: 0.4190 - dense_119_accuracy: 0.2423 - dense_120_accuracy: 0.4267 - dense_121_accuracy: 0.3185 - dense_122_accuracy: 0.2432 - dense_123_accuracy: 0.2348 - dense_124_accuracy: 0.3039 - dense_125_accuracy: 0.3115 - dense_126_accuracy: 0.4106 - dense_127_accuracy: 0.4009\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 14.2302 - dense_118_loss: 1.3021 - dense_119_loss: 1.6117 - dense_120_loss: 1.2974 - dense_121_loss: 1.4446 - dense_122_loss: 1.6144 - dense_123_loss: 1.6216 - dense_124_loss: 1.4611 - dense_125_loss: 1.3568 - dense_126_loss: 1.2433 - dense_127_loss: 1.2773 - dense_118_accuracy: 0.4255 - dense_119_accuracy: 0.2421 - dense_120_accuracy: 0.4337 - dense_121_accuracy: 0.3263 - dense_122_accuracy: 0.2463 - dense_123_accuracy: 0.2490 - dense_124_accuracy: 0.3125 - dense_125_accuracy: 0.3273 - dense_126_accuracy: 0.4101 - dense_127_accuracy: 0.3992\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 14.2073 - dense_118_loss: 1.2989 - dense_119_loss: 1.6082 - dense_120_loss: 1.2964 - dense_121_loss: 1.4430 - dense_122_loss: 1.6120 - dense_123_loss: 1.6202 - dense_124_loss: 1.4585 - dense_125_loss: 1.3530 - dense_126_loss: 1.2411 - dense_127_loss: 1.2761 - dense_118_accuracy: 0.4240 - dense_119_accuracy: 0.2513 - dense_120_accuracy: 0.4320 - dense_121_accuracy: 0.3242 - dense_122_accuracy: 0.2504 - dense_123_accuracy: 0.2499 - dense_124_accuracy: 0.3058 - dense_125_accuracy: 0.3285 - dense_126_accuracy: 0.4155 - dense_127_accuracy: 0.4106\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 14.1838 - dense_118_loss: 1.2988 - dense_119_loss: 1.6063 - dense_120_loss: 1.2917 - dense_121_loss: 1.4412 - dense_122_loss: 1.6082 - dense_123_loss: 1.6192 - dense_124_loss: 1.4554 - dense_125_loss: 1.3529 - dense_126_loss: 1.2393 - dense_127_loss: 1.2709 - dense_118_accuracy: 0.4201 - dense_119_accuracy: 0.2467 - dense_120_accuracy: 0.4336 - dense_121_accuracy: 0.3253 - dense_122_accuracy: 0.2520 - dense_123_accuracy: 0.2500 - dense_124_accuracy: 0.3142 - dense_125_accuracy: 0.3298 - dense_126_accuracy: 0.4188 - dense_127_accuracy: 0.4091\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 14.1226 - dense_118_loss: 1.2953 - dense_119_loss: 1.5956 - dense_120_loss: 1.2888 - dense_121_loss: 1.4350 - dense_122_loss: 1.6012 - dense_123_loss: 1.6103 - dense_124_loss: 1.4502 - dense_125_loss: 1.3446 - dense_126_loss: 1.2348 - dense_127_loss: 1.2669 - dense_118_accuracy: 0.4272 - dense_119_accuracy: 0.2591 - dense_120_accuracy: 0.4370 - dense_121_accuracy: 0.3335 - dense_122_accuracy: 0.2624 - dense_123_accuracy: 0.2599 - dense_124_accuracy: 0.3096 - dense_125_accuracy: 0.3417 - dense_126_accuracy: 0.4187 - dense_127_accuracy: 0.4098\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 14.1029 - dense_118_loss: 1.2923 - dense_119_loss: 1.5962 - dense_120_loss: 1.2884 - dense_121_loss: 1.4311 - dense_122_loss: 1.5989 - dense_123_loss: 1.6052 - dense_124_loss: 1.4445 - dense_125_loss: 1.3455 - dense_126_loss: 1.2330 - dense_127_loss: 1.2679 - dense_118_accuracy: 0.4278 - dense_119_accuracy: 0.2658 - dense_120_accuracy: 0.4376 - dense_121_accuracy: 0.3340 - dense_122_accuracy: 0.2664 - dense_123_accuracy: 0.2633 - dense_124_accuracy: 0.3273 - dense_125_accuracy: 0.3432 - dense_126_accuracy: 0.4249 - dense_127_accuracy: 0.4185\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 14.0450 - dense_118_loss: 1.2884 - dense_119_loss: 1.5877 - dense_120_loss: 1.2810 - dense_121_loss: 1.4249 - dense_122_loss: 1.5927 - dense_123_loss: 1.5993 - dense_124_loss: 1.4409 - dense_125_loss: 1.3447 - dense_126_loss: 1.2251 - dense_127_loss: 1.2603 - dense_118_accuracy: 0.4291 - dense_119_accuracy: 0.2725 - dense_120_accuracy: 0.4390 - dense_121_accuracy: 0.3415 - dense_122_accuracy: 0.2685 - dense_123_accuracy: 0.2709 - dense_124_accuracy: 0.3282 - dense_125_accuracy: 0.3390 - dense_126_accuracy: 0.4318 - dense_127_accuracy: 0.4198\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 14.0017 - dense_118_loss: 1.2846 - dense_119_loss: 1.5832 - dense_120_loss: 1.2821 - dense_121_loss: 1.4202 - dense_122_loss: 1.5861 - dense_123_loss: 1.5916 - dense_124_loss: 1.4328 - dense_125_loss: 1.3401 - dense_126_loss: 1.2214 - dense_127_loss: 1.2598 - dense_118_accuracy: 0.4350 - dense_119_accuracy: 0.2753 - dense_120_accuracy: 0.4397 - dense_121_accuracy: 0.3454 - dense_122_accuracy: 0.2725 - dense_123_accuracy: 0.2813 - dense_124_accuracy: 0.3339 - dense_125_accuracy: 0.3506 - dense_126_accuracy: 0.4433 - dense_127_accuracy: 0.4223\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D1737E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D1737E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3AEA9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3AEA9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "157/157 [==============================] - 11s 14ms/step - loss: 16.2466 - dense_128_loss: 1.5046 - dense_129_loss: 1.8601 - dense_130_loss: 1.5031 - dense_131_loss: 1.6267 - dense_132_loss: 1.8682 - dense_133_loss: 1.8608 - dense_134_loss: 1.6266 - dense_135_loss: 1.5330 - dense_136_loss: 1.4404 - dense_137_loss: 1.4230 - dense_128_accuracy: 0.3640 - dense_129_accuracy: 0.2092 - dense_130_accuracy: 0.3831 - dense_131_accuracy: 0.2951 - dense_132_accuracy: 0.2172 - dense_133_accuracy: 0.2089 - dense_134_accuracy: 0.2785 - dense_135_accuracy: 0.2931 - dense_136_accuracy: 0.3817 - dense_137_accuracy: 0.3717\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 14.3220 - dense_128_loss: 1.3080 - dense_129_loss: 1.6234 - dense_130_loss: 1.3015 - dense_131_loss: 1.4567 - dense_132_loss: 1.6258 - dense_133_loss: 1.6353 - dense_134_loss: 1.4691 - dense_135_loss: 1.3652 - dense_136_loss: 1.2533 - dense_137_loss: 1.2837 - dense_128_accuracy: 0.4250 - dense_129_accuracy: 0.2419 - dense_130_accuracy: 0.4367 - dense_131_accuracy: 0.3179 - dense_132_accuracy: 0.2437 - dense_133_accuracy: 0.2392 - dense_134_accuracy: 0.3085 - dense_135_accuracy: 0.3176 - dense_136_accuracy: 0.4086 - dense_137_accuracy: 0.3961\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 14.3052 - dense_128_loss: 1.3087 - dense_129_loss: 1.6229 - dense_130_loss: 1.3040 - dense_131_loss: 1.4531 - dense_132_loss: 1.6233 - dense_133_loss: 1.6313 - dense_134_loss: 1.4624 - dense_135_loss: 1.3662 - dense_136_loss: 1.2510 - dense_137_loss: 1.2822 - dense_128_accuracy: 0.4201 - dense_129_accuracy: 0.2373 - dense_130_accuracy: 0.4291 - dense_131_accuracy: 0.3188 - dense_132_accuracy: 0.2424 - dense_133_accuracy: 0.2388 - dense_134_accuracy: 0.3114 - dense_135_accuracy: 0.3147 - dense_136_accuracy: 0.4047 - dense_137_accuracy: 0.3935\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 14.2441 - dense_128_loss: 1.3007 - dense_129_loss: 1.6150 - dense_130_loss: 1.2963 - dense_131_loss: 1.4488 - dense_132_loss: 1.6169 - dense_133_loss: 1.6267 - dense_134_loss: 1.4567 - dense_135_loss: 1.3570 - dense_136_loss: 1.2475 - dense_137_loss: 1.2786 - dense_128_accuracy: 0.4220 - dense_129_accuracy: 0.2393 - dense_130_accuracy: 0.4344 - dense_131_accuracy: 0.3133 - dense_132_accuracy: 0.2424 - dense_133_accuracy: 0.2333 - dense_134_accuracy: 0.3078 - dense_135_accuracy: 0.3129 - dense_136_accuracy: 0.4067 - dense_137_accuracy: 0.3986\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 14.2174 - dense_128_loss: 1.2984 - dense_129_loss: 1.6112 - dense_130_loss: 1.2942 - dense_131_loss: 1.4450 - dense_132_loss: 1.6133 - dense_133_loss: 1.6226 - dense_134_loss: 1.4558 - dense_135_loss: 1.3552 - dense_136_loss: 1.2434 - dense_137_loss: 1.2782 - dense_128_accuracy: 0.4240 - dense_129_accuracy: 0.2441 - dense_130_accuracy: 0.4360 - dense_131_accuracy: 0.3212 - dense_132_accuracy: 0.2456 - dense_133_accuracy: 0.2465 - dense_134_accuracy: 0.3172 - dense_135_accuracy: 0.3233 - dense_136_accuracy: 0.4114 - dense_137_accuracy: 0.3999\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 14.1798 - dense_128_loss: 1.2962 - dense_129_loss: 1.6081 - dense_130_loss: 1.2901 - dense_131_loss: 1.4419 - dense_132_loss: 1.6092 - dense_133_loss: 1.6191 - dense_134_loss: 1.4521 - dense_135_loss: 1.3505 - dense_136_loss: 1.2396 - dense_137_loss: 1.2731 - dense_128_accuracy: 0.4219 - dense_129_accuracy: 0.2462 - dense_130_accuracy: 0.4343 - dense_131_accuracy: 0.3202 - dense_132_accuracy: 0.2453 - dense_133_accuracy: 0.2438 - dense_134_accuracy: 0.3156 - dense_135_accuracy: 0.3275 - dense_136_accuracy: 0.4126 - dense_137_accuracy: 0.4027\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 14.1645 - dense_128_loss: 1.2956 - dense_129_loss: 1.6063 - dense_130_loss: 1.2885 - dense_131_loss: 1.4405 - dense_132_loss: 1.6070 - dense_133_loss: 1.6160 - dense_134_loss: 1.4500 - dense_135_loss: 1.3488 - dense_136_loss: 1.2401 - dense_137_loss: 1.2716 - dense_128_accuracy: 0.4276 - dense_129_accuracy: 0.2448 - dense_130_accuracy: 0.4383 - dense_131_accuracy: 0.3241 - dense_132_accuracy: 0.2469 - dense_133_accuracy: 0.2434 - dense_134_accuracy: 0.3136 - dense_135_accuracy: 0.3317 - dense_136_accuracy: 0.4088 - dense_137_accuracy: 0.4002\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 14.1363 - dense_128_loss: 1.2932 - dense_129_loss: 1.6016 - dense_130_loss: 1.2870 - dense_131_loss: 1.4378 - dense_132_loss: 1.6051 - dense_133_loss: 1.6118 - dense_134_loss: 1.4454 - dense_135_loss: 1.3478 - dense_136_loss: 1.2369 - dense_137_loss: 1.2696 - dense_128_accuracy: 0.4250 - dense_129_accuracy: 0.2445 - dense_130_accuracy: 0.4333 - dense_131_accuracy: 0.3173 - dense_132_accuracy: 0.2437 - dense_133_accuracy: 0.2436 - dense_134_accuracy: 0.3127 - dense_135_accuracy: 0.3136 - dense_136_accuracy: 0.4060 - dense_137_accuracy: 0.4038\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 14.1611 - dense_128_loss: 1.2948 - dense_129_loss: 1.6050 - dense_130_loss: 1.2913 - dense_131_loss: 1.4390 - dense_132_loss: 1.6074 - dense_133_loss: 1.6162 - dense_134_loss: 1.4483 - dense_135_loss: 1.3491 - dense_136_loss: 1.2382 - dense_137_loss: 1.2717 - dense_128_accuracy: 0.4220 - dense_129_accuracy: 0.2412 - dense_130_accuracy: 0.4347 - dense_131_accuracy: 0.3175 - dense_132_accuracy: 0.2441 - dense_133_accuracy: 0.2387 - dense_134_accuracy: 0.3113 - dense_135_accuracy: 0.3166 - dense_136_accuracy: 0.4095 - dense_137_accuracy: 0.4013\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 14.1384 - dense_128_loss: 1.2936 - dense_129_loss: 1.6024 - dense_130_loss: 1.2883 - dense_131_loss: 1.4368 - dense_132_loss: 1.6054 - dense_133_loss: 1.6133 - dense_134_loss: 1.4470 - dense_135_loss: 1.3459 - dense_136_loss: 1.2370 - dense_137_loss: 1.2687 - dense_128_accuracy: 0.4217 - dense_129_accuracy: 0.2409 - dense_130_accuracy: 0.4358 - dense_131_accuracy: 0.3183 - dense_132_accuracy: 0.2432 - dense_133_accuracy: 0.2442 - dense_134_accuracy: 0.3081 - dense_135_accuracy: 0.3269 - dense_136_accuracy: 0.4104 - dense_137_accuracy: 0.4037\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D1553D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D1553D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3FFAC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3FFAC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 3s 24ms/step - loss: 0.2173\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0438\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0078\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 0.0063\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0060\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 0.0059\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0058\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 0.0058\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0058\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 0.0057\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D427E4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D427E4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 9s 15ms/step - loss: 20.3586 - dense_141_loss: 1.9312 - dense_142_loss: 1.9911 - dense_143_loss: 2.0755 - dense_144_loss: 1.9652 - dense_145_loss: 2.3532 - dense_146_loss: 2.0585 - dense_147_loss: 2.0659 - dense_148_loss: 1.9803 - dense_149_loss: 1.8273 - dense_150_loss: 2.1104 - dense_141_accuracy: 0.3118 - dense_142_accuracy: 0.2514 - dense_143_accuracy: 0.2200 - dense_144_accuracy: 0.2488 - dense_145_accuracy: 0.1658 - dense_146_accuracy: 0.2194 - dense_147_accuracy: 0.2366 - dense_148_accuracy: 0.2484 - dense_149_accuracy: 0.3098 - dense_150_accuracy: 0.1910\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 17.3070 - dense_141_loss: 1.5921 - dense_142_loss: 1.6922 - dense_143_loss: 1.7910 - dense_144_loss: 1.6710 - dense_145_loss: 1.9655 - dense_146_loss: 1.7667 - dense_147_loss: 1.7725 - dense_148_loss: 1.7028 - dense_149_loss: 1.5452 - dense_150_loss: 1.8079 - dense_141_accuracy: 0.4140 - dense_142_accuracy: 0.3220 - dense_143_accuracy: 0.2698 - dense_144_accuracy: 0.2896 - dense_145_accuracy: 0.2222 - dense_146_accuracy: 0.2730 - dense_147_accuracy: 0.2742 - dense_148_accuracy: 0.2898 - dense_149_accuracy: 0.3906 - dense_150_accuracy: 0.2444\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 17.2038 - dense_141_loss: 1.5771 - dense_142_loss: 1.6821 - dense_143_loss: 1.7858 - dense_144_loss: 1.6613 - dense_145_loss: 1.9535 - dense_146_loss: 1.7504 - dense_147_loss: 1.7632 - dense_148_loss: 1.6938 - dense_149_loss: 1.5363 - dense_150_loss: 1.8004 - dense_141_accuracy: 0.4126 - dense_142_accuracy: 0.3172 - dense_143_accuracy: 0.2578 - dense_144_accuracy: 0.2836 - dense_145_accuracy: 0.2146 - dense_146_accuracy: 0.2692 - dense_147_accuracy: 0.2838 - dense_148_accuracy: 0.2814 - dense_149_accuracy: 0.3898 - dense_150_accuracy: 0.2390\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 17.1100 - dense_141_loss: 1.5664 - dense_142_loss: 1.6694 - dense_143_loss: 1.7751 - dense_144_loss: 1.6546 - dense_145_loss: 1.9416 - dense_146_loss: 1.7374 - dense_147_loss: 1.7557 - dense_148_loss: 1.6842 - dense_149_loss: 1.5323 - dense_150_loss: 1.7932 - dense_141_accuracy: 0.4152 - dense_142_accuracy: 0.3306 - dense_143_accuracy: 0.2650 - dense_144_accuracy: 0.2940 - dense_145_accuracy: 0.2282 - dense_146_accuracy: 0.2726 - dense_147_accuracy: 0.2924 - dense_148_accuracy: 0.2944 - dense_149_accuracy: 0.3960 - dense_150_accuracy: 0.2412\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 17.0595 - dense_141_loss: 1.5608 - dense_142_loss: 1.6651 - dense_143_loss: 1.7675 - dense_144_loss: 1.6517 - dense_145_loss: 1.9409 - dense_146_loss: 1.7373 - dense_147_loss: 1.7503 - dense_148_loss: 1.6770 - dense_149_loss: 1.5242 - dense_150_loss: 1.7846 - dense_141_accuracy: 0.4126 - dense_142_accuracy: 0.3322 - dense_143_accuracy: 0.2770 - dense_144_accuracy: 0.2894 - dense_145_accuracy: 0.2338 - dense_146_accuracy: 0.2798 - dense_147_accuracy: 0.2890 - dense_148_accuracy: 0.3028 - dense_149_accuracy: 0.3960 - dense_150_accuracy: 0.2534\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 16.9958 - dense_141_loss: 1.5581 - dense_142_loss: 1.6628 - dense_143_loss: 1.7627 - dense_144_loss: 1.6385 - dense_145_loss: 1.9307 - dense_146_loss: 1.7258 - dense_147_loss: 1.7434 - dense_148_loss: 1.6732 - dense_149_loss: 1.5227 - dense_150_loss: 1.7779 - dense_141_accuracy: 0.4150 - dense_142_accuracy: 0.3308 - dense_143_accuracy: 0.2818 - dense_144_accuracy: 0.3010 - dense_145_accuracy: 0.2408 - dense_146_accuracy: 0.2790 - dense_147_accuracy: 0.2864 - dense_148_accuracy: 0.2940 - dense_149_accuracy: 0.3930 - dense_150_accuracy: 0.2640\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 16.9299 - dense_141_loss: 1.5512 - dense_142_loss: 1.6596 - dense_143_loss: 1.7607 - dense_144_loss: 1.6269 - dense_145_loss: 1.9228 - dense_146_loss: 1.7173 - dense_147_loss: 1.7359 - dense_148_loss: 1.6692 - dense_149_loss: 1.5178 - dense_150_loss: 1.7685 - dense_141_accuracy: 0.4162 - dense_142_accuracy: 0.3302 - dense_143_accuracy: 0.2778 - dense_144_accuracy: 0.3132 - dense_145_accuracy: 0.2546 - dense_146_accuracy: 0.2980 - dense_147_accuracy: 0.3142 - dense_148_accuracy: 0.3042 - dense_149_accuracy: 0.3982 - dense_150_accuracy: 0.2718\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 16.8697 - dense_141_loss: 1.5436 - dense_142_loss: 1.6475 - dense_143_loss: 1.7534 - dense_144_loss: 1.6289 - dense_145_loss: 1.9161 - dense_146_loss: 1.7116 - dense_147_loss: 1.7322 - dense_148_loss: 1.6635 - dense_149_loss: 1.5097 - dense_150_loss: 1.7631 - dense_141_accuracy: 0.4224 - dense_142_accuracy: 0.3358 - dense_143_accuracy: 0.2862 - dense_144_accuracy: 0.3114 - dense_145_accuracy: 0.2570 - dense_146_accuracy: 0.2994 - dense_147_accuracy: 0.3102 - dense_148_accuracy: 0.3206 - dense_149_accuracy: 0.4052 - dense_150_accuracy: 0.2792\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 16.7755 - dense_141_loss: 1.5385 - dense_142_loss: 1.6461 - dense_143_loss: 1.7412 - dense_144_loss: 1.6195 - dense_145_loss: 1.9004 - dense_146_loss: 1.7010 - dense_147_loss: 1.7222 - dense_148_loss: 1.6483 - dense_149_loss: 1.5025 - dense_150_loss: 1.7560 - dense_141_accuracy: 0.4238 - dense_142_accuracy: 0.3488 - dense_143_accuracy: 0.3068 - dense_144_accuracy: 0.3260 - dense_145_accuracy: 0.2882 - dense_146_accuracy: 0.3130 - dense_147_accuracy: 0.3122 - dense_148_accuracy: 0.3282 - dense_149_accuracy: 0.4106 - dense_150_accuracy: 0.2870\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 16.6490 - dense_141_loss: 1.5263 - dense_142_loss: 1.6326 - dense_143_loss: 1.7263 - dense_144_loss: 1.6067 - dense_145_loss: 1.8898 - dense_146_loss: 1.6890 - dense_147_loss: 1.7072 - dense_148_loss: 1.6339 - dense_149_loss: 1.4915 - dense_150_loss: 1.7456 - dense_141_accuracy: 0.4304 - dense_142_accuracy: 0.3516 - dense_143_accuracy: 0.3236 - dense_144_accuracy: 0.3414 - dense_145_accuracy: 0.2940 - dense_146_accuracy: 0.3214 - dense_147_accuracy: 0.3404 - dense_148_accuracy: 0.3424 - dense_149_accuracy: 0.4162 - dense_150_accuracy: 0.2974\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D39C3438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D39C3438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3FFF288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3FFF288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 10s 16ms/step - loss: 20.5089 - dense_151_loss: 1.9660 - dense_152_loss: 1.9889 - dense_153_loss: 2.1083 - dense_154_loss: 1.9570 - dense_155_loss: 2.3793 - dense_156_loss: 2.0804 - dense_157_loss: 2.0993 - dense_158_loss: 1.9604 - dense_159_loss: 1.8395 - dense_160_loss: 2.1298 - dense_151_accuracy: 0.3054 - dense_152_accuracy: 0.2606 - dense_153_accuracy: 0.2252 - dense_154_accuracy: 0.2606 - dense_155_accuracy: 0.1690 - dense_156_accuracy: 0.2346 - dense_157_accuracy: 0.2192 - dense_158_accuracy: 0.2598 - dense_159_accuracy: 0.3096 - dense_160_accuracy: 0.1790\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 17.3426 - dense_151_loss: 1.5975 - dense_152_loss: 1.6950 - dense_153_loss: 1.7923 - dense_154_loss: 1.6727 - dense_155_loss: 1.9748 - dense_156_loss: 1.7589 - dense_157_loss: 1.7767 - dense_158_loss: 1.7070 - dense_159_loss: 1.5554 - dense_160_loss: 1.8123 - dense_151_accuracy: 0.4124 - dense_152_accuracy: 0.3268 - dense_153_accuracy: 0.2558 - dense_154_accuracy: 0.2952 - dense_155_accuracy: 0.2100 - dense_156_accuracy: 0.2636 - dense_157_accuracy: 0.2764 - dense_158_accuracy: 0.2842 - dense_159_accuracy: 0.3910 - dense_160_accuracy: 0.2266\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 1s 14ms/step - loss: 17.1395 - dense_151_loss: 1.5757 - dense_152_loss: 1.6774 - dense_153_loss: 1.7765 - dense_154_loss: 1.6553 - dense_155_loss: 1.9447 - dense_156_loss: 1.7418 - dense_157_loss: 1.7543 - dense_158_loss: 1.6878 - dense_159_loss: 1.5346 - dense_160_loss: 1.7913 - dense_151_accuracy: 0.4090 - dense_152_accuracy: 0.3204 - dense_153_accuracy: 0.2638 - dense_154_accuracy: 0.3000 - dense_155_accuracy: 0.2254 - dense_156_accuracy: 0.2718 - dense_157_accuracy: 0.2874 - dense_158_accuracy: 0.2972 - dense_159_accuracy: 0.3964 - dense_160_accuracy: 0.2468\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 1s 14ms/step - loss: 17.1341 - dense_151_loss: 1.5732 - dense_152_loss: 1.6771 - dense_153_loss: 1.7746 - dense_154_loss: 1.6562 - dense_155_loss: 1.9488 - dense_156_loss: 1.7395 - dense_157_loss: 1.7559 - dense_158_loss: 1.6868 - dense_159_loss: 1.5314 - dense_160_loss: 1.7907 - dense_151_accuracy: 0.4128 - dense_152_accuracy: 0.3168 - dense_153_accuracy: 0.2528 - dense_154_accuracy: 0.2922 - dense_155_accuracy: 0.2150 - dense_156_accuracy: 0.2696 - dense_157_accuracy: 0.2794 - dense_158_accuracy: 0.2876 - dense_159_accuracy: 0.3936 - dense_160_accuracy: 0.2358\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 17.1189 - dense_151_loss: 1.5706 - dense_152_loss: 1.6732 - dense_153_loss: 1.7768 - dense_154_loss: 1.6512 - dense_155_loss: 1.9450 - dense_156_loss: 1.7374 - dense_157_loss: 1.7577 - dense_158_loss: 1.6865 - dense_159_loss: 1.5299 - dense_160_loss: 1.7905 - dense_151_accuracy: 0.4130 - dense_152_accuracy: 0.3238 - dense_153_accuracy: 0.2618 - dense_154_accuracy: 0.2946 - dense_155_accuracy: 0.2204 - dense_156_accuracy: 0.2720 - dense_157_accuracy: 0.2850 - dense_158_accuracy: 0.2912 - dense_159_accuracy: 0.3918 - dense_160_accuracy: 0.2418\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 17.0686 - dense_151_loss: 1.5669 - dense_152_loss: 1.6738 - dense_153_loss: 1.7677 - dense_154_loss: 1.6451 - dense_155_loss: 1.9404 - dense_156_loss: 1.7336 - dense_157_loss: 1.7494 - dense_158_loss: 1.6798 - dense_159_loss: 1.5281 - dense_160_loss: 1.7839 - dense_151_accuracy: 0.4174 - dense_152_accuracy: 0.3246 - dense_153_accuracy: 0.2694 - dense_154_accuracy: 0.2982 - dense_155_accuracy: 0.2166 - dense_156_accuracy: 0.2728 - dense_157_accuracy: 0.2802 - dense_158_accuracy: 0.2924 - dense_159_accuracy: 0.3922 - dense_160_accuracy: 0.2316\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 17.0292 - dense_151_loss: 1.5641 - dense_152_loss: 1.6682 - dense_153_loss: 1.7669 - dense_154_loss: 1.6420 - dense_155_loss: 1.9349 - dense_156_loss: 1.7293 - dense_157_loss: 1.7422 - dense_158_loss: 1.6757 - dense_159_loss: 1.5241 - dense_160_loss: 1.7817 - dense_151_accuracy: 0.4100 - dense_152_accuracy: 0.3280 - dense_153_accuracy: 0.2652 - dense_154_accuracy: 0.2930 - dense_155_accuracy: 0.2310 - dense_156_accuracy: 0.2750 - dense_157_accuracy: 0.2818 - dense_158_accuracy: 0.2932 - dense_159_accuracy: 0.3970 - dense_160_accuracy: 0.2408\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 1s 14ms/step - loss: 17.0261 - dense_151_loss: 1.5652 - dense_152_loss: 1.6684 - dense_153_loss: 1.7664 - dense_154_loss: 1.6416 - dense_155_loss: 1.9336 - dense_156_loss: 1.7300 - dense_157_loss: 1.7429 - dense_158_loss: 1.6748 - dense_159_loss: 1.5226 - dense_160_loss: 1.7806 - dense_151_accuracy: 0.4158 - dense_152_accuracy: 0.3234 - dense_153_accuracy: 0.2664 - dense_154_accuracy: 0.2992 - dense_155_accuracy: 0.2222 - dense_156_accuracy: 0.2698 - dense_157_accuracy: 0.2804 - dense_158_accuracy: 0.2930 - dense_159_accuracy: 0.3944 - dense_160_accuracy: 0.2370\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 17.0077 - dense_151_loss: 1.5582 - dense_152_loss: 1.6656 - dense_153_loss: 1.7658 - dense_154_loss: 1.6419 - dense_155_loss: 1.9323 - dense_156_loss: 1.7257 - dense_157_loss: 1.7414 - dense_158_loss: 1.6729 - dense_159_loss: 1.5221 - dense_160_loss: 1.7819 - dense_151_accuracy: 0.4186 - dense_152_accuracy: 0.3232 - dense_153_accuracy: 0.2742 - dense_154_accuracy: 0.2964 - dense_155_accuracy: 0.2260 - dense_156_accuracy: 0.2716 - dense_157_accuracy: 0.2876 - dense_158_accuracy: 0.2982 - dense_159_accuracy: 0.3982 - dense_160_accuracy: 0.2388\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 16.9777 - dense_151_loss: 1.5563 - dense_152_loss: 1.6615 - dense_153_loss: 1.7638 - dense_154_loss: 1.6388 - dense_155_loss: 1.9301 - dense_156_loss: 1.7229 - dense_157_loss: 1.7379 - dense_158_loss: 1.6717 - dense_159_loss: 1.5171 - dense_160_loss: 1.7775 - dense_151_accuracy: 0.4184 - dense_152_accuracy: 0.3296 - dense_153_accuracy: 0.2716 - dense_154_accuracy: 0.3000 - dense_155_accuracy: 0.2298 - dense_156_accuracy: 0.2740 - dense_157_accuracy: 0.2880 - dense_158_accuracy: 0.2946 - dense_159_accuracy: 0.4032 - dense_160_accuracy: 0.2464\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D3F871F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D3F871F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3F870D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3F870D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 4s 41ms/step - loss: 0.1798\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0105\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0055\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0052\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0050\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0047\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0042\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.0037\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.0033\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.0031\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215CC5839D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215CC5839D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 8s 19ms/step - loss: 19.9320 - dense_164_loss: 1.8863 - dense_165_loss: 2.2861 - dense_166_loss: 1.8999 - dense_167_loss: 1.9200 - dense_168_loss: 2.2639 - dense_169_loss: 2.2738 - dense_170_loss: 1.8849 - dense_171_loss: 1.8775 - dense_172_loss: 1.8921 - dense_173_loss: 1.7476 - dense_164_accuracy: 0.2492 - dense_165_accuracy: 0.1590 - dense_166_accuracy: 0.2520 - dense_167_accuracy: 0.2136 - dense_168_accuracy: 0.1542 - dense_169_accuracy: 0.1604 - dense_170_accuracy: 0.2768 - dense_171_accuracy: 0.2952 - dense_172_accuracy: 0.2660 - dense_173_accuracy: 0.3118\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 14.5659 - dense_164_loss: 1.3909 - dense_165_loss: 1.6209 - dense_166_loss: 1.3952 - dense_167_loss: 1.5133 - dense_168_loss: 1.6269 - dense_169_loss: 1.6064 - dense_170_loss: 1.3953 - dense_171_loss: 1.3353 - dense_172_loss: 1.3454 - dense_173_loss: 1.3363 - dense_164_accuracy: 0.3464 - dense_165_accuracy: 0.2502 - dense_166_accuracy: 0.3566 - dense_167_accuracy: 0.2762 - dense_168_accuracy: 0.2502 - dense_169_accuracy: 0.2530 - dense_170_accuracy: 0.3622 - dense_171_accuracy: 0.3632 - dense_172_accuracy: 0.3662 - dense_173_accuracy: 0.3770\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 14.2828 - dense_164_loss: 1.3613 - dense_165_loss: 1.5859 - dense_166_loss: 1.3689 - dense_167_loss: 1.4827 - dense_168_loss: 1.5909 - dense_169_loss: 1.5776 - dense_170_loss: 1.3763 - dense_171_loss: 1.3004 - dense_172_loss: 1.3238 - dense_173_loss: 1.3149 - dense_164_accuracy: 0.3560 - dense_165_accuracy: 0.2510 - dense_166_accuracy: 0.3558 - dense_167_accuracy: 0.2898 - dense_168_accuracy: 0.2566 - dense_169_accuracy: 0.2452 - dense_170_accuracy: 0.3594 - dense_171_accuracy: 0.3724 - dense_172_accuracy: 0.3648 - dense_173_accuracy: 0.3730\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 13.7983 - dense_164_loss: 1.3211 - dense_165_loss: 1.5258 - dense_166_loss: 1.3289 - dense_167_loss: 1.4456 - dense_168_loss: 1.5334 - dense_169_loss: 1.5205 - dense_170_loss: 1.3279 - dense_171_loss: 1.2463 - dense_172_loss: 1.2682 - dense_173_loss: 1.2805 - dense_164_accuracy: 0.3686 - dense_165_accuracy: 0.2636 - dense_166_accuracy: 0.3704 - dense_167_accuracy: 0.2904 - dense_168_accuracy: 0.2582 - dense_169_accuracy: 0.2572 - dense_170_accuracy: 0.3656 - dense_171_accuracy: 0.3798 - dense_172_accuracy: 0.3778 - dense_173_accuracy: 0.3728\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 13.7326 - dense_164_loss: 1.3149 - dense_165_loss: 1.5214 - dense_166_loss: 1.3243 - dense_167_loss: 1.4361 - dense_168_loss: 1.5274 - dense_169_loss: 1.5124 - dense_170_loss: 1.3097 - dense_171_loss: 1.2406 - dense_172_loss: 1.2694 - dense_173_loss: 1.2763 - dense_164_accuracy: 0.3552 - dense_165_accuracy: 0.2550 - dense_166_accuracy: 0.3592 - dense_167_accuracy: 0.2790 - dense_168_accuracy: 0.2500 - dense_169_accuracy: 0.2542 - dense_170_accuracy: 0.3686 - dense_171_accuracy: 0.3756 - dense_172_accuracy: 0.3696 - dense_173_accuracy: 0.3650\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 13.5596 - dense_164_loss: 1.3023 - dense_165_loss: 1.5025 - dense_166_loss: 1.3032 - dense_167_loss: 1.4200 - dense_168_loss: 1.5090 - dense_169_loss: 1.4965 - dense_170_loss: 1.2973 - dense_171_loss: 1.2259 - dense_172_loss: 1.2512 - dense_173_loss: 1.2517 - dense_164_accuracy: 0.3682 - dense_165_accuracy: 0.2604 - dense_166_accuracy: 0.3758 - dense_167_accuracy: 0.2940 - dense_168_accuracy: 0.2570 - dense_169_accuracy: 0.2610 - dense_170_accuracy: 0.3832 - dense_171_accuracy: 0.3848 - dense_172_accuracy: 0.3726 - dense_173_accuracy: 0.3848\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 13.5416 - dense_164_loss: 1.3018 - dense_165_loss: 1.4999 - dense_166_loss: 1.3069 - dense_167_loss: 1.4136 - dense_168_loss: 1.5059 - dense_169_loss: 1.4946 - dense_170_loss: 1.2960 - dense_171_loss: 1.2181 - dense_172_loss: 1.2518 - dense_173_loss: 1.2530 - dense_164_accuracy: 0.3602 - dense_165_accuracy: 0.2540 - dense_166_accuracy: 0.3702 - dense_167_accuracy: 0.2948 - dense_168_accuracy: 0.2566 - dense_169_accuracy: 0.2548 - dense_170_accuracy: 0.3766 - dense_171_accuracy: 0.3882 - dense_172_accuracy: 0.3772 - dense_173_accuracy: 0.3832\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 13.5147 - dense_164_loss: 1.2996 - dense_165_loss: 1.4932 - dense_166_loss: 1.3039 - dense_167_loss: 1.4149 - dense_168_loss: 1.5019 - dense_169_loss: 1.4894 - dense_170_loss: 1.2882 - dense_171_loss: 1.2204 - dense_172_loss: 1.2482 - dense_173_loss: 1.2549 - dense_164_accuracy: 0.3690 - dense_165_accuracy: 0.2658 - dense_166_accuracy: 0.3666 - dense_167_accuracy: 0.2950 - dense_168_accuracy: 0.2666 - dense_169_accuracy: 0.2650 - dense_170_accuracy: 0.3858 - dense_171_accuracy: 0.3894 - dense_172_accuracy: 0.3726 - dense_173_accuracy: 0.3764\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 13.4629 - dense_164_loss: 1.2990 - dense_165_loss: 1.4898 - dense_166_loss: 1.2976 - dense_167_loss: 1.4080 - dense_168_loss: 1.4940 - dense_169_loss: 1.4851 - dense_170_loss: 1.2874 - dense_171_loss: 1.2176 - dense_172_loss: 1.2391 - dense_173_loss: 1.2452 - dense_164_accuracy: 0.3692 - dense_165_accuracy: 0.2710 - dense_166_accuracy: 0.3720 - dense_167_accuracy: 0.2974 - dense_168_accuracy: 0.2678 - dense_169_accuracy: 0.2680 - dense_170_accuracy: 0.3888 - dense_171_accuracy: 0.3884 - dense_172_accuracy: 0.3876 - dense_173_accuracy: 0.3878\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 13.5977 - dense_164_loss: 1.3047 - dense_165_loss: 1.5023 - dense_166_loss: 1.3107 - dense_167_loss: 1.4234 - dense_168_loss: 1.5095 - dense_169_loss: 1.5000 - dense_170_loss: 1.3045 - dense_171_loss: 1.2290 - dense_172_loss: 1.2547 - dense_173_loss: 1.2589 - dense_164_accuracy: 0.3600 - dense_165_accuracy: 0.2582 - dense_166_accuracy: 0.3658 - dense_167_accuracy: 0.2972 - dense_168_accuracy: 0.2554 - dense_169_accuracy: 0.2576 - dense_170_accuracy: 0.3834 - dense_171_accuracy: 0.3866 - dense_172_accuracy: 0.3740 - dense_173_accuracy: 0.3832\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D2476048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D2476048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4C9D678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4C9D678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 7s 18ms/step - loss: 19.2763 - dense_174_loss: 1.8613 - dense_175_loss: 2.2223 - dense_176_loss: 1.7838 - dense_177_loss: 1.8510 - dense_178_loss: 2.1997 - dense_179_loss: 2.1958 - dense_180_loss: 1.8297 - dense_181_loss: 1.8288 - dense_182_loss: 1.8179 - dense_183_loss: 1.6859 - dense_174_accuracy: 0.2244 - dense_175_accuracy: 0.1598 - dense_176_accuracy: 0.2680 - dense_177_accuracy: 0.2188 - dense_178_accuracy: 0.1642 - dense_179_accuracy: 0.1516 - dense_180_accuracy: 0.2952 - dense_181_accuracy: 0.2940 - dense_182_accuracy: 0.2910 - dense_183_accuracy: 0.3438\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 15.2368 - dense_174_loss: 1.4595 - dense_175_loss: 1.7047 - dense_176_loss: 1.4406 - dense_177_loss: 1.5624 - dense_178_loss: 1.7048 - dense_179_loss: 1.6980 - dense_180_loss: 1.4584 - dense_181_loss: 1.3997 - dense_182_loss: 1.4208 - dense_183_loss: 1.3879 - dense_174_accuracy: 0.3358 - dense_175_accuracy: 0.2226 - dense_176_accuracy: 0.3364 - dense_177_accuracy: 0.2598 - dense_178_accuracy: 0.2286 - dense_179_accuracy: 0.2232 - dense_180_accuracy: 0.3514 - dense_181_accuracy: 0.3546 - dense_182_accuracy: 0.3552 - dense_183_accuracy: 0.3728\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 14.3348 - dense_174_loss: 1.3627 - dense_175_loss: 1.5975 - dense_176_loss: 1.3760 - dense_177_loss: 1.4797 - dense_178_loss: 1.6017 - dense_179_loss: 1.5882 - dense_180_loss: 1.3775 - dense_181_loss: 1.3022 - dense_182_loss: 1.3303 - dense_183_loss: 1.3191 - dense_174_accuracy: 0.3536 - dense_175_accuracy: 0.2342 - dense_176_accuracy: 0.3586 - dense_177_accuracy: 0.2802 - dense_178_accuracy: 0.2346 - dense_179_accuracy: 0.2348 - dense_180_accuracy: 0.3556 - dense_181_accuracy: 0.3752 - dense_182_accuracy: 0.3520 - dense_183_accuracy: 0.3610\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 13.8899 - dense_174_loss: 1.3259 - dense_175_loss: 1.5411 - dense_176_loss: 1.3366 - dense_177_loss: 1.4479 - dense_178_loss: 1.5489 - dense_179_loss: 1.5326 - dense_180_loss: 1.3337 - dense_181_loss: 1.2612 - dense_182_loss: 1.2835 - dense_183_loss: 1.2785 - dense_174_accuracy: 0.3488 - dense_175_accuracy: 0.2458 - dense_176_accuracy: 0.3662 - dense_177_accuracy: 0.2800 - dense_178_accuracy: 0.2434 - dense_179_accuracy: 0.2440 - dense_180_accuracy: 0.3628 - dense_181_accuracy: 0.3754 - dense_182_accuracy: 0.3618 - dense_183_accuracy: 0.3716\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 13.8112 - dense_174_loss: 1.3171 - dense_175_loss: 1.5305 - dense_176_loss: 1.3304 - dense_177_loss: 1.4408 - dense_178_loss: 1.5399 - dense_179_loss: 1.5241 - dense_180_loss: 1.3253 - dense_181_loss: 1.2495 - dense_182_loss: 1.2781 - dense_183_loss: 1.2755 - dense_174_accuracy: 0.3640 - dense_175_accuracy: 0.2488 - dense_176_accuracy: 0.3708 - dense_177_accuracy: 0.2898 - dense_178_accuracy: 0.2470 - dense_179_accuracy: 0.2442 - dense_180_accuracy: 0.3582 - dense_181_accuracy: 0.3776 - dense_182_accuracy: 0.3596 - dense_183_accuracy: 0.3686\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 13.6316 - dense_174_loss: 1.3027 - dense_175_loss: 1.5109 - dense_176_loss: 1.3129 - dense_177_loss: 1.4235 - dense_178_loss: 1.5185 - dense_179_loss: 1.5029 - dense_180_loss: 1.3072 - dense_181_loss: 1.2354 - dense_182_loss: 1.2575 - dense_183_loss: 1.2602 - dense_174_accuracy: 0.3564 - dense_175_accuracy: 0.2468 - dense_176_accuracy: 0.3702 - dense_177_accuracy: 0.2772 - dense_178_accuracy: 0.2420 - dense_179_accuracy: 0.2456 - dense_180_accuracy: 0.3696 - dense_181_accuracy: 0.3716 - dense_182_accuracy: 0.3638 - dense_183_accuracy: 0.3714\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 13.5560 - dense_174_loss: 1.2966 - dense_175_loss: 1.5022 - dense_176_loss: 1.3081 - dense_177_loss: 1.4174 - dense_178_loss: 1.5098 - dense_179_loss: 1.4945 - dense_180_loss: 1.2980 - dense_181_loss: 1.2219 - dense_182_loss: 1.2517 - dense_183_loss: 1.2557 - dense_174_accuracy: 0.3622 - dense_175_accuracy: 0.2462 - dense_176_accuracy: 0.3756 - dense_177_accuracy: 0.2820 - dense_178_accuracy: 0.2438 - dense_179_accuracy: 0.2474 - dense_180_accuracy: 0.3712 - dense_181_accuracy: 0.3810 - dense_182_accuracy: 0.3590 - dense_183_accuracy: 0.3750\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 13.5452 - dense_174_loss: 1.2978 - dense_175_loss: 1.5015 - dense_176_loss: 1.3052 - dense_177_loss: 1.4150 - dense_178_loss: 1.5074 - dense_179_loss: 1.4943 - dense_180_loss: 1.2978 - dense_181_loss: 1.2241 - dense_182_loss: 1.2485 - dense_183_loss: 1.2536 - dense_174_accuracy: 0.3650 - dense_175_accuracy: 0.2396 - dense_176_accuracy: 0.3726 - dense_177_accuracy: 0.2762 - dense_178_accuracy: 0.2364 - dense_179_accuracy: 0.2404 - dense_180_accuracy: 0.3640 - dense_181_accuracy: 0.3744 - dense_182_accuracy: 0.3546 - dense_183_accuracy: 0.3776\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 13.5545 - dense_174_loss: 1.2995 - dense_175_loss: 1.5004 - dense_176_loss: 1.3060 - dense_177_loss: 1.4175 - dense_178_loss: 1.5074 - dense_179_loss: 1.4939 - dense_180_loss: 1.3012 - dense_181_loss: 1.2224 - dense_182_loss: 1.2541 - dense_183_loss: 1.2521 - dense_174_accuracy: 0.3600 - dense_175_accuracy: 0.2532 - dense_176_accuracy: 0.3706 - dense_177_accuracy: 0.2874 - dense_178_accuracy: 0.2458 - dense_179_accuracy: 0.2476 - dense_180_accuracy: 0.3692 - dense_181_accuracy: 0.3824 - dense_182_accuracy: 0.3598 - dense_183_accuracy: 0.3624\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 13.5059 - dense_174_loss: 1.2968 - dense_175_loss: 1.4970 - dense_176_loss: 1.3007 - dense_177_loss: 1.4120 - dense_178_loss: 1.5024 - dense_179_loss: 1.4877 - dense_180_loss: 1.2921 - dense_181_loss: 1.2191 - dense_182_loss: 1.2497 - dense_183_loss: 1.2483 - dense_174_accuracy: 0.3688 - dense_175_accuracy: 0.2538 - dense_176_accuracy: 0.3742 - dense_177_accuracy: 0.2906 - dense_178_accuracy: 0.2586 - dense_179_accuracy: 0.2524 - dense_180_accuracy: 0.3818 - dense_181_accuracy: 0.3854 - dense_182_accuracy: 0.3696 - dense_183_accuracy: 0.3714\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4DD2708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4DD2708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3364EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3364EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 19ms/step - loss: 0.2485\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2433\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.2325\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2120\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1772\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1253\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0735\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0375\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0207\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0140\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3730EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3730EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - 11s 17ms/step - loss: 23.5471 - dense_187_loss: 2.0041 - dense_188_loss: 2.7439 - dense_189_loss: 2.2631 - dense_190_loss: 2.2228 - dense_191_loss: 2.7726 - dense_192_loss: 2.7942 - dense_193_loss: 2.3264 - dense_194_loss: 2.3348 - dense_195_loss: 2.1597 - dense_196_loss: 1.9254 - dense_187_accuracy: 0.2560 - dense_188_accuracy: 0.1040 - dense_189_accuracy: 0.2180 - dense_190_accuracy: 0.1290 - dense_191_accuracy: 0.0950 - dense_192_accuracy: 0.0870 - dense_193_accuracy: 0.1480 - dense_194_accuracy: 0.1700 - dense_195_accuracy: 0.3240 - dense_196_accuracy: 0.3810\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 18.5911 - dense_187_loss: 1.6951 - dense_188_loss: 2.1798 - dense_189_loss: 1.7658 - dense_190_loss: 1.8758 - dense_191_loss: 2.1279 - dense_192_loss: 2.1707 - dense_193_loss: 1.9050 - dense_194_loss: 1.9492 - dense_195_loss: 1.4820 - dense_196_loss: 1.4398 - dense_187_accuracy: 0.3190 - dense_188_accuracy: 0.1900 - dense_189_accuracy: 0.3500 - dense_190_accuracy: 0.2130 - dense_191_accuracy: 0.1960 - dense_192_accuracy: 0.1830 - dense_193_accuracy: 0.2470 - dense_194_accuracy: 0.2100 - dense_195_accuracy: 0.4390 - dense_196_accuracy: 0.4780\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 15.9463 - dense_187_loss: 1.5327 - dense_188_loss: 1.7740 - dense_189_loss: 1.5327 - dense_190_loss: 1.6633 - dense_191_loss: 1.8132 - dense_192_loss: 1.8212 - dense_193_loss: 1.6155 - dense_194_loss: 1.7146 - dense_195_loss: 1.2308 - dense_196_loss: 1.2484 - dense_187_accuracy: 0.3340 - dense_188_accuracy: 0.2350 - dense_189_accuracy: 0.3750 - dense_190_accuracy: 0.2360 - dense_191_accuracy: 0.2060 - dense_192_accuracy: 0.2160 - dense_193_accuracy: 0.2430 - dense_194_accuracy: 0.2250 - dense_195_accuracy: 0.5160 - dense_196_accuracy: 0.5200\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 15.3355 - dense_187_loss: 1.4508 - dense_188_loss: 1.6924 - dense_189_loss: 1.4719 - dense_190_loss: 1.6331 - dense_191_loss: 1.7317 - dense_192_loss: 1.7392 - dense_193_loss: 1.5776 - dense_194_loss: 1.6189 - dense_195_loss: 1.2004 - dense_196_loss: 1.2194 - dense_187_accuracy: 0.3750 - dense_188_accuracy: 0.2230 - dense_189_accuracy: 0.3770 - dense_190_accuracy: 0.2130 - dense_191_accuracy: 0.2390 - dense_192_accuracy: 0.2380 - dense_193_accuracy: 0.2670 - dense_194_accuracy: 0.2280 - dense_195_accuracy: 0.4910 - dense_196_accuracy: 0.5300\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 14.9471 - dense_187_loss: 1.4116 - dense_188_loss: 1.6300 - dense_189_loss: 1.4380 - dense_190_loss: 1.5975 - dense_191_loss: 1.6945 - dense_192_loss: 1.6845 - dense_193_loss: 1.5471 - dense_194_loss: 1.5881 - dense_195_loss: 1.1571 - dense_196_loss: 1.1987 - dense_187_accuracy: 0.3850 - dense_188_accuracy: 0.2480 - dense_189_accuracy: 0.3910 - dense_190_accuracy: 0.2470 - dense_191_accuracy: 0.2490 - dense_192_accuracy: 0.2630 - dense_193_accuracy: 0.3040 - dense_194_accuracy: 0.2420 - dense_195_accuracy: 0.5180 - dense_196_accuracy: 0.5380\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 14.6962 - dense_187_loss: 1.4029 - dense_188_loss: 1.6169 - dense_189_loss: 1.4124 - dense_190_loss: 1.5702 - dense_191_loss: 1.6670 - dense_192_loss: 1.6685 - dense_193_loss: 1.5118 - dense_194_loss: 1.5679 - dense_195_loss: 1.1388 - dense_196_loss: 1.1398 - dense_187_accuracy: 0.3800 - dense_188_accuracy: 0.2490 - dense_189_accuracy: 0.3830 - dense_190_accuracy: 0.2700 - dense_191_accuracy: 0.2570 - dense_192_accuracy: 0.2620 - dense_193_accuracy: 0.3010 - dense_194_accuracy: 0.2850 - dense_195_accuracy: 0.5120 - dense_196_accuracy: 0.5450\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 14.7347 - dense_187_loss: 1.3986 - dense_188_loss: 1.6164 - dense_189_loss: 1.4230 - dense_190_loss: 1.5676 - dense_191_loss: 1.6702 - dense_192_loss: 1.6808 - dense_193_loss: 1.5195 - dense_194_loss: 1.5753 - dense_195_loss: 1.1342 - dense_196_loss: 1.1492 - dense_187_accuracy: 0.3750 - dense_188_accuracy: 0.2260 - dense_189_accuracy: 0.3980 - dense_190_accuracy: 0.2480 - dense_191_accuracy: 0.2410 - dense_192_accuracy: 0.2280 - dense_193_accuracy: 0.2700 - dense_194_accuracy: 0.2560 - dense_195_accuracy: 0.5210 - dense_196_accuracy: 0.5370\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 14.5389 - dense_187_loss: 1.3941 - dense_188_loss: 1.5885 - dense_189_loss: 1.4093 - dense_190_loss: 1.5553 - dense_191_loss: 1.6447 - dense_192_loss: 1.6569 - dense_193_loss: 1.4940 - dense_194_loss: 1.5586 - dense_195_loss: 1.1153 - dense_196_loss: 1.1223 - dense_187_accuracy: 0.3770 - dense_188_accuracy: 0.2590 - dense_189_accuracy: 0.3830 - dense_190_accuracy: 0.2670 - dense_191_accuracy: 0.2460 - dense_192_accuracy: 0.2720 - dense_193_accuracy: 0.3050 - dense_194_accuracy: 0.2790 - dense_195_accuracy: 0.5210 - dense_196_accuracy: 0.5350\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 14.3205 - dense_187_loss: 1.3751 - dense_188_loss: 1.5646 - dense_189_loss: 1.3850 - dense_190_loss: 1.5361 - dense_191_loss: 1.6300 - dense_192_loss: 1.6328 - dense_193_loss: 1.4699 - dense_194_loss: 1.5322 - dense_195_loss: 1.0998 - dense_196_loss: 1.0951 - dense_187_accuracy: 0.4020 - dense_188_accuracy: 0.2850 - dense_189_accuracy: 0.4100 - dense_190_accuracy: 0.2980 - dense_191_accuracy: 0.2770 - dense_192_accuracy: 0.2940 - dense_193_accuracy: 0.3410 - dense_194_accuracy: 0.3020 - dense_195_accuracy: 0.5370 - dense_196_accuracy: 0.5630\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 14.1798 - dense_187_loss: 1.3581 - dense_188_loss: 1.5514 - dense_189_loss: 1.3750 - dense_190_loss: 1.5209 - dense_191_loss: 1.6105 - dense_192_loss: 1.6195 - dense_193_loss: 1.4544 - dense_194_loss: 1.5183 - dense_195_loss: 1.0874 - dense_196_loss: 1.0843 - dense_187_accuracy: 0.4060 - dense_188_accuracy: 0.3100 - dense_189_accuracy: 0.4250 - dense_190_accuracy: 0.3020 - dense_191_accuracy: 0.3010 - dense_192_accuracy: 0.2930 - dense_193_accuracy: 0.3310 - dense_194_accuracy: 0.2940 - dense_195_accuracy: 0.5340 - dense_196_accuracy: 0.5670\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4A8B798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4A8B798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4948DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4948DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - 9s 21ms/step - loss: 22.4862 - dense_197_loss: 1.9732 - dense_198_loss: 2.6337 - dense_199_loss: 2.1858 - dense_200_loss: 2.1727 - dense_201_loss: 2.6232 - dense_202_loss: 2.6628 - dense_203_loss: 2.2207 - dense_204_loss: 2.2622 - dense_205_loss: 1.9672 - dense_206_loss: 1.7848 - dense_197_accuracy: 0.2650 - dense_198_accuracy: 0.1360 - dense_199_accuracy: 0.2460 - dense_200_accuracy: 0.1420 - dense_201_accuracy: 0.1430 - dense_202_accuracy: 0.1540 - dense_203_accuracy: 0.2030 - dense_204_accuracy: 0.1430 - dense_205_accuracy: 0.3490 - dense_206_accuracy: 0.4190\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 17.1356 - dense_197_loss: 1.6145 - dense_198_loss: 1.9369 - dense_199_loss: 1.6313 - dense_200_loss: 1.7526 - dense_201_loss: 1.9707 - dense_202_loss: 2.0260 - dense_203_loss: 1.7466 - dense_204_loss: 1.8293 - dense_205_loss: 1.3133 - dense_206_loss: 1.3143 - dense_197_accuracy: 0.3320 - dense_198_accuracy: 0.2230 - dense_199_accuracy: 0.3270 - dense_200_accuracy: 0.2050 - dense_201_accuracy: 0.2080 - dense_202_accuracy: 0.2090 - dense_203_accuracy: 0.2650 - dense_204_accuracy: 0.2210 - dense_205_accuracy: 0.4890 - dense_206_accuracy: 0.5130\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 15.8056 - dense_197_loss: 1.5152 - dense_198_loss: 1.7342 - dense_199_loss: 1.5172 - dense_200_loss: 1.6716 - dense_201_loss: 1.7954 - dense_202_loss: 1.7992 - dense_203_loss: 1.6028 - dense_204_loss: 1.7024 - dense_205_loss: 1.2186 - dense_206_loss: 1.2490 - dense_197_accuracy: 0.3580 - dense_198_accuracy: 0.2410 - dense_199_accuracy: 0.3690 - dense_200_accuracy: 0.2270 - dense_201_accuracy: 0.2340 - dense_202_accuracy: 0.2260 - dense_203_accuracy: 0.2660 - dense_204_accuracy: 0.2140 - dense_205_accuracy: 0.5080 - dense_206_accuracy: 0.5040\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 15.2166 - dense_197_loss: 1.4440 - dense_198_loss: 1.6557 - dense_199_loss: 1.4560 - dense_200_loss: 1.6368 - dense_201_loss: 1.7336 - dense_202_loss: 1.7293 - dense_203_loss: 1.5568 - dense_204_loss: 1.6222 - dense_205_loss: 1.1732 - dense_206_loss: 1.2090 - dense_197_accuracy: 0.3620 - dense_198_accuracy: 0.2440 - dense_199_accuracy: 0.3720 - dense_200_accuracy: 0.2330 - dense_201_accuracy: 0.2420 - dense_202_accuracy: 0.2540 - dense_203_accuracy: 0.2780 - dense_204_accuracy: 0.2490 - dense_205_accuracy: 0.5110 - dense_206_accuracy: 0.5410\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 14.8369 - dense_197_loss: 1.4136 - dense_198_loss: 1.6147 - dense_199_loss: 1.4297 - dense_200_loss: 1.5905 - dense_201_loss: 1.6752 - dense_202_loss: 1.6880 - dense_203_loss: 1.5295 - dense_204_loss: 1.5749 - dense_205_loss: 1.1536 - dense_206_loss: 1.1673 - dense_197_accuracy: 0.3500 - dense_198_accuracy: 0.2410 - dense_199_accuracy: 0.3790 - dense_200_accuracy: 0.2370 - dense_201_accuracy: 0.2400 - dense_202_accuracy: 0.2450 - dense_203_accuracy: 0.2910 - dense_204_accuracy: 0.2650 - dense_205_accuracy: 0.5180 - dense_206_accuracy: 0.5440\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 14.7087 - dense_197_loss: 1.4074 - dense_198_loss: 1.6058 - dense_199_loss: 1.4215 - dense_200_loss: 1.5726 - dense_201_loss: 1.6641 - dense_202_loss: 1.6745 - dense_203_loss: 1.5138 - dense_204_loss: 1.5722 - dense_205_loss: 1.1337 - dense_206_loss: 1.1430 - dense_197_accuracy: 0.3810 - dense_198_accuracy: 0.2520 - dense_199_accuracy: 0.3840 - dense_200_accuracy: 0.2600 - dense_201_accuracy: 0.2570 - dense_202_accuracy: 0.2570 - dense_203_accuracy: 0.3010 - dense_204_accuracy: 0.2570 - dense_205_accuracy: 0.5100 - dense_206_accuracy: 0.5360\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 14.6451 - dense_197_loss: 1.4071 - dense_198_loss: 1.6017 - dense_199_loss: 1.4130 - dense_200_loss: 1.5619 - dense_201_loss: 1.6604 - dense_202_loss: 1.6721 - dense_203_loss: 1.5012 - dense_204_loss: 1.5674 - dense_205_loss: 1.1301 - dense_206_loss: 1.1302 - dense_197_accuracy: 0.3730 - dense_198_accuracy: 0.2460 - dense_199_accuracy: 0.3860 - dense_200_accuracy: 0.2510 - dense_201_accuracy: 0.2490 - dense_202_accuracy: 0.2390 - dense_203_accuracy: 0.2910 - dense_204_accuracy: 0.2640 - dense_205_accuracy: 0.5030 - dense_206_accuracy: 0.5460\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 14.6729 - dense_197_loss: 1.4069 - dense_198_loss: 1.6016 - dense_199_loss: 1.4163 - dense_200_loss: 1.5669 - dense_201_loss: 1.6602 - dense_202_loss: 1.6731 - dense_203_loss: 1.5071 - dense_204_loss: 1.5735 - dense_205_loss: 1.1319 - dense_206_loss: 1.1355 - dense_197_accuracy: 0.3610 - dense_198_accuracy: 0.2430 - dense_199_accuracy: 0.3670 - dense_200_accuracy: 0.2390 - dense_201_accuracy: 0.2460 - dense_202_accuracy: 0.2220 - dense_203_accuracy: 0.2800 - dense_204_accuracy: 0.2460 - dense_205_accuracy: 0.5090 - dense_206_accuracy: 0.5240\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 14.6091 - dense_197_loss: 1.3967 - dense_198_loss: 1.6005 - dense_199_loss: 1.4133 - dense_200_loss: 1.5601 - dense_201_loss: 1.6564 - dense_202_loss: 1.6732 - dense_203_loss: 1.5008 - dense_204_loss: 1.5664 - dense_205_loss: 1.1184 - dense_206_loss: 1.1235 - dense_197_accuracy: 0.3410 - dense_198_accuracy: 0.2530 - dense_199_accuracy: 0.3820 - dense_200_accuracy: 0.2440 - dense_201_accuracy: 0.2580 - dense_202_accuracy: 0.2460 - dense_203_accuracy: 0.2950 - dense_204_accuracy: 0.2660 - dense_205_accuracy: 0.5200 - dense_206_accuracy: 0.5450\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 14.6105 - dense_197_loss: 1.4037 - dense_198_loss: 1.5955 - dense_199_loss: 1.4126 - dense_200_loss: 1.5539 - dense_201_loss: 1.6595 - dense_202_loss: 1.6709 - dense_203_loss: 1.4991 - dense_204_loss: 1.5663 - dense_205_loss: 1.1270 - dense_206_loss: 1.1219 - dense_197_accuracy: 0.3550 - dense_198_accuracy: 0.2430 - dense_199_accuracy: 0.3730 - dense_200_accuracy: 0.2370 - dense_201_accuracy: 0.2350 - dense_202_accuracy: 0.2450 - dense_203_accuracy: 0.2700 - dense_204_accuracy: 0.2540 - dense_205_accuracy: 0.5040 - dense_206_accuracy: 0.5480\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D272D828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D272D828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215CFE94DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215CFE94DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 22ms/step - loss: 0.2486\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2431\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.2314\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.2094\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1700\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1185\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0671\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0339\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0190\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0128\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D49809D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D49809D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - 9s 15ms/step - loss: 23.5738 - dense_210_loss: 2.0098 - dense_211_loss: 2.7476 - dense_212_loss: 2.2680 - dense_213_loss: 2.2527 - dense_214_loss: 2.7037 - dense_215_loss: 2.7979 - dense_216_loss: 2.3719 - dense_217_loss: 2.3590 - dense_218_loss: 2.1722 - dense_219_loss: 1.8911 - dense_210_accuracy: 0.2460 - dense_211_accuracy: 0.0990 - dense_212_accuracy: 0.2440 - dense_213_accuracy: 0.1640 - dense_214_accuracy: 0.1030 - dense_215_accuracy: 0.0880 - dense_216_accuracy: 0.1510 - dense_217_accuracy: 0.1750 - dense_218_accuracy: 0.2460 - dense_219_accuracy: 0.3900\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 19.7665 - dense_210_loss: 1.6836 - dense_211_loss: 2.2817 - dense_212_loss: 1.8977 - dense_213_loss: 2.0418 - dense_214_loss: 2.2369 - dense_215_loss: 2.3700 - dense_216_loss: 2.0210 - dense_217_loss: 2.0655 - dense_218_loss: 1.6824 - dense_219_loss: 1.4858 - dense_210_accuracy: 0.3190 - dense_211_accuracy: 0.1680 - dense_212_accuracy: 0.3330 - dense_213_accuracy: 0.1770 - dense_214_accuracy: 0.1900 - dense_215_accuracy: 0.1710 - dense_216_accuracy: 0.2220 - dense_217_accuracy: 0.2050 - dense_218_accuracy: 0.4320 - dense_219_accuracy: 0.4310\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 16.5560 - dense_210_loss: 1.5028 - dense_211_loss: 1.8560 - dense_212_loss: 1.5977 - dense_213_loss: 1.7316 - dense_214_loss: 1.8152 - dense_215_loss: 1.9853 - dense_216_loss: 1.7026 - dense_217_loss: 1.7839 - dense_218_loss: 1.2965 - dense_219_loss: 1.2843 - dense_210_accuracy: 0.3670 - dense_211_accuracy: 0.2050 - dense_212_accuracy: 0.3650 - dense_213_accuracy: 0.2700 - dense_214_accuracy: 0.2310 - dense_215_accuracy: 0.2180 - dense_216_accuracy: 0.2530 - dense_217_accuracy: 0.2280 - dense_218_accuracy: 0.4930 - dense_219_accuracy: 0.4900\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 15.8825 - dense_210_loss: 1.4414 - dense_211_loss: 1.7753 - dense_212_loss: 1.5386 - dense_213_loss: 1.6641 - dense_214_loss: 1.7432 - dense_215_loss: 1.9130 - dense_216_loss: 1.6626 - dense_217_loss: 1.6707 - dense_218_loss: 1.2275 - dense_219_loss: 1.2462 - dense_210_accuracy: 0.3780 - dense_211_accuracy: 0.2020 - dense_212_accuracy: 0.3720 - dense_213_accuracy: 0.2510 - dense_214_accuracy: 0.2210 - dense_215_accuracy: 0.2000 - dense_216_accuracy: 0.2430 - dense_217_accuracy: 0.2430 - dense_218_accuracy: 0.4810 - dense_219_accuracy: 0.4970\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 15.4955 - dense_210_loss: 1.4080 - dense_211_loss: 1.7198 - dense_212_loss: 1.4956 - dense_213_loss: 1.6554 - dense_214_loss: 1.6926 - dense_215_loss: 1.8655 - dense_216_loss: 1.6270 - dense_217_loss: 1.6457 - dense_218_loss: 1.1851 - dense_219_loss: 1.2007 - dense_210_accuracy: 0.3890 - dense_211_accuracy: 0.2390 - dense_212_accuracy: 0.3500 - dense_213_accuracy: 0.2370 - dense_214_accuracy: 0.2350 - dense_215_accuracy: 0.2450 - dense_216_accuracy: 0.2700 - dense_217_accuracy: 0.2580 - dense_218_accuracy: 0.4960 - dense_219_accuracy: 0.5130\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 15.1363 - dense_210_loss: 1.3672 - dense_211_loss: 1.6852 - dense_212_loss: 1.4653 - dense_213_loss: 1.6261 - dense_214_loss: 1.6475 - dense_215_loss: 1.8239 - dense_216_loss: 1.6056 - dense_217_loss: 1.6003 - dense_218_loss: 1.1514 - dense_219_loss: 1.1639 - dense_210_accuracy: 0.3950 - dense_211_accuracy: 0.2590 - dense_212_accuracy: 0.3650 - dense_213_accuracy: 0.2670 - dense_214_accuracy: 0.2630 - dense_215_accuracy: 0.2250 - dense_216_accuracy: 0.3050 - dense_217_accuracy: 0.2780 - dense_218_accuracy: 0.5150 - dense_219_accuracy: 0.5280\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 15.0666 - dense_210_loss: 1.3705 - dense_211_loss: 1.6818 - dense_212_loss: 1.4631 - dense_213_loss: 1.6110 - dense_214_loss: 1.6500 - dense_215_loss: 1.8118 - dense_216_loss: 1.5942 - dense_217_loss: 1.5960 - dense_218_loss: 1.1414 - dense_219_loss: 1.1467 - dense_210_accuracy: 0.3750 - dense_211_accuracy: 0.2240 - dense_212_accuracy: 0.3570 - dense_213_accuracy: 0.2530 - dense_214_accuracy: 0.2400 - dense_215_accuracy: 0.2280 - dense_216_accuracy: 0.2660 - dense_217_accuracy: 0.2800 - dense_218_accuracy: 0.5090 - dense_219_accuracy: 0.5300\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 14.9763 - dense_210_loss: 1.3652 - dense_211_loss: 1.6739 - dense_212_loss: 1.4445 - dense_213_loss: 1.6004 - dense_214_loss: 1.6371 - dense_215_loss: 1.8020 - dense_216_loss: 1.5868 - dense_217_loss: 1.5841 - dense_218_loss: 1.1372 - dense_219_loss: 1.1451 - dense_210_accuracy: 0.3690 - dense_211_accuracy: 0.2420 - dense_212_accuracy: 0.3600 - dense_213_accuracy: 0.2730 - dense_214_accuracy: 0.2300 - dense_215_accuracy: 0.2270 - dense_216_accuracy: 0.2780 - dense_217_accuracy: 0.2770 - dense_218_accuracy: 0.5090 - dense_219_accuracy: 0.5210\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 14.8066 - dense_210_loss: 1.3569 - dense_211_loss: 1.6542 - dense_212_loss: 1.4374 - dense_213_loss: 1.5798 - dense_214_loss: 1.6236 - dense_215_loss: 1.7875 - dense_216_loss: 1.5668 - dense_217_loss: 1.5619 - dense_218_loss: 1.1189 - dense_219_loss: 1.1196 - dense_210_accuracy: 0.3910 - dense_211_accuracy: 0.2330 - dense_212_accuracy: 0.3630 - dense_213_accuracy: 0.2710 - dense_214_accuracy: 0.2480 - dense_215_accuracy: 0.2520 - dense_216_accuracy: 0.2940 - dense_217_accuracy: 0.2830 - dense_218_accuracy: 0.5050 - dense_219_accuracy: 0.5250\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 14.7207 - dense_210_loss: 1.3539 - dense_211_loss: 1.6466 - dense_212_loss: 1.4274 - dense_213_loss: 1.5739 - dense_214_loss: 1.6087 - dense_215_loss: 1.7728 - dense_216_loss: 1.5520 - dense_217_loss: 1.5580 - dense_218_loss: 1.1080 - dense_219_loss: 1.1193 - dense_210_accuracy: 0.3830 - dense_211_accuracy: 0.2610 - dense_212_accuracy: 0.3670 - dense_213_accuracy: 0.2770 - dense_214_accuracy: 0.2760 - dense_215_accuracy: 0.2630 - dense_216_accuracy: 0.3220 - dense_217_accuracy: 0.2800 - dense_218_accuracy: 0.5560 - dense_219_accuracy: 0.5300\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4C60948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4C60948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D06BEF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D06BEF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - 10s 16ms/step - loss: 23.2433 - dense_220_loss: 1.9884 - dense_221_loss: 2.6811 - dense_222_loss: 2.2898 - dense_223_loss: 2.2724 - dense_224_loss: 2.7059 - dense_225_loss: 2.7396 - dense_226_loss: 2.3215 - dense_227_loss: 2.3107 - dense_228_loss: 2.0613 - dense_229_loss: 1.8726 - dense_220_accuracy: 0.2840 - dense_221_accuracy: 0.1300 - dense_222_accuracy: 0.1500 - dense_223_accuracy: 0.1600 - dense_224_accuracy: 0.1270 - dense_225_accuracy: 0.0980 - dense_226_accuracy: 0.1490 - dense_227_accuracy: 0.1820 - dense_228_accuracy: 0.3640 - dense_229_accuracy: 0.3980\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 17.9502 - dense_220_loss: 1.6456 - dense_221_loss: 1.9935 - dense_222_loss: 1.7838 - dense_223_loss: 1.8536 - dense_224_loss: 2.0345 - dense_225_loss: 2.1638 - dense_226_loss: 1.8817 - dense_227_loss: 1.8896 - dense_228_loss: 1.3802 - dense_229_loss: 1.3240 - dense_220_accuracy: 0.3370 - dense_221_accuracy: 0.2140 - dense_222_accuracy: 0.2900 - dense_223_accuracy: 0.2060 - dense_224_accuracy: 0.2200 - dense_225_accuracy: 0.1880 - dense_226_accuracy: 0.2440 - dense_227_accuracy: 0.1940 - dense_228_accuracy: 0.4840 - dense_229_accuracy: 0.4960\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 16.4237 - dense_220_loss: 1.5109 - dense_221_loss: 1.8298 - dense_222_loss: 1.5986 - dense_223_loss: 1.7443 - dense_224_loss: 1.8024 - dense_225_loss: 1.9705 - dense_226_loss: 1.7082 - dense_227_loss: 1.7464 - dense_228_loss: 1.2651 - dense_229_loss: 1.2476 - dense_220_accuracy: 0.3660 - dense_221_accuracy: 0.2150 - dense_222_accuracy: 0.3380 - dense_223_accuracy: 0.2220 - dense_224_accuracy: 0.2130 - dense_225_accuracy: 0.2010 - dense_226_accuracy: 0.2480 - dense_227_accuracy: 0.2320 - dense_228_accuracy: 0.4920 - dense_229_accuracy: 0.5060\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 15.7702 - dense_220_loss: 1.4456 - dense_221_loss: 1.7556 - dense_222_loss: 1.5297 - dense_223_loss: 1.6852 - dense_224_loss: 1.7218 - dense_225_loss: 1.9022 - dense_226_loss: 1.6545 - dense_227_loss: 1.6703 - dense_228_loss: 1.1955 - dense_229_loss: 1.2097 - dense_220_accuracy: 0.3830 - dense_221_accuracy: 0.2250 - dense_222_accuracy: 0.3510 - dense_223_accuracy: 0.2260 - dense_224_accuracy: 0.2260 - dense_225_accuracy: 0.2110 - dense_226_accuracy: 0.2500 - dense_227_accuracy: 0.2180 - dense_228_accuracy: 0.4980 - dense_229_accuracy: 0.5220\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 15.3386 - dense_220_loss: 1.4016 - dense_221_loss: 1.6995 - dense_222_loss: 1.4844 - dense_223_loss: 1.6515 - dense_224_loss: 1.6726 - dense_225_loss: 1.8542 - dense_226_loss: 1.6140 - dense_227_loss: 1.6170 - dense_228_loss: 1.1709 - dense_229_loss: 1.1729 - dense_220_accuracy: 0.3750 - dense_221_accuracy: 0.2280 - dense_222_accuracy: 0.3690 - dense_223_accuracy: 0.2560 - dense_224_accuracy: 0.2440 - dense_225_accuracy: 0.2270 - dense_226_accuracy: 0.2850 - dense_227_accuracy: 0.2430 - dense_228_accuracy: 0.5060 - dense_229_accuracy: 0.5140\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 15.1667 - dense_220_loss: 1.3814 - dense_221_loss: 1.6886 - dense_222_loss: 1.4617 - dense_223_loss: 1.6324 - dense_224_loss: 1.6576 - dense_225_loss: 1.8290 - dense_226_loss: 1.6034 - dense_227_loss: 1.6099 - dense_228_loss: 1.1507 - dense_229_loss: 1.1519 - dense_220_accuracy: 0.3750 - dense_221_accuracy: 0.2290 - dense_222_accuracy: 0.3710 - dense_223_accuracy: 0.2480 - dense_224_accuracy: 0.2460 - dense_225_accuracy: 0.2090 - dense_226_accuracy: 0.2700 - dense_227_accuracy: 0.2340 - dense_228_accuracy: 0.4920 - dense_229_accuracy: 0.5240\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 15.0742 - dense_220_loss: 1.3701 - dense_221_loss: 1.6785 - dense_222_loss: 1.4594 - dense_223_loss: 1.6117 - dense_224_loss: 1.6481 - dense_225_loss: 1.8154 - dense_226_loss: 1.5947 - dense_227_loss: 1.6055 - dense_228_loss: 1.1458 - dense_229_loss: 1.1449 - dense_220_accuracy: 0.3690 - dense_221_accuracy: 0.2260 - dense_222_accuracy: 0.3580 - dense_223_accuracy: 0.2310 - dense_224_accuracy: 0.2220 - dense_225_accuracy: 0.2450 - dense_226_accuracy: 0.2720 - dense_227_accuracy: 0.2260 - dense_228_accuracy: 0.4890 - dense_229_accuracy: 0.5260\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 14.9767 - dense_220_loss: 1.3681 - dense_221_loss: 1.6633 - dense_222_loss: 1.4462 - dense_223_loss: 1.6056 - dense_224_loss: 1.6334 - dense_225_loss: 1.7990 - dense_226_loss: 1.5885 - dense_227_loss: 1.5936 - dense_228_loss: 1.1452 - dense_229_loss: 1.1339 - dense_220_accuracy: 0.3810 - dense_221_accuracy: 0.2200 - dense_222_accuracy: 0.3690 - dense_223_accuracy: 0.2500 - dense_224_accuracy: 0.2370 - dense_225_accuracy: 0.2280 - dense_226_accuracy: 0.2680 - dense_227_accuracy: 0.2360 - dense_228_accuracy: 0.4960 - dense_229_accuracy: 0.5250\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 14.9809 - dense_220_loss: 1.3757 - dense_221_loss: 1.6661 - dense_222_loss: 1.4442 - dense_223_loss: 1.6014 - dense_224_loss: 1.6383 - dense_225_loss: 1.8025 - dense_226_loss: 1.5874 - dense_227_loss: 1.5893 - dense_228_loss: 1.1412 - dense_229_loss: 1.1348 - dense_220_accuracy: 0.3800 - dense_221_accuracy: 0.2110 - dense_222_accuracy: 0.3570 - dense_223_accuracy: 0.2400 - dense_224_accuracy: 0.2210 - dense_225_accuracy: 0.2060 - dense_226_accuracy: 0.2580 - dense_227_accuracy: 0.2340 - dense_228_accuracy: 0.4860 - dense_229_accuracy: 0.5260\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 14.8382 - dense_220_loss: 1.3579 - dense_221_loss: 1.6434 - dense_222_loss: 1.4364 - dense_223_loss: 1.5865 - dense_224_loss: 1.6231 - dense_225_loss: 1.7840 - dense_226_loss: 1.5759 - dense_227_loss: 1.5812 - dense_228_loss: 1.1270 - dense_229_loss: 1.1227 - dense_220_accuracy: 0.3800 - dense_221_accuracy: 0.2440 - dense_222_accuracy: 0.3640 - dense_223_accuracy: 0.2700 - dense_224_accuracy: 0.2430 - dense_225_accuracy: 0.2390 - dense_226_accuracy: 0.2890 - dense_227_accuracy: 0.2440 - dense_228_accuracy: 0.5020 - dense_229_accuracy: 0.5300\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D2B44F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D2B44F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D01385E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D01385E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 18ms/step - loss: 0.2490\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.2466\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.2431\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2382\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.2308\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.2202\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.2067\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1882\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1636\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1362\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D264F558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D264F558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "8/8 [==============================] - 9s 23ms/step - loss: 24.7698 - dense_233_loss: 2.4563 - dense_234_loss: 2.4389 - dense_235_loss: 2.4584 - dense_236_loss: 2.3640 - dense_237_loss: 2.9424 - dense_238_loss: 2.5115 - dense_239_loss: 2.5270 - dense_240_loss: 2.3856 - dense_241_loss: 2.1855 - dense_242_loss: 2.5001 - dense_233_accuracy: 0.1240 - dense_234_accuracy: 0.1240 - dense_235_accuracy: 0.1280 - dense_236_accuracy: 0.2120 - dense_237_accuracy: 0.0980 - dense_238_accuracy: 0.1180 - dense_239_accuracy: 0.1400 - dense_240_accuracy: 0.1380 - dense_241_accuracy: 0.1560 - dense_242_accuracy: 0.1180\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 23.2491 - dense_233_loss: 2.2940 - dense_234_loss: 2.2441 - dense_235_loss: 2.2730 - dense_236_loss: 2.1882 - dense_237_loss: 2.7989 - dense_238_loss: 2.4307 - dense_239_loss: 2.3930 - dense_240_loss: 2.2241 - dense_241_loss: 2.0084 - dense_242_loss: 2.3947 - dense_233_accuracy: 0.2200 - dense_234_accuracy: 0.2120 - dense_235_accuracy: 0.1740 - dense_236_accuracy: 0.2540 - dense_237_accuracy: 0.1160 - dense_238_accuracy: 0.1280 - dense_239_accuracy: 0.1640 - dense_240_accuracy: 0.1420 - dense_241_accuracy: 0.1900 - dense_242_accuracy: 0.1580\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 21.5534 - dense_233_loss: 2.0622 - dense_234_loss: 2.0829 - dense_235_loss: 2.1244 - dense_236_loss: 2.0070 - dense_237_loss: 2.6300 - dense_238_loss: 2.2406 - dense_239_loss: 2.2082 - dense_240_loss: 2.0749 - dense_241_loss: 1.8777 - dense_242_loss: 2.2455 - dense_233_accuracy: 0.2940 - dense_234_accuracy: 0.2360 - dense_235_accuracy: 0.2060 - dense_236_accuracy: 0.2740 - dense_237_accuracy: 0.1200 - dense_238_accuracy: 0.1600 - dense_239_accuracy: 0.1960 - dense_240_accuracy: 0.2480 - dense_241_accuracy: 0.2580 - dense_242_accuracy: 0.2400\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 20.2728 - dense_233_loss: 1.9250 - dense_234_loss: 1.9782 - dense_235_loss: 1.9955 - dense_236_loss: 1.8935 - dense_237_loss: 2.4307 - dense_238_loss: 2.1160 - dense_239_loss: 2.1220 - dense_240_loss: 1.9155 - dense_241_loss: 1.7948 - dense_242_loss: 2.1015 - dense_233_accuracy: 0.2940 - dense_234_accuracy: 0.2080 - dense_235_accuracy: 0.2760 - dense_236_accuracy: 0.3040 - dense_237_accuracy: 0.1480 - dense_238_accuracy: 0.1900 - dense_239_accuracy: 0.2000 - dense_240_accuracy: 0.2400 - dense_241_accuracy: 0.3220 - dense_242_accuracy: 0.2440\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 19.6581 - dense_233_loss: 1.8553 - dense_234_loss: 1.8962 - dense_235_loss: 1.9381 - dense_236_loss: 1.8491 - dense_237_loss: 2.3038 - dense_238_loss: 2.0607 - dense_239_loss: 2.0719 - dense_240_loss: 1.8670 - dense_241_loss: 1.7505 - dense_242_loss: 2.0656 - dense_233_accuracy: 0.3500 - dense_234_accuracy: 0.2800 - dense_235_accuracy: 0.2620 - dense_236_accuracy: 0.3380 - dense_237_accuracy: 0.1760 - dense_238_accuracy: 0.1760 - dense_239_accuracy: 0.2160 - dense_240_accuracy: 0.2900 - dense_241_accuracy: 0.3260 - dense_242_accuracy: 0.2500\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 19.0800 - dense_233_loss: 1.7806 - dense_234_loss: 1.8282 - dense_235_loss: 1.8893 - dense_236_loss: 1.8080 - dense_237_loss: 2.2202 - dense_238_loss: 2.0014 - dense_239_loss: 2.0067 - dense_240_loss: 1.8097 - dense_241_loss: 1.7298 - dense_242_loss: 2.0061 - dense_233_accuracy: 0.3600 - dense_234_accuracy: 0.3160 - dense_235_accuracy: 0.2780 - dense_236_accuracy: 0.3300 - dense_237_accuracy: 0.2060 - dense_238_accuracy: 0.2440 - dense_239_accuracy: 0.2260 - dense_240_accuracy: 0.3040 - dense_241_accuracy: 0.3520 - dense_242_accuracy: 0.2880\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 18.3930 - dense_233_loss: 1.6889 - dense_234_loss: 1.7523 - dense_235_loss: 1.8589 - dense_236_loss: 1.7554 - dense_237_loss: 2.1314 - dense_238_loss: 1.9339 - dense_239_loss: 1.9323 - dense_240_loss: 1.7437 - dense_241_loss: 1.6710 - dense_242_loss: 1.9251 - dense_233_accuracy: 0.3660 - dense_234_accuracy: 0.3200 - dense_235_accuracy: 0.2840 - dense_236_accuracy: 0.3280 - dense_237_accuracy: 0.2340 - dense_238_accuracy: 0.2780 - dense_239_accuracy: 0.2640 - dense_240_accuracy: 0.3300 - dense_241_accuracy: 0.3500 - dense_242_accuracy: 0.3080\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 17.7481 - dense_233_loss: 1.6317 - dense_234_loss: 1.6774 - dense_235_loss: 1.8114 - dense_236_loss: 1.7026 - dense_237_loss: 2.0619 - dense_238_loss: 1.8610 - dense_239_loss: 1.8575 - dense_240_loss: 1.6963 - dense_241_loss: 1.6187 - dense_242_loss: 1.8297 - dense_233_accuracy: 0.3680 - dense_234_accuracy: 0.3420 - dense_235_accuracy: 0.3040 - dense_236_accuracy: 0.3240 - dense_237_accuracy: 0.2660 - dense_238_accuracy: 0.2900 - dense_239_accuracy: 0.2620 - dense_240_accuracy: 0.3000 - dense_241_accuracy: 0.3820 - dense_242_accuracy: 0.3000\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 17.1889 - dense_233_loss: 1.5692 - dense_234_loss: 1.6115 - dense_235_loss: 1.7517 - dense_236_loss: 1.6474 - dense_237_loss: 1.9847 - dense_238_loss: 1.8114 - dense_239_loss: 1.8008 - dense_240_loss: 1.6656 - dense_241_loss: 1.5846 - dense_242_loss: 1.7619 - dense_233_accuracy: 0.3640 - dense_234_accuracy: 0.3340 - dense_235_accuracy: 0.3060 - dense_236_accuracy: 0.3380 - dense_237_accuracy: 0.2680 - dense_238_accuracy: 0.2640 - dense_239_accuracy: 0.2740 - dense_240_accuracy: 0.3180 - dense_241_accuracy: 0.3880 - dense_242_accuracy: 0.2980\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 16.7337 - dense_233_loss: 1.5378 - dense_234_loss: 1.5734 - dense_235_loss: 1.6906 - dense_236_loss: 1.6098 - dense_237_loss: 1.9201 - dense_238_loss: 1.7648 - dense_239_loss: 1.7707 - dense_240_loss: 1.6293 - dense_241_loss: 1.5347 - dense_242_loss: 1.7025 - dense_233_accuracy: 0.3580 - dense_234_accuracy: 0.3560 - dense_235_accuracy: 0.3120 - dense_236_accuracy: 0.3460 - dense_237_accuracy: 0.2760 - dense_238_accuracy: 0.2940 - dense_239_accuracy: 0.2620 - dense_240_accuracy: 0.3140 - dense_241_accuracy: 0.3820 - dense_242_accuracy: 0.3280\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D3B12048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D3B12048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3FFA0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3FFA0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "8/8 [==============================] - 10s 39ms/step - loss: 24.4916 - dense_243_loss: 2.4296 - dense_244_loss: 2.3883 - dense_245_loss: 2.3786 - dense_246_loss: 2.3349 - dense_247_loss: 2.9101 - dense_248_loss: 2.5005 - dense_249_loss: 2.5391 - dense_250_loss: 2.3306 - dense_251_loss: 2.1683 - dense_252_loss: 2.5116 - dense_243_accuracy: 0.1180 - dense_244_accuracy: 0.1500 - dense_245_accuracy: 0.1620 - dense_246_accuracy: 0.2160 - dense_247_accuracy: 0.0960 - dense_248_accuracy: 0.1140 - dense_249_accuracy: 0.1540 - dense_250_accuracy: 0.1580 - dense_251_accuracy: 0.1580 - dense_252_accuracy: 0.1280\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 22.0304 - dense_243_loss: 2.1855 - dense_244_loss: 2.1071 - dense_245_loss: 2.1484 - dense_246_loss: 2.0426 - dense_247_loss: 2.6710 - dense_248_loss: 2.3305 - dense_249_loss: 2.2485 - dense_250_loss: 2.0862 - dense_251_loss: 1.9195 - dense_252_loss: 2.2914 - dense_243_accuracy: 0.1960 - dense_244_accuracy: 0.2180 - dense_245_accuracy: 0.2340 - dense_246_accuracy: 0.3100 - dense_247_accuracy: 0.1340 - dense_248_accuracy: 0.1740 - dense_249_accuracy: 0.2120 - dense_250_accuracy: 0.2000 - dense_251_accuracy: 0.2560 - dense_252_accuracy: 0.2380\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 20.6640 - dense_243_loss: 2.0208 - dense_244_loss: 1.9521 - dense_245_loss: 2.0454 - dense_246_loss: 1.9241 - dense_247_loss: 2.4935 - dense_248_loss: 2.1925 - dense_249_loss: 2.1512 - dense_250_loss: 1.9397 - dense_251_loss: 1.7939 - dense_252_loss: 2.1508 - dense_243_accuracy: 0.3160 - dense_244_accuracy: 0.2820 - dense_245_accuracy: 0.2440 - dense_246_accuracy: 0.3300 - dense_247_accuracy: 0.2260 - dense_248_accuracy: 0.1660 - dense_249_accuracy: 0.2120 - dense_250_accuracy: 0.2740 - dense_251_accuracy: 0.3500 - dense_252_accuracy: 0.2400\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 19.5795 - dense_243_loss: 1.8579 - dense_244_loss: 1.8447 - dense_245_loss: 1.9606 - dense_246_loss: 1.8281 - dense_247_loss: 2.3132 - dense_248_loss: 2.1152 - dense_249_loss: 2.0413 - dense_250_loss: 1.8593 - dense_251_loss: 1.7289 - dense_252_loss: 2.0304 - dense_243_accuracy: 0.3180 - dense_244_accuracy: 0.3400 - dense_245_accuracy: 0.2840 - dense_246_accuracy: 0.3000 - dense_247_accuracy: 0.2200 - dense_248_accuracy: 0.2200 - dense_249_accuracy: 0.2220 - dense_250_accuracy: 0.2660 - dense_251_accuracy: 0.3460 - dense_252_accuracy: 0.2800\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 18.5341 - dense_243_loss: 1.7324 - dense_244_loss: 1.7577 - dense_245_loss: 1.8871 - dense_246_loss: 1.7380 - dense_247_loss: 2.1696 - dense_248_loss: 1.9811 - dense_249_loss: 1.9451 - dense_250_loss: 1.7374 - dense_251_loss: 1.6549 - dense_252_loss: 1.9308 - dense_243_accuracy: 0.3620 - dense_244_accuracy: 0.3200 - dense_245_accuracy: 0.2680 - dense_246_accuracy: 0.3300 - dense_247_accuracy: 0.2320 - dense_248_accuracy: 0.2440 - dense_249_accuracy: 0.2500 - dense_250_accuracy: 0.3380 - dense_251_accuracy: 0.3480 - dense_252_accuracy: 0.3020\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 17.8039 - dense_243_loss: 1.6424 - dense_244_loss: 1.6975 - dense_245_loss: 1.8202 - dense_246_loss: 1.6925 - dense_247_loss: 2.0733 - dense_248_loss: 1.8742 - dense_249_loss: 1.8753 - dense_250_loss: 1.7056 - dense_251_loss: 1.5870 - dense_252_loss: 1.8359 - dense_243_accuracy: 0.3600 - dense_244_accuracy: 0.3300 - dense_245_accuracy: 0.2880 - dense_246_accuracy: 0.3340 - dense_247_accuracy: 0.2540 - dense_248_accuracy: 0.2740 - dense_249_accuracy: 0.2620 - dense_250_accuracy: 0.3220 - dense_251_accuracy: 0.3760 - dense_252_accuracy: 0.3140\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 16.8566 - dense_243_loss: 1.5260 - dense_244_loss: 1.5773 - dense_245_loss: 1.7324 - dense_246_loss: 1.6289 - dense_247_loss: 1.9464 - dense_248_loss: 1.7738 - dense_249_loss: 1.7906 - dense_250_loss: 1.6277 - dense_251_loss: 1.5235 - dense_252_loss: 1.7301 - dense_243_accuracy: 0.3700 - dense_244_accuracy: 0.3420 - dense_245_accuracy: 0.3220 - dense_246_accuracy: 0.3400 - dense_247_accuracy: 0.2640 - dense_248_accuracy: 0.2800 - dense_249_accuracy: 0.2920 - dense_250_accuracy: 0.3200 - dense_251_accuracy: 0.3880 - dense_252_accuracy: 0.3160\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 16.3519 - dense_243_loss: 1.4821 - dense_244_loss: 1.5273 - dense_245_loss: 1.6856 - dense_246_loss: 1.5796 - dense_247_loss: 1.8719 - dense_248_loss: 1.7221 - dense_249_loss: 1.7362 - dense_250_loss: 1.5898 - dense_251_loss: 1.4819 - dense_252_loss: 1.6755 - dense_243_accuracy: 0.3860 - dense_244_accuracy: 0.3760 - dense_245_accuracy: 0.3180 - dense_246_accuracy: 0.3420 - dense_247_accuracy: 0.2920 - dense_248_accuracy: 0.2900 - dense_249_accuracy: 0.2940 - dense_250_accuracy: 0.3380 - dense_251_accuracy: 0.3940 - dense_252_accuracy: 0.3160\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 16.2155 - dense_243_loss: 1.4878 - dense_244_loss: 1.5156 - dense_245_loss: 1.6674 - dense_246_loss: 1.5547 - dense_247_loss: 1.8386 - dense_248_loss: 1.7132 - dense_249_loss: 1.7129 - dense_250_loss: 1.5830 - dense_251_loss: 1.4787 - dense_252_loss: 1.6638 - dense_243_accuracy: 0.3760 - dense_244_accuracy: 0.3620 - dense_245_accuracy: 0.2940 - dense_246_accuracy: 0.3380 - dense_247_accuracy: 0.2600 - dense_248_accuracy: 0.2800 - dense_249_accuracy: 0.2820 - dense_250_accuracy: 0.3180 - dense_251_accuracy: 0.3780 - dense_252_accuracy: 0.3100\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 16.0026 - dense_243_loss: 1.4570 - dense_244_loss: 1.4886 - dense_245_loss: 1.6475 - dense_246_loss: 1.5485 - dense_247_loss: 1.8148 - dense_248_loss: 1.6919 - dense_249_loss: 1.6960 - dense_250_loss: 1.5622 - dense_251_loss: 1.4548 - dense_252_loss: 1.6413 - dense_243_accuracy: 0.3800 - dense_244_accuracy: 0.3620 - dense_245_accuracy: 0.3000 - dense_246_accuracy: 0.3380 - dense_247_accuracy: 0.2620 - dense_248_accuracy: 0.2880 - dense_249_accuracy: 0.2800 - dense_250_accuracy: 0.3200 - dense_251_accuracy: 0.4000 - dense_252_accuracy: 0.3100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215CFEEE288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215CFEEE288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D38B1CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D38B1CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 3s 25ms/step - loss: 0.2062\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 0.0261\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0058\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 0.0050\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 0.0048\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 0.0047\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 0.0047\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 0.0047\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 0.0046\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 0.0046\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4AACCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4AACCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 11s 17ms/step - loss: 17.3445 - dense_256_loss: 1.5449 - dense_257_loss: 1.7258 - dense_258_loss: 1.8251 - dense_259_loss: 1.6981 - dense_260_loss: 1.9712 - dense_261_loss: 1.7650 - dense_262_loss: 1.6799 - dense_263_loss: 1.7251 - dense_264_loss: 1.5921 - dense_265_loss: 1.8173 - dense_256_accuracy: 0.4104 - dense_257_accuracy: 0.2738 - dense_258_accuracy: 0.2164 - dense_259_accuracy: 0.2866 - dense_260_accuracy: 0.2102 - dense_261_accuracy: 0.2608 - dense_262_accuracy: 0.3296 - dense_263_accuracy: 0.2718 - dense_264_accuracy: 0.3550 - dense_265_accuracy: 0.2170\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 15.3757 - dense_256_loss: 1.3169 - dense_257_loss: 1.5487 - dense_258_loss: 1.6434 - dense_259_loss: 1.5195 - dense_260_loss: 1.7092 - dense_261_loss: 1.5504 - dense_262_loss: 1.4874 - dense_263_loss: 1.5589 - dense_264_loss: 1.4130 - dense_265_loss: 1.6284 - dense_256_accuracy: 0.4688 - dense_257_accuracy: 0.3038 - dense_258_accuracy: 0.2408 - dense_259_accuracy: 0.3012 - dense_260_accuracy: 0.2410 - dense_261_accuracy: 0.3004 - dense_262_accuracy: 0.3574 - dense_263_accuracy: 0.2984 - dense_264_accuracy: 0.4022 - dense_265_accuracy: 0.2392\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 15.3197 - dense_256_loss: 1.3152 - dense_257_loss: 1.5428 - dense_258_loss: 1.6346 - dense_259_loss: 1.5103 - dense_260_loss: 1.7042 - dense_261_loss: 1.5454 - dense_262_loss: 1.4838 - dense_263_loss: 1.5512 - dense_264_loss: 1.4109 - dense_265_loss: 1.6211 - dense_256_accuracy: 0.4718 - dense_257_accuracy: 0.3076 - dense_258_accuracy: 0.2338 - dense_259_accuracy: 0.2912 - dense_260_accuracy: 0.2316 - dense_261_accuracy: 0.2934 - dense_262_accuracy: 0.3580 - dense_263_accuracy: 0.3002 - dense_264_accuracy: 0.4004 - dense_265_accuracy: 0.2404\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 15.3203 - dense_256_loss: 1.3122 - dense_257_loss: 1.5430 - dense_258_loss: 1.6352 - dense_259_loss: 1.5141 - dense_260_loss: 1.7078 - dense_261_loss: 1.5454 - dense_262_loss: 1.4844 - dense_263_loss: 1.5546 - dense_264_loss: 1.4059 - dense_265_loss: 1.6178 - dense_256_accuracy: 0.4756 - dense_257_accuracy: 0.3066 - dense_258_accuracy: 0.2350 - dense_259_accuracy: 0.2982 - dense_260_accuracy: 0.2406 - dense_261_accuracy: 0.2928 - dense_262_accuracy: 0.3524 - dense_263_accuracy: 0.2964 - dense_264_accuracy: 0.4034 - dense_265_accuracy: 0.2424\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 15.2538 - dense_256_loss: 1.3071 - dense_257_loss: 1.5417 - dense_258_loss: 1.6292 - dense_259_loss: 1.5097 - dense_260_loss: 1.6975 - dense_261_loss: 1.5343 - dense_262_loss: 1.4772 - dense_263_loss: 1.5446 - dense_264_loss: 1.3998 - dense_265_loss: 1.6127 - dense_256_accuracy: 0.4770 - dense_257_accuracy: 0.3112 - dense_258_accuracy: 0.2508 - dense_259_accuracy: 0.3018 - dense_260_accuracy: 0.2452 - dense_261_accuracy: 0.3044 - dense_262_accuracy: 0.3608 - dense_263_accuracy: 0.3010 - dense_264_accuracy: 0.4046 - dense_265_accuracy: 0.2486\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 15.2504 - dense_256_loss: 1.3091 - dense_257_loss: 1.5388 - dense_258_loss: 1.6245 - dense_259_loss: 1.5056 - dense_260_loss: 1.6976 - dense_261_loss: 1.5318 - dense_262_loss: 1.4808 - dense_263_loss: 1.5470 - dense_264_loss: 1.4019 - dense_265_loss: 1.6133 - dense_256_accuracy: 0.4742 - dense_257_accuracy: 0.3084 - dense_258_accuracy: 0.2454 - dense_259_accuracy: 0.3078 - dense_260_accuracy: 0.2370 - dense_261_accuracy: 0.3016 - dense_262_accuracy: 0.3582 - dense_263_accuracy: 0.3076 - dense_264_accuracy: 0.4108 - dense_265_accuracy: 0.2458\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 15.1906 - dense_256_loss: 1.3064 - dense_257_loss: 1.5288 - dense_258_loss: 1.6224 - dense_259_loss: 1.4979 - dense_260_loss: 1.6904 - dense_261_loss: 1.5285 - dense_262_loss: 1.4739 - dense_263_loss: 1.5405 - dense_264_loss: 1.3929 - dense_265_loss: 1.6089 - dense_256_accuracy: 0.4714 - dense_257_accuracy: 0.3198 - dense_258_accuracy: 0.2576 - dense_259_accuracy: 0.3094 - dense_260_accuracy: 0.2538 - dense_261_accuracy: 0.3174 - dense_262_accuracy: 0.3726 - dense_263_accuracy: 0.3132 - dense_264_accuracy: 0.4124 - dense_265_accuracy: 0.2630\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 15.1027 - dense_256_loss: 1.2975 - dense_257_loss: 1.5197 - dense_258_loss: 1.6141 - dense_259_loss: 1.4917 - dense_260_loss: 1.6814 - dense_261_loss: 1.5191 - dense_262_loss: 1.4660 - dense_263_loss: 1.5326 - dense_264_loss: 1.3859 - dense_265_loss: 1.5947 - dense_256_accuracy: 0.4762 - dense_257_accuracy: 0.3288 - dense_258_accuracy: 0.2610 - dense_259_accuracy: 0.3240 - dense_260_accuracy: 0.2662 - dense_261_accuracy: 0.3142 - dense_262_accuracy: 0.3718 - dense_263_accuracy: 0.3216 - dense_264_accuracy: 0.4136 - dense_265_accuracy: 0.2714\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 15.0377 - dense_256_loss: 1.2875 - dense_257_loss: 1.5128 - dense_258_loss: 1.6049 - dense_259_loss: 1.4841 - dense_260_loss: 1.6723 - dense_261_loss: 1.5124 - dense_262_loss: 1.4617 - dense_263_loss: 1.5256 - dense_264_loss: 1.3839 - dense_265_loss: 1.5924 - dense_256_accuracy: 0.4818 - dense_257_accuracy: 0.3230 - dense_258_accuracy: 0.2690 - dense_259_accuracy: 0.3252 - dense_260_accuracy: 0.2678 - dense_261_accuracy: 0.3242 - dense_262_accuracy: 0.3802 - dense_263_accuracy: 0.3238 - dense_264_accuracy: 0.4246 - dense_265_accuracy: 0.2670\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 14.9064 - dense_256_loss: 1.2800 - dense_257_loss: 1.5010 - dense_258_loss: 1.5893 - dense_259_loss: 1.4681 - dense_260_loss: 1.6585 - dense_261_loss: 1.5010 - dense_262_loss: 1.4507 - dense_263_loss: 1.5114 - dense_264_loss: 1.3706 - dense_265_loss: 1.5757 - dense_256_accuracy: 0.4870 - dense_257_accuracy: 0.3356 - dense_258_accuracy: 0.2884 - dense_259_accuracy: 0.3330 - dense_260_accuracy: 0.2898 - dense_261_accuracy: 0.3326 - dense_262_accuracy: 0.3830 - dense_263_accuracy: 0.3438 - dense_264_accuracy: 0.4300 - dense_265_accuracy: 0.2920\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4B2A558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4B2A558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4A8B5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4A8B5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 12s 17ms/step - loss: 17.1192 - dense_266_loss: 1.5067 - dense_267_loss: 1.7086 - dense_268_loss: 1.8335 - dense_269_loss: 1.6777 - dense_270_loss: 1.9380 - dense_271_loss: 1.7155 - dense_272_loss: 1.6739 - dense_273_loss: 1.6920 - dense_274_loss: 1.5940 - dense_275_loss: 1.7794 - dense_266_accuracy: 0.4326 - dense_267_accuracy: 0.2750 - dense_268_accuracy: 0.2166 - dense_269_accuracy: 0.2756 - dense_270_accuracy: 0.2076 - dense_271_accuracy: 0.2616 - dense_272_accuracy: 0.3248 - dense_273_accuracy: 0.2890 - dense_274_accuracy: 0.3712 - dense_275_accuracy: 0.2198\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 15.3999 - dense_266_loss: 1.3226 - dense_267_loss: 1.5526 - dense_268_loss: 1.6420 - dense_269_loss: 1.5186 - dense_270_loss: 1.7155 - dense_271_loss: 1.5512 - dense_272_loss: 1.4923 - dense_273_loss: 1.5575 - dense_274_loss: 1.4201 - dense_275_loss: 1.6276 - dense_266_accuracy: 0.4672 - dense_267_accuracy: 0.2878 - dense_268_accuracy: 0.2322 - dense_269_accuracy: 0.2864 - dense_270_accuracy: 0.2236 - dense_271_accuracy: 0.2946 - dense_272_accuracy: 0.3494 - dense_273_accuracy: 0.2984 - dense_274_accuracy: 0.3822 - dense_275_accuracy: 0.2310\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 15.2912 - dense_266_loss: 1.3076 - dense_267_loss: 1.5437 - dense_268_loss: 1.6348 - dense_269_loss: 1.5084 - dense_270_loss: 1.7024 - dense_271_loss: 1.5411 - dense_272_loss: 1.4809 - dense_273_loss: 1.5492 - dense_274_loss: 1.4026 - dense_275_loss: 1.6205 - dense_266_accuracy: 0.4764 - dense_267_accuracy: 0.2980 - dense_268_accuracy: 0.2354 - dense_269_accuracy: 0.3044 - dense_270_accuracy: 0.2324 - dense_271_accuracy: 0.2898 - dense_272_accuracy: 0.3592 - dense_273_accuracy: 0.3018 - dense_274_accuracy: 0.4026 - dense_275_accuracy: 0.2374\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 15.2889 - dense_266_loss: 1.3114 - dense_267_loss: 1.5435 - dense_268_loss: 1.6295 - dense_269_loss: 1.5077 - dense_270_loss: 1.6996 - dense_271_loss: 1.5401 - dense_272_loss: 1.4820 - dense_273_loss: 1.5486 - dense_274_loss: 1.4076 - dense_275_loss: 1.6189 - dense_266_accuracy: 0.4760 - dense_267_accuracy: 0.3022 - dense_268_accuracy: 0.2454 - dense_269_accuracy: 0.3046 - dense_270_accuracy: 0.2412 - dense_271_accuracy: 0.2974 - dense_272_accuracy: 0.3606 - dense_273_accuracy: 0.2970 - dense_274_accuracy: 0.4056 - dense_275_accuracy: 0.2482\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 15.2666 - dense_266_loss: 1.3062 - dense_267_loss: 1.5399 - dense_268_loss: 1.6307 - dense_269_loss: 1.5051 - dense_270_loss: 1.6981 - dense_271_loss: 1.5361 - dense_272_loss: 1.4791 - dense_273_loss: 1.5482 - dense_274_loss: 1.4052 - dense_275_loss: 1.6180 - dense_266_accuracy: 0.4762 - dense_267_accuracy: 0.3066 - dense_268_accuracy: 0.2434 - dense_269_accuracy: 0.3066 - dense_270_accuracy: 0.2432 - dense_271_accuracy: 0.3090 - dense_272_accuracy: 0.3534 - dense_273_accuracy: 0.2962 - dense_274_accuracy: 0.4004 - dense_275_accuracy: 0.2334\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 15.2769 - dense_266_loss: 1.3087 - dense_267_loss: 1.5419 - dense_268_loss: 1.6314 - dense_269_loss: 1.5045 - dense_270_loss: 1.7017 - dense_271_loss: 1.5377 - dense_272_loss: 1.4787 - dense_273_loss: 1.5460 - dense_274_loss: 1.4086 - dense_275_loss: 1.6177 - dense_266_accuracy: 0.4760 - dense_267_accuracy: 0.3094 - dense_268_accuracy: 0.2392 - dense_269_accuracy: 0.2970 - dense_270_accuracy: 0.2418 - dense_271_accuracy: 0.3006 - dense_272_accuracy: 0.3604 - dense_273_accuracy: 0.2978 - dense_274_accuracy: 0.4070 - dense_275_accuracy: 0.2426\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 15.2964 - dense_266_loss: 1.3091 - dense_267_loss: 1.5425 - dense_268_loss: 1.6337 - dense_269_loss: 1.5075 - dense_270_loss: 1.7010 - dense_271_loss: 1.5416 - dense_272_loss: 1.4810 - dense_273_loss: 1.5519 - dense_274_loss: 1.4082 - dense_275_loss: 1.6201 - dense_266_accuracy: 0.4760 - dense_267_accuracy: 0.3056 - dense_268_accuracy: 0.2382 - dense_269_accuracy: 0.2952 - dense_270_accuracy: 0.2320 - dense_271_accuracy: 0.2994 - dense_272_accuracy: 0.3642 - dense_273_accuracy: 0.2922 - dense_274_accuracy: 0.4024 - dense_275_accuracy: 0.2432\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 15.2505 - dense_266_loss: 1.3050 - dense_267_loss: 1.5403 - dense_268_loss: 1.6280 - dense_269_loss: 1.5037 - dense_270_loss: 1.6978 - dense_271_loss: 1.5352 - dense_272_loss: 1.4768 - dense_273_loss: 1.5442 - dense_274_loss: 1.4040 - dense_275_loss: 1.6155 - dense_266_accuracy: 0.4762 - dense_267_accuracy: 0.2934 - dense_268_accuracy: 0.2396 - dense_269_accuracy: 0.2950 - dense_270_accuracy: 0.2338 - dense_271_accuracy: 0.2918 - dense_272_accuracy: 0.3506 - dense_273_accuracy: 0.3000 - dense_274_accuracy: 0.3994 - dense_275_accuracy: 0.2390\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 15.2406 - dense_266_loss: 1.3048 - dense_267_loss: 1.5362 - dense_268_loss: 1.6265 - dense_269_loss: 1.5017 - dense_270_loss: 1.6987 - dense_271_loss: 1.5351 - dense_272_loss: 1.4769 - dense_273_loss: 1.5439 - dense_274_loss: 1.4026 - dense_275_loss: 1.6143 - dense_266_accuracy: 0.4760 - dense_267_accuracy: 0.2982 - dense_268_accuracy: 0.2426 - dense_269_accuracy: 0.3086 - dense_270_accuracy: 0.2328 - dense_271_accuracy: 0.3058 - dense_272_accuracy: 0.3520 - dense_273_accuracy: 0.3018 - dense_274_accuracy: 0.4020 - dense_275_accuracy: 0.2418\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 15.2522 - dense_266_loss: 1.3076 - dense_267_loss: 1.5394 - dense_268_loss: 1.6285 - dense_269_loss: 1.5031 - dense_270_loss: 1.6976 - dense_271_loss: 1.5358 - dense_272_loss: 1.4778 - dense_273_loss: 1.5420 - dense_274_loss: 1.4057 - dense_275_loss: 1.6146 - dense_266_accuracy: 0.4764 - dense_267_accuracy: 0.3060 - dense_268_accuracy: 0.2432 - dense_269_accuracy: 0.3064 - dense_270_accuracy: 0.2368 - dense_271_accuracy: 0.3018 - dense_272_accuracy: 0.3588 - dense_273_accuracy: 0.3042 - dense_274_accuracy: 0.4044 - dense_275_accuracy: 0.2492\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4B20E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4B20E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D49804C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D49804C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "157/157 [==============================] - 5s 24ms/step - loss: 0.1317\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 4s 23ms/step - loss: 0.0061\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 4s 24ms/step - loss: 0.0051\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 4s 24ms/step - loss: 0.0049\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 4s 25ms/step - loss: 0.0047\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 4s 25ms/step - loss: 0.0044\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 4s 26ms/step - loss: 0.0039\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 4s 26ms/step - loss: 0.0036\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 4s 26ms/step - loss: 0.0034\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 4s 24ms/step - loss: 0.0033\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4AACAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4AACAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "157/157 [==============================] - 4s 6ms/step - loss: 16.6317 - dense_279_loss: 1.4978 - dense_280_loss: 1.9144 - dense_281_loss: 1.5426 - dense_282_loss: 1.6453 - dense_283_loss: 1.9036 - dense_284_loss: 1.9244 - dense_285_loss: 1.6912 - dense_286_loss: 1.5730 - dense_287_loss: 1.4865 - dense_288_loss: 1.4529 - dense_279_accuracy: 0.3698 - dense_280_accuracy: 0.2054 - dense_281_accuracy: 0.3809 - dense_282_accuracy: 0.2886 - dense_283_accuracy: 0.2014 - dense_284_accuracy: 0.2058 - dense_285_accuracy: 0.2751 - dense_286_accuracy: 0.2899 - dense_287_accuracy: 0.3732 - dense_288_accuracy: 0.3738\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 14.3791 - dense_279_loss: 1.3121 - dense_280_loss: 1.6291 - dense_281_loss: 1.3106 - dense_282_loss: 1.4586 - dense_283_loss: 1.6293 - dense_284_loss: 1.6408 - dense_285_loss: 1.4714 - dense_286_loss: 1.3730 - dense_287_loss: 1.2598 - dense_288_loss: 1.2944 - dense_279_accuracy: 0.4213 - dense_280_accuracy: 0.2464 - dense_281_accuracy: 0.4338 - dense_282_accuracy: 0.3150 - dense_283_accuracy: 0.2492 - dense_284_accuracy: 0.2401 - dense_285_accuracy: 0.3126 - dense_286_accuracy: 0.3133 - dense_287_accuracy: 0.4072 - dense_288_accuracy: 0.4010\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 14.2902 - dense_279_loss: 1.3052 - dense_280_loss: 1.6194 - dense_281_loss: 1.3002 - dense_282_loss: 1.4531 - dense_283_loss: 1.6227 - dense_284_loss: 1.6317 - dense_285_loss: 1.4624 - dense_286_loss: 1.3611 - dense_287_loss: 1.2501 - dense_288_loss: 1.2842 - dense_279_accuracy: 0.4237 - dense_280_accuracy: 0.2449 - dense_281_accuracy: 0.4325 - dense_282_accuracy: 0.3174 - dense_283_accuracy: 0.2426 - dense_284_accuracy: 0.2456 - dense_285_accuracy: 0.3171 - dense_286_accuracy: 0.3187 - dense_287_accuracy: 0.4101 - dense_288_accuracy: 0.3966\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 14.2487 - dense_279_loss: 1.3054 - dense_280_loss: 1.6139 - dense_281_loss: 1.2991 - dense_282_loss: 1.4472 - dense_283_loss: 1.6163 - dense_284_loss: 1.6247 - dense_285_loss: 1.4614 - dense_286_loss: 1.3580 - dense_287_loss: 1.2459 - dense_288_loss: 1.2769 - dense_279_accuracy: 0.4250 - dense_280_accuracy: 0.2399 - dense_281_accuracy: 0.4309 - dense_282_accuracy: 0.3177 - dense_283_accuracy: 0.2442 - dense_284_accuracy: 0.2398 - dense_285_accuracy: 0.3062 - dense_286_accuracy: 0.3149 - dense_287_accuracy: 0.4070 - dense_288_accuracy: 0.4002\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 14.2175 - dense_279_loss: 1.2995 - dense_280_loss: 1.6107 - dense_281_loss: 1.2969 - dense_282_loss: 1.4440 - dense_283_loss: 1.6140 - dense_284_loss: 1.6217 - dense_285_loss: 1.4561 - dense_286_loss: 1.3549 - dense_287_loss: 1.2429 - dense_288_loss: 1.2767 - dense_279_accuracy: 0.4242 - dense_280_accuracy: 0.2427 - dense_281_accuracy: 0.4327 - dense_282_accuracy: 0.3254 - dense_283_accuracy: 0.2396 - dense_284_accuracy: 0.2452 - dense_285_accuracy: 0.3106 - dense_286_accuracy: 0.3251 - dense_287_accuracy: 0.4127 - dense_288_accuracy: 0.4036\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 14.1923 - dense_279_loss: 1.2970 - dense_280_loss: 1.6074 - dense_281_loss: 1.2965 - dense_282_loss: 1.4450 - dense_283_loss: 1.6079 - dense_284_loss: 1.6192 - dense_285_loss: 1.4537 - dense_286_loss: 1.3536 - dense_287_loss: 1.2397 - dense_288_loss: 1.2722 - dense_279_accuracy: 0.4237 - dense_280_accuracy: 0.2546 - dense_281_accuracy: 0.4341 - dense_282_accuracy: 0.3254 - dense_283_accuracy: 0.2515 - dense_284_accuracy: 0.2492 - dense_285_accuracy: 0.3078 - dense_286_accuracy: 0.3281 - dense_287_accuracy: 0.4159 - dense_288_accuracy: 0.4048\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 14.1591 - dense_279_loss: 1.2970 - dense_280_loss: 1.6016 - dense_281_loss: 1.2927 - dense_282_loss: 1.4397 - dense_283_loss: 1.6044 - dense_284_loss: 1.6156 - dense_285_loss: 1.4519 - dense_286_loss: 1.3494 - dense_287_loss: 1.2368 - dense_288_loss: 1.2701 - dense_279_accuracy: 0.4212 - dense_280_accuracy: 0.2642 - dense_281_accuracy: 0.4333 - dense_282_accuracy: 0.3248 - dense_283_accuracy: 0.2630 - dense_284_accuracy: 0.2534 - dense_285_accuracy: 0.3097 - dense_286_accuracy: 0.3309 - dense_287_accuracy: 0.4235 - dense_288_accuracy: 0.4042\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 14.1348 - dense_279_loss: 1.2921 - dense_280_loss: 1.5989 - dense_281_loss: 1.2910 - dense_282_loss: 1.4359 - dense_283_loss: 1.6021 - dense_284_loss: 1.6123 - dense_285_loss: 1.4522 - dense_286_loss: 1.3488 - dense_287_loss: 1.2329 - dense_288_loss: 1.2686 - dense_279_accuracy: 0.4282 - dense_280_accuracy: 0.2630 - dense_281_accuracy: 0.4378 - dense_282_accuracy: 0.3308 - dense_283_accuracy: 0.2555 - dense_284_accuracy: 0.2560 - dense_285_accuracy: 0.3111 - dense_286_accuracy: 0.3373 - dense_287_accuracy: 0.4210 - dense_288_accuracy: 0.4169\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 14.0690 - dense_279_loss: 1.2874 - dense_280_loss: 1.5919 - dense_281_loss: 1.2836 - dense_282_loss: 1.4302 - dense_283_loss: 1.5942 - dense_284_loss: 1.6051 - dense_285_loss: 1.4418 - dense_286_loss: 1.3394 - dense_287_loss: 1.2301 - dense_288_loss: 1.2653 - dense_279_accuracy: 0.4282 - dense_280_accuracy: 0.2690 - dense_281_accuracy: 0.4367 - dense_282_accuracy: 0.3385 - dense_283_accuracy: 0.2690 - dense_284_accuracy: 0.2680 - dense_285_accuracy: 0.3233 - dense_286_accuracy: 0.3424 - dense_287_accuracy: 0.4290 - dense_288_accuracy: 0.4181\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 14.0139 - dense_279_loss: 1.2833 - dense_280_loss: 1.5848 - dense_281_loss: 1.2785 - dense_282_loss: 1.4261 - dense_283_loss: 1.5864 - dense_284_loss: 1.6002 - dense_285_loss: 1.4355 - dense_286_loss: 1.3368 - dense_287_loss: 1.2242 - dense_288_loss: 1.2581 - dense_279_accuracy: 0.4316 - dense_280_accuracy: 0.2734 - dense_281_accuracy: 0.4369 - dense_282_accuracy: 0.3377 - dense_283_accuracy: 0.2695 - dense_284_accuracy: 0.2647 - dense_285_accuracy: 0.3262 - dense_286_accuracy: 0.3441 - dense_287_accuracy: 0.4278 - dense_288_accuracy: 0.4183\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D34ECC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D34ECC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4C11708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4C11708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "157/157 [==============================] - 5s 10ms/step - loss: 16.2028 - dense_289_loss: 1.4639 - dense_290_loss: 1.8500 - dense_291_loss: 1.4996 - dense_292_loss: 1.6300 - dense_293_loss: 1.8568 - dense_294_loss: 1.8587 - dense_295_loss: 1.6359 - dense_296_loss: 1.5310 - dense_297_loss: 1.4578 - dense_298_loss: 1.4191 - dense_289_accuracy: 0.3892 - dense_290_accuracy: 0.2206 - dense_291_accuracy: 0.3919 - dense_292_accuracy: 0.2956 - dense_293_accuracy: 0.2161 - dense_294_accuracy: 0.2253 - dense_295_accuracy: 0.2912 - dense_296_accuracy: 0.2994 - dense_297_accuracy: 0.3779 - dense_298_accuracy: 0.3713\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 14.3617 - dense_289_loss: 1.3104 - dense_290_loss: 1.6292 - dense_291_loss: 1.3090 - dense_292_loss: 1.4567 - dense_293_loss: 1.6313 - dense_294_loss: 1.6378 - dense_295_loss: 1.4724 - dense_296_loss: 1.3691 - dense_297_loss: 1.2601 - dense_298_loss: 1.2857 - dense_289_accuracy: 0.4166 - dense_290_accuracy: 0.2440 - dense_291_accuracy: 0.4286 - dense_292_accuracy: 0.3149 - dense_293_accuracy: 0.2440 - dense_294_accuracy: 0.2397 - dense_295_accuracy: 0.3069 - dense_296_accuracy: 0.3249 - dense_297_accuracy: 0.4129 - dense_298_accuracy: 0.3993\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.2657 - dense_289_loss: 1.3037 - dense_290_loss: 1.6162 - dense_291_loss: 1.3002 - dense_292_loss: 1.4488 - dense_293_loss: 1.6197 - dense_294_loss: 1.6272 - dense_295_loss: 1.4606 - dense_296_loss: 1.3575 - dense_297_loss: 1.2495 - dense_298_loss: 1.2823 - dense_289_accuracy: 0.4237 - dense_290_accuracy: 0.2340 - dense_291_accuracy: 0.4338 - dense_292_accuracy: 0.3169 - dense_293_accuracy: 0.2422 - dense_294_accuracy: 0.2414 - dense_295_accuracy: 0.3052 - dense_296_accuracy: 0.3132 - dense_297_accuracy: 0.4068 - dense_298_accuracy: 0.3979\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.2172 - dense_289_loss: 1.2978 - dense_290_loss: 1.6098 - dense_291_loss: 1.2970 - dense_292_loss: 1.4454 - dense_293_loss: 1.6121 - dense_294_loss: 1.6234 - dense_295_loss: 1.4556 - dense_296_loss: 1.3547 - dense_297_loss: 1.2448 - dense_298_loss: 1.2766 - dense_289_accuracy: 0.4266 - dense_290_accuracy: 0.2440 - dense_291_accuracy: 0.4323 - dense_292_accuracy: 0.3214 - dense_293_accuracy: 0.2492 - dense_294_accuracy: 0.2442 - dense_295_accuracy: 0.3139 - dense_296_accuracy: 0.3186 - dense_297_accuracy: 0.4104 - dense_298_accuracy: 0.4019\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 14.2086 - dense_289_loss: 1.2977 - dense_290_loss: 1.6079 - dense_291_loss: 1.2965 - dense_292_loss: 1.4447 - dense_293_loss: 1.6128 - dense_294_loss: 1.6218 - dense_295_loss: 1.4546 - dense_296_loss: 1.3545 - dense_297_loss: 1.2426 - dense_298_loss: 1.2755 - dense_289_accuracy: 0.4248 - dense_290_accuracy: 0.2426 - dense_291_accuracy: 0.4333 - dense_292_accuracy: 0.3164 - dense_293_accuracy: 0.2460 - dense_294_accuracy: 0.2455 - dense_295_accuracy: 0.3101 - dense_296_accuracy: 0.3204 - dense_297_accuracy: 0.4086 - dense_298_accuracy: 0.4034\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.1657 - dense_289_loss: 1.2932 - dense_290_loss: 1.6062 - dense_291_loss: 1.2916 - dense_292_loss: 1.4402 - dense_293_loss: 1.6079 - dense_294_loss: 1.6153 - dense_295_loss: 1.4513 - dense_296_loss: 1.3482 - dense_297_loss: 1.2407 - dense_298_loss: 1.2710 - dense_289_accuracy: 0.4228 - dense_290_accuracy: 0.2463 - dense_291_accuracy: 0.4335 - dense_292_accuracy: 0.3261 - dense_293_accuracy: 0.2517 - dense_294_accuracy: 0.2466 - dense_295_accuracy: 0.3073 - dense_296_accuracy: 0.3299 - dense_297_accuracy: 0.4112 - dense_298_accuracy: 0.4071\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 14.1765 - dense_289_loss: 1.2950 - dense_290_loss: 1.6050 - dense_291_loss: 1.2904 - dense_292_loss: 1.4406 - dense_293_loss: 1.6087 - dense_294_loss: 1.6186 - dense_295_loss: 1.4529 - dense_296_loss: 1.3526 - dense_297_loss: 1.2391 - dense_298_loss: 1.2736 - dense_289_accuracy: 0.4227 - dense_290_accuracy: 0.2364 - dense_291_accuracy: 0.4329 - dense_292_accuracy: 0.3122 - dense_293_accuracy: 0.2371 - dense_294_accuracy: 0.2352 - dense_295_accuracy: 0.3085 - dense_296_accuracy: 0.3135 - dense_297_accuracy: 0.4088 - dense_298_accuracy: 0.3957\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 14.1408 - dense_289_loss: 1.2935 - dense_290_loss: 1.6011 - dense_291_loss: 1.2866 - dense_292_loss: 1.4370 - dense_293_loss: 1.6061 - dense_294_loss: 1.6142 - dense_295_loss: 1.4480 - dense_296_loss: 1.3488 - dense_297_loss: 1.2357 - dense_298_loss: 1.2698 - dense_289_accuracy: 0.4268 - dense_290_accuracy: 0.2430 - dense_291_accuracy: 0.4367 - dense_292_accuracy: 0.3185 - dense_293_accuracy: 0.2427 - dense_294_accuracy: 0.2478 - dense_295_accuracy: 0.3119 - dense_296_accuracy: 0.3228 - dense_297_accuracy: 0.4144 - dense_298_accuracy: 0.4027\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 14.1486 - dense_289_loss: 1.2936 - dense_290_loss: 1.6023 - dense_291_loss: 1.2894 - dense_292_loss: 1.4381 - dense_293_loss: 1.6061 - dense_294_loss: 1.6139 - dense_295_loss: 1.4480 - dense_296_loss: 1.3469 - dense_297_loss: 1.2370 - dense_298_loss: 1.2731 - dense_289_accuracy: 0.4245 - dense_290_accuracy: 0.2390 - dense_291_accuracy: 0.4315 - dense_292_accuracy: 0.3145 - dense_293_accuracy: 0.2405 - dense_294_accuracy: 0.2443 - dense_295_accuracy: 0.3072 - dense_296_accuracy: 0.3174 - dense_297_accuracy: 0.4092 - dense_298_accuracy: 0.4036\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 14.1361 - dense_289_loss: 1.2926 - dense_290_loss: 1.6017 - dense_291_loss: 1.2880 - dense_292_loss: 1.4369 - dense_293_loss: 1.6044 - dense_294_loss: 1.6125 - dense_295_loss: 1.4462 - dense_296_loss: 1.3483 - dense_297_loss: 1.2355 - dense_298_loss: 1.2700 - dense_289_accuracy: 0.4218 - dense_290_accuracy: 0.2367 - dense_291_accuracy: 0.4331 - dense_292_accuracy: 0.3122 - dense_293_accuracy: 0.2350 - dense_294_accuracy: 0.2352 - dense_295_accuracy: 0.3132 - dense_296_accuracy: 0.3147 - dense_297_accuracy: 0.4018 - dense_298_accuracy: 0.3975\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D31C14C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D31C14C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4C11C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4C11C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 19ms/step - loss: 0.2210\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 0.0481\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 0.0079\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 0.0064\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.0060\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.0059\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.0058\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.0058\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0057\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.0057\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215CC583798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215CC583798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 4s 8ms/step - loss: 20.6536 - dense_302_loss: 2.0011 - dense_303_loss: 2.0198 - dense_304_loss: 2.0927 - dense_305_loss: 1.9757 - dense_306_loss: 2.3966 - dense_307_loss: 2.0875 - dense_308_loss: 2.1226 - dense_309_loss: 2.0059 - dense_310_loss: 1.8222 - dense_311_loss: 2.1295 - dense_302_accuracy: 0.3172 - dense_303_accuracy: 0.2552 - dense_304_accuracy: 0.2242 - dense_305_accuracy: 0.2450 - dense_306_accuracy: 0.1694 - dense_307_accuracy: 0.2256 - dense_308_accuracy: 0.2206 - dense_309_accuracy: 0.2532 - dense_310_accuracy: 0.3154 - dense_311_accuracy: 0.1880\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 17.4003 - dense_302_loss: 1.6034 - dense_303_loss: 1.7045 - dense_304_loss: 1.7984 - dense_305_loss: 1.6762 - dense_306_loss: 1.9771 - dense_307_loss: 1.7603 - dense_308_loss: 1.7881 - dense_309_loss: 1.7124 - dense_310_loss: 1.5598 - dense_311_loss: 1.8200 - dense_302_accuracy: 0.3996 - dense_303_accuracy: 0.3136 - dense_304_accuracy: 0.2624 - dense_305_accuracy: 0.2870 - dense_306_accuracy: 0.2234 - dense_307_accuracy: 0.2770 - dense_308_accuracy: 0.2684 - dense_309_accuracy: 0.2750 - dense_310_accuracy: 0.3864 - dense_311_accuracy: 0.2384\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 17.1820 - dense_302_loss: 1.5811 - dense_303_loss: 1.6844 - dense_304_loss: 1.7770 - dense_305_loss: 1.6593 - dense_306_loss: 1.9503 - dense_307_loss: 1.7391 - dense_308_loss: 1.7677 - dense_309_loss: 1.6912 - dense_310_loss: 1.5367 - dense_311_loss: 1.7952 - dense_302_accuracy: 0.4110 - dense_303_accuracy: 0.3270 - dense_304_accuracy: 0.2670 - dense_305_accuracy: 0.2942 - dense_306_accuracy: 0.2220 - dense_307_accuracy: 0.2748 - dense_308_accuracy: 0.2792 - dense_309_accuracy: 0.2920 - dense_310_accuracy: 0.3886 - dense_311_accuracy: 0.2334\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 17.1316 - dense_302_loss: 1.5664 - dense_303_loss: 1.6767 - dense_304_loss: 1.7753 - dense_305_loss: 1.6539 - dense_306_loss: 1.9458 - dense_307_loss: 1.7416 - dense_308_loss: 1.7558 - dense_309_loss: 1.6912 - dense_310_loss: 1.5330 - dense_311_loss: 1.7919 - dense_302_accuracy: 0.4030 - dense_303_accuracy: 0.3262 - dense_304_accuracy: 0.2642 - dense_305_accuracy: 0.2916 - dense_306_accuracy: 0.2286 - dense_307_accuracy: 0.2658 - dense_308_accuracy: 0.2814 - dense_309_accuracy: 0.2932 - dense_310_accuracy: 0.3920 - dense_311_accuracy: 0.2438\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 17.0894 - dense_302_loss: 1.5699 - dense_303_loss: 1.6738 - dense_304_loss: 1.7690 - dense_305_loss: 1.6548 - dense_306_loss: 1.9401 - dense_307_loss: 1.7304 - dense_308_loss: 1.7505 - dense_309_loss: 1.6854 - dense_310_loss: 1.5271 - dense_311_loss: 1.7884 - dense_302_accuracy: 0.4094 - dense_303_accuracy: 0.3292 - dense_304_accuracy: 0.2664 - dense_305_accuracy: 0.2922 - dense_306_accuracy: 0.2284 - dense_307_accuracy: 0.2804 - dense_308_accuracy: 0.2892 - dense_309_accuracy: 0.2888 - dense_310_accuracy: 0.3966 - dense_311_accuracy: 0.2488\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 16.9774 - dense_302_loss: 1.5577 - dense_303_loss: 1.6615 - dense_304_loss: 1.7585 - dense_305_loss: 1.6431 - dense_306_loss: 1.9267 - dense_307_loss: 1.7217 - dense_308_loss: 1.7417 - dense_309_loss: 1.6723 - dense_310_loss: 1.5195 - dense_311_loss: 1.7746 - dense_302_accuracy: 0.4172 - dense_303_accuracy: 0.3400 - dense_304_accuracy: 0.2838 - dense_305_accuracy: 0.3008 - dense_306_accuracy: 0.2476 - dense_307_accuracy: 0.2914 - dense_308_accuracy: 0.2960 - dense_309_accuracy: 0.3038 - dense_310_accuracy: 0.3970 - dense_311_accuracy: 0.2578\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 16.9178 - dense_302_loss: 1.5567 - dense_303_loss: 1.6513 - dense_304_loss: 1.7539 - dense_305_loss: 1.6317 - dense_306_loss: 1.9209 - dense_307_loss: 1.7149 - dense_308_loss: 1.7327 - dense_309_loss: 1.6664 - dense_310_loss: 1.5205 - dense_311_loss: 1.7687 - dense_302_accuracy: 0.4190 - dense_303_accuracy: 0.3462 - dense_304_accuracy: 0.2932 - dense_305_accuracy: 0.3190 - dense_306_accuracy: 0.2552 - dense_307_accuracy: 0.3036 - dense_308_accuracy: 0.3048 - dense_309_accuracy: 0.3166 - dense_310_accuracy: 0.4010 - dense_311_accuracy: 0.2760\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 16.8045 - dense_302_loss: 1.5465 - dense_303_loss: 1.6458 - dense_304_loss: 1.7390 - dense_305_loss: 1.6250 - dense_306_loss: 1.9032 - dense_307_loss: 1.6977 - dense_308_loss: 1.7244 - dense_309_loss: 1.6547 - dense_310_loss: 1.5089 - dense_311_loss: 1.7593 - dense_302_accuracy: 0.4236 - dense_303_accuracy: 0.3476 - dense_304_accuracy: 0.2998 - dense_305_accuracy: 0.3190 - dense_306_accuracy: 0.2722 - dense_307_accuracy: 0.3124 - dense_308_accuracy: 0.3182 - dense_309_accuracy: 0.3212 - dense_310_accuracy: 0.3944 - dense_311_accuracy: 0.2832\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 16.6677 - dense_302_loss: 1.5328 - dense_303_loss: 1.6316 - dense_304_loss: 1.7213 - dense_305_loss: 1.6113 - dense_306_loss: 1.8863 - dense_307_loss: 1.6870 - dense_308_loss: 1.7111 - dense_309_loss: 1.6480 - dense_310_loss: 1.4986 - dense_311_loss: 1.7397 - dense_302_accuracy: 0.4264 - dense_303_accuracy: 0.3588 - dense_304_accuracy: 0.3226 - dense_305_accuracy: 0.3444 - dense_306_accuracy: 0.2912 - dense_307_accuracy: 0.3316 - dense_308_accuracy: 0.3344 - dense_309_accuracy: 0.3228 - dense_310_accuracy: 0.4034 - dense_311_accuracy: 0.3046\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 16.5667 - dense_302_loss: 1.5285 - dense_303_loss: 1.6224 - dense_304_loss: 1.7110 - dense_305_loss: 1.6015 - dense_306_loss: 1.8726 - dense_307_loss: 1.6781 - dense_308_loss: 1.6986 - dense_309_loss: 1.6354 - dense_310_loss: 1.4904 - dense_311_loss: 1.7282 - dense_302_accuracy: 0.4396 - dense_303_accuracy: 0.3738 - dense_304_accuracy: 0.3404 - dense_305_accuracy: 0.3470 - dense_306_accuracy: 0.3060 - dense_307_accuracy: 0.3380 - dense_308_accuracy: 0.3438 - dense_309_accuracy: 0.3450 - dense_310_accuracy: 0.4170 - dense_311_accuracy: 0.3132\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D35DB708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D35DB708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D34438B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D34438B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 4s 7ms/step - loss: 19.9844 - dense_312_loss: 1.9286 - dense_313_loss: 1.9221 - dense_314_loss: 2.0528 - dense_315_loss: 1.9125 - dense_316_loss: 2.2930 - dense_317_loss: 2.0148 - dense_318_loss: 2.0509 - dense_319_loss: 1.9411 - dense_320_loss: 1.7906 - dense_321_loss: 2.0782 - dense_312_accuracy: 0.3232 - dense_313_accuracy: 0.2708 - dense_314_accuracy: 0.2114 - dense_315_accuracy: 0.2708 - dense_316_accuracy: 0.1776 - dense_317_accuracy: 0.2324 - dense_318_accuracy: 0.2398 - dense_319_accuracy: 0.2554 - dense_320_accuracy: 0.3326 - dense_321_accuracy: 0.1904\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 17.2784 - dense_312_loss: 1.5888 - dense_313_loss: 1.6883 - dense_314_loss: 1.7905 - dense_315_loss: 1.6681 - dense_316_loss: 1.9657 - dense_317_loss: 1.7538 - dense_318_loss: 1.7704 - dense_319_loss: 1.7010 - dense_320_loss: 1.5462 - dense_321_loss: 1.8056 - dense_312_accuracy: 0.4158 - dense_313_accuracy: 0.3294 - dense_314_accuracy: 0.2660 - dense_315_accuracy: 0.2974 - dense_316_accuracy: 0.2312 - dense_317_accuracy: 0.2714 - dense_318_accuracy: 0.2812 - dense_319_accuracy: 0.2912 - dense_320_accuracy: 0.3954 - dense_321_accuracy: 0.2338\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 17.2166 - dense_312_loss: 1.5818 - dense_313_loss: 1.6850 - dense_314_loss: 1.7823 - dense_315_loss: 1.6624 - dense_316_loss: 1.9565 - dense_317_loss: 1.7467 - dense_318_loss: 1.7650 - dense_319_loss: 1.6918 - dense_320_loss: 1.5406 - dense_321_loss: 1.8044 - dense_312_accuracy: 0.4074 - dense_313_accuracy: 0.3300 - dense_314_accuracy: 0.2576 - dense_315_accuracy: 0.2890 - dense_316_accuracy: 0.2262 - dense_317_accuracy: 0.2702 - dense_318_accuracy: 0.2662 - dense_319_accuracy: 0.2918 - dense_320_accuracy: 0.3906 - dense_321_accuracy: 0.2294\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 17.2068 - dense_312_loss: 1.5815 - dense_313_loss: 1.6815 - dense_314_loss: 1.7821 - dense_315_loss: 1.6613 - dense_316_loss: 1.9579 - dense_317_loss: 1.7459 - dense_318_loss: 1.7617 - dense_319_loss: 1.6971 - dense_320_loss: 1.5391 - dense_321_loss: 1.7987 - dense_312_accuracy: 0.4134 - dense_313_accuracy: 0.3210 - dense_314_accuracy: 0.2590 - dense_315_accuracy: 0.2866 - dense_316_accuracy: 0.2270 - dense_317_accuracy: 0.2652 - dense_318_accuracy: 0.2830 - dense_319_accuracy: 0.2694 - dense_320_accuracy: 0.3910 - dense_321_accuracy: 0.2356\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 17.1082 - dense_312_loss: 1.5714 - dense_313_loss: 1.6757 - dense_314_loss: 1.7740 - dense_315_loss: 1.6529 - dense_316_loss: 1.9443 - dense_317_loss: 1.7353 - dense_318_loss: 1.7529 - dense_319_loss: 1.6840 - dense_320_loss: 1.5282 - dense_321_loss: 1.7894 - dense_312_accuracy: 0.4112 - dense_313_accuracy: 0.3224 - dense_314_accuracy: 0.2608 - dense_315_accuracy: 0.2928 - dense_316_accuracy: 0.2188 - dense_317_accuracy: 0.2646 - dense_318_accuracy: 0.2706 - dense_319_accuracy: 0.2918 - dense_320_accuracy: 0.3926 - dense_321_accuracy: 0.2384\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 17.0785 - dense_312_loss: 1.5672 - dense_313_loss: 1.6723 - dense_314_loss: 1.7713 - dense_315_loss: 1.6512 - dense_316_loss: 1.9385 - dense_317_loss: 1.7326 - dense_318_loss: 1.7516 - dense_319_loss: 1.6801 - dense_320_loss: 1.5274 - dense_321_loss: 1.7864 - dense_312_accuracy: 0.4128 - dense_313_accuracy: 0.3184 - dense_314_accuracy: 0.2700 - dense_315_accuracy: 0.2952 - dense_316_accuracy: 0.2176 - dense_317_accuracy: 0.2750 - dense_318_accuracy: 0.2830 - dense_319_accuracy: 0.2908 - dense_320_accuracy: 0.3876 - dense_321_accuracy: 0.2248\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 17.0240 - dense_312_loss: 1.5591 - dense_313_loss: 1.6663 - dense_314_loss: 1.7660 - dense_315_loss: 1.6442 - dense_316_loss: 1.9329 - dense_317_loss: 1.7292 - dense_318_loss: 1.7467 - dense_319_loss: 1.6757 - dense_320_loss: 1.5227 - dense_321_loss: 1.7812 - dense_312_accuracy: 0.4144 - dense_313_accuracy: 0.3208 - dense_314_accuracy: 0.2620 - dense_315_accuracy: 0.2904 - dense_316_accuracy: 0.2288 - dense_317_accuracy: 0.2694 - dense_318_accuracy: 0.2844 - dense_319_accuracy: 0.2884 - dense_320_accuracy: 0.3932 - dense_321_accuracy: 0.2440\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 17.0438 - dense_312_loss: 1.5628 - dense_313_loss: 1.6677 - dense_314_loss: 1.7663 - dense_315_loss: 1.6459 - dense_316_loss: 1.9381 - dense_317_loss: 1.7305 - dense_318_loss: 1.7485 - dense_319_loss: 1.6764 - dense_320_loss: 1.5247 - dense_321_loss: 1.7829 - dense_312_accuracy: 0.4116 - dense_313_accuracy: 0.3222 - dense_314_accuracy: 0.2652 - dense_315_accuracy: 0.2858 - dense_316_accuracy: 0.2194 - dense_317_accuracy: 0.2702 - dense_318_accuracy: 0.2846 - dense_319_accuracy: 0.2952 - dense_320_accuracy: 0.3962 - dense_321_accuracy: 0.2388\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 17.0210 - dense_312_loss: 1.5586 - dense_313_loss: 1.6662 - dense_314_loss: 1.7662 - dense_315_loss: 1.6444 - dense_316_loss: 1.9347 - dense_317_loss: 1.7258 - dense_318_loss: 1.7471 - dense_319_loss: 1.6751 - dense_320_loss: 1.5223 - dense_321_loss: 1.7807 - dense_312_accuracy: 0.4128 - dense_313_accuracy: 0.3306 - dense_314_accuracy: 0.2660 - dense_315_accuracy: 0.3054 - dense_316_accuracy: 0.2246 - dense_317_accuracy: 0.2802 - dense_318_accuracy: 0.2848 - dense_319_accuracy: 0.2924 - dense_320_accuracy: 0.3946 - dense_321_accuracy: 0.2430\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 16.9789 - dense_312_loss: 1.5564 - dense_313_loss: 1.6603 - dense_314_loss: 1.7618 - dense_315_loss: 1.6430 - dense_316_loss: 1.9272 - dense_317_loss: 1.7247 - dense_318_loss: 1.7412 - dense_319_loss: 1.6724 - dense_320_loss: 1.5154 - dense_321_loss: 1.7764 - dense_312_accuracy: 0.4192 - dense_313_accuracy: 0.3232 - dense_314_accuracy: 0.2724 - dense_315_accuracy: 0.3054 - dense_316_accuracy: 0.2256 - dense_317_accuracy: 0.2752 - dense_318_accuracy: 0.2856 - dense_319_accuracy: 0.3006 - dense_320_accuracy: 0.3942 - dense_321_accuracy: 0.2400\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D34EC798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D34EC798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D38B19D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D38B19D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 3s 28ms/step - loss: 0.1763\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 2s 28ms/step - loss: 0.0098\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 2s 30ms/step - loss: 0.0056\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 2s 29ms/step - loss: 0.0052\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 3s 32ms/step - loss: 0.0050\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 3s 32ms/step - loss: 0.0048\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 2s 30ms/step - loss: 0.0043\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 2s 31ms/step - loss: 0.0038\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 2s 31ms/step - loss: 0.0034\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 2s 29ms/step - loss: 0.0032\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0030\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 2s 28ms/step - loss: 0.0029\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 2s 28ms/step - loss: 0.0028\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 2s 28ms/step - loss: 0.0028\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0028\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0028\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 2s 28ms/step - loss: 0.0027\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 0.0027\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0027\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0026\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0026\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 2s 28ms/step - loss: 0.0025\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0025\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0025\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 2s 28ms/step - loss: 0.0025\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215CC5838B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215CC5838B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 4s 9ms/step - loss: 19.9760 - dense_325_loss: 1.9011 - dense_326_loss: 2.2782 - dense_327_loss: 1.8693 - dense_328_loss: 1.9066 - dense_329_loss: 2.2850 - dense_330_loss: 2.2918 - dense_331_loss: 1.8923 - dense_332_loss: 1.8997 - dense_333_loss: 1.8803 - dense_334_loss: 1.7718 - dense_325_accuracy: 0.2064 - dense_326_accuracy: 0.1530 - dense_327_accuracy: 0.2420 - dense_328_accuracy: 0.2094 - dense_329_accuracy: 0.1524 - dense_330_accuracy: 0.1576 - dense_331_accuracy: 0.2872 - dense_332_accuracy: 0.2724 - dense_333_accuracy: 0.2890 - dense_334_accuracy: 0.3200\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.4789 - dense_325_loss: 1.4656 - dense_326_loss: 1.7105 - dense_327_loss: 1.4501 - dense_328_loss: 1.5725 - dense_329_loss: 1.7143 - dense_330_loss: 1.6952 - dense_331_loss: 1.5133 - dense_332_loss: 1.4592 - dense_333_loss: 1.4603 - dense_334_loss: 1.4380 - dense_325_accuracy: 0.3286 - dense_326_accuracy: 0.2358 - dense_327_accuracy: 0.3266 - dense_328_accuracy: 0.2704 - dense_329_accuracy: 0.2330 - dense_330_accuracy: 0.2308 - dense_331_accuracy: 0.3502 - dense_332_accuracy: 0.3526 - dense_333_accuracy: 0.3470 - dense_334_accuracy: 0.3726\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 14.0541 - dense_325_loss: 1.3372 - dense_326_loss: 1.5607 - dense_327_loss: 1.3540 - dense_328_loss: 1.4648 - dense_329_loss: 1.5659 - dense_330_loss: 1.5426 - dense_331_loss: 1.3438 - dense_332_loss: 1.2762 - dense_333_loss: 1.3019 - dense_334_loss: 1.3070 - dense_325_accuracy: 0.3502 - dense_326_accuracy: 0.2426 - dense_327_accuracy: 0.3644 - dense_328_accuracy: 0.2834 - dense_329_accuracy: 0.2420 - dense_330_accuracy: 0.2444 - dense_331_accuracy: 0.3568 - dense_332_accuracy: 0.3728 - dense_333_accuracy: 0.3680 - dense_334_accuracy: 0.3706\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.9698 - dense_325_loss: 1.3339 - dense_326_loss: 1.5463 - dense_327_loss: 1.3484 - dense_328_loss: 1.4539 - dense_329_loss: 1.5564 - dense_330_loss: 1.5408 - dense_331_loss: 1.3453 - dense_332_loss: 1.2633 - dense_333_loss: 1.2935 - dense_334_loss: 1.2880 - dense_325_accuracy: 0.3560 - dense_326_accuracy: 0.2572 - dense_327_accuracy: 0.3620 - dense_328_accuracy: 0.2896 - dense_329_accuracy: 0.2490 - dense_330_accuracy: 0.2478 - dense_331_accuracy: 0.3668 - dense_332_accuracy: 0.3860 - dense_333_accuracy: 0.3672 - dense_334_accuracy: 0.3602\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.6862 - dense_325_loss: 1.3070 - dense_326_loss: 1.5182 - dense_327_loss: 1.3162 - dense_328_loss: 1.4307 - dense_329_loss: 1.5264 - dense_330_loss: 1.5101 - dense_331_loss: 1.3092 - dense_332_loss: 1.2361 - dense_333_loss: 1.2635 - dense_334_loss: 1.2687 - dense_325_accuracy: 0.3570 - dense_326_accuracy: 0.2434 - dense_327_accuracy: 0.3696 - dense_328_accuracy: 0.2762 - dense_329_accuracy: 0.2534 - dense_330_accuracy: 0.2404 - dense_331_accuracy: 0.3698 - dense_332_accuracy: 0.3802 - dense_333_accuracy: 0.3626 - dense_334_accuracy: 0.3746\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.6139 - dense_325_loss: 1.3013 - dense_326_loss: 1.5084 - dense_327_loss: 1.3109 - dense_328_loss: 1.4209 - dense_329_loss: 1.5158 - dense_330_loss: 1.4997 - dense_331_loss: 1.3032 - dense_332_loss: 1.2309 - dense_333_loss: 1.2578 - dense_334_loss: 1.2650 - dense_325_accuracy: 0.3712 - dense_326_accuracy: 0.2542 - dense_327_accuracy: 0.3740 - dense_328_accuracy: 0.2916 - dense_329_accuracy: 0.2604 - dense_330_accuracy: 0.2562 - dense_331_accuracy: 0.3760 - dense_332_accuracy: 0.3814 - dense_333_accuracy: 0.3708 - dense_334_accuracy: 0.3694\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.6302 - dense_325_loss: 1.3061 - dense_326_loss: 1.5087 - dense_327_loss: 1.3139 - dense_328_loss: 1.4240 - dense_329_loss: 1.5132 - dense_330_loss: 1.5000 - dense_331_loss: 1.3092 - dense_332_loss: 1.2367 - dense_333_loss: 1.2568 - dense_334_loss: 1.2615 - dense_325_accuracy: 0.3710 - dense_326_accuracy: 0.2456 - dense_327_accuracy: 0.3680 - dense_328_accuracy: 0.2890 - dense_329_accuracy: 0.2490 - dense_330_accuracy: 0.2448 - dense_331_accuracy: 0.3706 - dense_332_accuracy: 0.3706 - dense_333_accuracy: 0.3690 - dense_334_accuracy: 0.3754\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.5761 - dense_325_loss: 1.3006 - dense_326_loss: 1.5044 - dense_327_loss: 1.3110 - dense_328_loss: 1.4165 - dense_329_loss: 1.5116 - dense_330_loss: 1.4959 - dense_331_loss: 1.3002 - dense_332_loss: 1.2236 - dense_333_loss: 1.2529 - dense_334_loss: 1.2595 - dense_325_accuracy: 0.3584 - dense_326_accuracy: 0.2504 - dense_327_accuracy: 0.3668 - dense_328_accuracy: 0.2938 - dense_329_accuracy: 0.2436 - dense_330_accuracy: 0.2510 - dense_331_accuracy: 0.3760 - dense_332_accuracy: 0.3764 - dense_333_accuracy: 0.3620 - dense_334_accuracy: 0.3734\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.5180 - dense_325_loss: 1.2986 - dense_326_loss: 1.4985 - dense_327_loss: 1.2989 - dense_328_loss: 1.4139 - dense_329_loss: 1.5020 - dense_330_loss: 1.4910 - dense_331_loss: 1.2935 - dense_332_loss: 1.2195 - dense_333_loss: 1.2494 - dense_334_loss: 1.2527 - dense_325_accuracy: 0.3650 - dense_326_accuracy: 0.2474 - dense_327_accuracy: 0.3778 - dense_328_accuracy: 0.2872 - dense_329_accuracy: 0.2480 - dense_330_accuracy: 0.2496 - dense_331_accuracy: 0.3776 - dense_332_accuracy: 0.3834 - dense_333_accuracy: 0.3634 - dense_334_accuracy: 0.3818\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.5475 - dense_325_loss: 1.3010 - dense_326_loss: 1.5027 - dense_327_loss: 1.3054 - dense_328_loss: 1.4119 - dense_329_loss: 1.5065 - dense_330_loss: 1.4932 - dense_331_loss: 1.2975 - dense_332_loss: 1.2217 - dense_333_loss: 1.2518 - dense_334_loss: 1.2557 - dense_325_accuracy: 0.3624 - dense_326_accuracy: 0.2464 - dense_327_accuracy: 0.3752 - dense_328_accuracy: 0.2982 - dense_329_accuracy: 0.2520 - dense_330_accuracy: 0.2464 - dense_331_accuracy: 0.3748 - dense_332_accuracy: 0.3718 - dense_333_accuracy: 0.3690 - dense_334_accuracy: 0.3724\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.4802 - dense_325_loss: 1.3005 - dense_326_loss: 1.4956 - dense_327_loss: 1.2983 - dense_328_loss: 1.4015 - dense_329_loss: 1.4965 - dense_330_loss: 1.4854 - dense_331_loss: 1.2976 - dense_332_loss: 1.2138 - dense_333_loss: 1.2448 - dense_334_loss: 1.2462 - dense_325_accuracy: 0.3716 - dense_326_accuracy: 0.2624 - dense_327_accuracy: 0.3724 - dense_328_accuracy: 0.3120 - dense_329_accuracy: 0.2678 - dense_330_accuracy: 0.2544 - dense_331_accuracy: 0.3706 - dense_332_accuracy: 0.3932 - dense_333_accuracy: 0.3724 - dense_334_accuracy: 0.3876\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.4634 - dense_325_loss: 1.2936 - dense_326_loss: 1.4913 - dense_327_loss: 1.2960 - dense_328_loss: 1.4023 - dense_329_loss: 1.4929 - dense_330_loss: 1.4814 - dense_331_loss: 1.2916 - dense_332_loss: 1.2112 - dense_333_loss: 1.2502 - dense_334_loss: 1.2528 - dense_325_accuracy: 0.3680 - dense_326_accuracy: 0.2598 - dense_327_accuracy: 0.3784 - dense_328_accuracy: 0.3054 - dense_329_accuracy: 0.2644 - dense_330_accuracy: 0.2600 - dense_331_accuracy: 0.3802 - dense_332_accuracy: 0.3860 - dense_333_accuracy: 0.3724 - dense_334_accuracy: 0.3790\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.4015 - dense_325_loss: 1.2902 - dense_326_loss: 1.4845 - dense_327_loss: 1.2894 - dense_328_loss: 1.3979 - dense_329_loss: 1.4890 - dense_330_loss: 1.4745 - dense_331_loss: 1.2860 - dense_332_loss: 1.2100 - dense_333_loss: 1.2383 - dense_334_loss: 1.2419 - dense_325_accuracy: 0.3686 - dense_326_accuracy: 0.2638 - dense_327_accuracy: 0.3772 - dense_328_accuracy: 0.3162 - dense_329_accuracy: 0.2686 - dense_330_accuracy: 0.2690 - dense_331_accuracy: 0.3812 - dense_332_accuracy: 0.3822 - dense_333_accuracy: 0.3802 - dense_334_accuracy: 0.3840\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.4364 - dense_325_loss: 1.2924 - dense_326_loss: 1.4884 - dense_327_loss: 1.2949 - dense_328_loss: 1.3995 - dense_329_loss: 1.4924 - dense_330_loss: 1.4785 - dense_331_loss: 1.2936 - dense_332_loss: 1.2126 - dense_333_loss: 1.2401 - dense_334_loss: 1.2441 - dense_325_accuracy: 0.3754 - dense_326_accuracy: 0.2624 - dense_327_accuracy: 0.3782 - dense_328_accuracy: 0.3118 - dense_329_accuracy: 0.2704 - dense_330_accuracy: 0.2618 - dense_331_accuracy: 0.3826 - dense_332_accuracy: 0.3868 - dense_333_accuracy: 0.3848 - dense_334_accuracy: 0.3950\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.4013 - dense_325_loss: 1.2881 - dense_326_loss: 1.4796 - dense_327_loss: 1.2909 - dense_328_loss: 1.3997 - dense_329_loss: 1.4931 - dense_330_loss: 1.4737 - dense_331_loss: 1.2836 - dense_332_loss: 1.2102 - dense_333_loss: 1.2385 - dense_334_loss: 1.2437 - dense_325_accuracy: 0.3826 - dense_326_accuracy: 0.2850 - dense_327_accuracy: 0.3810 - dense_328_accuracy: 0.3232 - dense_329_accuracy: 0.2838 - dense_330_accuracy: 0.2796 - dense_331_accuracy: 0.3902 - dense_332_accuracy: 0.3880 - dense_333_accuracy: 0.3852 - dense_334_accuracy: 0.3860\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.3853 - dense_325_loss: 1.2871 - dense_326_loss: 1.4805 - dense_327_loss: 1.2926 - dense_328_loss: 1.3989 - dense_329_loss: 1.4872 - dense_330_loss: 1.4727 - dense_331_loss: 1.2837 - dense_332_loss: 1.2042 - dense_333_loss: 1.2366 - dense_334_loss: 1.2419 - dense_325_accuracy: 0.3748 - dense_326_accuracy: 0.2842 - dense_327_accuracy: 0.3812 - dense_328_accuracy: 0.3020 - dense_329_accuracy: 0.2768 - dense_330_accuracy: 0.2732 - dense_331_accuracy: 0.3864 - dense_332_accuracy: 0.3932 - dense_333_accuracy: 0.3794 - dense_334_accuracy: 0.3890\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.3226 - dense_325_loss: 1.2805 - dense_326_loss: 1.4728 - dense_327_loss: 1.2866 - dense_328_loss: 1.3898 - dense_329_loss: 1.4775 - dense_330_loss: 1.4670 - dense_331_loss: 1.2777 - dense_332_loss: 1.1993 - dense_333_loss: 1.2343 - dense_334_loss: 1.2370 - dense_325_accuracy: 0.3846 - dense_326_accuracy: 0.2834 - dense_327_accuracy: 0.3898 - dense_328_accuracy: 0.3178 - dense_329_accuracy: 0.2794 - dense_330_accuracy: 0.2760 - dense_331_accuracy: 0.3908 - dense_332_accuracy: 0.4038 - dense_333_accuracy: 0.3808 - dense_334_accuracy: 0.3934\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.4153 - dense_325_loss: 1.2922 - dense_326_loss: 1.4863 - dense_327_loss: 1.2902 - dense_328_loss: 1.3985 - dense_329_loss: 1.4906 - dense_330_loss: 1.4736 - dense_331_loss: 1.2887 - dense_332_loss: 1.2072 - dense_333_loss: 1.2399 - dense_334_loss: 1.2481 - dense_325_accuracy: 0.3814 - dense_326_accuracy: 0.2760 - dense_327_accuracy: 0.3896 - dense_328_accuracy: 0.3210 - dense_329_accuracy: 0.2804 - dense_330_accuracy: 0.2734 - dense_331_accuracy: 0.3786 - dense_332_accuracy: 0.3980 - dense_333_accuracy: 0.3908 - dense_334_accuracy: 0.3898\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.5989 - dense_325_loss: 1.3096 - dense_326_loss: 1.5032 - dense_327_loss: 1.3074 - dense_328_loss: 1.4134 - dense_329_loss: 1.5069 - dense_330_loss: 1.4941 - dense_331_loss: 1.3076 - dense_332_loss: 1.2296 - dense_333_loss: 1.2598 - dense_334_loss: 1.2672 - dense_325_accuracy: 0.3756 - dense_326_accuracy: 0.2834 - dense_327_accuracy: 0.3762 - dense_328_accuracy: 0.3142 - dense_329_accuracy: 0.2884 - dense_330_accuracy: 0.2896 - dense_331_accuracy: 0.3764 - dense_332_accuracy: 0.3958 - dense_333_accuracy: 0.3912 - dense_334_accuracy: 0.3992\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.3851 - dense_325_loss: 1.2876 - dense_326_loss: 1.4802 - dense_327_loss: 1.2863 - dense_328_loss: 1.4006 - dense_329_loss: 1.4855 - dense_330_loss: 1.4723 - dense_331_loss: 1.2818 - dense_332_loss: 1.2084 - dense_333_loss: 1.2392 - dense_334_loss: 1.2433 - dense_325_accuracy: 0.3814 - dense_326_accuracy: 0.2852 - dense_327_accuracy: 0.3828 - dense_328_accuracy: 0.3098 - dense_329_accuracy: 0.2782 - dense_330_accuracy: 0.2768 - dense_331_accuracy: 0.3848 - dense_332_accuracy: 0.4048 - dense_333_accuracy: 0.3882 - dense_334_accuracy: 0.3994\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.2636 - dense_325_loss: 1.2737 - dense_326_loss: 1.4675 - dense_327_loss: 1.2780 - dense_328_loss: 1.3850 - dense_329_loss: 1.4694 - dense_330_loss: 1.4571 - dense_331_loss: 1.2750 - dense_332_loss: 1.1952 - dense_333_loss: 1.2321 - dense_334_loss: 1.2307 - dense_325_accuracy: 0.3934 - dense_326_accuracy: 0.2998 - dense_327_accuracy: 0.4002 - dense_328_accuracy: 0.3332 - dense_329_accuracy: 0.2974 - dense_330_accuracy: 0.2998 - dense_331_accuracy: 0.3914 - dense_332_accuracy: 0.4082 - dense_333_accuracy: 0.4036 - dense_334_accuracy: 0.4048\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.1614 - dense_325_loss: 1.2664 - dense_326_loss: 1.4537 - dense_327_loss: 1.2679 - dense_328_loss: 1.3798 - dense_329_loss: 1.4581 - dense_330_loss: 1.4462 - dense_331_loss: 1.2635 - dense_332_loss: 1.1851 - dense_333_loss: 1.2184 - dense_334_loss: 1.2222 - dense_325_accuracy: 0.3974 - dense_326_accuracy: 0.3088 - dense_327_accuracy: 0.3996 - dense_328_accuracy: 0.3342 - dense_329_accuracy: 0.3060 - dense_330_accuracy: 0.3066 - dense_331_accuracy: 0.3942 - dense_332_accuracy: 0.4182 - dense_333_accuracy: 0.4062 - dense_334_accuracy: 0.4182\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.0893 - dense_325_loss: 1.2569 - dense_326_loss: 1.4464 - dense_327_loss: 1.2627 - dense_328_loss: 1.3670 - dense_329_loss: 1.4524 - dense_330_loss: 1.4388 - dense_331_loss: 1.2549 - dense_332_loss: 1.1725 - dense_333_loss: 1.2190 - dense_334_loss: 1.2187 - dense_325_accuracy: 0.4084 - dense_326_accuracy: 0.3212 - dense_327_accuracy: 0.4034 - dense_328_accuracy: 0.3496 - dense_329_accuracy: 0.3158 - dense_330_accuracy: 0.3184 - dense_331_accuracy: 0.4034 - dense_332_accuracy: 0.4226 - dense_333_accuracy: 0.4124 - dense_334_accuracy: 0.4244\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.0464 - dense_325_loss: 1.2557 - dense_326_loss: 1.4414 - dense_327_loss: 1.2579 - dense_328_loss: 1.3654 - dense_329_loss: 1.4450 - dense_330_loss: 1.4324 - dense_331_loss: 1.2519 - dense_332_loss: 1.1715 - dense_333_loss: 1.2140 - dense_334_loss: 1.2111 - dense_325_accuracy: 0.3972 - dense_326_accuracy: 0.3210 - dense_327_accuracy: 0.4118 - dense_328_accuracy: 0.3468 - dense_329_accuracy: 0.3162 - dense_330_accuracy: 0.3166 - dense_331_accuracy: 0.4088 - dense_332_accuracy: 0.4332 - dense_333_accuracy: 0.4102 - dense_334_accuracy: 0.4264\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.0779 - dense_325_loss: 1.2565 - dense_326_loss: 1.4439 - dense_327_loss: 1.2602 - dense_328_loss: 1.3643 - dense_329_loss: 1.4459 - dense_330_loss: 1.4359 - dense_331_loss: 1.2527 - dense_332_loss: 1.1835 - dense_333_loss: 1.2227 - dense_334_loss: 1.2124 - dense_325_accuracy: 0.4106 - dense_326_accuracy: 0.3310 - dense_327_accuracy: 0.4092 - dense_328_accuracy: 0.3542 - dense_329_accuracy: 0.3216 - dense_330_accuracy: 0.3274 - dense_331_accuracy: 0.4152 - dense_332_accuracy: 0.4212 - dense_333_accuracy: 0.4130 - dense_334_accuracy: 0.4308\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D2575A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D2575A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D393FE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D393FE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 4s 9ms/step - loss: 19.3539 - dense_335_loss: 1.8654 - dense_336_loss: 2.1894 - dense_337_loss: 1.7780 - dense_338_loss: 1.8572 - dense_339_loss: 2.2134 - dense_340_loss: 2.2135 - dense_341_loss: 1.8228 - dense_342_loss: 1.8316 - dense_343_loss: 1.8509 - dense_344_loss: 1.7318 - dense_335_accuracy: 0.2378 - dense_336_accuracy: 0.1598 - dense_337_accuracy: 0.2804 - dense_338_accuracy: 0.2286 - dense_339_accuracy: 0.1648 - dense_340_accuracy: 0.1678 - dense_341_accuracy: 0.2886 - dense_342_accuracy: 0.2850 - dense_343_accuracy: 0.2740 - dense_344_accuracy: 0.3260\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.4306 - dense_335_loss: 1.4668 - dense_336_loss: 1.7318 - dense_337_loss: 1.4604 - dense_338_loss: 1.5469 - dense_339_loss: 1.7294 - dense_340_loss: 1.7219 - dense_341_loss: 1.4751 - dense_342_loss: 1.4312 - dense_343_loss: 1.4444 - dense_344_loss: 1.4226 - dense_335_accuracy: 0.3446 - dense_336_accuracy: 0.2306 - dense_337_accuracy: 0.3570 - dense_338_accuracy: 0.2774 - dense_339_accuracy: 0.2304 - dense_340_accuracy: 0.2298 - dense_341_accuracy: 0.3478 - dense_342_accuracy: 0.3502 - dense_343_accuracy: 0.3362 - dense_344_accuracy: 0.3512\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 14.7947 - dense_335_loss: 1.4116 - dense_336_loss: 1.6513 - dense_337_loss: 1.4113 - dense_338_loss: 1.5029 - dense_339_loss: 1.6574 - dense_340_loss: 1.6471 - dense_341_loss: 1.4165 - dense_342_loss: 1.3568 - dense_343_loss: 1.3799 - dense_344_loss: 1.3598 - dense_335_accuracy: 0.3550 - dense_336_accuracy: 0.2406 - dense_337_accuracy: 0.3628 - dense_338_accuracy: 0.2836 - dense_339_accuracy: 0.2452 - dense_340_accuracy: 0.2412 - dense_341_accuracy: 0.3524 - dense_342_accuracy: 0.3628 - dense_343_accuracy: 0.3424 - dense_344_accuracy: 0.3700\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 14.2292 - dense_335_loss: 1.3499 - dense_336_loss: 1.5836 - dense_337_loss: 1.3665 - dense_338_loss: 1.4729 - dense_339_loss: 1.5905 - dense_340_loss: 1.5739 - dense_341_loss: 1.3603 - dense_342_loss: 1.2956 - dense_343_loss: 1.3293 - dense_344_loss: 1.3068 - dense_335_accuracy: 0.3598 - dense_336_accuracy: 0.2448 - dense_337_accuracy: 0.3698 - dense_338_accuracy: 0.2826 - dense_339_accuracy: 0.2406 - dense_340_accuracy: 0.2456 - dense_341_accuracy: 0.3632 - dense_342_accuracy: 0.3738 - dense_343_accuracy: 0.3598 - dense_344_accuracy: 0.3700\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.9553 - dense_335_loss: 1.3319 - dense_336_loss: 1.5506 - dense_337_loss: 1.3366 - dense_338_loss: 1.4493 - dense_339_loss: 1.5569 - dense_340_loss: 1.5415 - dense_341_loss: 1.3411 - dense_342_loss: 1.2727 - dense_343_loss: 1.2956 - dense_344_loss: 1.2792 - dense_335_accuracy: 0.3632 - dense_336_accuracy: 0.2402 - dense_337_accuracy: 0.3696 - dense_338_accuracy: 0.2850 - dense_339_accuracy: 0.2376 - dense_340_accuracy: 0.2456 - dense_341_accuracy: 0.3628 - dense_342_accuracy: 0.3694 - dense_343_accuracy: 0.3618 - dense_344_accuracy: 0.3746\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 14.0914 - dense_335_loss: 1.3495 - dense_336_loss: 1.5643 - dense_337_loss: 1.3569 - dense_338_loss: 1.4653 - dense_339_loss: 1.5727 - dense_340_loss: 1.5535 - dense_341_loss: 1.3499 - dense_342_loss: 1.2797 - dense_343_loss: 1.3077 - dense_344_loss: 1.2919 - dense_335_accuracy: 0.3524 - dense_336_accuracy: 0.2424 - dense_337_accuracy: 0.3670 - dense_338_accuracy: 0.2948 - dense_339_accuracy: 0.2460 - dense_340_accuracy: 0.2524 - dense_341_accuracy: 0.3650 - dense_342_accuracy: 0.3764 - dense_343_accuracy: 0.3648 - dense_344_accuracy: 0.3738\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.6531 - dense_335_loss: 1.3081 - dense_336_loss: 1.5118 - dense_337_loss: 1.3149 - dense_338_loss: 1.4300 - dense_339_loss: 1.5188 - dense_340_loss: 1.5057 - dense_341_loss: 1.3091 - dense_342_loss: 1.2370 - dense_343_loss: 1.2592 - dense_344_loss: 1.2588 - dense_335_accuracy: 0.3614 - dense_336_accuracy: 0.2394 - dense_337_accuracy: 0.3740 - dense_338_accuracy: 0.2846 - dense_339_accuracy: 0.2442 - dense_340_accuracy: 0.2456 - dense_341_accuracy: 0.3628 - dense_342_accuracy: 0.3732 - dense_343_accuracy: 0.3598 - dense_344_accuracy: 0.3708\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.6163 - dense_335_loss: 1.3057 - dense_336_loss: 1.5096 - dense_337_loss: 1.3128 - dense_338_loss: 1.4212 - dense_339_loss: 1.5147 - dense_340_loss: 1.4986 - dense_341_loss: 1.3054 - dense_342_loss: 1.2312 - dense_343_loss: 1.2566 - dense_344_loss: 1.2606 - dense_335_accuracy: 0.3616 - dense_336_accuracy: 0.2486 - dense_337_accuracy: 0.3714 - dense_338_accuracy: 0.2884 - dense_339_accuracy: 0.2538 - dense_340_accuracy: 0.2466 - dense_341_accuracy: 0.3760 - dense_342_accuracy: 0.3750 - dense_343_accuracy: 0.3750 - dense_344_accuracy: 0.3814\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.5339 - dense_335_loss: 1.3004 - dense_336_loss: 1.5007 - dense_337_loss: 1.3027 - dense_338_loss: 1.4174 - dense_339_loss: 1.5063 - dense_340_loss: 1.4919 - dense_341_loss: 1.2963 - dense_342_loss: 1.2219 - dense_343_loss: 1.2478 - dense_344_loss: 1.2485 - dense_335_accuracy: 0.3648 - dense_336_accuracy: 0.2472 - dense_337_accuracy: 0.3712 - dense_338_accuracy: 0.2858 - dense_339_accuracy: 0.2488 - dense_340_accuracy: 0.2480 - dense_341_accuracy: 0.3718 - dense_342_accuracy: 0.3776 - dense_343_accuracy: 0.3620 - dense_344_accuracy: 0.3732\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.4720 - dense_335_loss: 1.2959 - dense_336_loss: 1.4914 - dense_337_loss: 1.2972 - dense_338_loss: 1.4109 - dense_339_loss: 1.4990 - dense_340_loss: 1.4840 - dense_341_loss: 1.2890 - dense_342_loss: 1.2166 - dense_343_loss: 1.2431 - dense_344_loss: 1.2449 - dense_335_accuracy: 0.3690 - dense_336_accuracy: 0.2498 - dense_337_accuracy: 0.3768 - dense_338_accuracy: 0.2900 - dense_339_accuracy: 0.2476 - dense_340_accuracy: 0.2524 - dense_341_accuracy: 0.3734 - dense_342_accuracy: 0.3872 - dense_343_accuracy: 0.3748 - dense_344_accuracy: 0.3764\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 13.4650 - dense_335_loss: 1.2931 - dense_336_loss: 1.4927 - dense_337_loss: 1.2973 - dense_338_loss: 1.4112 - dense_339_loss: 1.4970 - dense_340_loss: 1.4842 - dense_341_loss: 1.2869 - dense_342_loss: 1.2153 - dense_343_loss: 1.2439 - dense_344_loss: 1.2435 - dense_335_accuracy: 0.3622 - dense_336_accuracy: 0.2490 - dense_337_accuracy: 0.3672 - dense_338_accuracy: 0.2810 - dense_339_accuracy: 0.2506 - dense_340_accuracy: 0.2498 - dense_341_accuracy: 0.3764 - dense_342_accuracy: 0.3848 - dense_343_accuracy: 0.3682 - dense_344_accuracy: 0.3796\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.4842 - dense_335_loss: 1.2953 - dense_336_loss: 1.4945 - dense_337_loss: 1.2971 - dense_338_loss: 1.4123 - dense_339_loss: 1.4992 - dense_340_loss: 1.4848 - dense_341_loss: 1.2953 - dense_342_loss: 1.2169 - dense_343_loss: 1.2443 - dense_344_loss: 1.2445 - dense_335_accuracy: 0.3690 - dense_336_accuracy: 0.2570 - dense_337_accuracy: 0.3720 - dense_338_accuracy: 0.2970 - dense_339_accuracy: 0.2564 - dense_340_accuracy: 0.2626 - dense_341_accuracy: 0.3690 - dense_342_accuracy: 0.3786 - dense_343_accuracy: 0.3736 - dense_344_accuracy: 0.3754\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.4727 - dense_335_loss: 1.2934 - dense_336_loss: 1.4920 - dense_337_loss: 1.2997 - dense_338_loss: 1.4083 - dense_339_loss: 1.4980 - dense_340_loss: 1.4846 - dense_341_loss: 1.2923 - dense_342_loss: 1.2173 - dense_343_loss: 1.2422 - dense_344_loss: 1.2449 - dense_335_accuracy: 0.3628 - dense_336_accuracy: 0.2462 - dense_337_accuracy: 0.3718 - dense_338_accuracy: 0.2902 - dense_339_accuracy: 0.2418 - dense_340_accuracy: 0.2428 - dense_341_accuracy: 0.3710 - dense_342_accuracy: 0.3694 - dense_343_accuracy: 0.3680 - dense_344_accuracy: 0.3730\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.4304 - dense_335_loss: 1.2928 - dense_336_loss: 1.4867 - dense_337_loss: 1.2920 - dense_338_loss: 1.4063 - dense_339_loss: 1.4943 - dense_340_loss: 1.4787 - dense_341_loss: 1.2873 - dense_342_loss: 1.2097 - dense_343_loss: 1.2405 - dense_344_loss: 1.2420 - dense_335_accuracy: 0.3738 - dense_336_accuracy: 0.2582 - dense_337_accuracy: 0.3754 - dense_338_accuracy: 0.2960 - dense_339_accuracy: 0.2586 - dense_340_accuracy: 0.2558 - dense_341_accuracy: 0.3754 - dense_342_accuracy: 0.3882 - dense_343_accuracy: 0.3658 - dense_344_accuracy: 0.3790\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.4426 - dense_335_loss: 1.2930 - dense_336_loss: 1.4884 - dense_337_loss: 1.2943 - dense_338_loss: 1.4053 - dense_339_loss: 1.4959 - dense_340_loss: 1.4800 - dense_341_loss: 1.2875 - dense_342_loss: 1.2119 - dense_343_loss: 1.2430 - dense_344_loss: 1.2433 - dense_335_accuracy: 0.3690 - dense_336_accuracy: 0.2628 - dense_337_accuracy: 0.3778 - dense_338_accuracy: 0.3030 - dense_339_accuracy: 0.2672 - dense_340_accuracy: 0.2608 - dense_341_accuracy: 0.3754 - dense_342_accuracy: 0.3924 - dense_343_accuracy: 0.3800 - dense_344_accuracy: 0.3820\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.4712 - dense_335_loss: 1.2973 - dense_336_loss: 1.4924 - dense_337_loss: 1.2958 - dense_338_loss: 1.4109 - dense_339_loss: 1.4989 - dense_340_loss: 1.4833 - dense_341_loss: 1.2890 - dense_342_loss: 1.2127 - dense_343_loss: 1.2459 - dense_344_loss: 1.2451 - dense_335_accuracy: 0.3694 - dense_336_accuracy: 0.2600 - dense_337_accuracy: 0.3776 - dense_338_accuracy: 0.2982 - dense_339_accuracy: 0.2586 - dense_340_accuracy: 0.2594 - dense_341_accuracy: 0.3804 - dense_342_accuracy: 0.3926 - dense_343_accuracy: 0.3638 - dense_344_accuracy: 0.3706\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.4054 - dense_335_loss: 1.2880 - dense_336_loss: 1.4826 - dense_337_loss: 1.2902 - dense_338_loss: 1.4033 - dense_339_loss: 1.4903 - dense_340_loss: 1.4756 - dense_341_loss: 1.2865 - dense_342_loss: 1.2072 - dense_343_loss: 1.2405 - dense_344_loss: 1.2412 - dense_335_accuracy: 0.3754 - dense_336_accuracy: 0.2580 - dense_337_accuracy: 0.3868 - dense_338_accuracy: 0.2956 - dense_339_accuracy: 0.2588 - dense_340_accuracy: 0.2620 - dense_341_accuracy: 0.3740 - dense_342_accuracy: 0.3900 - dense_343_accuracy: 0.3750 - dense_344_accuracy: 0.3802\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.4428 - dense_335_loss: 1.2964 - dense_336_loss: 1.4892 - dense_337_loss: 1.2952 - dense_338_loss: 1.4030 - dense_339_loss: 1.4934 - dense_340_loss: 1.4782 - dense_341_loss: 1.2908 - dense_342_loss: 1.2108 - dense_343_loss: 1.2442 - dense_344_loss: 1.2416 - dense_335_accuracy: 0.3692 - dense_336_accuracy: 0.2658 - dense_337_accuracy: 0.3822 - dense_338_accuracy: 0.2966 - dense_339_accuracy: 0.2560 - dense_340_accuracy: 0.2676 - dense_341_accuracy: 0.3816 - dense_342_accuracy: 0.3926 - dense_343_accuracy: 0.3698 - dense_344_accuracy: 0.3768\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.4280 - dense_335_loss: 1.2877 - dense_336_loss: 1.4852 - dense_337_loss: 1.2953 - dense_338_loss: 1.4067 - dense_339_loss: 1.4927 - dense_340_loss: 1.4783 - dense_341_loss: 1.2887 - dense_342_loss: 1.2096 - dense_343_loss: 1.2410 - dense_344_loss: 1.2429 - dense_335_accuracy: 0.3742 - dense_336_accuracy: 0.2656 - dense_337_accuracy: 0.3822 - dense_338_accuracy: 0.2986 - dense_339_accuracy: 0.2680 - dense_340_accuracy: 0.2664 - dense_341_accuracy: 0.3800 - dense_342_accuracy: 0.3898 - dense_343_accuracy: 0.3764 - dense_344_accuracy: 0.3804\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.4435 - dense_335_loss: 1.2961 - dense_336_loss: 1.4879 - dense_337_loss: 1.2958 - dense_338_loss: 1.4031 - dense_339_loss: 1.4943 - dense_340_loss: 1.4799 - dense_341_loss: 1.2880 - dense_342_loss: 1.2159 - dense_343_loss: 1.2416 - dense_344_loss: 1.2408 - dense_335_accuracy: 0.3654 - dense_336_accuracy: 0.2584 - dense_337_accuracy: 0.3762 - dense_338_accuracy: 0.2976 - dense_339_accuracy: 0.2578 - dense_340_accuracy: 0.2614 - dense_341_accuracy: 0.3850 - dense_342_accuracy: 0.3846 - dense_343_accuracy: 0.3700 - dense_344_accuracy: 0.3788\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.3889 - dense_335_loss: 1.2895 - dense_336_loss: 1.4821 - dense_337_loss: 1.2895 - dense_338_loss: 1.3989 - dense_339_loss: 1.4874 - dense_340_loss: 1.4758 - dense_341_loss: 1.2809 - dense_342_loss: 1.2074 - dense_343_loss: 1.2378 - dense_344_loss: 1.2395 - dense_335_accuracy: 0.3686 - dense_336_accuracy: 0.2612 - dense_337_accuracy: 0.3838 - dense_338_accuracy: 0.2926 - dense_339_accuracy: 0.2624 - dense_340_accuracy: 0.2594 - dense_341_accuracy: 0.3864 - dense_342_accuracy: 0.3904 - dense_343_accuracy: 0.3698 - dense_344_accuracy: 0.3748\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.3573 - dense_335_loss: 1.2842 - dense_336_loss: 1.4808 - dense_337_loss: 1.2845 - dense_338_loss: 1.3976 - dense_339_loss: 1.4837 - dense_340_loss: 1.4707 - dense_341_loss: 1.2815 - dense_342_loss: 1.2024 - dense_343_loss: 1.2376 - dense_344_loss: 1.2342 - dense_335_accuracy: 0.3746 - dense_336_accuracy: 0.2680 - dense_337_accuracy: 0.3806 - dense_338_accuracy: 0.2916 - dense_339_accuracy: 0.2668 - dense_340_accuracy: 0.2720 - dense_341_accuracy: 0.3906 - dense_342_accuracy: 0.4010 - dense_343_accuracy: 0.3778 - dense_344_accuracy: 0.3840\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.3470 - dense_335_loss: 1.2862 - dense_336_loss: 1.4770 - dense_337_loss: 1.2832 - dense_338_loss: 1.3975 - dense_339_loss: 1.4824 - dense_340_loss: 1.4687 - dense_341_loss: 1.2780 - dense_342_loss: 1.2033 - dense_343_loss: 1.2372 - dense_344_loss: 1.2335 - dense_335_accuracy: 0.3724 - dense_336_accuracy: 0.2748 - dense_337_accuracy: 0.3868 - dense_338_accuracy: 0.3020 - dense_339_accuracy: 0.2752 - dense_340_accuracy: 0.2722 - dense_341_accuracy: 0.3934 - dense_342_accuracy: 0.4038 - dense_343_accuracy: 0.3776 - dense_344_accuracy: 0.3848\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.3112 - dense_335_loss: 1.2826 - dense_336_loss: 1.4740 - dense_337_loss: 1.2800 - dense_338_loss: 1.3919 - dense_339_loss: 1.4785 - dense_340_loss: 1.4654 - dense_341_loss: 1.2752 - dense_342_loss: 1.1998 - dense_343_loss: 1.2333 - dense_344_loss: 1.2304 - dense_335_accuracy: 0.3766 - dense_336_accuracy: 0.2730 - dense_337_accuracy: 0.3862 - dense_338_accuracy: 0.3028 - dense_339_accuracy: 0.2722 - dense_340_accuracy: 0.2690 - dense_341_accuracy: 0.3858 - dense_342_accuracy: 0.3964 - dense_343_accuracy: 0.3810 - dense_344_accuracy: 0.3890\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.2465 - dense_335_loss: 1.2763 - dense_336_loss: 1.4674 - dense_337_loss: 1.2751 - dense_338_loss: 1.3852 - dense_339_loss: 1.4714 - dense_340_loss: 1.4581 - dense_341_loss: 1.2679 - dense_342_loss: 1.1916 - dense_343_loss: 1.2268 - dense_344_loss: 1.2267 - dense_335_accuracy: 0.3790 - dense_336_accuracy: 0.2722 - dense_337_accuracy: 0.3908 - dense_338_accuracy: 0.3104 - dense_339_accuracy: 0.2746 - dense_340_accuracy: 0.2700 - dense_341_accuracy: 0.3948 - dense_342_accuracy: 0.4002 - dense_343_accuracy: 0.3788 - dense_344_accuracy: 0.3808\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4936B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4936B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D264FF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D264FF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 11ms/step - loss: 0.2484\n",
      "Epoch 2/25\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2425\n",
      "Epoch 3/25\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2309\n",
      "Epoch 4/25\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2074\n",
      "Epoch 5/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1695\n",
      "Epoch 6/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1160\n",
      "Epoch 7/25\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0649\n",
      "Epoch 8/25\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0329\n",
      "Epoch 9/25\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0178\n",
      "Epoch 10/25\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0134\n",
      "Epoch 11/25\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0104\n",
      "Epoch 12/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0088\n",
      "Epoch 13/25\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0082\n",
      "Epoch 14/25\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0075\n",
      "Epoch 15/25\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0070\n",
      "Epoch 16/25\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0067\n",
      "Epoch 17/25\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0067\n",
      "Epoch 18/25\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0065\n",
      "Epoch 19/25\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0065\n",
      "Epoch 20/25\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0063\n",
      "Epoch 21/25\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0061\n",
      "Epoch 22/25\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0061\n",
      "Epoch 23/25\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0060\n",
      "Epoch 24/25\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0061\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0059\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D25755E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D25755E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - 3s 7ms/step - loss: 23.5734 - dense_348_loss: 2.0358 - dense_349_loss: 2.7493 - dense_350_loss: 2.2911 - dense_351_loss: 2.2295 - dense_352_loss: 2.7625 - dense_353_loss: 2.7721 - dense_354_loss: 2.3312 - dense_355_loss: 2.3497 - dense_356_loss: 2.1549 - dense_357_loss: 1.8972 - dense_348_accuracy: 0.2700 - dense_349_accuracy: 0.1170 - dense_350_accuracy: 0.1110 - dense_351_accuracy: 0.1270 - dense_352_accuracy: 0.0980 - dense_353_accuracy: 0.1070 - dense_354_accuracy: 0.1390 - dense_355_accuracy: 0.1400 - dense_356_accuracy: 0.3350 - dense_357_accuracy: 0.3880\n",
      "Epoch 2/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 18.7542 - dense_348_loss: 1.7228 - dense_349_loss: 2.1270 - dense_350_loss: 1.8195 - dense_351_loss: 1.9198 - dense_352_loss: 2.1803 - dense_353_loss: 2.2320 - dense_354_loss: 1.9237 - dense_355_loss: 1.9430 - dense_356_loss: 1.4693 - dense_357_loss: 1.4169 - dense_348_accuracy: 0.3290 - dense_349_accuracy: 0.2220 - dense_350_accuracy: 0.2920 - dense_351_accuracy: 0.2160 - dense_352_accuracy: 0.1830 - dense_353_accuracy: 0.1690 - dense_354_accuracy: 0.2330 - dense_355_accuracy: 0.2150 - dense_356_accuracy: 0.4920 - dense_357_accuracy: 0.4940\n",
      "Epoch 3/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 16.0722 - dense_348_loss: 1.5503 - dense_349_loss: 1.7759 - dense_350_loss: 1.5265 - dense_351_loss: 1.6643 - dense_352_loss: 1.8392 - dense_353_loss: 1.8614 - dense_354_loss: 1.6455 - dense_355_loss: 1.7024 - dense_356_loss: 1.2393 - dense_357_loss: 1.2672 - dense_348_accuracy: 0.3190 - dense_349_accuracy: 0.2400 - dense_350_accuracy: 0.3510 - dense_351_accuracy: 0.2480 - dense_352_accuracy: 0.2460 - dense_353_accuracy: 0.2260 - dense_354_accuracy: 0.2720 - dense_355_accuracy: 0.2370 - dense_356_accuracy: 0.5000 - dense_357_accuracy: 0.5240\n",
      "Epoch 4/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 15.5801 - dense_348_loss: 1.4975 - dense_349_loss: 1.7176 - dense_350_loss: 1.5014 - dense_351_loss: 1.6244 - dense_352_loss: 1.7690 - dense_353_loss: 1.7853 - dense_354_loss: 1.6002 - dense_355_loss: 1.6571 - dense_356_loss: 1.2051 - dense_357_loss: 1.2223 - dense_348_accuracy: 0.3530 - dense_349_accuracy: 0.2340 - dense_350_accuracy: 0.3810 - dense_351_accuracy: 0.2450 - dense_352_accuracy: 0.2340 - dense_353_accuracy: 0.2390 - dense_354_accuracy: 0.2680 - dense_355_accuracy: 0.2180 - dense_356_accuracy: 0.5120 - dense_357_accuracy: 0.5270\n",
      "Epoch 5/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 15.3216 - dense_348_loss: 1.4684 - dense_349_loss: 1.6833 - dense_350_loss: 1.4685 - dense_351_loss: 1.6126 - dense_352_loss: 1.7489 - dense_353_loss: 1.7603 - dense_354_loss: 1.5619 - dense_355_loss: 1.6179 - dense_356_loss: 1.1899 - dense_357_loss: 1.2099 - dense_348_accuracy: 0.3430 - dense_349_accuracy: 0.2160 - dense_350_accuracy: 0.3760 - dense_351_accuracy: 0.2380 - dense_352_accuracy: 0.2270 - dense_353_accuracy: 0.2280 - dense_354_accuracy: 0.2840 - dense_355_accuracy: 0.2610 - dense_356_accuracy: 0.5150 - dense_357_accuracy: 0.5240\n",
      "Epoch 6/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.8427 - dense_348_loss: 1.4230 - dense_349_loss: 1.6120 - dense_350_loss: 1.4175 - dense_351_loss: 1.5895 - dense_352_loss: 1.6876 - dense_353_loss: 1.6978 - dense_354_loss: 1.5143 - dense_355_loss: 1.5800 - dense_356_loss: 1.1566 - dense_357_loss: 1.1643 - dense_348_accuracy: 0.3690 - dense_349_accuracy: 0.2620 - dense_350_accuracy: 0.3990 - dense_351_accuracy: 0.2720 - dense_352_accuracy: 0.2750 - dense_353_accuracy: 0.2560 - dense_354_accuracy: 0.3190 - dense_355_accuracy: 0.2780 - dense_356_accuracy: 0.5160 - dense_357_accuracy: 0.5390\n",
      "Epoch 7/25\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 14.5902 - dense_348_loss: 1.4056 - dense_349_loss: 1.5983 - dense_350_loss: 1.4059 - dense_351_loss: 1.5581 - dense_352_loss: 1.6529 - dense_353_loss: 1.6644 - dense_354_loss: 1.4991 - dense_355_loss: 1.5512 - dense_356_loss: 1.1305 - dense_357_loss: 1.1243 - dense_348_accuracy: 0.3660 - dense_349_accuracy: 0.2590 - dense_350_accuracy: 0.3960 - dense_351_accuracy: 0.2660 - dense_352_accuracy: 0.2590 - dense_353_accuracy: 0.2500 - dense_354_accuracy: 0.3130 - dense_355_accuracy: 0.2800 - dense_356_accuracy: 0.5180 - dense_357_accuracy: 0.5430\n",
      "Epoch 8/25\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 14.4879 - dense_348_loss: 1.4023 - dense_349_loss: 1.5842 - dense_350_loss: 1.4029 - dense_351_loss: 1.5428 - dense_352_loss: 1.6404 - dense_353_loss: 1.6560 - dense_354_loss: 1.4853 - dense_355_loss: 1.5418 - dense_356_loss: 1.1149 - dense_357_loss: 1.1173 - dense_348_accuracy: 0.3860 - dense_349_accuracy: 0.2780 - dense_350_accuracy: 0.3790 - dense_351_accuracy: 0.2970 - dense_352_accuracy: 0.2840 - dense_353_accuracy: 0.2720 - dense_354_accuracy: 0.3080 - dense_355_accuracy: 0.2760 - dense_356_accuracy: 0.5280 - dense_357_accuracy: 0.5450\n",
      "Epoch 9/25\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 14.3711 - dense_348_loss: 1.4001 - dense_349_loss: 1.5753 - dense_350_loss: 1.3901 - dense_351_loss: 1.5262 - dense_352_loss: 1.6269 - dense_353_loss: 1.6393 - dense_354_loss: 1.4727 - dense_355_loss: 1.5277 - dense_356_loss: 1.1075 - dense_357_loss: 1.1054 - dense_348_accuracy: 0.3670 - dense_349_accuracy: 0.2920 - dense_350_accuracy: 0.4080 - dense_351_accuracy: 0.3130 - dense_352_accuracy: 0.2890 - dense_353_accuracy: 0.2940 - dense_354_accuracy: 0.3350 - dense_355_accuracy: 0.3160 - dense_356_accuracy: 0.5260 - dense_357_accuracy: 0.5510\n",
      "Epoch 10/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.2300 - dense_348_loss: 1.3818 - dense_349_loss: 1.5597 - dense_350_loss: 1.3792 - dense_351_loss: 1.5136 - dense_352_loss: 1.6158 - dense_353_loss: 1.6243 - dense_354_loss: 1.4511 - dense_355_loss: 1.5253 - dense_356_loss: 1.0910 - dense_357_loss: 1.0881 - dense_348_accuracy: 0.3860 - dense_349_accuracy: 0.2990 - dense_350_accuracy: 0.3950 - dense_351_accuracy: 0.3010 - dense_352_accuracy: 0.2940 - dense_353_accuracy: 0.3000 - dense_354_accuracy: 0.3480 - dense_355_accuracy: 0.2820 - dense_356_accuracy: 0.5250 - dense_357_accuracy: 0.5660\n",
      "Epoch 11/25\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 14.2226 - dense_348_loss: 1.3867 - dense_349_loss: 1.5538 - dense_350_loss: 1.3760 - dense_351_loss: 1.5098 - dense_352_loss: 1.6019 - dense_353_loss: 1.6185 - dense_354_loss: 1.4536 - dense_355_loss: 1.5291 - dense_356_loss: 1.0971 - dense_357_loss: 1.0961 - dense_348_accuracy: 0.3950 - dense_349_accuracy: 0.3320 - dense_350_accuracy: 0.4230 - dense_351_accuracy: 0.3080 - dense_352_accuracy: 0.3220 - dense_353_accuracy: 0.2950 - dense_354_accuracy: 0.3490 - dense_355_accuracy: 0.2990 - dense_356_accuracy: 0.5460 - dense_357_accuracy: 0.5610\n",
      "Epoch 12/25\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 14.0026 - dense_348_loss: 1.3604 - dense_349_loss: 1.5319 - dense_350_loss: 1.3579 - dense_351_loss: 1.4922 - dense_352_loss: 1.5745 - dense_353_loss: 1.5922 - dense_354_loss: 1.4302 - dense_355_loss: 1.5038 - dense_356_loss: 1.0866 - dense_357_loss: 1.0728 - dense_348_accuracy: 0.4230 - dense_349_accuracy: 0.3170 - dense_350_accuracy: 0.4130 - dense_351_accuracy: 0.3210 - dense_352_accuracy: 0.3410 - dense_353_accuracy: 0.3200 - dense_354_accuracy: 0.3880 - dense_355_accuracy: 0.3300 - dense_356_accuracy: 0.5440 - dense_357_accuracy: 0.5700\n",
      "Epoch 13/25\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 13.8186 - dense_348_loss: 1.3491 - dense_349_loss: 1.5059 - dense_350_loss: 1.3445 - dense_351_loss: 1.4703 - dense_352_loss: 1.5524 - dense_353_loss: 1.5740 - dense_354_loss: 1.4167 - dense_355_loss: 1.4874 - dense_356_loss: 1.0653 - dense_357_loss: 1.0531 - dense_348_accuracy: 0.4090 - dense_349_accuracy: 0.3640 - dense_350_accuracy: 0.4350 - dense_351_accuracy: 0.3380 - dense_352_accuracy: 0.3670 - dense_353_accuracy: 0.3610 - dense_354_accuracy: 0.4020 - dense_355_accuracy: 0.3330 - dense_356_accuracy: 0.5690 - dense_357_accuracy: 0.5770\n",
      "Epoch 14/25\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 13.6562 - dense_348_loss: 1.3308 - dense_349_loss: 1.4865 - dense_350_loss: 1.3223 - dense_351_loss: 1.4548 - dense_352_loss: 1.5348 - dense_353_loss: 1.5544 - dense_354_loss: 1.4009 - dense_355_loss: 1.4762 - dense_356_loss: 1.0576 - dense_357_loss: 1.0379 - dense_348_accuracy: 0.4360 - dense_349_accuracy: 0.3810 - dense_350_accuracy: 0.4590 - dense_351_accuracy: 0.3660 - dense_352_accuracy: 0.3750 - dense_353_accuracy: 0.3610 - dense_354_accuracy: 0.3960 - dense_355_accuracy: 0.3720 - dense_356_accuracy: 0.5710 - dense_357_accuracy: 0.5910\n",
      "Epoch 15/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 13.5262 - dense_348_loss: 1.3132 - dense_349_loss: 1.4756 - dense_350_loss: 1.3104 - dense_351_loss: 1.4398 - dense_352_loss: 1.5182 - dense_353_loss: 1.5378 - dense_354_loss: 1.3859 - dense_355_loss: 1.4552 - dense_356_loss: 1.0547 - dense_357_loss: 1.0354 - dense_348_accuracy: 0.4620 - dense_349_accuracy: 0.3900 - dense_350_accuracy: 0.4680 - dense_351_accuracy: 0.3950 - dense_352_accuracy: 0.3840 - dense_353_accuracy: 0.3850 - dense_354_accuracy: 0.4150 - dense_355_accuracy: 0.3790 - dense_356_accuracy: 0.5550 - dense_357_accuracy: 0.5940\n",
      "Epoch 16/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 13.3332 - dense_348_loss: 1.3104 - dense_349_loss: 1.4383 - dense_350_loss: 1.2930 - dense_351_loss: 1.4227 - dense_352_loss: 1.5004 - dense_353_loss: 1.5197 - dense_354_loss: 1.3713 - dense_355_loss: 1.4307 - dense_356_loss: 1.0296 - dense_357_loss: 1.0170 - dense_348_accuracy: 0.4670 - dense_349_accuracy: 0.4130 - dense_350_accuracy: 0.4700 - dense_351_accuracy: 0.4100 - dense_352_accuracy: 0.4010 - dense_353_accuracy: 0.4060 - dense_354_accuracy: 0.4300 - dense_355_accuracy: 0.4060 - dense_356_accuracy: 0.5900 - dense_357_accuracy: 0.5990\n",
      "Epoch 17/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 13.1058 - dense_348_loss: 1.2780 - dense_349_loss: 1.4146 - dense_350_loss: 1.2738 - dense_351_loss: 1.3945 - dense_352_loss: 1.4630 - dense_353_loss: 1.4944 - dense_354_loss: 1.3442 - dense_355_loss: 1.4106 - dense_356_loss: 1.0273 - dense_357_loss: 1.0053 - dense_348_accuracy: 0.4700 - dense_349_accuracy: 0.4360 - dense_350_accuracy: 0.4700 - dense_351_accuracy: 0.4190 - dense_352_accuracy: 0.4360 - dense_353_accuracy: 0.4150 - dense_354_accuracy: 0.4440 - dense_355_accuracy: 0.4220 - dense_356_accuracy: 0.5870 - dense_357_accuracy: 0.6090\n",
      "Epoch 18/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 12.9652 - dense_348_loss: 1.2702 - dense_349_loss: 1.3955 - dense_350_loss: 1.2638 - dense_351_loss: 1.3642 - dense_352_loss: 1.4591 - dense_353_loss: 1.4819 - dense_354_loss: 1.3348 - dense_355_loss: 1.3993 - dense_356_loss: 1.0116 - dense_357_loss: 0.9849 - dense_348_accuracy: 0.4890 - dense_349_accuracy: 0.4420 - dense_350_accuracy: 0.4840 - dense_351_accuracy: 0.4330 - dense_352_accuracy: 0.4280 - dense_353_accuracy: 0.4300 - dense_354_accuracy: 0.4560 - dense_355_accuracy: 0.4060 - dense_356_accuracy: 0.5980 - dense_357_accuracy: 0.6110\n",
      "Epoch 19/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 12.7926 - dense_348_loss: 1.2653 - dense_349_loss: 1.3748 - dense_350_loss: 1.2418 - dense_351_loss: 1.3532 - dense_352_loss: 1.4373 - dense_353_loss: 1.4432 - dense_354_loss: 1.3188 - dense_355_loss: 1.3775 - dense_356_loss: 1.0043 - dense_357_loss: 0.9763 - dense_348_accuracy: 0.4900 - dense_349_accuracy: 0.4400 - dense_350_accuracy: 0.5000 - dense_351_accuracy: 0.4390 - dense_352_accuracy: 0.4320 - dense_353_accuracy: 0.4370 - dense_354_accuracy: 0.4500 - dense_355_accuracy: 0.4270 - dense_356_accuracy: 0.5920 - dense_357_accuracy: 0.6360\n",
      "Epoch 20/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 12.5802 - dense_348_loss: 1.2502 - dense_349_loss: 1.3441 - dense_350_loss: 1.2245 - dense_351_loss: 1.3343 - dense_352_loss: 1.3997 - dense_353_loss: 1.4228 - dense_354_loss: 1.2982 - dense_355_loss: 1.3603 - dense_356_loss: 0.9846 - dense_357_loss: 0.9615 - dense_348_accuracy: 0.4990 - dense_349_accuracy: 0.4630 - dense_350_accuracy: 0.5080 - dense_351_accuracy: 0.4550 - dense_352_accuracy: 0.4580 - dense_353_accuracy: 0.4430 - dense_354_accuracy: 0.4620 - dense_355_accuracy: 0.4380 - dense_356_accuracy: 0.6130 - dense_357_accuracy: 0.6470\n",
      "Epoch 21/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 12.2727 - dense_348_loss: 1.2133 - dense_349_loss: 1.3142 - dense_350_loss: 1.1781 - dense_351_loss: 1.3120 - dense_352_loss: 1.3670 - dense_353_loss: 1.3948 - dense_354_loss: 1.2689 - dense_355_loss: 1.3215 - dense_356_loss: 0.9771 - dense_357_loss: 0.9258 - dense_348_accuracy: 0.5220 - dense_349_accuracy: 0.4790 - dense_350_accuracy: 0.5360 - dense_351_accuracy: 0.4650 - dense_352_accuracy: 0.4690 - dense_353_accuracy: 0.4710 - dense_354_accuracy: 0.4830 - dense_355_accuracy: 0.4730 - dense_356_accuracy: 0.6050 - dense_357_accuracy: 0.6490\n",
      "Epoch 22/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 12.1976 - dense_348_loss: 1.2163 - dense_349_loss: 1.3111 - dense_350_loss: 1.1782 - dense_351_loss: 1.2926 - dense_352_loss: 1.3605 - dense_353_loss: 1.3811 - dense_354_loss: 1.2529 - dense_355_loss: 1.3258 - dense_356_loss: 0.9521 - dense_357_loss: 0.9269 - dense_348_accuracy: 0.5240 - dense_349_accuracy: 0.4950 - dense_350_accuracy: 0.5410 - dense_351_accuracy: 0.4870 - dense_352_accuracy: 0.4960 - dense_353_accuracy: 0.4780 - dense_354_accuracy: 0.4990 - dense_355_accuracy: 0.4690 - dense_356_accuracy: 0.6480 - dense_357_accuracy: 0.6620\n",
      "Epoch 23/25\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 11.8897 - dense_348_loss: 1.1763 - dense_349_loss: 1.2655 - dense_350_loss: 1.1416 - dense_351_loss: 1.2749 - dense_352_loss: 1.3213 - dense_353_loss: 1.3487 - dense_354_loss: 1.2189 - dense_355_loss: 1.2931 - dense_356_loss: 0.9417 - dense_357_loss: 0.9075 - dense_348_accuracy: 0.5490 - dense_349_accuracy: 0.4890 - dense_350_accuracy: 0.5480 - dense_351_accuracy: 0.4840 - dense_352_accuracy: 0.4840 - dense_353_accuracy: 0.4850 - dense_354_accuracy: 0.5110 - dense_355_accuracy: 0.4770 - dense_356_accuracy: 0.6320 - dense_357_accuracy: 0.6620\n",
      "Epoch 24/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 11.5609 - dense_348_loss: 1.1530 - dense_349_loss: 1.2314 - dense_350_loss: 1.1131 - dense_351_loss: 1.2229 - dense_352_loss: 1.2879 - dense_353_loss: 1.3087 - dense_354_loss: 1.1923 - dense_355_loss: 1.2506 - dense_356_loss: 0.9207 - dense_357_loss: 0.8802 - dense_348_accuracy: 0.5580 - dense_349_accuracy: 0.5240 - dense_350_accuracy: 0.5780 - dense_351_accuracy: 0.5150 - dense_352_accuracy: 0.5230 - dense_353_accuracy: 0.5020 - dense_354_accuracy: 0.5380 - dense_355_accuracy: 0.4990 - dense_356_accuracy: 0.6450 - dense_357_accuracy: 0.6870\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 11.4433 - dense_348_loss: 1.1378 - dense_349_loss: 1.2154 - dense_350_loss: 1.0953 - dense_351_loss: 1.2238 - dense_352_loss: 1.2617 - dense_353_loss: 1.2916 - dense_354_loss: 1.1748 - dense_355_loss: 1.2482 - dense_356_loss: 0.9204 - dense_357_loss: 0.8742 - dense_348_accuracy: 0.5630 - dense_349_accuracy: 0.5230 - dense_350_accuracy: 0.5840 - dense_351_accuracy: 0.5320 - dense_352_accuracy: 0.5390 - dense_353_accuracy: 0.5300 - dense_354_accuracy: 0.5330 - dense_355_accuracy: 0.5120 - dense_356_accuracy: 0.6480 - dense_357_accuracy: 0.6960\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D186D0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D186D0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4B34C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4B34C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - 3s 9ms/step - loss: 23.0452 - dense_358_loss: 2.0009 - dense_359_loss: 2.7058 - dense_360_loss: 2.2456 - dense_361_loss: 2.1745 - dense_362_loss: 2.6900 - dense_363_loss: 2.6959 - dense_364_loss: 2.2778 - dense_365_loss: 2.3150 - dense_366_loss: 2.0777 - dense_367_loss: 1.8620 - dense_358_accuracy: 0.2800 - dense_359_accuracy: 0.1100 - dense_360_accuracy: 0.2000 - dense_361_accuracy: 0.1920 - dense_362_accuracy: 0.1170 - dense_363_accuracy: 0.1330 - dense_364_accuracy: 0.1760 - dense_365_accuracy: 0.1500 - dense_366_accuracy: 0.3370 - dense_367_accuracy: 0.2990\n",
      "Epoch 2/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 17.7202 - dense_358_loss: 1.6659 - dense_359_loss: 2.0013 - dense_360_loss: 1.7478 - dense_361_loss: 1.7809 - dense_362_loss: 2.0492 - dense_363_loss: 2.0470 - dense_364_loss: 1.8268 - dense_365_loss: 1.8749 - dense_366_loss: 1.3750 - dense_367_loss: 1.3515 - dense_358_accuracy: 0.3320 - dense_359_accuracy: 0.2140 - dense_360_accuracy: 0.3350 - dense_361_accuracy: 0.2630 - dense_362_accuracy: 0.2070 - dense_363_accuracy: 0.2400 - dense_364_accuracy: 0.2420 - dense_365_accuracy: 0.2250 - dense_366_accuracy: 0.4800 - dense_367_accuracy: 0.4970\n",
      "Epoch 3/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 15.9082 - dense_358_loss: 1.5302 - dense_359_loss: 1.7522 - dense_360_loss: 1.5437 - dense_361_loss: 1.6652 - dense_362_loss: 1.8157 - dense_363_loss: 1.8185 - dense_364_loss: 1.6167 - dense_365_loss: 1.6945 - dense_366_loss: 1.2259 - dense_367_loss: 1.2457 - dense_358_accuracy: 0.3460 - dense_359_accuracy: 0.2370 - dense_360_accuracy: 0.3740 - dense_361_accuracy: 0.2300 - dense_362_accuracy: 0.2360 - dense_363_accuracy: 0.2390 - dense_364_accuracy: 0.2640 - dense_365_accuracy: 0.2440 - dense_366_accuracy: 0.4960 - dense_367_accuracy: 0.5210\n",
      "Epoch 4/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 15.2640 - dense_358_loss: 1.4464 - dense_359_loss: 1.6705 - dense_360_loss: 1.4674 - dense_361_loss: 1.6345 - dense_362_loss: 1.7452 - dense_363_loss: 1.7395 - dense_364_loss: 1.5564 - dense_365_loss: 1.6235 - dense_366_loss: 1.1780 - dense_367_loss: 1.2026 - dense_358_accuracy: 0.3800 - dense_359_accuracy: 0.2580 - dense_360_accuracy: 0.3780 - dense_361_accuracy: 0.2260 - dense_362_accuracy: 0.2320 - dense_363_accuracy: 0.2390 - dense_364_accuracy: 0.3000 - dense_365_accuracy: 0.2520 - dense_366_accuracy: 0.5030 - dense_367_accuracy: 0.5310\n",
      "Epoch 5/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 15.0052 - dense_358_loss: 1.4209 - dense_359_loss: 1.6338 - dense_360_loss: 1.4406 - dense_361_loss: 1.6120 - dense_362_loss: 1.7037 - dense_363_loss: 1.7036 - dense_364_loss: 1.5323 - dense_365_loss: 1.5925 - dense_366_loss: 1.1682 - dense_367_loss: 1.1977 - dense_358_accuracy: 0.3640 - dense_359_accuracy: 0.2380 - dense_360_accuracy: 0.3860 - dense_361_accuracy: 0.2210 - dense_362_accuracy: 0.2320 - dense_363_accuracy: 0.2410 - dense_364_accuracy: 0.2900 - dense_365_accuracy: 0.2290 - dense_366_accuracy: 0.4960 - dense_367_accuracy: 0.5360\n",
      "Epoch 6/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.7817 - dense_358_loss: 1.4131 - dense_359_loss: 1.6118 - dense_360_loss: 1.4227 - dense_361_loss: 1.5789 - dense_362_loss: 1.6769 - dense_363_loss: 1.6791 - dense_364_loss: 1.5163 - dense_365_loss: 1.5674 - dense_366_loss: 1.1461 - dense_367_loss: 1.1692 - dense_358_accuracy: 0.3770 - dense_359_accuracy: 0.2540 - dense_360_accuracy: 0.3780 - dense_361_accuracy: 0.2570 - dense_362_accuracy: 0.2250 - dense_363_accuracy: 0.2360 - dense_364_accuracy: 0.2870 - dense_365_accuracy: 0.2560 - dense_366_accuracy: 0.5120 - dense_367_accuracy: 0.5310\n",
      "Epoch 7/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.6613 - dense_358_loss: 1.3997 - dense_359_loss: 1.6041 - dense_360_loss: 1.4203 - dense_361_loss: 1.5621 - dense_362_loss: 1.6627 - dense_363_loss: 1.6736 - dense_364_loss: 1.5011 - dense_365_loss: 1.5639 - dense_366_loss: 1.1362 - dense_367_loss: 1.1376 - dense_358_accuracy: 0.3780 - dense_359_accuracy: 0.2480 - dense_360_accuracy: 0.3710 - dense_361_accuracy: 0.2580 - dense_362_accuracy: 0.2500 - dense_363_accuracy: 0.2410 - dense_364_accuracy: 0.2960 - dense_365_accuracy: 0.2520 - dense_366_accuracy: 0.5050 - dense_367_accuracy: 0.5350\n",
      "Epoch 8/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.6423 - dense_358_loss: 1.4025 - dense_359_loss: 1.6028 - dense_360_loss: 1.4117 - dense_361_loss: 1.5616 - dense_362_loss: 1.6615 - dense_363_loss: 1.6764 - dense_364_loss: 1.5044 - dense_365_loss: 1.5649 - dense_366_loss: 1.1281 - dense_367_loss: 1.1286 - dense_358_accuracy: 0.3660 - dense_359_accuracy: 0.2450 - dense_360_accuracy: 0.3850 - dense_361_accuracy: 0.2460 - dense_362_accuracy: 0.2560 - dense_363_accuracy: 0.2400 - dense_364_accuracy: 0.2820 - dense_365_accuracy: 0.2420 - dense_366_accuracy: 0.5020 - dense_367_accuracy: 0.5370\n",
      "Epoch 9/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.6599 - dense_358_loss: 1.3985 - dense_359_loss: 1.6004 - dense_360_loss: 1.4158 - dense_361_loss: 1.5704 - dense_362_loss: 1.6634 - dense_363_loss: 1.6757 - dense_364_loss: 1.5021 - dense_365_loss: 1.5662 - dense_366_loss: 1.1346 - dense_367_loss: 1.1328 - dense_358_accuracy: 0.3680 - dense_359_accuracy: 0.2400 - dense_360_accuracy: 0.3770 - dense_361_accuracy: 0.2510 - dense_362_accuracy: 0.2190 - dense_363_accuracy: 0.2420 - dense_364_accuracy: 0.2730 - dense_365_accuracy: 0.2410 - dense_366_accuracy: 0.5120 - dense_367_accuracy: 0.5400\n",
      "Epoch 10/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.5806 - dense_358_loss: 1.3970 - dense_359_loss: 1.5959 - dense_360_loss: 1.4082 - dense_361_loss: 1.5565 - dense_362_loss: 1.6505 - dense_363_loss: 1.6692 - dense_364_loss: 1.4964 - dense_365_loss: 1.5615 - dense_366_loss: 1.1215 - dense_367_loss: 1.1240 - dense_358_accuracy: 0.3750 - dense_359_accuracy: 0.2550 - dense_360_accuracy: 0.3680 - dense_361_accuracy: 0.2620 - dense_362_accuracy: 0.2540 - dense_363_accuracy: 0.2460 - dense_364_accuracy: 0.2990 - dense_365_accuracy: 0.2510 - dense_366_accuracy: 0.5150 - dense_367_accuracy: 0.5370\n",
      "Epoch 11/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.5847 - dense_358_loss: 1.3961 - dense_359_loss: 1.5991 - dense_360_loss: 1.4134 - dense_361_loss: 1.5561 - dense_362_loss: 1.6544 - dense_363_loss: 1.6706 - dense_364_loss: 1.4951 - dense_365_loss: 1.5565 - dense_366_loss: 1.1218 - dense_367_loss: 1.1216 - dense_358_accuracy: 0.3610 - dense_359_accuracy: 0.2230 - dense_360_accuracy: 0.3830 - dense_361_accuracy: 0.2490 - dense_362_accuracy: 0.2350 - dense_363_accuracy: 0.2270 - dense_364_accuracy: 0.2750 - dense_365_accuracy: 0.2410 - dense_366_accuracy: 0.4850 - dense_367_accuracy: 0.5390\n",
      "Epoch 12/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.5323 - dense_358_loss: 1.3917 - dense_359_loss: 1.5919 - dense_360_loss: 1.4104 - dense_361_loss: 1.5539 - dense_362_loss: 1.6494 - dense_363_loss: 1.6632 - dense_364_loss: 1.4867 - dense_365_loss: 1.5494 - dense_366_loss: 1.1187 - dense_367_loss: 1.1170 - dense_358_accuracy: 0.3800 - dense_359_accuracy: 0.2700 - dense_360_accuracy: 0.4000 - dense_361_accuracy: 0.2720 - dense_362_accuracy: 0.2630 - dense_363_accuracy: 0.2600 - dense_364_accuracy: 0.2960 - dense_365_accuracy: 0.2730 - dense_366_accuracy: 0.5220 - dense_367_accuracy: 0.5350\n",
      "Epoch 13/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.4721 - dense_358_loss: 1.3885 - dense_359_loss: 1.5802 - dense_360_loss: 1.3980 - dense_361_loss: 1.5404 - dense_362_loss: 1.6383 - dense_363_loss: 1.6557 - dense_364_loss: 1.4912 - dense_365_loss: 1.5521 - dense_366_loss: 1.1143 - dense_367_loss: 1.1133 - dense_358_accuracy: 0.3930 - dense_359_accuracy: 0.2320 - dense_360_accuracy: 0.3950 - dense_361_accuracy: 0.2510 - dense_362_accuracy: 0.2790 - dense_363_accuracy: 0.2430 - dense_364_accuracy: 0.3050 - dense_365_accuracy: 0.2450 - dense_366_accuracy: 0.4910 - dense_367_accuracy: 0.5390\n",
      "Epoch 14/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.4145 - dense_358_loss: 1.3843 - dense_359_loss: 1.5752 - dense_360_loss: 1.3952 - dense_361_loss: 1.5356 - dense_362_loss: 1.6322 - dense_363_loss: 1.6511 - dense_364_loss: 1.4837 - dense_365_loss: 1.5450 - dense_366_loss: 1.1072 - dense_367_loss: 1.1050 - dense_358_accuracy: 0.3800 - dense_359_accuracy: 0.2820 - dense_360_accuracy: 0.3980 - dense_361_accuracy: 0.2830 - dense_362_accuracy: 0.2810 - dense_363_accuracy: 0.2640 - dense_364_accuracy: 0.3010 - dense_365_accuracy: 0.2780 - dense_366_accuracy: 0.5170 - dense_367_accuracy: 0.5380\n",
      "Epoch 15/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.4402 - dense_358_loss: 1.3936 - dense_359_loss: 1.5786 - dense_360_loss: 1.4051 - dense_361_loss: 1.5380 - dense_362_loss: 1.6337 - dense_363_loss: 1.6492 - dense_364_loss: 1.4897 - dense_365_loss: 1.5476 - dense_366_loss: 1.0990 - dense_367_loss: 1.1058 - dense_358_accuracy: 0.3490 - dense_359_accuracy: 0.2590 - dense_360_accuracy: 0.3820 - dense_361_accuracy: 0.2610 - dense_362_accuracy: 0.2320 - dense_363_accuracy: 0.2600 - dense_364_accuracy: 0.2960 - dense_365_accuracy: 0.2640 - dense_366_accuracy: 0.5280 - dense_367_accuracy: 0.5400\n",
      "Epoch 16/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.3993 - dense_358_loss: 1.3881 - dense_359_loss: 1.5653 - dense_360_loss: 1.3915 - dense_361_loss: 1.5369 - dense_362_loss: 1.6354 - dense_363_loss: 1.6458 - dense_364_loss: 1.4905 - dense_365_loss: 1.5404 - dense_366_loss: 1.1040 - dense_367_loss: 1.1014 - dense_358_accuracy: 0.3850 - dense_359_accuracy: 0.2680 - dense_360_accuracy: 0.4040 - dense_361_accuracy: 0.2740 - dense_362_accuracy: 0.2700 - dense_363_accuracy: 0.2630 - dense_364_accuracy: 0.3060 - dense_365_accuracy: 0.2640 - dense_366_accuracy: 0.5080 - dense_367_accuracy: 0.5390\n",
      "Epoch 17/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.3438 - dense_358_loss: 1.3838 - dense_359_loss: 1.5610 - dense_360_loss: 1.3809 - dense_361_loss: 1.5254 - dense_362_loss: 1.6310 - dense_363_loss: 1.6391 - dense_364_loss: 1.4848 - dense_365_loss: 1.5365 - dense_366_loss: 1.1061 - dense_367_loss: 1.0952 - dense_358_accuracy: 0.3990 - dense_359_accuracy: 0.2640 - dense_360_accuracy: 0.3990 - dense_361_accuracy: 0.2690 - dense_362_accuracy: 0.2680 - dense_363_accuracy: 0.2780 - dense_364_accuracy: 0.3010 - dense_365_accuracy: 0.2800 - dense_366_accuracy: 0.5170 - dense_367_accuracy: 0.5360\n",
      "Epoch 18/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.2205 - dense_358_loss: 1.3731 - dense_359_loss: 1.5511 - dense_360_loss: 1.3743 - dense_361_loss: 1.5130 - dense_362_loss: 1.6127 - dense_363_loss: 1.6232 - dense_364_loss: 1.4675 - dense_365_loss: 1.5256 - dense_366_loss: 1.0917 - dense_367_loss: 1.0883 - dense_358_accuracy: 0.4060 - dense_359_accuracy: 0.2740 - dense_360_accuracy: 0.4090 - dense_361_accuracy: 0.2930 - dense_362_accuracy: 0.2810 - dense_363_accuracy: 0.2770 - dense_364_accuracy: 0.3030 - dense_365_accuracy: 0.2900 - dense_366_accuracy: 0.5220 - dense_367_accuracy: 0.5480\n",
      "Epoch 19/25\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 14.1867 - dense_358_loss: 1.3646 - dense_359_loss: 1.5429 - dense_360_loss: 1.3760 - dense_361_loss: 1.5154 - dense_362_loss: 1.6069 - dense_363_loss: 1.6212 - dense_364_loss: 1.4595 - dense_365_loss: 1.5168 - dense_366_loss: 1.0986 - dense_367_loss: 1.0848 - dense_358_accuracy: 0.3970 - dense_359_accuracy: 0.2870 - dense_360_accuracy: 0.4110 - dense_361_accuracy: 0.2780 - dense_362_accuracy: 0.3050 - dense_363_accuracy: 0.2890 - dense_364_accuracy: 0.3300 - dense_365_accuracy: 0.3110 - dense_366_accuracy: 0.5100 - dense_367_accuracy: 0.5560\n",
      "Epoch 20/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.1229 - dense_358_loss: 1.3568 - dense_359_loss: 1.5388 - dense_360_loss: 1.3660 - dense_361_loss: 1.5037 - dense_362_loss: 1.5949 - dense_363_loss: 1.6106 - dense_364_loss: 1.4584 - dense_365_loss: 1.5160 - dense_366_loss: 1.0972 - dense_367_loss: 1.0804 - dense_358_accuracy: 0.4190 - dense_359_accuracy: 0.2850 - dense_360_accuracy: 0.4110 - dense_361_accuracy: 0.3030 - dense_362_accuracy: 0.3150 - dense_363_accuracy: 0.2860 - dense_364_accuracy: 0.3060 - dense_365_accuracy: 0.2930 - dense_366_accuracy: 0.5150 - dense_367_accuracy: 0.5710\n",
      "Epoch 21/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.0198 - dense_358_loss: 1.3533 - dense_359_loss: 1.5209 - dense_360_loss: 1.3627 - dense_361_loss: 1.4957 - dense_362_loss: 1.5836 - dense_363_loss: 1.5979 - dense_364_loss: 1.4466 - dense_365_loss: 1.4979 - dense_366_loss: 1.0934 - dense_367_loss: 1.0677 - dense_358_accuracy: 0.4050 - dense_359_accuracy: 0.3220 - dense_360_accuracy: 0.4290 - dense_361_accuracy: 0.2990 - dense_362_accuracy: 0.3180 - dense_363_accuracy: 0.3130 - dense_364_accuracy: 0.3560 - dense_365_accuracy: 0.3210 - dense_366_accuracy: 0.5440 - dense_367_accuracy: 0.5850\n",
      "Epoch 22/25\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 13.9735 - dense_358_loss: 1.3515 - dense_359_loss: 1.5171 - dense_360_loss: 1.3604 - dense_361_loss: 1.4902 - dense_362_loss: 1.5751 - dense_363_loss: 1.5884 - dense_364_loss: 1.4424 - dense_365_loss: 1.5056 - dense_366_loss: 1.0783 - dense_367_loss: 1.0645 - dense_358_accuracy: 0.4260 - dense_359_accuracy: 0.3240 - dense_360_accuracy: 0.4300 - dense_361_accuracy: 0.3240 - dense_362_accuracy: 0.3180 - dense_363_accuracy: 0.3300 - dense_364_accuracy: 0.3380 - dense_365_accuracy: 0.3140 - dense_366_accuracy: 0.5480 - dense_367_accuracy: 0.5830\n",
      "Epoch 23/25\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 13.8130 - dense_358_loss: 1.3324 - dense_359_loss: 1.4934 - dense_360_loss: 1.3463 - dense_361_loss: 1.4682 - dense_362_loss: 1.5580 - dense_363_loss: 1.5827 - dense_364_loss: 1.4272 - dense_365_loss: 1.4860 - dense_366_loss: 1.0763 - dense_367_loss: 1.0424 - dense_358_accuracy: 0.4410 - dense_359_accuracy: 0.3360 - dense_360_accuracy: 0.4360 - dense_361_accuracy: 0.3210 - dense_362_accuracy: 0.3340 - dense_363_accuracy: 0.3250 - dense_364_accuracy: 0.3730 - dense_365_accuracy: 0.3430 - dense_366_accuracy: 0.5360 - dense_367_accuracy: 0.5980\n",
      "Epoch 24/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 13.5352 - dense_358_loss: 1.3155 - dense_359_loss: 1.4604 - dense_360_loss: 1.3140 - dense_361_loss: 1.4418 - dense_362_loss: 1.5227 - dense_363_loss: 1.5413 - dense_364_loss: 1.3986 - dense_365_loss: 1.4567 - dense_366_loss: 1.0545 - dense_367_loss: 1.0297 - dense_358_accuracy: 0.4390 - dense_359_accuracy: 0.3390 - dense_360_accuracy: 0.4740 - dense_361_accuracy: 0.3690 - dense_362_accuracy: 0.3440 - dense_363_accuracy: 0.3590 - dense_364_accuracy: 0.3860 - dense_365_accuracy: 0.3510 - dense_366_accuracy: 0.5540 - dense_367_accuracy: 0.6020\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 13.5097 - dense_358_loss: 1.3048 - dense_359_loss: 1.4608 - dense_360_loss: 1.3069 - dense_361_loss: 1.4516 - dense_362_loss: 1.5222 - dense_363_loss: 1.5416 - dense_364_loss: 1.3879 - dense_365_loss: 1.4570 - dense_366_loss: 1.0539 - dense_367_loss: 1.0231 - dense_358_accuracy: 0.4420 - dense_359_accuracy: 0.3600 - dense_360_accuracy: 0.4700 - dense_361_accuracy: 0.3430 - dense_362_accuracy: 0.3520 - dense_363_accuracy: 0.3610 - dense_364_accuracy: 0.4000 - dense_365_accuracy: 0.3500 - dense_366_accuracy: 0.5490 - dense_367_accuracy: 0.6090\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D0DDC288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D0DDC288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3AEA948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3AEA948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 11ms/step - loss: 0.2484\n",
      "Epoch 2/25\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2426\n",
      "Epoch 3/25\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2303\n",
      "Epoch 4/25\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2063\n",
      "Epoch 5/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1648\n",
      "Epoch 6/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1087\n",
      "Epoch 7/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0586\n",
      "Epoch 8/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0286\n",
      "Epoch 9/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0166\n",
      "Epoch 10/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0119\n",
      "Epoch 11/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0096\n",
      "Epoch 12/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0085\n",
      "Epoch 13/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0076\n",
      "Epoch 14/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0072\n",
      "Epoch 15/25\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0069\n",
      "Epoch 16/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0065\n",
      "Epoch 17/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0064\n",
      "Epoch 18/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0064\n",
      "Epoch 19/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0063\n",
      "Epoch 20/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0062\n",
      "Epoch 21/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0062\n",
      "Epoch 22/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0060\n",
      "Epoch 23/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0059\n",
      "Epoch 24/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0059\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0058\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D49805E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D49805E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - 3s 7ms/step - loss: 23.6383 - dense_371_loss: 2.0055 - dense_372_loss: 2.7471 - dense_373_loss: 2.2905 - dense_374_loss: 2.2579 - dense_375_loss: 2.7575 - dense_376_loss: 2.7952 - dense_377_loss: 2.3709 - dense_378_loss: 2.3582 - dense_379_loss: 2.1557 - dense_380_loss: 1.8998 - dense_371_accuracy: 0.2470 - dense_372_accuracy: 0.0910 - dense_373_accuracy: 0.1590 - dense_374_accuracy: 0.1480 - dense_375_accuracy: 0.0920 - dense_376_accuracy: 0.0950 - dense_377_accuracy: 0.1590 - dense_378_accuracy: 0.1570 - dense_379_accuracy: 0.2410 - dense_380_accuracy: 0.3860\n",
      "Epoch 2/25\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 20.4272 - dense_371_loss: 1.6277 - dense_372_loss: 2.3576 - dense_373_loss: 1.9813 - dense_374_loss: 2.1405 - dense_375_loss: 2.3709 - dense_376_loss: 2.4572 - dense_377_loss: 2.1319 - dense_378_loss: 2.1043 - dense_379_loss: 1.6920 - dense_380_loss: 1.5637 - dense_371_accuracy: 0.3370 - dense_372_accuracy: 0.1910 - dense_373_accuracy: 0.2770 - dense_374_accuracy: 0.1870 - dense_375_accuracy: 0.1740 - dense_376_accuracy: 0.1520 - dense_377_accuracy: 0.2120 - dense_378_accuracy: 0.2460 - dense_379_accuracy: 0.3830 - dense_380_accuracy: 0.4290\n",
      "Epoch 3/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 16.6350 - dense_371_loss: 1.4894 - dense_372_loss: 1.8393 - dense_373_loss: 1.5888 - dense_374_loss: 1.7328 - dense_375_loss: 1.8507 - dense_376_loss: 1.9930 - dense_377_loss: 1.7634 - dense_378_loss: 1.7844 - dense_379_loss: 1.2991 - dense_380_loss: 1.2941 - dense_371_accuracy: 0.3680 - dense_372_accuracy: 0.2380 - dense_373_accuracy: 0.3610 - dense_374_accuracy: 0.2310 - dense_375_accuracy: 0.2340 - dense_376_accuracy: 0.2150 - dense_377_accuracy: 0.2590 - dense_378_accuracy: 0.2390 - dense_379_accuracy: 0.5000 - dense_380_accuracy: 0.5020\n",
      "Epoch 4/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 15.9508 - dense_371_loss: 1.4502 - dense_372_loss: 1.7812 - dense_373_loss: 1.5522 - dense_374_loss: 1.6527 - dense_375_loss: 1.7624 - dense_376_loss: 1.9208 - dense_377_loss: 1.6625 - dense_378_loss: 1.6810 - dense_379_loss: 1.2463 - dense_380_loss: 1.2415 - dense_371_accuracy: 0.3760 - dense_372_accuracy: 0.2300 - dense_373_accuracy: 0.3690 - dense_374_accuracy: 0.2800 - dense_375_accuracy: 0.2170 - dense_376_accuracy: 0.1930 - dense_377_accuracy: 0.2500 - dense_378_accuracy: 0.2620 - dense_379_accuracy: 0.4880 - dense_380_accuracy: 0.5070\n",
      "Epoch 5/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 15.8007 - dense_371_loss: 1.4466 - dense_372_loss: 1.7739 - dense_373_loss: 1.5298 - dense_374_loss: 1.6438 - dense_375_loss: 1.7407 - dense_376_loss: 1.9036 - dense_377_loss: 1.6528 - dense_378_loss: 1.6640 - dense_379_loss: 1.2155 - dense_380_loss: 1.2300 - dense_371_accuracy: 0.3670 - dense_372_accuracy: 0.2380 - dense_373_accuracy: 0.3550 - dense_374_accuracy: 0.2520 - dense_375_accuracy: 0.2520 - dense_376_accuracy: 0.2240 - dense_377_accuracy: 0.2800 - dense_378_accuracy: 0.2630 - dense_379_accuracy: 0.5200 - dense_380_accuracy: 0.5160\n",
      "Epoch 6/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 15.6932 - dense_371_loss: 1.4297 - dense_372_loss: 1.7538 - dense_373_loss: 1.5216 - dense_374_loss: 1.6421 - dense_375_loss: 1.7328 - dense_376_loss: 1.8888 - dense_377_loss: 1.6387 - dense_378_loss: 1.6493 - dense_379_loss: 1.2148 - dense_380_loss: 1.2217 - dense_371_accuracy: 0.3820 - dense_372_accuracy: 0.2260 - dense_373_accuracy: 0.3620 - dense_374_accuracy: 0.2700 - dense_375_accuracy: 0.2320 - dense_376_accuracy: 0.2210 - dense_377_accuracy: 0.2790 - dense_378_accuracy: 0.2850 - dense_379_accuracy: 0.5170 - dense_380_accuracy: 0.5120\n",
      "Epoch 7/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 15.4063 - dense_371_loss: 1.4042 - dense_372_loss: 1.7147 - dense_373_loss: 1.4786 - dense_374_loss: 1.6345 - dense_375_loss: 1.6894 - dense_376_loss: 1.8567 - dense_377_loss: 1.6201 - dense_378_loss: 1.6244 - dense_379_loss: 1.1988 - dense_380_loss: 1.1849 - dense_371_accuracy: 0.3840 - dense_372_accuracy: 0.2620 - dense_373_accuracy: 0.3650 - dense_374_accuracy: 0.2520 - dense_375_accuracy: 0.2210 - dense_376_accuracy: 0.2340 - dense_377_accuracy: 0.2900 - dense_378_accuracy: 0.2870 - dense_379_accuracy: 0.5140 - dense_380_accuracy: 0.5240\n",
      "Epoch 8/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.9853 - dense_371_loss: 1.3784 - dense_372_loss: 1.6707 - dense_373_loss: 1.4487 - dense_374_loss: 1.6071 - dense_375_loss: 1.6327 - dense_376_loss: 1.7931 - dense_377_loss: 1.5724 - dense_378_loss: 1.5832 - dense_379_loss: 1.1618 - dense_380_loss: 1.1372 - dense_371_accuracy: 0.3920 - dense_372_accuracy: 0.2800 - dense_373_accuracy: 0.3810 - dense_374_accuracy: 0.2770 - dense_375_accuracy: 0.2850 - dense_376_accuracy: 0.2640 - dense_377_accuracy: 0.3290 - dense_378_accuracy: 0.3010 - dense_379_accuracy: 0.5220 - dense_380_accuracy: 0.5310\n",
      "Epoch 9/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.7743 - dense_371_loss: 1.3566 - dense_372_loss: 1.6427 - dense_373_loss: 1.4388 - dense_374_loss: 1.5895 - dense_375_loss: 1.6111 - dense_376_loss: 1.7691 - dense_377_loss: 1.5540 - dense_378_loss: 1.5580 - dense_379_loss: 1.1338 - dense_380_loss: 1.1206 - dense_371_accuracy: 0.3860 - dense_372_accuracy: 0.2690 - dense_373_accuracy: 0.3810 - dense_374_accuracy: 0.2940 - dense_375_accuracy: 0.2990 - dense_376_accuracy: 0.2770 - dense_377_accuracy: 0.3050 - dense_378_accuracy: 0.3010 - dense_379_accuracy: 0.5280 - dense_380_accuracy: 0.5290\n",
      "Epoch 10/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.6556 - dense_371_loss: 1.3577 - dense_372_loss: 1.6258 - dense_373_loss: 1.4252 - dense_374_loss: 1.5736 - dense_375_loss: 1.6022 - dense_376_loss: 1.7568 - dense_377_loss: 1.5402 - dense_378_loss: 1.5521 - dense_379_loss: 1.1206 - dense_380_loss: 1.1015 - dense_371_accuracy: 0.3830 - dense_372_accuracy: 0.3040 - dense_373_accuracy: 0.3940 - dense_374_accuracy: 0.2950 - dense_375_accuracy: 0.2810 - dense_376_accuracy: 0.2820 - dense_377_accuracy: 0.3170 - dense_378_accuracy: 0.3070 - dense_379_accuracy: 0.5340 - dense_380_accuracy: 0.5390\n",
      "Epoch 11/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.3994 - dense_371_loss: 1.3381 - dense_372_loss: 1.5932 - dense_373_loss: 1.4025 - dense_374_loss: 1.5462 - dense_375_loss: 1.5690 - dense_376_loss: 1.7299 - dense_377_loss: 1.5153 - dense_378_loss: 1.5143 - dense_379_loss: 1.1090 - dense_380_loss: 1.0819 - dense_371_accuracy: 0.4070 - dense_372_accuracy: 0.3260 - dense_373_accuracy: 0.3930 - dense_374_accuracy: 0.3230 - dense_375_accuracy: 0.3290 - dense_376_accuracy: 0.3220 - dense_377_accuracy: 0.3550 - dense_378_accuracy: 0.3400 - dense_379_accuracy: 0.5380 - dense_380_accuracy: 0.5640\n",
      "Epoch 12/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.2131 - dense_371_loss: 1.3141 - dense_372_loss: 1.5720 - dense_373_loss: 1.3887 - dense_374_loss: 1.5291 - dense_375_loss: 1.5436 - dense_376_loss: 1.7032 - dense_377_loss: 1.4945 - dense_378_loss: 1.4957 - dense_379_loss: 1.1057 - dense_380_loss: 1.0664 - dense_371_accuracy: 0.4230 - dense_372_accuracy: 0.3490 - dense_373_accuracy: 0.4020 - dense_374_accuracy: 0.3260 - dense_375_accuracy: 0.3560 - dense_376_accuracy: 0.3350 - dense_377_accuracy: 0.3750 - dense_378_accuracy: 0.3580 - dense_379_accuracy: 0.5690 - dense_380_accuracy: 0.5660\n",
      "Epoch 13/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.0477 - dense_371_loss: 1.3096 - dense_372_loss: 1.5489 - dense_373_loss: 1.3663 - dense_374_loss: 1.5149 - dense_375_loss: 1.5209 - dense_376_loss: 1.6767 - dense_377_loss: 1.4811 - dense_378_loss: 1.4840 - dense_379_loss: 1.0879 - dense_380_loss: 1.0573 - dense_371_accuracy: 0.4100 - dense_372_accuracy: 0.3600 - dense_373_accuracy: 0.4220 - dense_374_accuracy: 0.3440 - dense_375_accuracy: 0.3810 - dense_376_accuracy: 0.3530 - dense_377_accuracy: 0.3970 - dense_378_accuracy: 0.3700 - dense_379_accuracy: 0.5580 - dense_380_accuracy: 0.5600\n",
      "Epoch 14/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 13.9802 - dense_371_loss: 1.2901 - dense_372_loss: 1.5509 - dense_373_loss: 1.3674 - dense_374_loss: 1.4969 - dense_375_loss: 1.5105 - dense_376_loss: 1.6719 - dense_377_loss: 1.4714 - dense_378_loss: 1.4845 - dense_379_loss: 1.0765 - dense_380_loss: 1.0601 - dense_371_accuracy: 0.4350 - dense_372_accuracy: 0.3690 - dense_373_accuracy: 0.4340 - dense_374_accuracy: 0.3680 - dense_375_accuracy: 0.3740 - dense_376_accuracy: 0.3450 - dense_377_accuracy: 0.3920 - dense_378_accuracy: 0.3830 - dense_379_accuracy: 0.5800 - dense_380_accuracy: 0.5630\n",
      "Epoch 15/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 13.7242 - dense_371_loss: 1.2841 - dense_372_loss: 1.5181 - dense_373_loss: 1.3394 - dense_374_loss: 1.4745 - dense_375_loss: 1.4712 - dense_376_loss: 1.6479 - dense_377_loss: 1.4443 - dense_378_loss: 1.4513 - dense_379_loss: 1.0637 - dense_380_loss: 1.0297 - dense_371_accuracy: 0.4400 - dense_372_accuracy: 0.3810 - dense_373_accuracy: 0.4360 - dense_374_accuracy: 0.3880 - dense_375_accuracy: 0.4160 - dense_376_accuracy: 0.3630 - dense_377_accuracy: 0.4040 - dense_378_accuracy: 0.3900 - dense_379_accuracy: 0.5740 - dense_380_accuracy: 0.5790\n",
      "Epoch 16/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 13.4011 - dense_371_loss: 1.2494 - dense_372_loss: 1.4752 - dense_373_loss: 1.3075 - dense_374_loss: 1.4353 - dense_375_loss: 1.4342 - dense_376_loss: 1.6119 - dense_377_loss: 1.4133 - dense_378_loss: 1.4242 - dense_379_loss: 1.0394 - dense_380_loss: 1.0106 - dense_371_accuracy: 0.4540 - dense_372_accuracy: 0.4120 - dense_373_accuracy: 0.4700 - dense_374_accuracy: 0.4130 - dense_375_accuracy: 0.4220 - dense_376_accuracy: 0.3700 - dense_377_accuracy: 0.4410 - dense_378_accuracy: 0.4090 - dense_379_accuracy: 0.6040 - dense_380_accuracy: 0.6070\n",
      "Epoch 17/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 13.2165 - dense_371_loss: 1.2384 - dense_372_loss: 1.4575 - dense_373_loss: 1.2785 - dense_374_loss: 1.4149 - dense_375_loss: 1.4184 - dense_376_loss: 1.5859 - dense_377_loss: 1.3977 - dense_378_loss: 1.4133 - dense_379_loss: 1.0233 - dense_380_loss: 0.9886 - dense_371_accuracy: 0.4810 - dense_372_accuracy: 0.4190 - dense_373_accuracy: 0.4630 - dense_374_accuracy: 0.4100 - dense_375_accuracy: 0.4170 - dense_376_accuracy: 0.4180 - dense_377_accuracy: 0.4330 - dense_378_accuracy: 0.4230 - dense_379_accuracy: 0.6130 - dense_380_accuracy: 0.5980\n",
      "Epoch 18/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 12.9288 - dense_371_loss: 1.2151 - dense_372_loss: 1.4177 - dense_373_loss: 1.2649 - dense_374_loss: 1.3735 - dense_375_loss: 1.3846 - dense_376_loss: 1.5575 - dense_377_loss: 1.3558 - dense_378_loss: 1.3672 - dense_379_loss: 1.0124 - dense_380_loss: 0.9802 - dense_371_accuracy: 0.4840 - dense_372_accuracy: 0.4470 - dense_373_accuracy: 0.4960 - dense_374_accuracy: 0.4580 - dense_375_accuracy: 0.4540 - dense_376_accuracy: 0.4380 - dense_377_accuracy: 0.4490 - dense_378_accuracy: 0.4450 - dense_379_accuracy: 0.6250 - dense_380_accuracy: 0.6220\n",
      "Epoch 19/25\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 12.6551 - dense_371_loss: 1.1894 - dense_372_loss: 1.3935 - dense_373_loss: 1.2339 - dense_374_loss: 1.3558 - dense_375_loss: 1.3569 - dense_376_loss: 1.5278 - dense_377_loss: 1.3247 - dense_378_loss: 1.3321 - dense_379_loss: 0.9912 - dense_380_loss: 0.9498 - dense_371_accuracy: 0.4960 - dense_372_accuracy: 0.4560 - dense_373_accuracy: 0.5000 - dense_374_accuracy: 0.4600 - dense_375_accuracy: 0.4640 - dense_376_accuracy: 0.4360 - dense_377_accuracy: 0.4870 - dense_378_accuracy: 0.4690 - dense_379_accuracy: 0.6240 - dense_380_accuracy: 0.6360\n",
      "Epoch 20/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 12.4742 - dense_371_loss: 1.1786 - dense_372_loss: 1.3609 - dense_373_loss: 1.2219 - dense_374_loss: 1.3233 - dense_375_loss: 1.3398 - dense_376_loss: 1.5023 - dense_377_loss: 1.3022 - dense_378_loss: 1.3220 - dense_379_loss: 0.9903 - dense_380_loss: 0.9331 - dense_371_accuracy: 0.5020 - dense_372_accuracy: 0.4710 - dense_373_accuracy: 0.5010 - dense_374_accuracy: 0.4780 - dense_375_accuracy: 0.4730 - dense_376_accuracy: 0.4510 - dense_377_accuracy: 0.4880 - dense_378_accuracy: 0.4740 - dense_379_accuracy: 0.6220 - dense_380_accuracy: 0.6240\n",
      "Epoch 21/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 12.2518 - dense_371_loss: 1.1556 - dense_372_loss: 1.3337 - dense_373_loss: 1.1868 - dense_374_loss: 1.3096 - dense_375_loss: 1.3079 - dense_376_loss: 1.4832 - dense_377_loss: 1.2868 - dense_378_loss: 1.3079 - dense_379_loss: 0.9678 - dense_380_loss: 0.9125 - dense_371_accuracy: 0.5320 - dense_372_accuracy: 0.4970 - dense_373_accuracy: 0.5420 - dense_374_accuracy: 0.4820 - dense_375_accuracy: 0.5010 - dense_376_accuracy: 0.4590 - dense_377_accuracy: 0.5090 - dense_378_accuracy: 0.4730 - dense_379_accuracy: 0.6420 - dense_380_accuracy: 0.6500\n",
      "Epoch 22/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 11.9339 - dense_371_loss: 1.1305 - dense_372_loss: 1.3030 - dense_373_loss: 1.1464 - dense_374_loss: 1.2712 - dense_375_loss: 1.2828 - dense_376_loss: 1.4384 - dense_377_loss: 1.2578 - dense_378_loss: 1.2753 - dense_379_loss: 0.9541 - dense_380_loss: 0.8745 - dense_371_accuracy: 0.5320 - dense_372_accuracy: 0.4940 - dense_373_accuracy: 0.5600 - dense_374_accuracy: 0.4890 - dense_375_accuracy: 0.5030 - dense_376_accuracy: 0.4870 - dense_377_accuracy: 0.5060 - dense_378_accuracy: 0.4970 - dense_379_accuracy: 0.6440 - dense_380_accuracy: 0.6750\n",
      "Epoch 23/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 11.5598 - dense_371_loss: 1.1036 - dense_372_loss: 1.2638 - dense_373_loss: 1.1165 - dense_374_loss: 1.2264 - dense_375_loss: 1.2346 - dense_376_loss: 1.3885 - dense_377_loss: 1.2122 - dense_378_loss: 1.2474 - dense_379_loss: 0.9202 - dense_380_loss: 0.8467 - dense_371_accuracy: 0.5560 - dense_372_accuracy: 0.5210 - dense_373_accuracy: 0.5600 - dense_374_accuracy: 0.5250 - dense_375_accuracy: 0.5290 - dense_376_accuracy: 0.5120 - dense_377_accuracy: 0.5390 - dense_378_accuracy: 0.5150 - dense_379_accuracy: 0.6670 - dense_380_accuracy: 0.6930\n",
      "Epoch 24/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 11.4996 - dense_371_loss: 1.0855 - dense_372_loss: 1.2449 - dense_373_loss: 1.1054 - dense_374_loss: 1.2307 - dense_375_loss: 1.2315 - dense_376_loss: 1.3918 - dense_377_loss: 1.2021 - dense_378_loss: 1.2324 - dense_379_loss: 0.9294 - dense_380_loss: 0.8460 - dense_371_accuracy: 0.5610 - dense_372_accuracy: 0.5180 - dense_373_accuracy: 0.5630 - dense_374_accuracy: 0.5070 - dense_375_accuracy: 0.5370 - dense_376_accuracy: 0.5140 - dense_377_accuracy: 0.5280 - dense_378_accuracy: 0.5080 - dense_379_accuracy: 0.6640 - dense_380_accuracy: 0.6820\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 11.3712 - dense_371_loss: 1.0928 - dense_372_loss: 1.2362 - dense_373_loss: 1.0941 - dense_374_loss: 1.2119 - dense_375_loss: 1.2148 - dense_376_loss: 1.3755 - dense_377_loss: 1.1945 - dense_378_loss: 1.2089 - dense_379_loss: 0.9126 - dense_380_loss: 0.8300 - dense_371_accuracy: 0.5500 - dense_372_accuracy: 0.5380 - dense_373_accuracy: 0.5730 - dense_374_accuracy: 0.5390 - dense_375_accuracy: 0.5510 - dense_376_accuracy: 0.5350 - dense_377_accuracy: 0.5690 - dense_378_accuracy: 0.5460 - dense_379_accuracy: 0.6580 - dense_380_accuracy: 0.6950\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4BDECA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4BDECA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D0EB6E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D0EB6E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - 3s 7ms/step - loss: 23.2957 - dense_381_loss: 1.9824 - dense_382_loss: 2.6607 - dense_383_loss: 2.2594 - dense_384_loss: 2.2707 - dense_385_loss: 2.7166 - dense_386_loss: 2.7681 - dense_387_loss: 2.3165 - dense_388_loss: 2.3371 - dense_389_loss: 2.1509 - dense_390_loss: 1.8333 - dense_381_accuracy: 0.2550 - dense_382_accuracy: 0.1270 - dense_383_accuracy: 0.1980 - dense_384_accuracy: 0.1910 - dense_385_accuracy: 0.1450 - dense_386_accuracy: 0.1170 - dense_387_accuracy: 0.1600 - dense_388_accuracy: 0.1420 - dense_389_accuracy: 0.3290 - dense_390_accuracy: 0.3880\n",
      "Epoch 2/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 18.3148 - dense_381_loss: 1.6240 - dense_382_loss: 2.0741 - dense_383_loss: 1.7860 - dense_384_loss: 1.8170 - dense_385_loss: 2.0812 - dense_386_loss: 2.1839 - dense_387_loss: 1.9170 - dense_388_loss: 1.9475 - dense_389_loss: 1.5045 - dense_390_loss: 1.3796 - dense_381_accuracy: 0.3350 - dense_382_accuracy: 0.1930 - dense_383_accuracy: 0.3410 - dense_384_accuracy: 0.2560 - dense_385_accuracy: 0.2180 - dense_386_accuracy: 0.1860 - dense_387_accuracy: 0.2160 - dense_388_accuracy: 0.1980 - dense_389_accuracy: 0.4490 - dense_390_accuracy: 0.4640\n",
      "Epoch 3/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 16.4127 - dense_381_loss: 1.4995 - dense_382_loss: 1.8441 - dense_383_loss: 1.6029 - dense_384_loss: 1.7060 - dense_385_loss: 1.8136 - dense_386_loss: 1.9615 - dense_387_loss: 1.6997 - dense_388_loss: 1.7558 - dense_389_loss: 1.2735 - dense_390_loss: 1.2562 - dense_381_accuracy: 0.3540 - dense_382_accuracy: 0.2140 - dense_383_accuracy: 0.3410 - dense_384_accuracy: 0.2380 - dense_385_accuracy: 0.2240 - dense_386_accuracy: 0.2030 - dense_387_accuracy: 0.2490 - dense_388_accuracy: 0.2420 - dense_389_accuracy: 0.4960 - dense_390_accuracy: 0.4900\n",
      "Epoch 4/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 15.7121 - dense_381_loss: 1.4286 - dense_382_loss: 1.7466 - dense_383_loss: 1.5373 - dense_384_loss: 1.6789 - dense_385_loss: 1.7063 - dense_386_loss: 1.8767 - dense_387_loss: 1.6485 - dense_388_loss: 1.6777 - dense_389_loss: 1.2147 - dense_390_loss: 1.1966 - dense_381_accuracy: 0.3750 - dense_382_accuracy: 0.2450 - dense_383_accuracy: 0.3660 - dense_384_accuracy: 0.2190 - dense_385_accuracy: 0.2180 - dense_386_accuracy: 0.2030 - dense_387_accuracy: 0.2610 - dense_388_accuracy: 0.2160 - dense_389_accuracy: 0.4840 - dense_390_accuracy: 0.5280\n",
      "Epoch 5/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 15.3766 - dense_381_loss: 1.3901 - dense_382_loss: 1.7142 - dense_383_loss: 1.4991 - dense_384_loss: 1.6570 - dense_385_loss: 1.6699 - dense_386_loss: 1.8374 - dense_387_loss: 1.6260 - dense_388_loss: 1.6392 - dense_389_loss: 1.1746 - dense_390_loss: 1.1690 - dense_381_accuracy: 0.3830 - dense_382_accuracy: 0.2220 - dense_383_accuracy: 0.3350 - dense_384_accuracy: 0.2320 - dense_385_accuracy: 0.2270 - dense_386_accuracy: 0.2420 - dense_387_accuracy: 0.2700 - dense_388_accuracy: 0.2360 - dense_389_accuracy: 0.4990 - dense_390_accuracy: 0.5220\n",
      "Epoch 6/25\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 15.1588 - dense_381_loss: 1.3753 - dense_382_loss: 1.6864 - dense_383_loss: 1.4714 - dense_384_loss: 1.6291 - dense_385_loss: 1.6558 - dense_386_loss: 1.8218 - dense_387_loss: 1.6015 - dense_388_loss: 1.6142 - dense_389_loss: 1.1574 - dense_390_loss: 1.1458 - dense_381_accuracy: 0.3850 - dense_382_accuracy: 0.2470 - dense_383_accuracy: 0.3560 - dense_384_accuracy: 0.2330 - dense_385_accuracy: 0.2530 - dense_386_accuracy: 0.2300 - dense_387_accuracy: 0.2670 - dense_388_accuracy: 0.2350 - dense_389_accuracy: 0.5050 - dense_390_accuracy: 0.5200\n",
      "Epoch 7/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 15.0578 - dense_381_loss: 1.3723 - dense_382_loss: 1.6811 - dense_383_loss: 1.4514 - dense_384_loss: 1.6144 - dense_385_loss: 1.6450 - dense_386_loss: 1.8131 - dense_387_loss: 1.5918 - dense_388_loss: 1.6039 - dense_389_loss: 1.1495 - dense_390_loss: 1.1353 - dense_381_accuracy: 0.3760 - dense_382_accuracy: 0.2290 - dense_383_accuracy: 0.3630 - dense_384_accuracy: 0.2630 - dense_385_accuracy: 0.2460 - dense_386_accuracy: 0.2450 - dense_387_accuracy: 0.2790 - dense_388_accuracy: 0.2350 - dense_389_accuracy: 0.5090 - dense_390_accuracy: 0.5260\n",
      "Epoch 8/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 15.0307 - dense_381_loss: 1.3716 - dense_382_loss: 1.6734 - dense_383_loss: 1.4535 - dense_384_loss: 1.6077 - dense_385_loss: 1.6409 - dense_386_loss: 1.8064 - dense_387_loss: 1.5824 - dense_388_loss: 1.6056 - dense_389_loss: 1.1452 - dense_390_loss: 1.1439 - dense_381_accuracy: 0.3760 - dense_382_accuracy: 0.2250 - dense_383_accuracy: 0.3610 - dense_384_accuracy: 0.2540 - dense_385_accuracy: 0.2570 - dense_386_accuracy: 0.2360 - dense_387_accuracy: 0.2990 - dense_388_accuracy: 0.2530 - dense_389_accuracy: 0.5110 - dense_390_accuracy: 0.5180\n",
      "Epoch 9/25\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 14.9540 - dense_381_loss: 1.3736 - dense_382_loss: 1.6645 - dense_383_loss: 1.4559 - dense_384_loss: 1.5995 - dense_385_loss: 1.6353 - dense_386_loss: 1.8006 - dense_387_loss: 1.5760 - dense_388_loss: 1.5955 - dense_389_loss: 1.1297 - dense_390_loss: 1.1236 - dense_381_accuracy: 0.3740 - dense_382_accuracy: 0.2370 - dense_383_accuracy: 0.3550 - dense_384_accuracy: 0.2630 - dense_385_accuracy: 0.2490 - dense_386_accuracy: 0.2230 - dense_387_accuracy: 0.2720 - dense_388_accuracy: 0.2410 - dense_389_accuracy: 0.5100 - dense_390_accuracy: 0.5220\n",
      "Epoch 10/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.9518 - dense_381_loss: 1.3705 - dense_382_loss: 1.6655 - dense_383_loss: 1.4512 - dense_384_loss: 1.5868 - dense_385_loss: 1.6341 - dense_386_loss: 1.7977 - dense_387_loss: 1.5766 - dense_388_loss: 1.6020 - dense_389_loss: 1.1368 - dense_390_loss: 1.1306 - dense_381_accuracy: 0.3790 - dense_382_accuracy: 0.2190 - dense_383_accuracy: 0.3660 - dense_384_accuracy: 0.2500 - dense_385_accuracy: 0.2510 - dense_386_accuracy: 0.2200 - dense_387_accuracy: 0.2880 - dense_388_accuracy: 0.2430 - dense_389_accuracy: 0.5080 - dense_390_accuracy: 0.5260\n",
      "Epoch 11/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.8722 - dense_381_loss: 1.3588 - dense_382_loss: 1.6523 - dense_383_loss: 1.4470 - dense_384_loss: 1.5870 - dense_385_loss: 1.6270 - dense_386_loss: 1.7934 - dense_387_loss: 1.5711 - dense_388_loss: 1.5822 - dense_389_loss: 1.1294 - dense_390_loss: 1.1240 - dense_381_accuracy: 0.3820 - dense_382_accuracy: 0.2240 - dense_383_accuracy: 0.3640 - dense_384_accuracy: 0.2550 - dense_385_accuracy: 0.2620 - dense_386_accuracy: 0.2360 - dense_387_accuracy: 0.2860 - dense_388_accuracy: 0.2420 - dense_389_accuracy: 0.5050 - dense_390_accuracy: 0.5220\n",
      "Epoch 12/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.8472 - dense_381_loss: 1.3693 - dense_382_loss: 1.6475 - dense_383_loss: 1.4447 - dense_384_loss: 1.5889 - dense_385_loss: 1.6207 - dense_386_loss: 1.7879 - dense_387_loss: 1.5705 - dense_388_loss: 1.5797 - dense_389_loss: 1.1208 - dense_390_loss: 1.1171 - dense_381_accuracy: 0.3820 - dense_382_accuracy: 0.2330 - dense_383_accuracy: 0.3540 - dense_384_accuracy: 0.2620 - dense_385_accuracy: 0.2430 - dense_386_accuracy: 0.2330 - dense_387_accuracy: 0.2760 - dense_388_accuracy: 0.2470 - dense_389_accuracy: 0.5160 - dense_390_accuracy: 0.5290\n",
      "Epoch 13/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.7493 - dense_381_loss: 1.3585 - dense_382_loss: 1.6385 - dense_383_loss: 1.4317 - dense_384_loss: 1.5794 - dense_385_loss: 1.6094 - dense_386_loss: 1.7704 - dense_387_loss: 1.5610 - dense_388_loss: 1.5712 - dense_389_loss: 1.1187 - dense_390_loss: 1.1104 - dense_381_accuracy: 0.3840 - dense_382_accuracy: 0.2350 - dense_383_accuracy: 0.3580 - dense_384_accuracy: 0.2620 - dense_385_accuracy: 0.2370 - dense_386_accuracy: 0.2400 - dense_387_accuracy: 0.2920 - dense_388_accuracy: 0.2470 - dense_389_accuracy: 0.5060 - dense_390_accuracy: 0.5300\n",
      "Epoch 14/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.7629 - dense_381_loss: 1.3550 - dense_382_loss: 1.6434 - dense_383_loss: 1.4328 - dense_384_loss: 1.5807 - dense_385_loss: 1.6096 - dense_386_loss: 1.7715 - dense_387_loss: 1.5633 - dense_388_loss: 1.5723 - dense_389_loss: 1.1211 - dense_390_loss: 1.1135 - dense_381_accuracy: 0.3900 - dense_382_accuracy: 0.2420 - dense_383_accuracy: 0.3640 - dense_384_accuracy: 0.2650 - dense_385_accuracy: 0.2490 - dense_386_accuracy: 0.2360 - dense_387_accuracy: 0.2830 - dense_388_accuracy: 0.2460 - dense_389_accuracy: 0.5020 - dense_390_accuracy: 0.5250\n",
      "Epoch 15/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.7494 - dense_381_loss: 1.3529 - dense_382_loss: 1.6372 - dense_383_loss: 1.4308 - dense_384_loss: 1.5791 - dense_385_loss: 1.6109 - dense_386_loss: 1.7738 - dense_387_loss: 1.5609 - dense_388_loss: 1.5716 - dense_389_loss: 1.1202 - dense_390_loss: 1.1120 - dense_381_accuracy: 0.3900 - dense_382_accuracy: 0.2370 - dense_383_accuracy: 0.3740 - dense_384_accuracy: 0.2720 - dense_385_accuracy: 0.2580 - dense_386_accuracy: 0.2520 - dense_387_accuracy: 0.2970 - dense_388_accuracy: 0.2570 - dense_389_accuracy: 0.5210 - dense_390_accuracy: 0.5210\n",
      "Epoch 16/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.7724 - dense_381_loss: 1.3549 - dense_382_loss: 1.6408 - dense_383_loss: 1.4334 - dense_384_loss: 1.5766 - dense_385_loss: 1.6157 - dense_386_loss: 1.7772 - dense_387_loss: 1.5653 - dense_388_loss: 1.5749 - dense_389_loss: 1.1167 - dense_390_loss: 1.1169 - dense_381_accuracy: 0.3820 - dense_382_accuracy: 0.2360 - dense_383_accuracy: 0.3490 - dense_384_accuracy: 0.2630 - dense_385_accuracy: 0.2340 - dense_386_accuracy: 0.2140 - dense_387_accuracy: 0.2970 - dense_388_accuracy: 0.2430 - dense_389_accuracy: 0.5190 - dense_390_accuracy: 0.5290\n",
      "Epoch 17/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.7247 - dense_381_loss: 1.3533 - dense_382_loss: 1.6352 - dense_383_loss: 1.4250 - dense_384_loss: 1.5731 - dense_385_loss: 1.6069 - dense_386_loss: 1.7728 - dense_387_loss: 1.5660 - dense_388_loss: 1.5716 - dense_389_loss: 1.1128 - dense_390_loss: 1.1079 - dense_381_accuracy: 0.3970 - dense_382_accuracy: 0.2540 - dense_383_accuracy: 0.3660 - dense_384_accuracy: 0.2850 - dense_385_accuracy: 0.2480 - dense_386_accuracy: 0.2500 - dense_387_accuracy: 0.2790 - dense_388_accuracy: 0.2430 - dense_389_accuracy: 0.5100 - dense_390_accuracy: 0.5340\n",
      "Epoch 18/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.6633 - dense_381_loss: 1.3486 - dense_382_loss: 1.6308 - dense_383_loss: 1.4199 - dense_384_loss: 1.5674 - dense_385_loss: 1.5956 - dense_386_loss: 1.7680 - dense_387_loss: 1.5581 - dense_388_loss: 1.5594 - dense_389_loss: 1.1073 - dense_390_loss: 1.1084 - dense_381_accuracy: 0.3860 - dense_382_accuracy: 0.2340 - dense_383_accuracy: 0.3780 - dense_384_accuracy: 0.2780 - dense_385_accuracy: 0.2590 - dense_386_accuracy: 0.2460 - dense_387_accuracy: 0.2870 - dense_388_accuracy: 0.2590 - dense_389_accuracy: 0.5250 - dense_390_accuracy: 0.5260\n",
      "Epoch 19/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.6236 - dense_381_loss: 1.3447 - dense_382_loss: 1.6219 - dense_383_loss: 1.4206 - dense_384_loss: 1.5649 - dense_385_loss: 1.6009 - dense_386_loss: 1.7546 - dense_387_loss: 1.5552 - dense_388_loss: 1.5589 - dense_389_loss: 1.1003 - dense_390_loss: 1.1016 - dense_381_accuracy: 0.3980 - dense_382_accuracy: 0.2670 - dense_383_accuracy: 0.3730 - dense_384_accuracy: 0.2800 - dense_385_accuracy: 0.2720 - dense_386_accuracy: 0.2800 - dense_387_accuracy: 0.3010 - dense_388_accuracy: 0.2620 - dense_389_accuracy: 0.5340 - dense_390_accuracy: 0.5390\n",
      "Epoch 20/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.5528 - dense_381_loss: 1.3381 - dense_382_loss: 1.6181 - dense_383_loss: 1.4098 - dense_384_loss: 1.5595 - dense_385_loss: 1.5830 - dense_386_loss: 1.7494 - dense_387_loss: 1.5511 - dense_388_loss: 1.5571 - dense_389_loss: 1.0950 - dense_390_loss: 1.0918 - dense_381_accuracy: 0.4040 - dense_382_accuracy: 0.2460 - dense_383_accuracy: 0.3660 - dense_384_accuracy: 0.2900 - dense_385_accuracy: 0.2870 - dense_386_accuracy: 0.2520 - dense_387_accuracy: 0.2950 - dense_388_accuracy: 0.2660 - dense_389_accuracy: 0.5390 - dense_390_accuracy: 0.5570\n",
      "Epoch 21/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.4700 - dense_381_loss: 1.3347 - dense_382_loss: 1.6035 - dense_383_loss: 1.4034 - dense_384_loss: 1.5512 - dense_385_loss: 1.5800 - dense_386_loss: 1.7363 - dense_387_loss: 1.5384 - dense_388_loss: 1.5457 - dense_389_loss: 1.0903 - dense_390_loss: 1.0865 - dense_381_accuracy: 0.3990 - dense_382_accuracy: 0.2480 - dense_383_accuracy: 0.3940 - dense_384_accuracy: 0.3120 - dense_385_accuracy: 0.2800 - dense_386_accuracy: 0.2860 - dense_387_accuracy: 0.3240 - dense_388_accuracy: 0.2910 - dense_389_accuracy: 0.5340 - dense_390_accuracy: 0.5560\n",
      "Epoch 22/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.4137 - dense_381_loss: 1.3295 - dense_382_loss: 1.5928 - dense_383_loss: 1.3989 - dense_384_loss: 1.5472 - dense_385_loss: 1.5708 - dense_386_loss: 1.7293 - dense_387_loss: 1.5339 - dense_388_loss: 1.5354 - dense_389_loss: 1.0898 - dense_390_loss: 1.0861 - dense_381_accuracy: 0.3870 - dense_382_accuracy: 0.2900 - dense_383_accuracy: 0.3890 - dense_384_accuracy: 0.2890 - dense_385_accuracy: 0.3020 - dense_386_accuracy: 0.2860 - dense_387_accuracy: 0.3280 - dense_388_accuracy: 0.2990 - dense_389_accuracy: 0.5430 - dense_390_accuracy: 0.5420\n",
      "Epoch 23/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.4294 - dense_381_loss: 1.3249 - dense_382_loss: 1.5988 - dense_383_loss: 1.4012 - dense_384_loss: 1.5426 - dense_385_loss: 1.5726 - dense_386_loss: 1.7377 - dense_387_loss: 1.5364 - dense_388_loss: 1.5348 - dense_389_loss: 1.0953 - dense_390_loss: 1.0850 - dense_381_accuracy: 0.4100 - dense_382_accuracy: 0.2940 - dense_383_accuracy: 0.3960 - dense_384_accuracy: 0.3110 - dense_385_accuracy: 0.2910 - dense_386_accuracy: 0.2810 - dense_387_accuracy: 0.3210 - dense_388_accuracy: 0.3090 - dense_389_accuracy: 0.5290 - dense_390_accuracy: 0.5450\n",
      "Epoch 24/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.5320 - dense_381_loss: 1.3360 - dense_382_loss: 1.6234 - dense_383_loss: 1.4094 - dense_384_loss: 1.5489 - dense_385_loss: 1.5751 - dense_386_loss: 1.7481 - dense_387_loss: 1.5463 - dense_388_loss: 1.5568 - dense_389_loss: 1.0950 - dense_390_loss: 1.0931 - dense_381_accuracy: 0.4110 - dense_382_accuracy: 0.2790 - dense_383_accuracy: 0.4030 - dense_384_accuracy: 0.3150 - dense_385_accuracy: 0.3100 - dense_386_accuracy: 0.2970 - dense_387_accuracy: 0.3220 - dense_388_accuracy: 0.3030 - dense_389_accuracy: 0.5430 - dense_390_accuracy: 0.5330\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.2034 - dense_381_loss: 1.3026 - dense_382_loss: 1.5786 - dense_383_loss: 1.3808 - dense_384_loss: 1.5207 - dense_385_loss: 1.5387 - dense_386_loss: 1.7098 - dense_387_loss: 1.5060 - dense_388_loss: 1.5182 - dense_389_loss: 1.0764 - dense_390_loss: 1.0716 - dense_381_accuracy: 0.4280 - dense_382_accuracy: 0.3230 - dense_383_accuracy: 0.4180 - dense_384_accuracy: 0.3320 - dense_385_accuracy: 0.3330 - dense_386_accuracy: 0.3160 - dense_387_accuracy: 0.3550 - dense_388_accuracy: 0.3170 - dense_389_accuracy: 0.5460 - dense_390_accuracy: 0.5500\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D38B19D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D38B19D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D42AE3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D42AE3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2494\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2473\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2444\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2400\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2334\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2240\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2111\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1931\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1707\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1444\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1156\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0864\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0627\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0452\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0323\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0244\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0182\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0151\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0133\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0122\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0114\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0109\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0102\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0099\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0096\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4B348B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4B348B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "8/8 [==============================] - 3s 8ms/step - loss: 24.8641 - dense_394_loss: 2.4658 - dense_395_loss: 2.3664 - dense_396_loss: 2.4450 - dense_397_loss: 2.3668 - dense_398_loss: 2.9608 - dense_399_loss: 2.5257 - dense_400_loss: 2.6282 - dense_401_loss: 2.3882 - dense_402_loss: 2.1847 - dense_403_loss: 2.5325 - dense_394_accuracy: 0.1600 - dense_395_accuracy: 0.1900 - dense_396_accuracy: 0.1840 - dense_397_accuracy: 0.1800 - dense_398_accuracy: 0.0940 - dense_399_accuracy: 0.1480 - dense_400_accuracy: 0.0780 - dense_401_accuracy: 0.1560 - dense_402_accuracy: 0.1500 - dense_403_accuracy: 0.1280\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23.2047 - dense_394_loss: 2.2791 - dense_395_loss: 2.2161 - dense_396_loss: 2.2649 - dense_397_loss: 2.1594 - dense_398_loss: 2.7801 - dense_399_loss: 2.4410 - dense_400_loss: 2.4243 - dense_401_loss: 2.2161 - dense_402_loss: 2.0305 - dense_403_loss: 2.3933 - dense_394_accuracy: 0.2240 - dense_395_accuracy: 0.2120 - dense_396_accuracy: 0.1660 - dense_397_accuracy: 0.2580 - dense_398_accuracy: 0.1120 - dense_399_accuracy: 0.1520 - dense_400_accuracy: 0.1460 - dense_401_accuracy: 0.1600 - dense_402_accuracy: 0.1740 - dense_403_accuracy: 0.1660\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21.6226 - dense_394_loss: 2.0615 - dense_395_loss: 2.0647 - dense_396_loss: 2.1813 - dense_397_loss: 1.9937 - dense_398_loss: 2.5617 - dense_399_loss: 2.2962 - dense_400_loss: 2.2524 - dense_401_loss: 2.0430 - dense_402_loss: 1.9302 - dense_403_loss: 2.2380 - dense_394_accuracy: 0.2940 - dense_395_accuracy: 0.2240 - dense_396_accuracy: 0.1940 - dense_397_accuracy: 0.3120 - dense_398_accuracy: 0.1260 - dense_399_accuracy: 0.1800 - dense_400_accuracy: 0.1240 - dense_401_accuracy: 0.2580 - dense_402_accuracy: 0.2680 - dense_403_accuracy: 0.2420\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 20.3947 - dense_394_loss: 1.9576 - dense_395_loss: 1.9542 - dense_396_loss: 2.0286 - dense_397_loss: 1.9043 - dense_398_loss: 2.3998 - dense_399_loss: 2.1665 - dense_400_loss: 2.1570 - dense_401_loss: 1.9306 - dense_402_loss: 1.7711 - dense_403_loss: 2.1251 - dense_394_accuracy: 0.3000 - dense_395_accuracy: 0.2760 - dense_396_accuracy: 0.2480 - dense_397_accuracy: 0.3220 - dense_398_accuracy: 0.1740 - dense_399_accuracy: 0.1660 - dense_400_accuracy: 0.1920 - dense_401_accuracy: 0.2980 - dense_402_accuracy: 0.3380 - dense_403_accuracy: 0.2420\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 19.6897 - dense_394_loss: 1.8928 - dense_395_loss: 1.9011 - dense_396_loss: 1.9508 - dense_397_loss: 1.8515 - dense_398_loss: 2.2908 - dense_399_loss: 2.0927 - dense_400_loss: 2.0990 - dense_401_loss: 1.8434 - dense_402_loss: 1.7094 - dense_403_loss: 2.0581 - dense_394_accuracy: 0.3220 - dense_395_accuracy: 0.3120 - dense_396_accuracy: 0.2640 - dense_397_accuracy: 0.3320 - dense_398_accuracy: 0.2220 - dense_399_accuracy: 0.1440 - dense_400_accuracy: 0.2140 - dense_401_accuracy: 0.2920 - dense_402_accuracy: 0.3460 - dense_403_accuracy: 0.2600\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 19.1634 - dense_394_loss: 1.8019 - dense_395_loss: 1.8443 - dense_396_loss: 1.8921 - dense_397_loss: 1.8233 - dense_398_loss: 2.2115 - dense_399_loss: 2.0502 - dense_400_loss: 2.0577 - dense_401_loss: 1.7932 - dense_402_loss: 1.6686 - dense_403_loss: 2.0206 - dense_394_accuracy: 0.3620 - dense_395_accuracy: 0.3200 - dense_396_accuracy: 0.3020 - dense_397_accuracy: 0.3280 - dense_398_accuracy: 0.2080 - dense_399_accuracy: 0.1820 - dense_400_accuracy: 0.2280 - dense_401_accuracy: 0.3220 - dense_402_accuracy: 0.3540 - dense_403_accuracy: 0.2520\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 18.4309 - dense_394_loss: 1.7177 - dense_395_loss: 1.7544 - dense_396_loss: 1.8314 - dense_397_loss: 1.7666 - dense_398_loss: 2.1004 - dense_399_loss: 1.9631 - dense_400_loss: 1.9974 - dense_401_loss: 1.7429 - dense_402_loss: 1.6296 - dense_403_loss: 1.9273 - dense_394_accuracy: 0.3660 - dense_395_accuracy: 0.3440 - dense_396_accuracy: 0.2920 - dense_397_accuracy: 0.3200 - dense_398_accuracy: 0.2260 - dense_399_accuracy: 0.2660 - dense_400_accuracy: 0.2220 - dense_401_accuracy: 0.3280 - dense_402_accuracy: 0.3600 - dense_403_accuracy: 0.2900\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 17.6066 - dense_394_loss: 1.6309 - dense_395_loss: 1.6511 - dense_396_loss: 1.7818 - dense_397_loss: 1.7037 - dense_398_loss: 1.9939 - dense_399_loss: 1.8638 - dense_400_loss: 1.9255 - dense_401_loss: 1.6813 - dense_402_loss: 1.5627 - dense_403_loss: 1.8120 - dense_394_accuracy: 0.3700 - dense_395_accuracy: 0.3660 - dense_396_accuracy: 0.3060 - dense_397_accuracy: 0.2960 - dense_398_accuracy: 0.2700 - dense_399_accuracy: 0.2740 - dense_400_accuracy: 0.2340 - dense_401_accuracy: 0.3260 - dense_402_accuracy: 0.3880 - dense_403_accuracy: 0.3060\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 16.9413 - dense_394_loss: 1.5546 - dense_395_loss: 1.5862 - dense_396_loss: 1.7240 - dense_397_loss: 1.6242 - dense_398_loss: 1.9284 - dense_399_loss: 1.7964 - dense_400_loss: 1.8500 - dense_401_loss: 1.6201 - dense_402_loss: 1.5185 - dense_403_loss: 1.7389 - dense_394_accuracy: 0.3620 - dense_395_accuracy: 0.3440 - dense_396_accuracy: 0.3220 - dense_397_accuracy: 0.3380 - dense_398_accuracy: 0.2720 - dense_399_accuracy: 0.2720 - dense_400_accuracy: 0.2640 - dense_401_accuracy: 0.3220 - dense_402_accuracy: 0.3740 - dense_403_accuracy: 0.3340\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 16.5993 - dense_394_loss: 1.5063 - dense_395_loss: 1.5550 - dense_396_loss: 1.6898 - dense_397_loss: 1.6026 - dense_398_loss: 1.8852 - dense_399_loss: 1.7627 - dense_400_loss: 1.7844 - dense_401_loss: 1.6177 - dense_402_loss: 1.4984 - dense_403_loss: 1.6973 - dense_394_accuracy: 0.3820 - dense_395_accuracy: 0.3520 - dense_396_accuracy: 0.3260 - dense_397_accuracy: 0.3080 - dense_398_accuracy: 0.2620 - dense_399_accuracy: 0.2720 - dense_400_accuracy: 0.2680 - dense_401_accuracy: 0.3080 - dense_402_accuracy: 0.3660 - dense_403_accuracy: 0.3120\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 16.1716 - dense_394_loss: 1.4889 - dense_395_loss: 1.5008 - dense_396_loss: 1.6566 - dense_397_loss: 1.5546 - dense_398_loss: 1.8329 - dense_399_loss: 1.7088 - dense_400_loss: 1.7179 - dense_401_loss: 1.5832 - dense_402_loss: 1.4661 - dense_403_loss: 1.6617 - dense_394_accuracy: 0.3540 - dense_395_accuracy: 0.3600 - dense_396_accuracy: 0.3220 - dense_397_accuracy: 0.3280 - dense_398_accuracy: 0.2640 - dense_399_accuracy: 0.2900 - dense_400_accuracy: 0.2580 - dense_401_accuracy: 0.3020 - dense_402_accuracy: 0.3820 - dense_403_accuracy: 0.3300\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 16.1084 - dense_394_loss: 1.4692 - dense_395_loss: 1.4919 - dense_396_loss: 1.6526 - dense_397_loss: 1.5481 - dense_398_loss: 1.8305 - dense_399_loss: 1.7075 - dense_400_loss: 1.6961 - dense_401_loss: 1.5866 - dense_402_loss: 1.4651 - dense_403_loss: 1.6607 - dense_394_accuracy: 0.3760 - dense_395_accuracy: 0.3680 - dense_396_accuracy: 0.3120 - dense_397_accuracy: 0.3320 - dense_398_accuracy: 0.2720 - dense_399_accuracy: 0.2880 - dense_400_accuracy: 0.2420 - dense_401_accuracy: 0.3240 - dense_402_accuracy: 0.3860 - dense_403_accuracy: 0.3120\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 15.9530 - dense_394_loss: 1.4666 - dense_395_loss: 1.4913 - dense_396_loss: 1.6218 - dense_397_loss: 1.5312 - dense_398_loss: 1.8022 - dense_399_loss: 1.6915 - dense_400_loss: 1.6908 - dense_401_loss: 1.5612 - dense_402_loss: 1.4485 - dense_403_loss: 1.6480 - dense_394_accuracy: 0.3720 - dense_395_accuracy: 0.3800 - dense_396_accuracy: 0.3340 - dense_397_accuracy: 0.3380 - dense_398_accuracy: 0.2820 - dense_399_accuracy: 0.2880 - dense_400_accuracy: 0.2840 - dense_401_accuracy: 0.3360 - dense_402_accuracy: 0.3880 - dense_403_accuracy: 0.3160\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 15.8583 - dense_394_loss: 1.4491 - dense_395_loss: 1.4831 - dense_396_loss: 1.6260 - dense_397_loss: 1.5181 - dense_398_loss: 1.7901 - dense_399_loss: 1.6881 - dense_400_loss: 1.6777 - dense_401_loss: 1.5612 - dense_402_loss: 1.4304 - dense_403_loss: 1.6344 - dense_394_accuracy: 0.3840 - dense_395_accuracy: 0.3860 - dense_396_accuracy: 0.3280 - dense_397_accuracy: 0.3460 - dense_398_accuracy: 0.2880 - dense_399_accuracy: 0.2860 - dense_400_accuracy: 0.2880 - dense_401_accuracy: 0.3300 - dense_402_accuracy: 0.3880 - dense_403_accuracy: 0.3400\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 15.8140 - dense_394_loss: 1.4496 - dense_395_loss: 1.4844 - dense_396_loss: 1.6369 - dense_397_loss: 1.5054 - dense_398_loss: 1.7867 - dense_399_loss: 1.6797 - dense_400_loss: 1.6657 - dense_401_loss: 1.5412 - dense_402_loss: 1.4305 - dense_403_loss: 1.6338 - dense_394_accuracy: 0.3900 - dense_395_accuracy: 0.3940 - dense_396_accuracy: 0.3080 - dense_397_accuracy: 0.3420 - dense_398_accuracy: 0.3020 - dense_399_accuracy: 0.2900 - dense_400_accuracy: 0.2840 - dense_401_accuracy: 0.3420 - dense_402_accuracy: 0.4100 - dense_403_accuracy: 0.3140\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 15.7220 - dense_394_loss: 1.4487 - dense_395_loss: 1.4534 - dense_396_loss: 1.6120 - dense_397_loss: 1.5091 - dense_398_loss: 1.7649 - dense_399_loss: 1.6703 - dense_400_loss: 1.6525 - dense_401_loss: 1.5591 - dense_402_loss: 1.4273 - dense_403_loss: 1.6245 - dense_394_accuracy: 0.3900 - dense_395_accuracy: 0.4100 - dense_396_accuracy: 0.3540 - dense_397_accuracy: 0.3380 - dense_398_accuracy: 0.3000 - dense_399_accuracy: 0.3040 - dense_400_accuracy: 0.3440 - dense_401_accuracy: 0.3620 - dense_402_accuracy: 0.4080 - dense_403_accuracy: 0.3400\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 15.5980 - dense_394_loss: 1.4290 - dense_395_loss: 1.4517 - dense_396_loss: 1.6088 - dense_397_loss: 1.4976 - dense_398_loss: 1.7466 - dense_399_loss: 1.6501 - dense_400_loss: 1.6449 - dense_401_loss: 1.5375 - dense_402_loss: 1.4172 - dense_403_loss: 1.6148 - dense_394_accuracy: 0.4060 - dense_395_accuracy: 0.4160 - dense_396_accuracy: 0.3040 - dense_397_accuracy: 0.3520 - dense_398_accuracy: 0.3100 - dense_399_accuracy: 0.3040 - dense_400_accuracy: 0.3080 - dense_401_accuracy: 0.3420 - dense_402_accuracy: 0.4240 - dense_403_accuracy: 0.3620\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 15.5002 - dense_394_loss: 1.4157 - dense_395_loss: 1.4427 - dense_396_loss: 1.6023 - dense_397_loss: 1.4907 - dense_398_loss: 1.7376 - dense_399_loss: 1.6439 - dense_400_loss: 1.6319 - dense_401_loss: 1.5395 - dense_402_loss: 1.3962 - dense_403_loss: 1.5996 - dense_394_accuracy: 0.4040 - dense_395_accuracy: 0.4020 - dense_396_accuracy: 0.3700 - dense_397_accuracy: 0.3560 - dense_398_accuracy: 0.3260 - dense_399_accuracy: 0.3120 - dense_400_accuracy: 0.3060 - dense_401_accuracy: 0.3380 - dense_402_accuracy: 0.4300 - dense_403_accuracy: 0.3600\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 15.3734 - dense_394_loss: 1.4073 - dense_395_loss: 1.4287 - dense_396_loss: 1.5869 - dense_397_loss: 1.4767 - dense_398_loss: 1.7180 - dense_399_loss: 1.6382 - dense_400_loss: 1.6167 - dense_401_loss: 1.5246 - dense_402_loss: 1.3889 - dense_403_loss: 1.5872 - dense_394_accuracy: 0.4380 - dense_395_accuracy: 0.4140 - dense_396_accuracy: 0.3680 - dense_397_accuracy: 0.3760 - dense_398_accuracy: 0.3360 - dense_399_accuracy: 0.3100 - dense_400_accuracy: 0.3460 - dense_401_accuracy: 0.3460 - dense_402_accuracy: 0.4460 - dense_403_accuracy: 0.3580\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 15.1669 - dense_394_loss: 1.3866 - dense_395_loss: 1.4099 - dense_396_loss: 1.5646 - dense_397_loss: 1.4646 - dense_398_loss: 1.6928 - dense_399_loss: 1.6124 - dense_400_loss: 1.6009 - dense_401_loss: 1.5049 - dense_402_loss: 1.3619 - dense_403_loss: 1.5684 - dense_394_accuracy: 0.4460 - dense_395_accuracy: 0.4300 - dense_396_accuracy: 0.3700 - dense_397_accuracy: 0.3840 - dense_398_accuracy: 0.3580 - dense_399_accuracy: 0.3420 - dense_400_accuracy: 0.3500 - dense_401_accuracy: 0.4080 - dense_402_accuracy: 0.4540 - dense_403_accuracy: 0.3940\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 14.9690 - dense_394_loss: 1.3599 - dense_395_loss: 1.3784 - dense_396_loss: 1.5452 - dense_397_loss: 1.4533 - dense_398_loss: 1.6651 - dense_399_loss: 1.6062 - dense_400_loss: 1.5792 - dense_401_loss: 1.4912 - dense_402_loss: 1.3393 - dense_403_loss: 1.5512 - dense_394_accuracy: 0.4740 - dense_395_accuracy: 0.4880 - dense_396_accuracy: 0.3840 - dense_397_accuracy: 0.4160 - dense_398_accuracy: 0.3840 - dense_399_accuracy: 0.3680 - dense_400_accuracy: 0.3640 - dense_401_accuracy: 0.4020 - dense_402_accuracy: 0.4640 - dense_403_accuracy: 0.4380\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 14.8412 - dense_394_loss: 1.3444 - dense_395_loss: 1.3796 - dense_396_loss: 1.5303 - dense_397_loss: 1.4448 - dense_398_loss: 1.6623 - dense_399_loss: 1.5817 - dense_400_loss: 1.5513 - dense_401_loss: 1.4968 - dense_402_loss: 1.3164 - dense_403_loss: 1.5337 - dense_394_accuracy: 0.4580 - dense_395_accuracy: 0.4560 - dense_396_accuracy: 0.4100 - dense_397_accuracy: 0.3800 - dense_398_accuracy: 0.3680 - dense_399_accuracy: 0.3900 - dense_400_accuracy: 0.3780 - dense_401_accuracy: 0.3980 - dense_402_accuracy: 0.4640 - dense_403_accuracy: 0.4200\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 14.5825 - dense_394_loss: 1.3361 - dense_395_loss: 1.3422 - dense_396_loss: 1.5091 - dense_397_loss: 1.4181 - dense_398_loss: 1.6154 - dense_399_loss: 1.5672 - dense_400_loss: 1.5244 - dense_401_loss: 1.4617 - dense_402_loss: 1.3018 - dense_403_loss: 1.5067 - dense_394_accuracy: 0.4620 - dense_395_accuracy: 0.4780 - dense_396_accuracy: 0.3980 - dense_397_accuracy: 0.3940 - dense_398_accuracy: 0.4120 - dense_399_accuracy: 0.4020 - dense_400_accuracy: 0.4280 - dense_401_accuracy: 0.4180 - dense_402_accuracy: 0.4920 - dense_403_accuracy: 0.4620\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 14.2740 - dense_394_loss: 1.3008 - dense_395_loss: 1.3223 - dense_396_loss: 1.4807 - dense_397_loss: 1.3899 - dense_398_loss: 1.5848 - dense_399_loss: 1.5381 - dense_400_loss: 1.4807 - dense_401_loss: 1.4183 - dense_402_loss: 1.2849 - dense_403_loss: 1.4732 - dense_394_accuracy: 0.5240 - dense_395_accuracy: 0.5140 - dense_396_accuracy: 0.4420 - dense_397_accuracy: 0.4800 - dense_398_accuracy: 0.4320 - dense_399_accuracy: 0.4120 - dense_400_accuracy: 0.4400 - dense_401_accuracy: 0.4680 - dense_402_accuracy: 0.5180 - dense_403_accuracy: 0.4780\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 14.1518 - dense_394_loss: 1.2811 - dense_395_loss: 1.3313 - dense_396_loss: 1.4601 - dense_397_loss: 1.3855 - dense_398_loss: 1.5723 - dense_399_loss: 1.5274 - dense_400_loss: 1.4658 - dense_401_loss: 1.3965 - dense_402_loss: 1.2729 - dense_403_loss: 1.4588 - dense_394_accuracy: 0.5300 - dense_395_accuracy: 0.4760 - dense_396_accuracy: 0.4440 - dense_397_accuracy: 0.4600 - dense_398_accuracy: 0.4160 - dense_399_accuracy: 0.4180 - dense_400_accuracy: 0.3960 - dense_401_accuracy: 0.4580 - dense_402_accuracy: 0.4960 - dense_403_accuracy: 0.4540\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D478E9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D478E9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3FFA948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3FFA948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "8/8 [==============================] - 3s 8ms/step - loss: 24.8652 - dense_404_loss: 2.4775 - dense_405_loss: 2.3916 - dense_406_loss: 2.4801 - dense_407_loss: 2.3481 - dense_408_loss: 2.9645 - dense_409_loss: 2.5491 - dense_410_loss: 2.5224 - dense_411_loss: 2.3904 - dense_412_loss: 2.2068 - dense_413_loss: 2.5348 - dense_404_accuracy: 0.1540 - dense_405_accuracy: 0.2080 - dense_406_accuracy: 0.1520 - dense_407_accuracy: 0.2640 - dense_408_accuracy: 0.0820 - dense_409_accuracy: 0.1240 - dense_410_accuracy: 0.1340 - dense_411_accuracy: 0.1400 - dense_412_accuracy: 0.1940 - dense_413_accuracy: 0.1040   \n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23.0569 - dense_404_loss: 2.2592 - dense_405_loss: 2.2078 - dense_406_loss: 2.2552 - dense_407_loss: 2.1384 - dense_408_loss: 2.7512 - dense_409_loss: 2.4383 - dense_410_loss: 2.3513 - dense_411_loss: 2.2268 - dense_412_loss: 2.0303 - dense_413_loss: 2.3983 - dense_404_accuracy: 0.1720 - dense_405_accuracy: 0.1660 - dense_406_accuracy: 0.1560 - dense_407_accuracy: 0.2320 - dense_408_accuracy: 0.0980 - dense_409_accuracy: 0.1700 - dense_410_accuracy: 0.1340 - dense_411_accuracy: 0.1780 - dense_412_accuracy: 0.1420 - dense_413_accuracy: 0.1520\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 21.5552 - dense_404_loss: 2.1025 - dense_405_loss: 2.0245 - dense_406_loss: 2.1353 - dense_407_loss: 1.9987 - dense_408_loss: 2.5473 - dense_409_loss: 2.2805 - dense_410_loss: 2.2110 - dense_411_loss: 2.1057 - dense_412_loss: 1.9021 - dense_413_loss: 2.2476 - dense_404_accuracy: 0.2320 - dense_405_accuracy: 0.2480 - dense_406_accuracy: 0.2000 - dense_407_accuracy: 0.2740 - dense_408_accuracy: 0.1680 - dense_409_accuracy: 0.1920 - dense_410_accuracy: 0.1900 - dense_411_accuracy: 0.2420 - dense_412_accuracy: 0.2060 - dense_413_accuracy: 0.2460\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 20.0596 - dense_404_loss: 1.9127 - dense_405_loss: 1.8931 - dense_406_loss: 2.0213 - dense_407_loss: 1.8855 - dense_408_loss: 2.3532 - dense_409_loss: 2.1344 - dense_410_loss: 2.0448 - dense_411_loss: 1.9891 - dense_412_loss: 1.7451 - dense_413_loss: 2.0804 - dense_404_accuracy: 0.3100 - dense_405_accuracy: 0.3220 - dense_406_accuracy: 0.2380 - dense_407_accuracy: 0.3000 - dense_408_accuracy: 0.1860 - dense_409_accuracy: 0.1580 - dense_410_accuracy: 0.2180 - dense_411_accuracy: 0.2400 - dense_412_accuracy: 0.3220 - dense_413_accuracy: 0.2620\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 18.5933 - dense_404_loss: 1.7274 - dense_405_loss: 1.7601 - dense_406_loss: 1.8945 - dense_407_loss: 1.7489 - dense_408_loss: 2.1967 - dense_409_loss: 1.9795 - dense_410_loss: 1.9464 - dense_411_loss: 1.8088 - dense_412_loss: 1.6150 - dense_413_loss: 1.9160 - dense_404_accuracy: 0.3500 - dense_405_accuracy: 0.3360 - dense_406_accuracy: 0.2500 - dense_407_accuracy: 0.3220 - dense_408_accuracy: 0.1960 - dense_409_accuracy: 0.2360 - dense_410_accuracy: 0.2400 - dense_411_accuracy: 0.3220 - dense_412_accuracy: 0.3620 - dense_413_accuracy: 0.2780\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 17.3471 - dense_404_loss: 1.6084 - dense_405_loss: 1.6333 - dense_406_loss: 1.7746 - dense_407_loss: 1.6412 - dense_408_loss: 2.0288 - dense_409_loss: 1.8281 - dense_410_loss: 1.8441 - dense_411_loss: 1.6773 - dense_412_loss: 1.5502 - dense_413_loss: 1.7611 - dense_404_accuracy: 0.3620 - dense_405_accuracy: 0.3500 - dense_406_accuracy: 0.3020 - dense_407_accuracy: 0.3260 - dense_408_accuracy: 0.2600 - dense_409_accuracy: 0.2500 - dense_410_accuracy: 0.2660 - dense_411_accuracy: 0.3520 - dense_412_accuracy: 0.3900 - dense_413_accuracy: 0.3220\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 16.9220 - dense_404_loss: 1.5794 - dense_405_loss: 1.5755 - dense_406_loss: 1.7076 - dense_407_loss: 1.6164 - dense_408_loss: 1.9398 - dense_409_loss: 1.7768 - dense_410_loss: 1.8119 - dense_411_loss: 1.6421 - dense_412_loss: 1.5527 - dense_413_loss: 1.7199 - dense_404_accuracy: 0.3420 - dense_405_accuracy: 0.3640 - dense_406_accuracy: 0.3160 - dense_407_accuracy: 0.3100 - dense_408_accuracy: 0.2600 - dense_409_accuracy: 0.2920 - dense_410_accuracy: 0.2800 - dense_411_accuracy: 0.3080 - dense_412_accuracy: 0.3760 - dense_413_accuracy: 0.3020\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 16.4911 - dense_404_loss: 1.5217 - dense_405_loss: 1.5420 - dense_406_loss: 1.6662 - dense_407_loss: 1.5851 - dense_408_loss: 1.8686 - dense_409_loss: 1.7424 - dense_410_loss: 1.7565 - dense_411_loss: 1.6338 - dense_412_loss: 1.4918 - dense_413_loss: 1.6830 - dense_404_accuracy: 0.3800 - dense_405_accuracy: 0.3720 - dense_406_accuracy: 0.3360 - dense_407_accuracy: 0.3340 - dense_408_accuracy: 0.2700 - dense_409_accuracy: 0.2940 - dense_410_accuracy: 0.2700 - dense_411_accuracy: 0.3240 - dense_412_accuracy: 0.3880 - dense_413_accuracy: 0.3320\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 16.2245 - dense_404_loss: 1.4938 - dense_405_loss: 1.5063 - dense_406_loss: 1.6560 - dense_407_loss: 1.5522 - dense_408_loss: 1.8400 - dense_409_loss: 1.7156 - dense_410_loss: 1.7250 - dense_411_loss: 1.5934 - dense_412_loss: 1.4790 - dense_413_loss: 1.6631 - dense_404_accuracy: 0.3640 - dense_405_accuracy: 0.3680 - dense_406_accuracy: 0.3200 - dense_407_accuracy: 0.3240 - dense_408_accuracy: 0.2620 - dense_409_accuracy: 0.2840 - dense_410_accuracy: 0.2580 - dense_411_accuracy: 0.3260 - dense_412_accuracy: 0.3960 - dense_413_accuracy: 0.3280\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 16.1189 - dense_404_loss: 1.4845 - dense_405_loss: 1.5012 - dense_406_loss: 1.6358 - dense_407_loss: 1.5680 - dense_408_loss: 1.8295 - dense_409_loss: 1.6974 - dense_410_loss: 1.7151 - dense_411_loss: 1.5775 - dense_412_loss: 1.4690 - dense_413_loss: 1.6408 - dense_404_accuracy: 0.3760 - dense_405_accuracy: 0.3720 - dense_406_accuracy: 0.3480 - dense_407_accuracy: 0.3280 - dense_408_accuracy: 0.2780 - dense_409_accuracy: 0.2960 - dense_410_accuracy: 0.2740 - dense_411_accuracy: 0.3180 - dense_412_accuracy: 0.3940 - dense_413_accuracy: 0.3180\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 15.9347 - dense_404_loss: 1.4591 - dense_405_loss: 1.4830 - dense_406_loss: 1.6257 - dense_407_loss: 1.5442 - dense_408_loss: 1.8089 - dense_409_loss: 1.6854 - dense_410_loss: 1.6964 - dense_411_loss: 1.5598 - dense_412_loss: 1.4489 - dense_413_loss: 1.6232 - dense_404_accuracy: 0.3920 - dense_405_accuracy: 0.3680 - dense_406_accuracy: 0.3460 - dense_407_accuracy: 0.3360 - dense_408_accuracy: 0.2780 - dense_409_accuracy: 0.2820 - dense_410_accuracy: 0.2840 - dense_411_accuracy: 0.3120 - dense_412_accuracy: 0.4100 - dense_413_accuracy: 0.3420\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 15.7984 - dense_404_loss: 1.4475 - dense_405_loss: 1.4700 - dense_406_loss: 1.6076 - dense_407_loss: 1.5224 - dense_408_loss: 1.7921 - dense_409_loss: 1.6756 - dense_410_loss: 1.6780 - dense_411_loss: 1.5455 - dense_412_loss: 1.4289 - dense_413_loss: 1.6308 - dense_404_accuracy: 0.3980 - dense_405_accuracy: 0.3900 - dense_406_accuracy: 0.3680 - dense_407_accuracy: 0.3480 - dense_408_accuracy: 0.3000 - dense_409_accuracy: 0.3120 - dense_410_accuracy: 0.3260 - dense_411_accuracy: 0.3440 - dense_412_accuracy: 0.4160 - dense_413_accuracy: 0.3380\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 15.7669 - dense_404_loss: 1.4406 - dense_405_loss: 1.4665 - dense_406_loss: 1.6020 - dense_407_loss: 1.5350 - dense_408_loss: 1.7874 - dense_409_loss: 1.6747 - dense_410_loss: 1.6706 - dense_411_loss: 1.5310 - dense_412_loss: 1.4305 - dense_413_loss: 1.6286 - dense_404_accuracy: 0.4020 - dense_405_accuracy: 0.3720 - dense_406_accuracy: 0.3640 - dense_407_accuracy: 0.3420 - dense_408_accuracy: 0.2920 - dense_409_accuracy: 0.3180 - dense_410_accuracy: 0.3140 - dense_411_accuracy: 0.3520 - dense_412_accuracy: 0.4100 - dense_413_accuracy: 0.3380\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 15.7355 - dense_404_loss: 1.4453 - dense_405_loss: 1.4624 - dense_406_loss: 1.6029 - dense_407_loss: 1.5315 - dense_408_loss: 1.7790 - dense_409_loss: 1.6692 - dense_410_loss: 1.6642 - dense_411_loss: 1.5382 - dense_412_loss: 1.4159 - dense_413_loss: 1.6268 - dense_404_accuracy: 0.3780 - dense_405_accuracy: 0.3640 - dense_406_accuracy: 0.3560 - dense_407_accuracy: 0.3480 - dense_408_accuracy: 0.3060 - dense_409_accuracy: 0.3180 - dense_410_accuracy: 0.3200 - dense_411_accuracy: 0.3300 - dense_412_accuracy: 0.4200 - dense_413_accuracy: 0.3420\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 15.6713 - dense_404_loss: 1.4338 - dense_405_loss: 1.4593 - dense_406_loss: 1.5949 - dense_407_loss: 1.5177 - dense_408_loss: 1.7740 - dense_409_loss: 1.6604 - dense_410_loss: 1.6519 - dense_411_loss: 1.5389 - dense_412_loss: 1.4235 - dense_413_loss: 1.6170 - dense_404_accuracy: 0.4140 - dense_405_accuracy: 0.3880 - dense_406_accuracy: 0.3880 - dense_407_accuracy: 0.3660 - dense_408_accuracy: 0.3160 - dense_409_accuracy: 0.3260 - dense_410_accuracy: 0.3440 - dense_411_accuracy: 0.3640 - dense_412_accuracy: 0.4360 - dense_413_accuracy: 0.3440\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 15.5281 - dense_404_loss: 1.4034 - dense_405_loss: 1.4419 - dense_406_loss: 1.5870 - dense_407_loss: 1.5092 - dense_408_loss: 1.7482 - dense_409_loss: 1.6412 - dense_410_loss: 1.6434 - dense_411_loss: 1.5293 - dense_412_loss: 1.4154 - dense_413_loss: 1.6090 - dense_404_accuracy: 0.4160 - dense_405_accuracy: 0.3960 - dense_406_accuracy: 0.3780 - dense_407_accuracy: 0.3680 - dense_408_accuracy: 0.3180 - dense_409_accuracy: 0.3560 - dense_410_accuracy: 0.3520 - dense_411_accuracy: 0.3560 - dense_412_accuracy: 0.4220 - dense_413_accuracy: 0.3560\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 15.5267 - dense_404_loss: 1.4238 - dense_405_loss: 1.4352 - dense_406_loss: 1.5953 - dense_407_loss: 1.5069 - dense_408_loss: 1.7474 - dense_409_loss: 1.6423 - dense_410_loss: 1.6480 - dense_411_loss: 1.5194 - dense_412_loss: 1.4081 - dense_413_loss: 1.6004 - dense_404_accuracy: 0.4020 - dense_405_accuracy: 0.3680 - dense_406_accuracy: 0.3600 - dense_407_accuracy: 0.3980 - dense_408_accuracy: 0.3260 - dense_409_accuracy: 0.3640 - dense_410_accuracy: 0.3540 - dense_411_accuracy: 0.3740 - dense_412_accuracy: 0.4120 - dense_413_accuracy: 0.3700\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 15.4181 - dense_404_loss: 1.4054 - dense_405_loss: 1.4341 - dense_406_loss: 1.5803 - dense_407_loss: 1.4854 - dense_408_loss: 1.7340 - dense_409_loss: 1.6424 - dense_410_loss: 1.6275 - dense_411_loss: 1.5083 - dense_412_loss: 1.4116 - dense_413_loss: 1.5891 - dense_404_accuracy: 0.3900 - dense_405_accuracy: 0.3780 - dense_406_accuracy: 0.3720 - dense_407_accuracy: 0.3820 - dense_408_accuracy: 0.3400 - dense_409_accuracy: 0.3660 - dense_410_accuracy: 0.3500 - dense_411_accuracy: 0.3660 - dense_412_accuracy: 0.4180 - dense_413_accuracy: 0.3820\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 15.3407 - dense_404_loss: 1.4090 - dense_405_loss: 1.4114 - dense_406_loss: 1.5617 - dense_407_loss: 1.4818 - dense_408_loss: 1.7276 - dense_409_loss: 1.6405 - dense_410_loss: 1.6255 - dense_411_loss: 1.5033 - dense_412_loss: 1.4033 - dense_413_loss: 1.5765 - dense_404_accuracy: 0.3980 - dense_405_accuracy: 0.3940 - dense_406_accuracy: 0.3840 - dense_407_accuracy: 0.3900 - dense_408_accuracy: 0.3360 - dense_409_accuracy: 0.3560 - dense_410_accuracy: 0.3360 - dense_411_accuracy: 0.3860 - dense_412_accuracy: 0.4080 - dense_413_accuracy: 0.3800\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 15.1263 - dense_404_loss: 1.3785 - dense_405_loss: 1.4108 - dense_406_loss: 1.5387 - dense_407_loss: 1.4709 - dense_408_loss: 1.7016 - dense_409_loss: 1.6170 - dense_410_loss: 1.5902 - dense_411_loss: 1.4832 - dense_412_loss: 1.3861 - dense_413_loss: 1.5493 - dense_404_accuracy: 0.4340 - dense_405_accuracy: 0.4200 - dense_406_accuracy: 0.4060 - dense_407_accuracy: 0.3800 - dense_408_accuracy: 0.3560 - dense_409_accuracy: 0.3840 - dense_410_accuracy: 0.3620 - dense_411_accuracy: 0.4020 - dense_412_accuracy: 0.4360 - dense_413_accuracy: 0.3840\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 14.8731 - dense_404_loss: 1.3418 - dense_405_loss: 1.3780 - dense_406_loss: 1.5135 - dense_407_loss: 1.4445 - dense_408_loss: 1.6772 - dense_409_loss: 1.6016 - dense_410_loss: 1.5690 - dense_411_loss: 1.4518 - dense_412_loss: 1.3618 - dense_413_loss: 1.5339 - dense_404_accuracy: 0.4440 - dense_405_accuracy: 0.4400 - dense_406_accuracy: 0.4060 - dense_407_accuracy: 0.3940 - dense_408_accuracy: 0.3800 - dense_409_accuracy: 0.3880 - dense_410_accuracy: 0.3740 - dense_411_accuracy: 0.3940 - dense_412_accuracy: 0.4600 - dense_413_accuracy: 0.4100\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 14.7874 - dense_404_loss: 1.3460 - dense_405_loss: 1.3724 - dense_406_loss: 1.5089 - dense_407_loss: 1.4355 - dense_408_loss: 1.6607 - dense_409_loss: 1.5901 - dense_410_loss: 1.5586 - dense_411_loss: 1.4469 - dense_412_loss: 1.3450 - dense_413_loss: 1.5233 - dense_404_accuracy: 0.4560 - dense_405_accuracy: 0.4360 - dense_406_accuracy: 0.4220 - dense_407_accuracy: 0.4160 - dense_408_accuracy: 0.3820 - dense_409_accuracy: 0.3680 - dense_410_accuracy: 0.3780 - dense_411_accuracy: 0.4160 - dense_412_accuracy: 0.4420 - dense_413_accuracy: 0.4360\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 14.6662 - dense_404_loss: 1.3095 - dense_405_loss: 1.3641 - dense_406_loss: 1.4926 - dense_407_loss: 1.4136 - dense_408_loss: 1.6625 - dense_409_loss: 1.5792 - dense_410_loss: 1.5384 - dense_411_loss: 1.4405 - dense_412_loss: 1.3483 - dense_413_loss: 1.5175 - dense_404_accuracy: 0.4940 - dense_405_accuracy: 0.4300 - dense_406_accuracy: 0.4360 - dense_407_accuracy: 0.4300 - dense_408_accuracy: 0.3840 - dense_409_accuracy: 0.3680 - dense_410_accuracy: 0.3740 - dense_411_accuracy: 0.4340 - dense_412_accuracy: 0.4420 - dense_413_accuracy: 0.4160\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 14.5109 - dense_404_loss: 1.2995 - dense_405_loss: 1.3407 - dense_406_loss: 1.4894 - dense_407_loss: 1.4099 - dense_408_loss: 1.6333 - dense_409_loss: 1.5562 - dense_410_loss: 1.5258 - dense_411_loss: 1.4165 - dense_412_loss: 1.3411 - dense_413_loss: 1.4984 - dense_404_accuracy: 0.4940 - dense_405_accuracy: 0.4360 - dense_406_accuracy: 0.4140 - dense_407_accuracy: 0.4160 - dense_408_accuracy: 0.3760 - dense_409_accuracy: 0.3880 - dense_410_accuracy: 0.3780 - dense_411_accuracy: 0.4420 - dense_412_accuracy: 0.4480 - dense_413_accuracy: 0.4360\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 14.4298 - dense_404_loss: 1.3058 - dense_405_loss: 1.3453 - dense_406_loss: 1.4709 - dense_407_loss: 1.3892 - dense_408_loss: 1.6318 - dense_409_loss: 1.5614 - dense_410_loss: 1.5111 - dense_411_loss: 1.4160 - dense_412_loss: 1.3143 - dense_413_loss: 1.4840 - dense_404_accuracy: 0.4680 - dense_405_accuracy: 0.4620 - dense_406_accuracy: 0.4560 - dense_407_accuracy: 0.4520 - dense_408_accuracy: 0.3940 - dense_409_accuracy: 0.4020 - dense_410_accuracy: 0.4080 - dense_411_accuracy: 0.4440 - dense_412_accuracy: 0.4860 - dense_413_accuracy: 0.4560\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D2CB9828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D2CB9828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4B8F168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4B8F168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 18ms/step - loss: 0.2079\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0260\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.0058\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0050\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0048\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0047\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0047\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0046\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0046\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0046\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0045\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0044\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0042\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.0040\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0038\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0036\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0035\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0033\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 0.0032\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 0.0032\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 0.0031\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0031\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.0031\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0031\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0030\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D38B13A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D38B13A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 4s 8ms/step - loss: 17.5224 - dense_417_loss: 1.5515 - dense_418_loss: 1.7345 - dense_419_loss: 1.8639 - dense_420_loss: 1.7210 - dense_421_loss: 1.9934 - dense_422_loss: 1.7807 - dense_423_loss: 1.7124 - dense_424_loss: 1.7620 - dense_425_loss: 1.5892 - dense_426_loss: 1.8138 - dense_417_accuracy: 0.4034 - dense_418_accuracy: 0.2764 - dense_419_accuracy: 0.2134 - dense_420_accuracy: 0.2630 - dense_421_accuracy: 0.2054 - dense_422_accuracy: 0.2528 - dense_423_accuracy: 0.3298 - dense_424_accuracy: 0.2480 - dense_425_accuracy: 0.3632 - dense_426_accuracy: 0.2280\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.3779 - dense_417_loss: 1.3169 - dense_418_loss: 1.5485 - dense_419_loss: 1.6412 - dense_420_loss: 1.5156 - dense_421_loss: 1.7122 - dense_422_loss: 1.5497 - dense_423_loss: 1.4909 - dense_424_loss: 1.5569 - dense_425_loss: 1.4165 - dense_426_loss: 1.6293 - dense_417_accuracy: 0.4726 - dense_418_accuracy: 0.2980 - dense_419_accuracy: 0.2322 - dense_420_accuracy: 0.2958 - dense_421_accuracy: 0.2304 - dense_422_accuracy: 0.2952 - dense_423_accuracy: 0.3530 - dense_424_accuracy: 0.2946 - dense_425_accuracy: 0.3974 - dense_426_accuracy: 0.2366\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.3256 - dense_417_loss: 1.3111 - dense_418_loss: 1.5466 - dense_419_loss: 1.6343 - dense_420_loss: 1.5134 - dense_421_loss: 1.7061 - dense_422_loss: 1.5437 - dense_423_loss: 1.4840 - dense_424_loss: 1.5558 - dense_425_loss: 1.4086 - dense_426_loss: 1.6218 - dense_417_accuracy: 0.4758 - dense_418_accuracy: 0.3016 - dense_419_accuracy: 0.2434 - dense_420_accuracy: 0.3034 - dense_421_accuracy: 0.2350 - dense_422_accuracy: 0.2926 - dense_423_accuracy: 0.3552 - dense_424_accuracy: 0.2934 - dense_425_accuracy: 0.4002 - dense_426_accuracy: 0.2394\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.3031 - dense_417_loss: 1.3104 - dense_418_loss: 1.5440 - dense_419_loss: 1.6342 - dense_420_loss: 1.5094 - dense_421_loss: 1.7035 - dense_422_loss: 1.5407 - dense_423_loss: 1.4811 - dense_424_loss: 1.5514 - dense_425_loss: 1.4085 - dense_426_loss: 1.6197 - dense_417_accuracy: 0.4762 - dense_418_accuracy: 0.3006 - dense_419_accuracy: 0.2360 - dense_420_accuracy: 0.2980 - dense_421_accuracy: 0.2336 - dense_422_accuracy: 0.2990 - dense_423_accuracy: 0.3590 - dense_424_accuracy: 0.2984 - dense_425_accuracy: 0.4050 - dense_426_accuracy: 0.2338\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.3153 - dense_417_loss: 1.3157 - dense_418_loss: 1.5424 - dense_419_loss: 1.6362 - dense_420_loss: 1.5136 - dense_421_loss: 1.7028 - dense_422_loss: 1.5406 - dense_423_loss: 1.4871 - dense_424_loss: 1.5466 - dense_425_loss: 1.4109 - dense_426_loss: 1.6193 - dense_417_accuracy: 0.4728 - dense_418_accuracy: 0.3140 - dense_419_accuracy: 0.2442 - dense_420_accuracy: 0.2922 - dense_421_accuracy: 0.2402 - dense_422_accuracy: 0.2936 - dense_423_accuracy: 0.3554 - dense_424_accuracy: 0.3100 - dense_425_accuracy: 0.4004 - dense_426_accuracy: 0.2380\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 15.2374 - dense_417_loss: 1.3042 - dense_418_loss: 1.5391 - dense_419_loss: 1.6311 - dense_420_loss: 1.5063 - dense_421_loss: 1.6964 - dense_422_loss: 1.5330 - dense_423_loss: 1.4752 - dense_424_loss: 1.5405 - dense_425_loss: 1.4021 - dense_426_loss: 1.6096 - dense_417_accuracy: 0.4752 - dense_418_accuracy: 0.3146 - dense_419_accuracy: 0.2530 - dense_420_accuracy: 0.3168 - dense_421_accuracy: 0.2532 - dense_422_accuracy: 0.3078 - dense_423_accuracy: 0.3670 - dense_424_accuracy: 0.3130 - dense_425_accuracy: 0.4124 - dense_426_accuracy: 0.2618\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 15.2092 - dense_417_loss: 1.3021 - dense_418_loss: 1.5383 - dense_419_loss: 1.6275 - dense_420_loss: 1.5021 - dense_421_loss: 1.6937 - dense_422_loss: 1.5278 - dense_423_loss: 1.4719 - dense_424_loss: 1.5387 - dense_425_loss: 1.4012 - dense_426_loss: 1.6059 - dense_417_accuracy: 0.4782 - dense_418_accuracy: 0.3046 - dense_419_accuracy: 0.2450 - dense_420_accuracy: 0.3046 - dense_421_accuracy: 0.2456 - dense_422_accuracy: 0.3016 - dense_423_accuracy: 0.3638 - dense_424_accuracy: 0.3038 - dense_425_accuracy: 0.4016 - dense_426_accuracy: 0.2554\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 15.1618 - dense_417_loss: 1.3010 - dense_418_loss: 1.5311 - dense_419_loss: 1.6213 - dense_420_loss: 1.4943 - dense_421_loss: 1.6851 - dense_422_loss: 1.5241 - dense_423_loss: 1.4696 - dense_424_loss: 1.5373 - dense_425_loss: 1.3942 - dense_426_loss: 1.6039 - dense_417_accuracy: 0.4820 - dense_418_accuracy: 0.3272 - dense_419_accuracy: 0.2560 - dense_420_accuracy: 0.3202 - dense_421_accuracy: 0.2626 - dense_422_accuracy: 0.3142 - dense_423_accuracy: 0.3716 - dense_424_accuracy: 0.3166 - dense_425_accuracy: 0.4086 - dense_426_accuracy: 0.2566\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 15.0914 - dense_417_loss: 1.2920 - dense_418_loss: 1.5243 - dense_419_loss: 1.6130 - dense_420_loss: 1.4915 - dense_421_loss: 1.6787 - dense_422_loss: 1.5194 - dense_423_loss: 1.4605 - dense_424_loss: 1.5240 - dense_425_loss: 1.3889 - dense_426_loss: 1.5992 - dense_417_accuracy: 0.4836 - dense_418_accuracy: 0.3302 - dense_419_accuracy: 0.2604 - dense_420_accuracy: 0.3192 - dense_421_accuracy: 0.2764 - dense_422_accuracy: 0.3242 - dense_423_accuracy: 0.3742 - dense_424_accuracy: 0.3276 - dense_425_accuracy: 0.4196 - dense_426_accuracy: 0.2694\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 15.0007 - dense_417_loss: 1.2841 - dense_418_loss: 1.5154 - dense_419_loss: 1.6079 - dense_420_loss: 1.4794 - dense_421_loss: 1.6691 - dense_422_loss: 1.5050 - dense_423_loss: 1.4509 - dense_424_loss: 1.5196 - dense_425_loss: 1.3799 - dense_426_loss: 1.5894 - dense_417_accuracy: 0.4860 - dense_418_accuracy: 0.3320 - dense_419_accuracy: 0.2606 - dense_420_accuracy: 0.3288 - dense_421_accuracy: 0.2698 - dense_422_accuracy: 0.3310 - dense_423_accuracy: 0.3856 - dense_424_accuracy: 0.3290 - dense_425_accuracy: 0.4236 - dense_426_accuracy: 0.2754\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 14.9140 - dense_417_loss: 1.2755 - dense_418_loss: 1.5061 - dense_419_loss: 1.5918 - dense_420_loss: 1.4716 - dense_421_loss: 1.6609 - dense_422_loss: 1.4970 - dense_423_loss: 1.4467 - dense_424_loss: 1.5102 - dense_425_loss: 1.3721 - dense_426_loss: 1.5820 - dense_417_accuracy: 0.4920 - dense_418_accuracy: 0.3246 - dense_419_accuracy: 0.2750 - dense_420_accuracy: 0.3294 - dense_421_accuracy: 0.2696 - dense_422_accuracy: 0.3298 - dense_423_accuracy: 0.3886 - dense_424_accuracy: 0.3260 - dense_425_accuracy: 0.4214 - dense_426_accuracy: 0.2716\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 14.8369 - dense_417_loss: 1.2723 - dense_418_loss: 1.5022 - dense_419_loss: 1.5862 - dense_420_loss: 1.4617 - dense_421_loss: 1.6493 - dense_422_loss: 1.4911 - dense_423_loss: 1.4374 - dense_424_loss: 1.4983 - dense_425_loss: 1.3680 - dense_426_loss: 1.5706 - dense_417_accuracy: 0.4964 - dense_418_accuracy: 0.3266 - dense_419_accuracy: 0.2778 - dense_420_accuracy: 0.3390 - dense_421_accuracy: 0.2718 - dense_422_accuracy: 0.3376 - dense_423_accuracy: 0.3894 - dense_424_accuracy: 0.3380 - dense_425_accuracy: 0.4254 - dense_426_accuracy: 0.2818\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 14.7677 - dense_417_loss: 1.2679 - dense_418_loss: 1.4981 - dense_419_loss: 1.5766 - dense_420_loss: 1.4543 - dense_421_loss: 1.6415 - dense_422_loss: 1.4821 - dense_423_loss: 1.4321 - dense_424_loss: 1.4914 - dense_425_loss: 1.3615 - dense_426_loss: 1.5622 - dense_417_accuracy: 0.4908 - dense_418_accuracy: 0.3346 - dense_419_accuracy: 0.2892 - dense_420_accuracy: 0.3410 - dense_421_accuracy: 0.2898 - dense_422_accuracy: 0.3508 - dense_423_accuracy: 0.3916 - dense_424_accuracy: 0.3450 - dense_425_accuracy: 0.4230 - dense_426_accuracy: 0.3000\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 14.6881 - dense_417_loss: 1.2621 - dense_418_loss: 1.4859 - dense_419_loss: 1.5660 - dense_420_loss: 1.4448 - dense_421_loss: 1.6329 - dense_422_loss: 1.4774 - dense_423_loss: 1.4241 - dense_424_loss: 1.4837 - dense_425_loss: 1.3555 - dense_426_loss: 1.5556 - dense_417_accuracy: 0.5004 - dense_418_accuracy: 0.3452 - dense_419_accuracy: 0.2926 - dense_420_accuracy: 0.3498 - dense_421_accuracy: 0.2884 - dense_422_accuracy: 0.3444 - dense_423_accuracy: 0.3950 - dense_424_accuracy: 0.3442 - dense_425_accuracy: 0.4340 - dense_426_accuracy: 0.2926\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 14.5467 - dense_417_loss: 1.2470 - dense_418_loss: 1.4732 - dense_419_loss: 1.5490 - dense_420_loss: 1.4336 - dense_421_loss: 1.6180 - dense_422_loss: 1.4631 - dense_423_loss: 1.4061 - dense_424_loss: 1.4705 - dense_425_loss: 1.3442 - dense_426_loss: 1.5421 - dense_417_accuracy: 0.5006 - dense_418_accuracy: 0.3458 - dense_419_accuracy: 0.3016 - dense_420_accuracy: 0.3530 - dense_421_accuracy: 0.3046 - dense_422_accuracy: 0.3592 - dense_423_accuracy: 0.4160 - dense_424_accuracy: 0.3524 - dense_425_accuracy: 0.4338 - dense_426_accuracy: 0.3056\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 14.4495 - dense_417_loss: 1.2433 - dense_418_loss: 1.4606 - dense_419_loss: 1.5372 - dense_420_loss: 1.4234 - dense_421_loss: 1.6057 - dense_422_loss: 1.4549 - dense_423_loss: 1.4003 - dense_424_loss: 1.4624 - dense_425_loss: 1.3321 - dense_426_loss: 1.5295 - dense_417_accuracy: 0.5056 - dense_418_accuracy: 0.3588 - dense_419_accuracy: 0.3142 - dense_420_accuracy: 0.3538 - dense_421_accuracy: 0.3216 - dense_422_accuracy: 0.3706 - dense_423_accuracy: 0.4218 - dense_424_accuracy: 0.3578 - dense_425_accuracy: 0.4510 - dense_426_accuracy: 0.3198\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 14.3695 - dense_417_loss: 1.2377 - dense_418_loss: 1.4540 - dense_419_loss: 1.5280 - dense_420_loss: 1.4164 - dense_421_loss: 1.5954 - dense_422_loss: 1.4454 - dense_423_loss: 1.3930 - dense_424_loss: 1.4516 - dense_425_loss: 1.3235 - dense_426_loss: 1.5243 - dense_417_accuracy: 0.5044 - dense_418_accuracy: 0.3616 - dense_419_accuracy: 0.3204 - dense_420_accuracy: 0.3640 - dense_421_accuracy: 0.3240 - dense_422_accuracy: 0.3690 - dense_423_accuracy: 0.4222 - dense_424_accuracy: 0.3624 - dense_425_accuracy: 0.4466 - dense_426_accuracy: 0.3218\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 14.2873 - dense_417_loss: 1.2281 - dense_418_loss: 1.4460 - dense_419_loss: 1.5214 - dense_420_loss: 1.4064 - dense_421_loss: 1.5868 - dense_422_loss: 1.4377 - dense_423_loss: 1.3800 - dense_424_loss: 1.4429 - dense_425_loss: 1.3239 - dense_426_loss: 1.5140 - dense_417_accuracy: 0.5182 - dense_418_accuracy: 0.3702 - dense_419_accuracy: 0.3264 - dense_420_accuracy: 0.3672 - dense_421_accuracy: 0.3192 - dense_422_accuracy: 0.3720 - dense_423_accuracy: 0.4272 - dense_424_accuracy: 0.3716 - dense_425_accuracy: 0.4504 - dense_426_accuracy: 0.3218\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 14.1993 - dense_417_loss: 1.2217 - dense_418_loss: 1.4372 - dense_419_loss: 1.5104 - dense_420_loss: 1.4010 - dense_421_loss: 1.5748 - dense_422_loss: 1.4299 - dense_423_loss: 1.3749 - dense_424_loss: 1.4342 - dense_425_loss: 1.3118 - dense_426_loss: 1.5034 - dense_417_accuracy: 0.5070 - dense_418_accuracy: 0.3760 - dense_419_accuracy: 0.3432 - dense_420_accuracy: 0.3700 - dense_421_accuracy: 0.3436 - dense_422_accuracy: 0.3884 - dense_423_accuracy: 0.4376 - dense_424_accuracy: 0.3730 - dense_425_accuracy: 0.4546 - dense_426_accuracy: 0.3404\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 14.1168 - dense_417_loss: 1.2127 - dense_418_loss: 1.4311 - dense_419_loss: 1.5046 - dense_420_loss: 1.3882 - dense_421_loss: 1.5665 - dense_422_loss: 1.4202 - dense_423_loss: 1.3677 - dense_424_loss: 1.4260 - dense_425_loss: 1.3050 - dense_426_loss: 1.4949 - dense_417_accuracy: 0.5196 - dense_418_accuracy: 0.3784 - dense_419_accuracy: 0.3400 - dense_420_accuracy: 0.3806 - dense_421_accuracy: 0.3396 - dense_422_accuracy: 0.3862 - dense_423_accuracy: 0.4424 - dense_424_accuracy: 0.3824 - dense_425_accuracy: 0.4604 - dense_426_accuracy: 0.3394\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.9956 - dense_417_loss: 1.2068 - dense_418_loss: 1.4176 - dense_419_loss: 1.4887 - dense_420_loss: 1.3793 - dense_421_loss: 1.5522 - dense_422_loss: 1.4078 - dense_423_loss: 1.3525 - dense_424_loss: 1.4124 - dense_425_loss: 1.2989 - dense_426_loss: 1.4794 - dense_417_accuracy: 0.5214 - dense_418_accuracy: 0.3834 - dense_419_accuracy: 0.3528 - dense_420_accuracy: 0.3886 - dense_421_accuracy: 0.3524 - dense_422_accuracy: 0.3900 - dense_423_accuracy: 0.4488 - dense_424_accuracy: 0.3878 - dense_425_accuracy: 0.4656 - dense_426_accuracy: 0.3580\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.9578 - dense_417_loss: 1.1969 - dense_418_loss: 1.4134 - dense_419_loss: 1.4886 - dense_420_loss: 1.3763 - dense_421_loss: 1.5510 - dense_422_loss: 1.4060 - dense_423_loss: 1.3480 - dense_424_loss: 1.4116 - dense_425_loss: 1.2930 - dense_426_loss: 1.4730 - dense_417_accuracy: 0.5248 - dense_418_accuracy: 0.3854 - dense_419_accuracy: 0.3498 - dense_420_accuracy: 0.3882 - dense_421_accuracy: 0.3446 - dense_422_accuracy: 0.3930 - dense_423_accuracy: 0.4534 - dense_424_accuracy: 0.3796 - dense_425_accuracy: 0.4690 - dense_426_accuracy: 0.3530\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.8786 - dense_417_loss: 1.1933 - dense_418_loss: 1.4054 - dense_419_loss: 1.4747 - dense_420_loss: 1.3705 - dense_421_loss: 1.5371 - dense_422_loss: 1.3981 - dense_423_loss: 1.3441 - dense_424_loss: 1.4026 - dense_425_loss: 1.2867 - dense_426_loss: 1.4660 - dense_417_accuracy: 0.5256 - dense_418_accuracy: 0.3896 - dense_419_accuracy: 0.3608 - dense_420_accuracy: 0.3910 - dense_421_accuracy: 0.3572 - dense_422_accuracy: 0.3960 - dense_423_accuracy: 0.4544 - dense_424_accuracy: 0.3902 - dense_425_accuracy: 0.4708 - dense_426_accuracy: 0.3542\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.7424 - dense_417_loss: 1.1822 - dense_418_loss: 1.3926 - dense_419_loss: 1.4594 - dense_420_loss: 1.3525 - dense_421_loss: 1.5248 - dense_422_loss: 1.3822 - dense_423_loss: 1.3314 - dense_424_loss: 1.3908 - dense_425_loss: 1.2755 - dense_426_loss: 1.4509 - dense_417_accuracy: 0.5302 - dense_418_accuracy: 0.3978 - dense_419_accuracy: 0.3692 - dense_420_accuracy: 0.4080 - dense_421_accuracy: 0.3632 - dense_422_accuracy: 0.4006 - dense_423_accuracy: 0.4622 - dense_424_accuracy: 0.3928 - dense_425_accuracy: 0.4810 - dense_426_accuracy: 0.3720\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 13.8013 - dense_417_loss: 1.1884 - dense_418_loss: 1.4007 - dense_419_loss: 1.4710 - dense_420_loss: 1.3564 - dense_421_loss: 1.5288 - dense_422_loss: 1.3837 - dense_423_loss: 1.3368 - dense_424_loss: 1.3963 - dense_425_loss: 1.2785 - dense_426_loss: 1.4607 - dense_417_accuracy: 0.5330 - dense_418_accuracy: 0.3966 - dense_419_accuracy: 0.3720 - dense_420_accuracy: 0.4004 - dense_421_accuracy: 0.3682 - dense_422_accuracy: 0.3996 - dense_423_accuracy: 0.4626 - dense_424_accuracy: 0.3966 - dense_425_accuracy: 0.4782 - dense_426_accuracy: 0.3642\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D478E798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D478E798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D0D0FD38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D0D0FD38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 4s 9ms/step - loss: 17.3748 - dense_427_loss: 1.5527 - dense_428_loss: 1.7380 - dense_429_loss: 1.8486 - dense_430_loss: 1.7042 - dense_431_loss: 1.9522 - dense_432_loss: 1.7536 - dense_433_loss: 1.6857 - dense_434_loss: 1.7223 - dense_435_loss: 1.5939 - dense_436_loss: 1.8236 - dense_427_accuracy: 0.4164 - dense_428_accuracy: 0.2772 - dense_429_accuracy: 0.2186 - dense_430_accuracy: 0.2806 - dense_431_accuracy: 0.2118 - dense_432_accuracy: 0.2556 - dense_433_accuracy: 0.3338 - dense_434_accuracy: 0.2678 - dense_435_accuracy: 0.3506 - dense_436_accuracy: 0.2266\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.3526 - dense_427_loss: 1.3107 - dense_428_loss: 1.5475 - dense_429_loss: 1.6383 - dense_430_loss: 1.5163 - dense_431_loss: 1.7125 - dense_432_loss: 1.5449 - dense_433_loss: 1.4875 - dense_434_loss: 1.5546 - dense_435_loss: 1.4146 - dense_436_loss: 1.6257 - dense_427_accuracy: 0.4764 - dense_428_accuracy: 0.3002 - dense_429_accuracy: 0.2364 - dense_430_accuracy: 0.2956 - dense_431_accuracy: 0.2300 - dense_432_accuracy: 0.2888 - dense_433_accuracy: 0.3500 - dense_434_accuracy: 0.2932 - dense_435_accuracy: 0.4070 - dense_436_accuracy: 0.2364\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.2810 - dense_427_loss: 1.3084 - dense_428_loss: 1.5416 - dense_429_loss: 1.6340 - dense_430_loss: 1.5086 - dense_431_loss: 1.7010 - dense_432_loss: 1.5364 - dense_433_loss: 1.4801 - dense_434_loss: 1.5480 - dense_435_loss: 1.4065 - dense_436_loss: 1.6166 - dense_427_accuracy: 0.4762 - dense_428_accuracy: 0.2986 - dense_429_accuracy: 0.2372 - dense_430_accuracy: 0.3014 - dense_431_accuracy: 0.2398 - dense_432_accuracy: 0.3036 - dense_433_accuracy: 0.3590 - dense_434_accuracy: 0.2986 - dense_435_accuracy: 0.4048 - dense_436_accuracy: 0.2410\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.2841 - dense_427_loss: 1.3044 - dense_428_loss: 1.5409 - dense_429_loss: 1.6349 - dense_430_loss: 1.5112 - dense_431_loss: 1.7017 - dense_432_loss: 1.5377 - dense_433_loss: 1.4776 - dense_434_loss: 1.5484 - dense_435_loss: 1.4088 - dense_436_loss: 1.6186 - dense_427_accuracy: 0.4766 - dense_428_accuracy: 0.3034 - dense_429_accuracy: 0.2416 - dense_430_accuracy: 0.3044 - dense_431_accuracy: 0.2440 - dense_432_accuracy: 0.3048 - dense_433_accuracy: 0.3574 - dense_434_accuracy: 0.2988 - dense_435_accuracy: 0.4000 - dense_436_accuracy: 0.2482\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.2713 - dense_427_loss: 1.3064 - dense_428_loss: 1.5408 - dense_429_loss: 1.6310 - dense_430_loss: 1.5055 - dense_431_loss: 1.7003 - dense_432_loss: 1.5383 - dense_433_loss: 1.4808 - dense_434_loss: 1.5456 - dense_435_loss: 1.4051 - dense_436_loss: 1.6176 - dense_427_accuracy: 0.4762 - dense_428_accuracy: 0.3028 - dense_429_accuracy: 0.2416 - dense_430_accuracy: 0.3014 - dense_431_accuracy: 0.2406 - dense_432_accuracy: 0.3024 - dense_433_accuracy: 0.3584 - dense_434_accuracy: 0.3100 - dense_435_accuracy: 0.4016 - dense_436_accuracy: 0.2404\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.2437 - dense_427_loss: 1.3058 - dense_428_loss: 1.5353 - dense_429_loss: 1.6284 - dense_430_loss: 1.5057 - dense_431_loss: 1.6972 - dense_432_loss: 1.5332 - dense_433_loss: 1.4770 - dense_434_loss: 1.5439 - dense_435_loss: 1.4043 - dense_436_loss: 1.6130 - dense_427_accuracy: 0.4760 - dense_428_accuracy: 0.3072 - dense_429_accuracy: 0.2424 - dense_430_accuracy: 0.3032 - dense_431_accuracy: 0.2416 - dense_432_accuracy: 0.3028 - dense_433_accuracy: 0.3562 - dense_434_accuracy: 0.3018 - dense_435_accuracy: 0.4086 - dense_436_accuracy: 0.2452\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 15.2558 - dense_427_loss: 1.3071 - dense_428_loss: 1.5391 - dense_429_loss: 1.6288 - dense_430_loss: 1.5069 - dense_431_loss: 1.6988 - dense_432_loss: 1.5364 - dense_433_loss: 1.4760 - dense_434_loss: 1.5441 - dense_435_loss: 1.4056 - dense_436_loss: 1.6129 - dense_427_accuracy: 0.4762 - dense_428_accuracy: 0.3028 - dense_429_accuracy: 0.2314 - dense_430_accuracy: 0.3034 - dense_431_accuracy: 0.2414 - dense_432_accuracy: 0.2988 - dense_433_accuracy: 0.3562 - dense_434_accuracy: 0.3076 - dense_435_accuracy: 0.4040 - dense_436_accuracy: 0.2494\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.2603 - dense_427_loss: 1.3062 - dense_428_loss: 1.5393 - dense_429_loss: 1.6297 - dense_430_loss: 1.5062 - dense_431_loss: 1.6991 - dense_432_loss: 1.5373 - dense_433_loss: 1.4797 - dense_434_loss: 1.5445 - dense_435_loss: 1.4048 - dense_436_loss: 1.6135 - dense_427_accuracy: 0.4764 - dense_428_accuracy: 0.2994 - dense_429_accuracy: 0.2292 - dense_430_accuracy: 0.3004 - dense_431_accuracy: 0.2294 - dense_432_accuracy: 0.2910 - dense_433_accuracy: 0.3574 - dense_434_accuracy: 0.3070 - dense_435_accuracy: 0.4114 - dense_436_accuracy: 0.2426\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.2643 - dense_427_loss: 1.3094 - dense_428_loss: 1.5382 - dense_429_loss: 1.6301 - dense_430_loss: 1.5065 - dense_431_loss: 1.7005 - dense_432_loss: 1.5373 - dense_433_loss: 1.4792 - dense_434_loss: 1.5460 - dense_435_loss: 1.4030 - dense_436_loss: 1.6139 - dense_427_accuracy: 0.4764 - dense_428_accuracy: 0.2980 - dense_429_accuracy: 0.2374 - dense_430_accuracy: 0.3048 - dense_431_accuracy: 0.2340 - dense_432_accuracy: 0.2988 - dense_433_accuracy: 0.3536 - dense_434_accuracy: 0.2916 - dense_435_accuracy: 0.4046 - dense_436_accuracy: 0.2382\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.2213 - dense_427_loss: 1.3048 - dense_428_loss: 1.5366 - dense_429_loss: 1.6252 - dense_430_loss: 1.4989 - dense_431_loss: 1.6954 - dense_432_loss: 1.5311 - dense_433_loss: 1.4765 - dense_434_loss: 1.5417 - dense_435_loss: 1.4007 - dense_436_loss: 1.6104 - dense_427_accuracy: 0.4778 - dense_428_accuracy: 0.3030 - dense_429_accuracy: 0.2426 - dense_430_accuracy: 0.3166 - dense_431_accuracy: 0.2438 - dense_432_accuracy: 0.3084 - dense_433_accuracy: 0.3614 - dense_434_accuracy: 0.2976 - dense_435_accuracy: 0.4018 - dense_436_accuracy: 0.2448\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.2090 - dense_427_loss: 1.3003 - dense_428_loss: 1.5341 - dense_429_loss: 1.6254 - dense_430_loss: 1.4996 - dense_431_loss: 1.6934 - dense_432_loss: 1.5307 - dense_433_loss: 1.4740 - dense_434_loss: 1.5398 - dense_435_loss: 1.4025 - dense_436_loss: 1.6093 - dense_427_accuracy: 0.4796 - dense_428_accuracy: 0.3152 - dense_429_accuracy: 0.2384 - dense_430_accuracy: 0.3150 - dense_431_accuracy: 0.2362 - dense_432_accuracy: 0.3032 - dense_433_accuracy: 0.3662 - dense_434_accuracy: 0.3056 - dense_435_accuracy: 0.4074 - dense_436_accuracy: 0.2506\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.2035 - dense_427_loss: 1.3003 - dense_428_loss: 1.5353 - dense_429_loss: 1.6248 - dense_430_loss: 1.5037 - dense_431_loss: 1.6935 - dense_432_loss: 1.5305 - dense_433_loss: 1.4722 - dense_434_loss: 1.5372 - dense_435_loss: 1.3985 - dense_436_loss: 1.6075 - dense_427_accuracy: 0.4802 - dense_428_accuracy: 0.3020 - dense_429_accuracy: 0.2350 - dense_430_accuracy: 0.3002 - dense_431_accuracy: 0.2358 - dense_432_accuracy: 0.2914 - dense_433_accuracy: 0.3632 - dense_434_accuracy: 0.3022 - dense_435_accuracy: 0.4074 - dense_436_accuracy: 0.2378\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.1678 - dense_427_loss: 1.2993 - dense_428_loss: 1.5313 - dense_429_loss: 1.6203 - dense_430_loss: 1.4964 - dense_431_loss: 1.6898 - dense_432_loss: 1.5278 - dense_433_loss: 1.4684 - dense_434_loss: 1.5340 - dense_435_loss: 1.3947 - dense_436_loss: 1.6058 - dense_427_accuracy: 0.4812 - dense_428_accuracy: 0.3050 - dense_429_accuracy: 0.2422 - dense_430_accuracy: 0.3080 - dense_431_accuracy: 0.2422 - dense_432_accuracy: 0.3018 - dense_433_accuracy: 0.3700 - dense_434_accuracy: 0.3022 - dense_435_accuracy: 0.4092 - dense_436_accuracy: 0.2476\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.1022 - dense_427_loss: 1.2930 - dense_428_loss: 1.5239 - dense_429_loss: 1.6126 - dense_430_loss: 1.4896 - dense_431_loss: 1.6820 - dense_432_loss: 1.5207 - dense_433_loss: 1.4620 - dense_434_loss: 1.5274 - dense_435_loss: 1.3906 - dense_436_loss: 1.6005 - dense_427_accuracy: 0.4824 - dense_428_accuracy: 0.3048 - dense_429_accuracy: 0.2552 - dense_430_accuracy: 0.3128 - dense_431_accuracy: 0.2452 - dense_432_accuracy: 0.3058 - dense_433_accuracy: 0.3698 - dense_434_accuracy: 0.3142 - dense_435_accuracy: 0.4090 - dense_436_accuracy: 0.2446\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 15.0937 - dense_427_loss: 1.2931 - dense_428_loss: 1.5250 - dense_429_loss: 1.6108 - dense_430_loss: 1.4882 - dense_431_loss: 1.6810 - dense_432_loss: 1.5181 - dense_433_loss: 1.4597 - dense_434_loss: 1.5257 - dense_435_loss: 1.3930 - dense_436_loss: 1.5991 - dense_427_accuracy: 0.4842 - dense_428_accuracy: 0.3194 - dense_429_accuracy: 0.2494 - dense_430_accuracy: 0.3160 - dense_431_accuracy: 0.2478 - dense_432_accuracy: 0.3136 - dense_433_accuracy: 0.3686 - dense_434_accuracy: 0.3174 - dense_435_accuracy: 0.4084 - dense_436_accuracy: 0.2462\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.0670 - dense_427_loss: 1.2914 - dense_428_loss: 1.5249 - dense_429_loss: 1.6092 - dense_430_loss: 1.4825 - dense_431_loss: 1.6794 - dense_432_loss: 1.5154 - dense_433_loss: 1.4571 - dense_434_loss: 1.5234 - dense_435_loss: 1.3871 - dense_436_loss: 1.5966 - dense_427_accuracy: 0.4832 - dense_428_accuracy: 0.3136 - dense_429_accuracy: 0.2562 - dense_430_accuracy: 0.3212 - dense_431_accuracy: 0.2548 - dense_432_accuracy: 0.3054 - dense_433_accuracy: 0.3634 - dense_434_accuracy: 0.3228 - dense_435_accuracy: 0.4160 - dense_436_accuracy: 0.2548\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 15.0633 - dense_427_loss: 1.2879 - dense_428_loss: 1.5241 - dense_429_loss: 1.6088 - dense_430_loss: 1.4838 - dense_431_loss: 1.6777 - dense_432_loss: 1.5179 - dense_433_loss: 1.4588 - dense_434_loss: 1.5211 - dense_435_loss: 1.3889 - dense_436_loss: 1.5942 - dense_427_accuracy: 0.4868 - dense_428_accuracy: 0.3186 - dense_429_accuracy: 0.2514 - dense_430_accuracy: 0.3220 - dense_431_accuracy: 0.2494 - dense_432_accuracy: 0.3098 - dense_433_accuracy: 0.3708 - dense_434_accuracy: 0.3180 - dense_435_accuracy: 0.4160 - dense_436_accuracy: 0.2622\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.0105 - dense_427_loss: 1.2833 - dense_428_loss: 1.5160 - dense_429_loss: 1.6038 - dense_430_loss: 1.4804 - dense_431_loss: 1.6711 - dense_432_loss: 1.5156 - dense_433_loss: 1.4527 - dense_434_loss: 1.5176 - dense_435_loss: 1.3814 - dense_436_loss: 1.5884 - dense_427_accuracy: 0.4864 - dense_428_accuracy: 0.3230 - dense_429_accuracy: 0.2690 - dense_430_accuracy: 0.3244 - dense_431_accuracy: 0.2596 - dense_432_accuracy: 0.3170 - dense_433_accuracy: 0.3780 - dense_434_accuracy: 0.3240 - dense_435_accuracy: 0.4218 - dense_436_accuracy: 0.2574\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 15.0081 - dense_427_loss: 1.2832 - dense_428_loss: 1.5161 - dense_429_loss: 1.6041 - dense_430_loss: 1.4787 - dense_431_loss: 1.6704 - dense_432_loss: 1.5161 - dense_433_loss: 1.4521 - dense_434_loss: 1.5180 - dense_435_loss: 1.3801 - dense_436_loss: 1.5894 - dense_427_accuracy: 0.4882 - dense_428_accuracy: 0.3128 - dense_429_accuracy: 0.2494 - dense_430_accuracy: 0.3136 - dense_431_accuracy: 0.2506 - dense_432_accuracy: 0.3064 - dense_433_accuracy: 0.3662 - dense_434_accuracy: 0.3136 - dense_435_accuracy: 0.4196 - dense_436_accuracy: 0.2484\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 14.9402 - dense_427_loss: 1.2744 - dense_428_loss: 1.5093 - dense_429_loss: 1.5971 - dense_430_loss: 1.4732 - dense_431_loss: 1.6615 - dense_432_loss: 1.5074 - dense_433_loss: 1.4453 - dense_434_loss: 1.5109 - dense_435_loss: 1.3754 - dense_436_loss: 1.5856 - dense_427_accuracy: 0.4946 - dense_428_accuracy: 0.3220 - dense_429_accuracy: 0.2702 - dense_430_accuracy: 0.3234 - dense_431_accuracy: 0.2568 - dense_432_accuracy: 0.3138 - dense_433_accuracy: 0.3764 - dense_434_accuracy: 0.3218 - dense_435_accuracy: 0.4224 - dense_436_accuracy: 0.2562\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 14.8854 - dense_427_loss: 1.2698 - dense_428_loss: 1.5047 - dense_429_loss: 1.5891 - dense_430_loss: 1.4675 - dense_431_loss: 1.6571 - dense_432_loss: 1.5046 - dense_433_loss: 1.4398 - dense_434_loss: 1.5042 - dense_435_loss: 1.3690 - dense_436_loss: 1.5797 - dense_427_accuracy: 0.4942 - dense_428_accuracy: 0.3242 - dense_429_accuracy: 0.2640 - dense_430_accuracy: 0.3254 - dense_431_accuracy: 0.2628 - dense_432_accuracy: 0.3110 - dense_433_accuracy: 0.3812 - dense_434_accuracy: 0.3248 - dense_435_accuracy: 0.4306 - dense_436_accuracy: 0.2664\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 14.8775 - dense_427_loss: 1.2705 - dense_428_loss: 1.5048 - dense_429_loss: 1.5879 - dense_430_loss: 1.4677 - dense_431_loss: 1.6557 - dense_432_loss: 1.5012 - dense_433_loss: 1.4371 - dense_434_loss: 1.5079 - dense_435_loss: 1.3679 - dense_436_loss: 1.5768 - dense_427_accuracy: 0.4948 - dense_428_accuracy: 0.3270 - dense_429_accuracy: 0.2598 - dense_430_accuracy: 0.3298 - dense_431_accuracy: 0.2670 - dense_432_accuracy: 0.3238 - dense_433_accuracy: 0.3888 - dense_434_accuracy: 0.3244 - dense_435_accuracy: 0.4250 - dense_436_accuracy: 0.2704\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 14.8475 - dense_427_loss: 1.2684 - dense_428_loss: 1.5023 - dense_429_loss: 1.5839 - dense_430_loss: 1.4613 - dense_431_loss: 1.6528 - dense_432_loss: 1.4983 - dense_433_loss: 1.4370 - dense_434_loss: 1.5014 - dense_435_loss: 1.3658 - dense_436_loss: 1.5763 - dense_427_accuracy: 0.4962 - dense_428_accuracy: 0.3220 - dense_429_accuracy: 0.2762 - dense_430_accuracy: 0.3354 - dense_431_accuracy: 0.2688 - dense_432_accuracy: 0.3168 - dense_433_accuracy: 0.3880 - dense_434_accuracy: 0.3314 - dense_435_accuracy: 0.4272 - dense_436_accuracy: 0.2680\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 14.8245 - dense_427_loss: 1.2637 - dense_428_loss: 1.5015 - dense_429_loss: 1.5824 - dense_430_loss: 1.4607 - dense_431_loss: 1.6486 - dense_432_loss: 1.5007 - dense_433_loss: 1.4312 - dense_434_loss: 1.4985 - dense_435_loss: 1.3639 - dense_436_loss: 1.5735 - dense_427_accuracy: 0.4986 - dense_428_accuracy: 0.3242 - dense_429_accuracy: 0.2760 - dense_430_accuracy: 0.3340 - dense_431_accuracy: 0.2754 - dense_432_accuracy: 0.3252 - dense_433_accuracy: 0.3910 - dense_434_accuracy: 0.3318 - dense_435_accuracy: 0.4266 - dense_436_accuracy: 0.2724\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 14.7666 - dense_427_loss: 1.2573 - dense_428_loss: 1.4957 - dense_429_loss: 1.5767 - dense_430_loss: 1.4553 - dense_431_loss: 1.6438 - dense_432_loss: 1.4924 - dense_433_loss: 1.4275 - dense_434_loss: 1.4924 - dense_435_loss: 1.3589 - dense_436_loss: 1.5666 - dense_427_accuracy: 0.5026 - dense_428_accuracy: 0.3288 - dense_429_accuracy: 0.2662 - dense_430_accuracy: 0.3282 - dense_431_accuracy: 0.2660 - dense_432_accuracy: 0.3166 - dense_433_accuracy: 0.3864 - dense_434_accuracy: 0.3248 - dense_435_accuracy: 0.4286 - dense_436_accuracy: 0.2746\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4F92168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4F92168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D2B44048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D2B44048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 3s 15ms/step - loss: 0.1300\n",
      "Epoch 2/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0061\n",
      "Epoch 3/25\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.0051\n",
      "Epoch 4/25\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.0049\n",
      "Epoch 5/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0048\n",
      "Epoch 6/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0046\n",
      "Epoch 7/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0041\n",
      "Epoch 8/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0036\n",
      "Epoch 9/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0034\n",
      "Epoch 10/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0033\n",
      "Epoch 11/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0032\n",
      "Epoch 12/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0032\n",
      "Epoch 13/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0031\n",
      "Epoch 14/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0031\n",
      "Epoch 15/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0030\n",
      "Epoch 16/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0030\n",
      "Epoch 17/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0029\n",
      "Epoch 18/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0029\n",
      "Epoch 19/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0028\n",
      "Epoch 20/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0028\n",
      "Epoch 21/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0028\n",
      "Epoch 22/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0027\n",
      "Epoch 23/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0027\n",
      "Epoch 24/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0027\n",
      "Epoch 25/25\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0027\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3011438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3011438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "157/157 [==============================] - 4s 7ms/step - loss: 16.4890 - dense_440_loss: 1.5047 - dense_441_loss: 1.8930 - dense_442_loss: 1.5142 - dense_443_loss: 1.6432 - dense_444_loss: 1.8825 - dense_445_loss: 1.8942 - dense_446_loss: 1.6577 - dense_447_loss: 1.5761 - dense_448_loss: 1.4781 - dense_449_loss: 1.4454 - dense_440_accuracy: 0.3810 - dense_441_accuracy: 0.2065 - dense_442_accuracy: 0.3854 - dense_443_accuracy: 0.2938 - dense_444_accuracy: 0.2095 - dense_445_accuracy: 0.2067 - dense_446_accuracy: 0.2707 - dense_447_accuracy: 0.2891 - dense_448_accuracy: 0.3688 - dense_449_accuracy: 0.3690\n",
      "Epoch 2/25\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 14.3435 - dense_440_loss: 1.3118 - dense_441_loss: 1.6241 - dense_442_loss: 1.3097 - dense_443_loss: 1.4556 - dense_444_loss: 1.6269 - dense_445_loss: 1.6357 - dense_446_loss: 1.4701 - dense_447_loss: 1.3659 - dense_448_loss: 1.2574 - dense_449_loss: 1.2862 - dense_440_accuracy: 0.4190 - dense_441_accuracy: 0.2372 - dense_442_accuracy: 0.4316 - dense_443_accuracy: 0.3211 - dense_444_accuracy: 0.2397 - dense_445_accuracy: 0.2362 - dense_446_accuracy: 0.3023 - dense_447_accuracy: 0.3186 - dense_448_accuracy: 0.3985 - dense_449_accuracy: 0.3936\n",
      "Epoch 3/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.2865 - dense_440_loss: 1.3059 - dense_441_loss: 1.6186 - dense_442_loss: 1.3019 - dense_443_loss: 1.4521 - dense_444_loss: 1.6207 - dense_445_loss: 1.6279 - dense_446_loss: 1.4646 - dense_447_loss: 1.3628 - dense_448_loss: 1.2518 - dense_449_loss: 1.2801 - dense_440_accuracy: 0.4178 - dense_441_accuracy: 0.2339 - dense_442_accuracy: 0.4276 - dense_443_accuracy: 0.3151 - dense_444_accuracy: 0.2365 - dense_445_accuracy: 0.2413 - dense_446_accuracy: 0.3054 - dense_447_accuracy: 0.3211 - dense_448_accuracy: 0.4071 - dense_449_accuracy: 0.3986\n",
      "Epoch 4/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.1995 - dense_440_loss: 1.2982 - dense_441_loss: 1.6077 - dense_442_loss: 1.2954 - dense_443_loss: 1.4423 - dense_444_loss: 1.6096 - dense_445_loss: 1.6189 - dense_446_loss: 1.4555 - dense_447_loss: 1.3540 - dense_448_loss: 1.2426 - dense_449_loss: 1.2753 - dense_440_accuracy: 0.4252 - dense_441_accuracy: 0.2466 - dense_442_accuracy: 0.4337 - dense_443_accuracy: 0.3240 - dense_444_accuracy: 0.2483 - dense_445_accuracy: 0.2409 - dense_446_accuracy: 0.3129 - dense_447_accuracy: 0.3187 - dense_448_accuracy: 0.4113 - dense_449_accuracy: 0.4017\n",
      "Epoch 5/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 14.1994 - dense_440_loss: 1.2986 - dense_441_loss: 1.6093 - dense_442_loss: 1.2942 - dense_443_loss: 1.4437 - dense_444_loss: 1.6092 - dense_445_loss: 1.6198 - dense_446_loss: 1.4553 - dense_447_loss: 1.3539 - dense_448_loss: 1.2424 - dense_449_loss: 1.2731 - dense_440_accuracy: 0.4243 - dense_441_accuracy: 0.2395 - dense_442_accuracy: 0.4348 - dense_443_accuracy: 0.3190 - dense_444_accuracy: 0.2468 - dense_445_accuracy: 0.2428 - dense_446_accuracy: 0.3079 - dense_447_accuracy: 0.3230 - dense_448_accuracy: 0.4064 - dense_449_accuracy: 0.3969\n",
      "Epoch 6/25\n",
      "157/157 [==============================] - 1s 10ms/step - loss: 14.1652 - dense_440_loss: 1.2971 - dense_441_loss: 1.6021 - dense_442_loss: 1.2925 - dense_443_loss: 1.4373 - dense_444_loss: 1.6066 - dense_445_loss: 1.6165 - dense_446_loss: 1.4544 - dense_447_loss: 1.3497 - dense_448_loss: 1.2402 - dense_449_loss: 1.2688 - dense_440_accuracy: 0.4259 - dense_441_accuracy: 0.2531 - dense_442_accuracy: 0.4343 - dense_443_accuracy: 0.3330 - dense_444_accuracy: 0.2553 - dense_445_accuracy: 0.2540 - dense_446_accuracy: 0.3154 - dense_447_accuracy: 0.3332 - dense_448_accuracy: 0.4190 - dense_449_accuracy: 0.4127\n",
      "Epoch 7/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.1186 - dense_440_loss: 1.2933 - dense_441_loss: 1.5971 - dense_442_loss: 1.2907 - dense_443_loss: 1.4360 - dense_444_loss: 1.6007 - dense_445_loss: 1.6088 - dense_446_loss: 1.4456 - dense_447_loss: 1.3468 - dense_448_loss: 1.2332 - dense_449_loss: 1.2665 - dense_440_accuracy: 0.4247 - dense_441_accuracy: 0.2561 - dense_442_accuracy: 0.4357 - dense_443_accuracy: 0.3275 - dense_444_accuracy: 0.2600 - dense_445_accuracy: 0.2612 - dense_446_accuracy: 0.3145 - dense_447_accuracy: 0.3355 - dense_448_accuracy: 0.4231 - dense_449_accuracy: 0.4103\n",
      "Epoch 8/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.1246 - dense_440_loss: 1.2929 - dense_441_loss: 1.5983 - dense_442_loss: 1.2901 - dense_443_loss: 1.4324 - dense_444_loss: 1.6013 - dense_445_loss: 1.6089 - dense_446_loss: 1.4499 - dense_447_loss: 1.3490 - dense_448_loss: 1.2347 - dense_449_loss: 1.2670 - dense_440_accuracy: 0.4289 - dense_441_accuracy: 0.2604 - dense_442_accuracy: 0.4322 - dense_443_accuracy: 0.3341 - dense_444_accuracy: 0.2653 - dense_445_accuracy: 0.2611 - dense_446_accuracy: 0.3177 - dense_447_accuracy: 0.3243 - dense_448_accuracy: 0.4261 - dense_449_accuracy: 0.4158\n",
      "Epoch 9/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.0738 - dense_440_loss: 1.2896 - dense_441_loss: 1.5892 - dense_442_loss: 1.2879 - dense_443_loss: 1.4310 - dense_444_loss: 1.5916 - dense_445_loss: 1.6015 - dense_446_loss: 1.4451 - dense_447_loss: 1.3437 - dense_448_loss: 1.2301 - dense_449_loss: 1.2642 - dense_440_accuracy: 0.4317 - dense_441_accuracy: 0.2619 - dense_442_accuracy: 0.4381 - dense_443_accuracy: 0.3368 - dense_444_accuracy: 0.2661 - dense_445_accuracy: 0.2669 - dense_446_accuracy: 0.3234 - dense_447_accuracy: 0.3336 - dense_448_accuracy: 0.4229 - dense_449_accuracy: 0.4113\n",
      "Epoch 10/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 13.9885 - dense_440_loss: 1.2815 - dense_441_loss: 1.5791 - dense_442_loss: 1.2784 - dense_443_loss: 1.4224 - dense_444_loss: 1.5834 - dense_445_loss: 1.5933 - dense_446_loss: 1.4355 - dense_447_loss: 1.3353 - dense_448_loss: 1.2253 - dense_449_loss: 1.2542 - dense_440_accuracy: 0.4315 - dense_441_accuracy: 0.2763 - dense_442_accuracy: 0.4399 - dense_443_accuracy: 0.3437 - dense_444_accuracy: 0.2863 - dense_445_accuracy: 0.2833 - dense_446_accuracy: 0.3300 - dense_447_accuracy: 0.3528 - dense_448_accuracy: 0.4349 - dense_449_accuracy: 0.4283\n",
      "Epoch 11/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 13.9391 - dense_440_loss: 1.2797 - dense_441_loss: 1.5730 - dense_442_loss: 1.2754 - dense_443_loss: 1.4190 - dense_444_loss: 1.5770 - dense_445_loss: 1.5874 - dense_446_loss: 1.4297 - dense_447_loss: 1.3299 - dense_448_loss: 1.2147 - dense_449_loss: 1.2533 - dense_440_accuracy: 0.4410 - dense_441_accuracy: 0.2829 - dense_442_accuracy: 0.4423 - dense_443_accuracy: 0.3467 - dense_444_accuracy: 0.2822 - dense_445_accuracy: 0.2804 - dense_446_accuracy: 0.3328 - dense_447_accuracy: 0.3489 - dense_448_accuracy: 0.4398 - dense_449_accuracy: 0.4216\n",
      "Epoch 12/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 13.9138 - dense_440_loss: 1.2763 - dense_441_loss: 1.5702 - dense_442_loss: 1.2699 - dense_443_loss: 1.4157 - dense_444_loss: 1.5710 - dense_445_loss: 1.5846 - dense_446_loss: 1.4317 - dense_447_loss: 1.3295 - dense_448_loss: 1.2170 - dense_449_loss: 1.2479 - dense_440_accuracy: 0.4363 - dense_441_accuracy: 0.2799 - dense_442_accuracy: 0.4505 - dense_443_accuracy: 0.3460 - dense_444_accuracy: 0.2852 - dense_445_accuracy: 0.2818 - dense_446_accuracy: 0.3387 - dense_447_accuracy: 0.3527 - dense_448_accuracy: 0.4363 - dense_449_accuracy: 0.4286\n",
      "Epoch 13/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 13.7531 - dense_440_loss: 1.2658 - dense_441_loss: 1.5519 - dense_442_loss: 1.2584 - dense_443_loss: 1.3988 - dense_444_loss: 1.5536 - dense_445_loss: 1.5654 - dense_446_loss: 1.4132 - dense_447_loss: 1.3123 - dense_448_loss: 1.1986 - dense_449_loss: 1.2351 - dense_440_accuracy: 0.4440 - dense_441_accuracy: 0.2941 - dense_442_accuracy: 0.4564 - dense_443_accuracy: 0.3616 - dense_444_accuracy: 0.2990 - dense_445_accuracy: 0.2939 - dense_446_accuracy: 0.3468 - dense_447_accuracy: 0.3659 - dense_448_accuracy: 0.4469 - dense_449_accuracy: 0.4298\n",
      "Epoch 14/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 13.7395 - dense_440_loss: 1.2645 - dense_441_loss: 1.5494 - dense_442_loss: 1.2582 - dense_443_loss: 1.3983 - dense_444_loss: 1.5531 - dense_445_loss: 1.5609 - dense_446_loss: 1.4089 - dense_447_loss: 1.3102 - dense_448_loss: 1.2001 - dense_449_loss: 1.2359 - dense_440_accuracy: 0.4498 - dense_441_accuracy: 0.2982 - dense_442_accuracy: 0.4585 - dense_443_accuracy: 0.3637 - dense_444_accuracy: 0.2974 - dense_445_accuracy: 0.2997 - dense_446_accuracy: 0.3561 - dense_447_accuracy: 0.3645 - dense_448_accuracy: 0.4465 - dense_449_accuracy: 0.4311\n",
      "Epoch 15/25\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 13.6798 - dense_440_loss: 1.2593 - dense_441_loss: 1.5439 - dense_442_loss: 1.2523 - dense_443_loss: 1.3899 - dense_444_loss: 1.5461 - dense_445_loss: 1.5557 - dense_446_loss: 1.4033 - dense_447_loss: 1.3062 - dense_448_loss: 1.1927 - dense_449_loss: 1.2303 - dense_440_accuracy: 0.4469 - dense_441_accuracy: 0.2993 - dense_442_accuracy: 0.4564 - dense_443_accuracy: 0.3614 - dense_444_accuracy: 0.3012 - dense_445_accuracy: 0.2973 - dense_446_accuracy: 0.3523 - dense_447_accuracy: 0.3726 - dense_448_accuracy: 0.4525 - dense_449_accuracy: 0.4313\n",
      "Epoch 16/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.5980 - dense_440_loss: 1.2520 - dense_441_loss: 1.5323 - dense_442_loss: 1.2437 - dense_443_loss: 1.3810 - dense_444_loss: 1.5364 - dense_445_loss: 1.5475 - dense_446_loss: 1.3970 - dense_447_loss: 1.2965 - dense_448_loss: 1.1869 - dense_449_loss: 1.2245 - dense_440_accuracy: 0.4534 - dense_441_accuracy: 0.3056 - dense_442_accuracy: 0.4629 - dense_443_accuracy: 0.3674 - dense_444_accuracy: 0.3068 - dense_445_accuracy: 0.3028 - dense_446_accuracy: 0.3561 - dense_447_accuracy: 0.3765 - dense_448_accuracy: 0.4575 - dense_449_accuracy: 0.4410\n",
      "Epoch 17/25\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 13.5427 - dense_440_loss: 1.2473 - dense_441_loss: 1.5258 - dense_442_loss: 1.2371 - dense_443_loss: 1.3763 - dense_444_loss: 1.5307 - dense_445_loss: 1.5393 - dense_446_loss: 1.3908 - dense_447_loss: 1.2911 - dense_448_loss: 1.1839 - dense_449_loss: 1.2204 - dense_440_accuracy: 0.4547 - dense_441_accuracy: 0.3113 - dense_442_accuracy: 0.4702 - dense_443_accuracy: 0.3730 - dense_444_accuracy: 0.3108 - dense_445_accuracy: 0.3054 - dense_446_accuracy: 0.3568 - dense_447_accuracy: 0.3830 - dense_448_accuracy: 0.4574 - dense_449_accuracy: 0.4437\n",
      "Epoch 18/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 13.5207 - dense_440_loss: 1.2452 - dense_441_loss: 1.5231 - dense_442_loss: 1.2385 - dense_443_loss: 1.3754 - dense_444_loss: 1.5253 - dense_445_loss: 1.5360 - dense_446_loss: 1.3897 - dense_447_loss: 1.2901 - dense_448_loss: 1.1787 - dense_449_loss: 1.2187 - dense_440_accuracy: 0.4526 - dense_441_accuracy: 0.3093 - dense_442_accuracy: 0.4675 - dense_443_accuracy: 0.3749 - dense_444_accuracy: 0.3090 - dense_445_accuracy: 0.3068 - dense_446_accuracy: 0.3591 - dense_447_accuracy: 0.3776 - dense_448_accuracy: 0.4617 - dense_449_accuracy: 0.4446\n",
      "Epoch 19/25\n",
      "157/157 [==============================] - 1s 10ms/step - loss: 13.5382 - dense_440_loss: 1.2439 - dense_441_loss: 1.5264 - dense_442_loss: 1.2412 - dense_443_loss: 1.3766 - dense_444_loss: 1.5277 - dense_445_loss: 1.5377 - dense_446_loss: 1.3915 - dense_447_loss: 1.2907 - dense_448_loss: 1.1823 - dense_449_loss: 1.2204 - dense_440_accuracy: 0.4559 - dense_441_accuracy: 0.3079 - dense_442_accuracy: 0.4605 - dense_443_accuracy: 0.3705 - dense_444_accuracy: 0.3058 - dense_445_accuracy: 0.3079 - dense_446_accuracy: 0.3582 - dense_447_accuracy: 0.3796 - dense_448_accuracy: 0.4612 - dense_449_accuracy: 0.4444\n",
      "Epoch 20/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 13.4445 - dense_440_loss: 1.2381 - dense_441_loss: 1.5143 - dense_442_loss: 1.2310 - dense_443_loss: 1.3657 - dense_444_loss: 1.5184 - dense_445_loss: 1.5276 - dense_446_loss: 1.3829 - dense_447_loss: 1.2825 - dense_448_loss: 1.1732 - dense_449_loss: 1.2107 - dense_440_accuracy: 0.4553 - dense_441_accuracy: 0.3196 - dense_442_accuracy: 0.4655 - dense_443_accuracy: 0.3779 - dense_444_accuracy: 0.3182 - dense_445_accuracy: 0.3171 - dense_446_accuracy: 0.3636 - dense_447_accuracy: 0.3880 - dense_448_accuracy: 0.4672 - dense_449_accuracy: 0.4487\n",
      "Epoch 21/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.4455 - dense_440_loss: 1.2383 - dense_441_loss: 1.5134 - dense_442_loss: 1.2315 - dense_443_loss: 1.3658 - dense_444_loss: 1.5190 - dense_445_loss: 1.5283 - dense_446_loss: 1.3808 - dense_447_loss: 1.2839 - dense_448_loss: 1.1726 - dense_449_loss: 1.2119 - dense_440_accuracy: 0.4566 - dense_441_accuracy: 0.3163 - dense_442_accuracy: 0.4624 - dense_443_accuracy: 0.3825 - dense_444_accuracy: 0.3174 - dense_445_accuracy: 0.3139 - dense_446_accuracy: 0.3649 - dense_447_accuracy: 0.3886 - dense_448_accuracy: 0.4687 - dense_449_accuracy: 0.4505\n",
      "Epoch 22/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.4036 - dense_440_loss: 1.2343 - dense_441_loss: 1.5119 - dense_442_loss: 1.2294 - dense_443_loss: 1.3632 - dense_444_loss: 1.5113 - dense_445_loss: 1.5211 - dense_446_loss: 1.3753 - dense_447_loss: 1.2769 - dense_448_loss: 1.1703 - dense_449_loss: 1.2099 - dense_440_accuracy: 0.4624 - dense_441_accuracy: 0.3162 - dense_442_accuracy: 0.4702 - dense_443_accuracy: 0.3775 - dense_444_accuracy: 0.3145 - dense_445_accuracy: 0.3168 - dense_446_accuracy: 0.3688 - dense_447_accuracy: 0.3865 - dense_448_accuracy: 0.4696 - dense_449_accuracy: 0.4515\n",
      "Epoch 23/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.4646 - dense_440_loss: 1.2438 - dense_441_loss: 1.5158 - dense_442_loss: 1.2354 - dense_443_loss: 1.3703 - dense_444_loss: 1.5192 - dense_445_loss: 1.5285 - dense_446_loss: 1.3805 - dense_447_loss: 1.2817 - dense_448_loss: 1.1755 - dense_449_loss: 1.2139 - dense_440_accuracy: 0.4552 - dense_441_accuracy: 0.3119 - dense_442_accuracy: 0.4640 - dense_443_accuracy: 0.3756 - dense_444_accuracy: 0.3186 - dense_445_accuracy: 0.3141 - dense_446_accuracy: 0.3663 - dense_447_accuracy: 0.3868 - dense_448_accuracy: 0.4631 - dense_449_accuracy: 0.4460\n",
      "Epoch 24/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.4084 - dense_440_loss: 1.2356 - dense_441_loss: 1.5088 - dense_442_loss: 1.2301 - dense_443_loss: 1.3634 - dense_444_loss: 1.5145 - dense_445_loss: 1.5235 - dense_446_loss: 1.3762 - dense_447_loss: 1.2815 - dense_448_loss: 1.1707 - dense_449_loss: 1.2040 - dense_440_accuracy: 0.4608 - dense_441_accuracy: 0.3253 - dense_442_accuracy: 0.4714 - dense_443_accuracy: 0.3831 - dense_444_accuracy: 0.3245 - dense_445_accuracy: 0.3202 - dense_446_accuracy: 0.3677 - dense_447_accuracy: 0.3816 - dense_448_accuracy: 0.4721 - dense_449_accuracy: 0.4505\n",
      "Epoch 25/25\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 13.3084 - dense_440_loss: 1.2265 - dense_441_loss: 1.4988 - dense_442_loss: 1.2182 - dense_443_loss: 1.3535 - dense_444_loss: 1.5046 - dense_445_loss: 1.5109 - dense_446_loss: 1.3673 - dense_447_loss: 1.2681 - dense_448_loss: 1.1619 - dense_449_loss: 1.1986 - dense_440_accuracy: 0.4627 - dense_441_accuracy: 0.3290 - dense_442_accuracy: 0.4778 - dense_443_accuracy: 0.3854 - dense_444_accuracy: 0.3235 - dense_445_accuracy: 0.3244 - dense_446_accuracy: 0.3792 - dense_447_accuracy: 0.3950 - dense_448_accuracy: 0.4754 - dense_449_accuracy: 0.4565\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D2BCD288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D2BCD288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D2CF8F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D2CF8F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "157/157 [==============================] - 6s 10ms/step - loss: 16.2734 - dense_450_loss: 1.4969 - dense_451_loss: 1.8752 - dense_452_loss: 1.4828 - dense_453_loss: 1.6092 - dense_454_loss: 1.8679 - dense_455_loss: 1.8627 - dense_456_loss: 1.6510 - dense_457_loss: 1.5388 - dense_458_loss: 1.4477 - dense_459_loss: 1.4412 - dense_450_accuracy: 0.3776 - dense_451_accuracy: 0.2156 - dense_452_accuracy: 0.3915 - dense_453_accuracy: 0.2930 - dense_454_accuracy: 0.2147 - dense_455_accuracy: 0.2131 - dense_456_accuracy: 0.2775 - dense_457_accuracy: 0.2966 - dense_458_accuracy: 0.3790 - dense_459_accuracy: 0.3745\n",
      "Epoch 2/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 14.4065 - dense_450_loss: 1.3176 - dense_451_loss: 1.6347 - dense_452_loss: 1.3113 - dense_453_loss: 1.4589 - dense_454_loss: 1.6382 - dense_455_loss: 1.6442 - dense_456_loss: 1.4748 - dense_457_loss: 1.3719 - dense_458_loss: 1.2658 - dense_459_loss: 1.2891 - dense_450_accuracy: 0.4241 - dense_451_accuracy: 0.2396 - dense_452_accuracy: 0.4351 - dense_453_accuracy: 0.3166 - dense_454_accuracy: 0.2372 - dense_455_accuracy: 0.2349 - dense_456_accuracy: 0.3076 - dense_457_accuracy: 0.3218 - dense_458_accuracy: 0.4040 - dense_459_accuracy: 0.4008\n",
      "Epoch 3/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.2856 - dense_450_loss: 1.3052 - dense_451_loss: 1.6199 - dense_452_loss: 1.3022 - dense_453_loss: 1.4502 - dense_454_loss: 1.6213 - dense_455_loss: 1.6295 - dense_456_loss: 1.4636 - dense_457_loss: 1.3627 - dense_458_loss: 1.2512 - dense_459_loss: 1.2798 - dense_450_accuracy: 0.4227 - dense_451_accuracy: 0.2381 - dense_452_accuracy: 0.4383 - dense_453_accuracy: 0.3198 - dense_454_accuracy: 0.2353 - dense_455_accuracy: 0.2389 - dense_456_accuracy: 0.3077 - dense_457_accuracy: 0.3165 - dense_458_accuracy: 0.4065 - dense_459_accuracy: 0.3953\n",
      "Epoch 4/25\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 14.2146 - dense_450_loss: 1.3007 - dense_451_loss: 1.6105 - dense_452_loss: 1.2950 - dense_453_loss: 1.4437 - dense_454_loss: 1.6121 - dense_455_loss: 1.6216 - dense_456_loss: 1.4554 - dense_457_loss: 1.3554 - dense_458_loss: 1.2444 - dense_459_loss: 1.2756 - dense_450_accuracy: 0.4243 - dense_451_accuracy: 0.2406 - dense_452_accuracy: 0.4349 - dense_453_accuracy: 0.3167 - dense_454_accuracy: 0.2459 - dense_455_accuracy: 0.2442 - dense_456_accuracy: 0.3122 - dense_457_accuracy: 0.3188 - dense_458_accuracy: 0.4078 - dense_459_accuracy: 0.4003\n",
      "Epoch 5/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.1881 - dense_450_loss: 1.2979 - dense_451_loss: 1.6062 - dense_452_loss: 1.2918 - dense_453_loss: 1.4428 - dense_454_loss: 1.6102 - dense_455_loss: 1.6189 - dense_456_loss: 1.4529 - dense_457_loss: 1.3520 - dense_458_loss: 1.2405 - dense_459_loss: 1.2748 - dense_450_accuracy: 0.4247 - dense_451_accuracy: 0.2383 - dense_452_accuracy: 0.4348 - dense_453_accuracy: 0.3152 - dense_454_accuracy: 0.2448 - dense_455_accuracy: 0.2377 - dense_456_accuracy: 0.3068 - dense_457_accuracy: 0.3203 - dense_458_accuracy: 0.4109 - dense_459_accuracy: 0.4019\n",
      "Epoch 6/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.1987 - dense_450_loss: 1.2970 - dense_451_loss: 1.6088 - dense_452_loss: 1.2932 - dense_453_loss: 1.4418 - dense_454_loss: 1.6113 - dense_455_loss: 1.6186 - dense_456_loss: 1.4523 - dense_457_loss: 1.3535 - dense_458_loss: 1.2458 - dense_459_loss: 1.2766 - dense_450_accuracy: 0.4275 - dense_451_accuracy: 0.2418 - dense_452_accuracy: 0.4307 - dense_453_accuracy: 0.3182 - dense_454_accuracy: 0.2410 - dense_455_accuracy: 0.2409 - dense_456_accuracy: 0.3154 - dense_457_accuracy: 0.3165 - dense_458_accuracy: 0.3965 - dense_459_accuracy: 0.3975\n",
      "Epoch 7/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.1773 - dense_450_loss: 1.2962 - dense_451_loss: 1.6059 - dense_452_loss: 1.2920 - dense_453_loss: 1.4400 - dense_454_loss: 1.6083 - dense_455_loss: 1.6175 - dense_456_loss: 1.4505 - dense_457_loss: 1.3523 - dense_458_loss: 1.2404 - dense_459_loss: 1.2743 - dense_450_accuracy: 0.4252 - dense_451_accuracy: 0.2381 - dense_452_accuracy: 0.4322 - dense_453_accuracy: 0.3199 - dense_454_accuracy: 0.2382 - dense_455_accuracy: 0.2421 - dense_456_accuracy: 0.3096 - dense_457_accuracy: 0.3175 - dense_458_accuracy: 0.4070 - dense_459_accuracy: 0.3948\n",
      "Epoch 8/25\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 14.1812 - dense_450_loss: 1.2964 - dense_451_loss: 1.6071 - dense_452_loss: 1.2912 - dense_453_loss: 1.4405 - dense_454_loss: 1.6096 - dense_455_loss: 1.6179 - dense_456_loss: 1.4505 - dense_457_loss: 1.3531 - dense_458_loss: 1.2411 - dense_459_loss: 1.2738 - dense_450_accuracy: 0.4220 - dense_451_accuracy: 0.2374 - dense_452_accuracy: 0.4337 - dense_453_accuracy: 0.3155 - dense_454_accuracy: 0.2372 - dense_455_accuracy: 0.2326 - dense_456_accuracy: 0.3052 - dense_457_accuracy: 0.3166 - dense_458_accuracy: 0.4044 - dense_459_accuracy: 0.3994\n",
      "Epoch 9/25\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 14.1375 - dense_450_loss: 1.2927 - dense_451_loss: 1.6014 - dense_452_loss: 1.2882 - dense_453_loss: 1.4364 - dense_454_loss: 1.6039 - dense_455_loss: 1.6134 - dense_456_loss: 1.4460 - dense_457_loss: 1.3484 - dense_458_loss: 1.2357 - dense_459_loss: 1.2713 - dense_450_accuracy: 0.4221 - dense_451_accuracy: 0.2452 - dense_452_accuracy: 0.4321 - dense_453_accuracy: 0.3248 - dense_454_accuracy: 0.2432 - dense_455_accuracy: 0.2454 - dense_456_accuracy: 0.3146 - dense_457_accuracy: 0.3211 - dense_458_accuracy: 0.4153 - dense_459_accuracy: 0.4015\n",
      "Epoch 10/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.1310 - dense_450_loss: 1.2910 - dense_451_loss: 1.6012 - dense_452_loss: 1.2864 - dense_453_loss: 1.4361 - dense_454_loss: 1.6034 - dense_455_loss: 1.6121 - dense_456_loss: 1.4458 - dense_457_loss: 1.3482 - dense_458_loss: 1.2365 - dense_459_loss: 1.2705 - dense_450_accuracy: 0.4263 - dense_451_accuracy: 0.2483 - dense_452_accuracy: 0.4378 - dense_453_accuracy: 0.3257 - dense_454_accuracy: 0.2471 - dense_455_accuracy: 0.2396 - dense_456_accuracy: 0.3078 - dense_457_accuracy: 0.3238 - dense_458_accuracy: 0.4074 - dense_459_accuracy: 0.3993\n",
      "Epoch 11/25\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 14.1186 - dense_450_loss: 1.2901 - dense_451_loss: 1.5999 - dense_452_loss: 1.2850 - dense_453_loss: 1.4339 - dense_454_loss: 1.6017 - dense_455_loss: 1.6103 - dense_456_loss: 1.4454 - dense_457_loss: 1.3471 - dense_458_loss: 1.2354 - dense_459_loss: 1.2698 - dense_450_accuracy: 0.4276 - dense_451_accuracy: 0.2385 - dense_452_accuracy: 0.4358 - dense_453_accuracy: 0.3247 - dense_454_accuracy: 0.2458 - dense_455_accuracy: 0.2412 - dense_456_accuracy: 0.3073 - dense_457_accuracy: 0.3200 - dense_458_accuracy: 0.4075 - dense_459_accuracy: 0.4009\n",
      "Epoch 12/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.1112 - dense_450_loss: 1.2900 - dense_451_loss: 1.6001 - dense_452_loss: 1.2848 - dense_453_loss: 1.4336 - dense_454_loss: 1.6014 - dense_455_loss: 1.6100 - dense_456_loss: 1.4436 - dense_457_loss: 1.3447 - dense_458_loss: 1.2342 - dense_459_loss: 1.2688 - dense_450_accuracy: 0.4236 - dense_451_accuracy: 0.2431 - dense_452_accuracy: 0.4323 - dense_453_accuracy: 0.3251 - dense_454_accuracy: 0.2480 - dense_455_accuracy: 0.2469 - dense_456_accuracy: 0.3133 - dense_457_accuracy: 0.3252 - dense_458_accuracy: 0.4146 - dense_459_accuracy: 0.4052\n",
      "Epoch 13/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 14.1139 - dense_450_loss: 1.2929 - dense_451_loss: 1.5989 - dense_452_loss: 1.2863 - dense_453_loss: 1.4346 - dense_454_loss: 1.6002 - dense_455_loss: 1.6103 - dense_456_loss: 1.4434 - dense_457_loss: 1.3456 - dense_458_loss: 1.2335 - dense_459_loss: 1.2681 - dense_450_accuracy: 0.4229 - dense_451_accuracy: 0.2523 - dense_452_accuracy: 0.4371 - dense_453_accuracy: 0.3249 - dense_454_accuracy: 0.2530 - dense_455_accuracy: 0.2529 - dense_456_accuracy: 0.3177 - dense_457_accuracy: 0.3273 - dense_458_accuracy: 0.4194 - dense_459_accuracy: 0.4092\n",
      "Epoch 14/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.0887 - dense_450_loss: 1.2871 - dense_451_loss: 1.5974 - dense_452_loss: 1.2830 - dense_453_loss: 1.4315 - dense_454_loss: 1.5978 - dense_455_loss: 1.6074 - dense_456_loss: 1.4414 - dense_457_loss: 1.3443 - dense_458_loss: 1.2328 - dense_459_loss: 1.2660 - dense_450_accuracy: 0.4248 - dense_451_accuracy: 0.2442 - dense_452_accuracy: 0.4356 - dense_453_accuracy: 0.3229 - dense_454_accuracy: 0.2520 - dense_455_accuracy: 0.2532 - dense_456_accuracy: 0.3113 - dense_457_accuracy: 0.3268 - dense_458_accuracy: 0.4199 - dense_459_accuracy: 0.4087\n",
      "Epoch 15/25\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 14.0749 - dense_450_loss: 1.2881 - dense_451_loss: 1.5948 - dense_452_loss: 1.2812 - dense_453_loss: 1.4306 - dense_454_loss: 1.5957 - dense_455_loss: 1.6047 - dense_456_loss: 1.4416 - dense_457_loss: 1.3423 - dense_458_loss: 1.2303 - dense_459_loss: 1.2656 - dense_450_accuracy: 0.4264 - dense_451_accuracy: 0.2536 - dense_452_accuracy: 0.4381 - dense_453_accuracy: 0.3261 - dense_454_accuracy: 0.2587 - dense_455_accuracy: 0.2558 - dense_456_accuracy: 0.3212 - dense_457_accuracy: 0.3284 - dense_458_accuracy: 0.4195 - dense_459_accuracy: 0.4092\n",
      "Epoch 16/25\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 14.0816 - dense_450_loss: 1.2875 - dense_451_loss: 1.5960 - dense_452_loss: 1.2840 - dense_453_loss: 1.4297 - dense_454_loss: 1.5986 - dense_455_loss: 1.6062 - dense_456_loss: 1.4402 - dense_457_loss: 1.3450 - dense_458_loss: 1.2301 - dense_459_loss: 1.2643 - dense_450_accuracy: 0.4277 - dense_451_accuracy: 0.2518 - dense_452_accuracy: 0.4360 - dense_453_accuracy: 0.3303 - dense_454_accuracy: 0.2554 - dense_455_accuracy: 0.2606 - dense_456_accuracy: 0.3172 - dense_457_accuracy: 0.3291 - dense_458_accuracy: 0.4186 - dense_459_accuracy: 0.4152\n",
      "Epoch 17/25\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 14.0046 - dense_450_loss: 1.2841 - dense_451_loss: 1.5877 - dense_452_loss: 1.2751 - dense_453_loss: 1.4224 - dense_454_loss: 1.5884 - dense_455_loss: 1.5958 - dense_456_loss: 1.4329 - dense_457_loss: 1.3375 - dense_458_loss: 1.2225 - dense_459_loss: 1.2581 - dense_450_accuracy: 0.4241 - dense_451_accuracy: 0.2621 - dense_452_accuracy: 0.4370 - dense_453_accuracy: 0.3426 - dense_454_accuracy: 0.2694 - dense_455_accuracy: 0.2667 - dense_456_accuracy: 0.3198 - dense_457_accuracy: 0.3426 - dense_458_accuracy: 0.4295 - dense_459_accuracy: 0.4181\n",
      "Epoch 18/25\n",
      "157/157 [==============================] - 1s 10ms/step - loss: 13.9993 - dense_450_loss: 1.2828 - dense_451_loss: 1.5870 - dense_452_loss: 1.2767 - dense_453_loss: 1.4207 - dense_454_loss: 1.5873 - dense_455_loss: 1.5966 - dense_456_loss: 1.4345 - dense_457_loss: 1.3358 - dense_458_loss: 1.2220 - dense_459_loss: 1.2560 - dense_450_accuracy: 0.4286 - dense_451_accuracy: 0.2671 - dense_452_accuracy: 0.4404 - dense_453_accuracy: 0.3452 - dense_454_accuracy: 0.2726 - dense_455_accuracy: 0.2664 - dense_456_accuracy: 0.3235 - dense_457_accuracy: 0.3384 - dense_458_accuracy: 0.4309 - dense_459_accuracy: 0.4227\n",
      "Epoch 19/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 13.9649 - dense_450_loss: 1.2824 - dense_451_loss: 1.5820 - dense_452_loss: 1.2736 - dense_453_loss: 1.4177 - dense_454_loss: 1.5821 - dense_455_loss: 1.5920 - dense_456_loss: 1.4301 - dense_457_loss: 1.3351 - dense_458_loss: 1.2181 - dense_459_loss: 1.2518 - dense_450_accuracy: 0.4302 - dense_451_accuracy: 0.2719 - dense_452_accuracy: 0.4395 - dense_453_accuracy: 0.3415 - dense_454_accuracy: 0.2700 - dense_455_accuracy: 0.2694 - dense_456_accuracy: 0.3237 - dense_457_accuracy: 0.3332 - dense_458_accuracy: 0.4338 - dense_459_accuracy: 0.4222\n",
      "Epoch 20/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.9616 - dense_450_loss: 1.2808 - dense_451_loss: 1.5821 - dense_452_loss: 1.2735 - dense_453_loss: 1.4176 - dense_454_loss: 1.5817 - dense_455_loss: 1.5913 - dense_456_loss: 1.4294 - dense_457_loss: 1.3347 - dense_458_loss: 1.2178 - dense_459_loss: 1.2527 - dense_450_accuracy: 0.4340 - dense_451_accuracy: 0.2769 - dense_452_accuracy: 0.4397 - dense_453_accuracy: 0.3442 - dense_454_accuracy: 0.2799 - dense_455_accuracy: 0.2765 - dense_456_accuracy: 0.3316 - dense_457_accuracy: 0.3485 - dense_458_accuracy: 0.4408 - dense_459_accuracy: 0.4253\n",
      "Epoch 21/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.8979 - dense_450_loss: 1.2760 - dense_451_loss: 1.5748 - dense_452_loss: 1.2671 - dense_453_loss: 1.4104 - dense_454_loss: 1.5757 - dense_455_loss: 1.5840 - dense_456_loss: 1.4227 - dense_457_loss: 1.3272 - dense_458_loss: 1.2118 - dense_459_loss: 1.2482 - dense_450_accuracy: 0.4312 - dense_451_accuracy: 0.2803 - dense_452_accuracy: 0.4443 - dense_453_accuracy: 0.3515 - dense_454_accuracy: 0.2792 - dense_455_accuracy: 0.2751 - dense_456_accuracy: 0.3349 - dense_457_accuracy: 0.3563 - dense_458_accuracy: 0.4382 - dense_459_accuracy: 0.4280\n",
      "Epoch 22/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.8967 - dense_450_loss: 1.2725 - dense_451_loss: 1.5747 - dense_452_loss: 1.2676 - dense_453_loss: 1.4121 - dense_454_loss: 1.5739 - dense_455_loss: 1.5844 - dense_456_loss: 1.4251 - dense_457_loss: 1.3271 - dense_458_loss: 1.2123 - dense_459_loss: 1.2471 - dense_450_accuracy: 0.4367 - dense_451_accuracy: 0.2804 - dense_452_accuracy: 0.4470 - dense_453_accuracy: 0.3533 - dense_454_accuracy: 0.2785 - dense_455_accuracy: 0.2768 - dense_456_accuracy: 0.3276 - dense_457_accuracy: 0.3542 - dense_458_accuracy: 0.4375 - dense_459_accuracy: 0.4267\n",
      "Epoch 23/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.8387 - dense_450_loss: 1.2691 - dense_451_loss: 1.5682 - dense_452_loss: 1.2620 - dense_453_loss: 1.4064 - dense_454_loss: 1.5671 - dense_455_loss: 1.5760 - dense_456_loss: 1.4178 - dense_457_loss: 1.3225 - dense_458_loss: 1.2071 - dense_459_loss: 1.2426 - dense_450_accuracy: 0.4365 - dense_451_accuracy: 0.2874 - dense_452_accuracy: 0.4493 - dense_453_accuracy: 0.3599 - dense_454_accuracy: 0.2949 - dense_455_accuracy: 0.2872 - dense_456_accuracy: 0.3465 - dense_457_accuracy: 0.3569 - dense_458_accuracy: 0.4507 - dense_459_accuracy: 0.4304\n",
      "Epoch 24/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 13.8203 - dense_450_loss: 1.2679 - dense_451_loss: 1.5667 - dense_452_loss: 1.2598 - dense_453_loss: 1.4035 - dense_454_loss: 1.5641 - dense_455_loss: 1.5753 - dense_456_loss: 1.4162 - dense_457_loss: 1.3207 - dense_458_loss: 1.2050 - dense_459_loss: 1.2410 - dense_450_accuracy: 0.4380 - dense_451_accuracy: 0.2855 - dense_452_accuracy: 0.4484 - dense_453_accuracy: 0.3608 - dense_454_accuracy: 0.2882 - dense_455_accuracy: 0.2886 - dense_456_accuracy: 0.3388 - dense_457_accuracy: 0.3564 - dense_458_accuracy: 0.4485 - dense_459_accuracy: 0.4331\n",
      "Epoch 25/25\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 13.7799 - dense_450_loss: 1.2652 - dense_451_loss: 1.5607 - dense_452_loss: 1.2576 - dense_453_loss: 1.4004 - dense_454_loss: 1.5602 - dense_455_loss: 1.5696 - dense_456_loss: 1.4117 - dense_457_loss: 1.3166 - dense_458_loss: 1.2009 - dense_459_loss: 1.2369 - dense_450_accuracy: 0.4406 - dense_451_accuracy: 0.2979 - dense_452_accuracy: 0.4520 - dense_453_accuracy: 0.3692 - dense_454_accuracy: 0.2985 - dense_455_accuracy: 0.3002 - dense_456_accuracy: 0.3409 - dense_457_accuracy: 0.3708 - dense_458_accuracy: 0.4546 - dense_459_accuracy: 0.4406\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D0F043A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D0F043A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D2CB9558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D2CB9558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 21ms/step - loss: 0.2204\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.0472\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.0078\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.0064\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 0.0060\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.0059\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 0.0058\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.0058\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 0.0057\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 0.0057\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 0.0057\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 0.0057\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0057\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.0056\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.0056\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.0055\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.0054\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.0053\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.0051\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.0051\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 0.0050\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 0.0050\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.0049\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.0049\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.0048\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D2CB95E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D2CB95E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 3s 7ms/step - loss: 20.7020 - dense_463_loss: 1.9957 - dense_464_loss: 2.0032 - dense_465_loss: 2.1028 - dense_466_loss: 1.9669 - dense_467_loss: 2.3959 - dense_468_loss: 2.0863 - dense_469_loss: 2.1448 - dense_470_loss: 2.0112 - dense_471_loss: 1.8546 - dense_472_loss: 2.1406 - dense_463_accuracy: 0.3020 - dense_464_accuracy: 0.2524 - dense_465_accuracy: 0.2342 - dense_466_accuracy: 0.2500 - dense_467_accuracy: 0.1628 - dense_468_accuracy: 0.2120 - dense_469_accuracy: 0.2146 - dense_470_accuracy: 0.2454 - dense_471_accuracy: 0.3020 - dense_472_accuracy: 0.1886\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 17.4508 - dense_463_loss: 1.6033 - dense_464_loss: 1.7103 - dense_465_loss: 1.8063 - dense_466_loss: 1.6902 - dense_467_loss: 1.9814 - dense_468_loss: 1.7717 - dense_469_loss: 1.7881 - dense_470_loss: 1.7220 - dense_471_loss: 1.5565 - dense_472_loss: 1.8212 - dense_463_accuracy: 0.4048 - dense_464_accuracy: 0.3194 - dense_465_accuracy: 0.2602 - dense_466_accuracy: 0.2860 - dense_467_accuracy: 0.2226 - dense_468_accuracy: 0.2756 - dense_469_accuracy: 0.2724 - dense_470_accuracy: 0.2822 - dense_471_accuracy: 0.3894 - dense_472_accuracy: 0.2428\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 17.1721 - dense_463_loss: 1.5755 - dense_464_loss: 1.6764 - dense_465_loss: 1.7781 - dense_466_loss: 1.6592 - dense_467_loss: 1.9505 - dense_468_loss: 1.7451 - dense_469_loss: 1.7635 - dense_470_loss: 1.6917 - dense_471_loss: 1.5342 - dense_472_loss: 1.7980 - dense_463_accuracy: 0.4128 - dense_464_accuracy: 0.3234 - dense_465_accuracy: 0.2606 - dense_466_accuracy: 0.2910 - dense_467_accuracy: 0.2146 - dense_468_accuracy: 0.2706 - dense_469_accuracy: 0.2770 - dense_470_accuracy: 0.2788 - dense_471_accuracy: 0.3946 - dense_472_accuracy: 0.2326\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 17.1375 - dense_463_loss: 1.5726 - dense_464_loss: 1.6762 - dense_465_loss: 1.7774 - dense_466_loss: 1.6565 - dense_467_loss: 1.9490 - dense_468_loss: 1.7371 - dense_469_loss: 1.7595 - dense_470_loss: 1.6858 - dense_471_loss: 1.5316 - dense_472_loss: 1.7917 - dense_463_accuracy: 0.4112 - dense_464_accuracy: 0.3280 - dense_465_accuracy: 0.2744 - dense_466_accuracy: 0.2952 - dense_467_accuracy: 0.2298 - dense_468_accuracy: 0.2748 - dense_469_accuracy: 0.2834 - dense_470_accuracy: 0.2926 - dense_471_accuracy: 0.3936 - dense_472_accuracy: 0.2418\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 17.0974 - dense_463_loss: 1.5708 - dense_464_loss: 1.6718 - dense_465_loss: 1.7703 - dense_466_loss: 1.6465 - dense_467_loss: 1.9422 - dense_468_loss: 1.7397 - dense_469_loss: 1.7533 - dense_470_loss: 1.6855 - dense_471_loss: 1.5295 - dense_472_loss: 1.7877 - dense_463_accuracy: 0.4112 - dense_464_accuracy: 0.3272 - dense_465_accuracy: 0.2756 - dense_466_accuracy: 0.3020 - dense_467_accuracy: 0.2284 - dense_468_accuracy: 0.2796 - dense_469_accuracy: 0.2876 - dense_470_accuracy: 0.3010 - dense_471_accuracy: 0.3928 - dense_472_accuracy: 0.2470\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 17.0179 - dense_463_loss: 1.5634 - dense_464_loss: 1.6677 - dense_465_loss: 1.7568 - dense_466_loss: 1.6443 - dense_467_loss: 1.9316 - dense_468_loss: 1.7234 - dense_469_loss: 1.7489 - dense_470_loss: 1.6761 - dense_471_loss: 1.5252 - dense_472_loss: 1.7807 - dense_463_accuracy: 0.4114 - dense_464_accuracy: 0.3268 - dense_465_accuracy: 0.2858 - dense_466_accuracy: 0.3000 - dense_467_accuracy: 0.2448 - dense_468_accuracy: 0.2886 - dense_469_accuracy: 0.2902 - dense_470_accuracy: 0.2990 - dense_471_accuracy: 0.3928 - dense_472_accuracy: 0.2572\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 16.9064 - dense_463_loss: 1.5512 - dense_464_loss: 1.6581 - dense_465_loss: 1.7515 - dense_466_loss: 1.6300 - dense_467_loss: 1.9210 - dense_468_loss: 1.7156 - dense_469_loss: 1.7366 - dense_470_loss: 1.6630 - dense_471_loss: 1.5137 - dense_472_loss: 1.7657 - dense_463_accuracy: 0.4202 - dense_464_accuracy: 0.3414 - dense_465_accuracy: 0.2916 - dense_466_accuracy: 0.3084 - dense_467_accuracy: 0.2564 - dense_468_accuracy: 0.3006 - dense_469_accuracy: 0.2982 - dense_470_accuracy: 0.3080 - dense_471_accuracy: 0.4018 - dense_472_accuracy: 0.2666\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 16.8219 - dense_463_loss: 1.5446 - dense_464_loss: 1.6474 - dense_465_loss: 1.7437 - dense_466_loss: 1.6246 - dense_467_loss: 1.9064 - dense_468_loss: 1.7024 - dense_469_loss: 1.7320 - dense_470_loss: 1.6539 - dense_471_loss: 1.5102 - dense_472_loss: 1.7568 - dense_463_accuracy: 0.4190 - dense_464_accuracy: 0.3542 - dense_465_accuracy: 0.2980 - dense_466_accuracy: 0.3202 - dense_467_accuracy: 0.2738 - dense_468_accuracy: 0.3106 - dense_469_accuracy: 0.3030 - dense_470_accuracy: 0.3296 - dense_471_accuracy: 0.4008 - dense_472_accuracy: 0.2880\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 16.7257 - dense_463_loss: 1.5393 - dense_464_loss: 1.6363 - dense_465_loss: 1.7304 - dense_466_loss: 1.6091 - dense_467_loss: 1.8957 - dense_468_loss: 1.6948 - dense_469_loss: 1.7233 - dense_470_loss: 1.6515 - dense_471_loss: 1.5026 - dense_472_loss: 1.7426 - dense_463_accuracy: 0.4216 - dense_464_accuracy: 0.3570 - dense_465_accuracy: 0.3210 - dense_466_accuracy: 0.3398 - dense_467_accuracy: 0.2796 - dense_468_accuracy: 0.3258 - dense_469_accuracy: 0.3210 - dense_470_accuracy: 0.3218 - dense_471_accuracy: 0.4066 - dense_472_accuracy: 0.2934\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 16.5167 - dense_463_loss: 1.5235 - dense_464_loss: 1.6223 - dense_465_loss: 1.7143 - dense_466_loss: 1.5946 - dense_467_loss: 1.8668 - dense_468_loss: 1.6713 - dense_469_loss: 1.6991 - dense_470_loss: 1.6233 - dense_471_loss: 1.4797 - dense_472_loss: 1.7217 - dense_463_accuracy: 0.4308 - dense_464_accuracy: 0.3746 - dense_465_accuracy: 0.3308 - dense_466_accuracy: 0.3420 - dense_467_accuracy: 0.3044 - dense_468_accuracy: 0.3326 - dense_469_accuracy: 0.3362 - dense_470_accuracy: 0.3410 - dense_471_accuracy: 0.4140 - dense_472_accuracy: 0.3076\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 16.3727 - dense_463_loss: 1.5146 - dense_464_loss: 1.6057 - dense_465_loss: 1.6942 - dense_466_loss: 1.5766 - dense_467_loss: 1.8522 - dense_468_loss: 1.6553 - dense_469_loss: 1.6842 - dense_470_loss: 1.6091 - dense_471_loss: 1.4729 - dense_472_loss: 1.7078 - dense_463_accuracy: 0.4408 - dense_464_accuracy: 0.3802 - dense_465_accuracy: 0.3452 - dense_466_accuracy: 0.3650 - dense_467_accuracy: 0.3142 - dense_468_accuracy: 0.3516 - dense_469_accuracy: 0.3472 - dense_470_accuracy: 0.3572 - dense_471_accuracy: 0.4344 - dense_472_accuracy: 0.3284\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 16.2023 - dense_463_loss: 1.4981 - dense_464_loss: 1.5922 - dense_465_loss: 1.6767 - dense_466_loss: 1.5559 - dense_467_loss: 1.8284 - dense_468_loss: 1.6408 - dense_469_loss: 1.6701 - dense_470_loss: 1.5960 - dense_471_loss: 1.4543 - dense_472_loss: 1.6899 - dense_463_accuracy: 0.4552 - dense_464_accuracy: 0.3898 - dense_465_accuracy: 0.3612 - dense_466_accuracy: 0.3798 - dense_467_accuracy: 0.3338 - dense_468_accuracy: 0.3548 - dense_469_accuracy: 0.3676 - dense_470_accuracy: 0.3664 - dense_471_accuracy: 0.4350 - dense_472_accuracy: 0.3336\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 16.0202 - dense_463_loss: 1.4815 - dense_464_loss: 1.5727 - dense_465_loss: 1.6600 - dense_466_loss: 1.5414 - dense_467_loss: 1.8054 - dense_468_loss: 1.6225 - dense_469_loss: 1.6524 - dense_470_loss: 1.5756 - dense_471_loss: 1.4381 - dense_472_loss: 1.6706 - dense_463_accuracy: 0.4634 - dense_464_accuracy: 0.4038 - dense_465_accuracy: 0.3734 - dense_466_accuracy: 0.3852 - dense_467_accuracy: 0.3470 - dense_468_accuracy: 0.3764 - dense_469_accuracy: 0.3726 - dense_470_accuracy: 0.3824 - dense_471_accuracy: 0.4498 - dense_472_accuracy: 0.3540\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 15.9135 - dense_463_loss: 1.4693 - dense_464_loss: 1.5638 - dense_465_loss: 1.6498 - dense_466_loss: 1.5318 - dense_467_loss: 1.7957 - dense_468_loss: 1.6102 - dense_469_loss: 1.6392 - dense_470_loss: 1.5642 - dense_471_loss: 1.4316 - dense_472_loss: 1.6579 - dense_463_accuracy: 0.4766 - dense_464_accuracy: 0.4120 - dense_465_accuracy: 0.3778 - dense_466_accuracy: 0.4002 - dense_467_accuracy: 0.3564 - dense_468_accuracy: 0.3956 - dense_469_accuracy: 0.3882 - dense_470_accuracy: 0.3880 - dense_471_accuracy: 0.4546 - dense_472_accuracy: 0.3536\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 15.8734 - dense_463_loss: 1.4638 - dense_464_loss: 1.5623 - dense_465_loss: 1.6479 - dense_466_loss: 1.5288 - dense_467_loss: 1.7921 - dense_468_loss: 1.6030 - dense_469_loss: 1.6338 - dense_470_loss: 1.5617 - dense_471_loss: 1.4264 - dense_472_loss: 1.6536 - dense_463_accuracy: 0.4638 - dense_464_accuracy: 0.4148 - dense_465_accuracy: 0.3808 - dense_466_accuracy: 0.4030 - dense_467_accuracy: 0.3594 - dense_468_accuracy: 0.3930 - dense_469_accuracy: 0.3912 - dense_470_accuracy: 0.4022 - dense_471_accuracy: 0.4648 - dense_472_accuracy: 0.3652\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 15.8816 - dense_463_loss: 1.4655 - dense_464_loss: 1.5591 - dense_465_loss: 1.6477 - dense_466_loss: 1.5269 - dense_467_loss: 1.7910 - dense_468_loss: 1.6065 - dense_469_loss: 1.6354 - dense_470_loss: 1.5637 - dense_471_loss: 1.4309 - dense_472_loss: 1.6548 - dense_463_accuracy: 0.4744 - dense_464_accuracy: 0.4206 - dense_465_accuracy: 0.3784 - dense_466_accuracy: 0.3960 - dense_467_accuracy: 0.3610 - dense_468_accuracy: 0.3888 - dense_469_accuracy: 0.3940 - dense_470_accuracy: 0.3942 - dense_471_accuracy: 0.4608 - dense_472_accuracy: 0.3612\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 15.6371 - dense_463_loss: 1.4467 - dense_464_loss: 1.5300 - dense_465_loss: 1.6203 - dense_466_loss: 1.5092 - dense_467_loss: 1.7680 - dense_468_loss: 1.5795 - dense_469_loss: 1.6086 - dense_470_loss: 1.5364 - dense_471_loss: 1.4099 - dense_472_loss: 1.6286 - dense_463_accuracy: 0.4866 - dense_464_accuracy: 0.4288 - dense_465_accuracy: 0.4022 - dense_466_accuracy: 0.4194 - dense_467_accuracy: 0.3858 - dense_468_accuracy: 0.4044 - dense_469_accuracy: 0.4046 - dense_470_accuracy: 0.4072 - dense_471_accuracy: 0.4702 - dense_472_accuracy: 0.3810\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 15.4666 - dense_463_loss: 1.4270 - dense_464_loss: 1.5157 - dense_465_loss: 1.6013 - dense_466_loss: 1.4889 - dense_467_loss: 1.7437 - dense_468_loss: 1.5650 - dense_469_loss: 1.5958 - dense_470_loss: 1.5210 - dense_471_loss: 1.3973 - dense_472_loss: 1.6109 - dense_463_accuracy: 0.4994 - dense_464_accuracy: 0.4356 - dense_465_accuracy: 0.4060 - dense_466_accuracy: 0.4238 - dense_467_accuracy: 0.3796 - dense_468_accuracy: 0.4126 - dense_469_accuracy: 0.4088 - dense_470_accuracy: 0.4178 - dense_471_accuracy: 0.4850 - dense_472_accuracy: 0.3902\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 15.2003 - dense_463_loss: 1.4059 - dense_464_loss: 1.4962 - dense_465_loss: 1.5748 - dense_466_loss: 1.4612 - dense_467_loss: 1.7149 - dense_468_loss: 1.5308 - dense_469_loss: 1.5670 - dense_470_loss: 1.4969 - dense_471_loss: 1.3702 - dense_472_loss: 1.5824 - dense_463_accuracy: 0.5130 - dense_464_accuracy: 0.4510 - dense_465_accuracy: 0.4306 - dense_466_accuracy: 0.4452 - dense_467_accuracy: 0.4044 - dense_468_accuracy: 0.4352 - dense_469_accuracy: 0.4310 - dense_470_accuracy: 0.4326 - dense_471_accuracy: 0.5012 - dense_472_accuracy: 0.4150\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 15.0200 - dense_463_loss: 1.3870 - dense_464_loss: 1.4773 - dense_465_loss: 1.5567 - dense_466_loss: 1.4335 - dense_467_loss: 1.6956 - dense_468_loss: 1.5198 - dense_469_loss: 1.5487 - dense_470_loss: 1.4756 - dense_471_loss: 1.3595 - dense_472_loss: 1.5663 - dense_463_accuracy: 0.5234 - dense_464_accuracy: 0.4612 - dense_465_accuracy: 0.4346 - dense_466_accuracy: 0.4638 - dense_467_accuracy: 0.4150 - dense_468_accuracy: 0.4404 - dense_469_accuracy: 0.4404 - dense_470_accuracy: 0.4524 - dense_471_accuracy: 0.4964 - dense_472_accuracy: 0.4184\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 14.8711 - dense_463_loss: 1.3745 - dense_464_loss: 1.4605 - dense_465_loss: 1.5363 - dense_466_loss: 1.4264 - dense_467_loss: 1.6719 - dense_468_loss: 1.5057 - dense_469_loss: 1.5324 - dense_470_loss: 1.4613 - dense_471_loss: 1.3475 - dense_472_loss: 1.5546 - dense_463_accuracy: 0.5260 - dense_464_accuracy: 0.4726 - dense_465_accuracy: 0.4460 - dense_466_accuracy: 0.4684 - dense_467_accuracy: 0.4324 - dense_468_accuracy: 0.4506 - dense_469_accuracy: 0.4568 - dense_470_accuracy: 0.4704 - dense_471_accuracy: 0.5088 - dense_472_accuracy: 0.4278\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 14.7910 - dense_463_loss: 1.3651 - dense_464_loss: 1.4579 - dense_465_loss: 1.5346 - dense_466_loss: 1.4180 - dense_467_loss: 1.6653 - dense_468_loss: 1.4950 - dense_469_loss: 1.5189 - dense_470_loss: 1.4580 - dense_471_loss: 1.3382 - dense_472_loss: 1.5401 - dense_463_accuracy: 0.5328 - dense_464_accuracy: 0.4716 - dense_465_accuracy: 0.4468 - dense_466_accuracy: 0.4752 - dense_467_accuracy: 0.4302 - dense_468_accuracy: 0.4588 - dense_469_accuracy: 0.4632 - dense_470_accuracy: 0.4592 - dense_471_accuracy: 0.5088 - dense_472_accuracy: 0.4374\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 14.7290 - dense_463_loss: 1.3578 - dense_464_loss: 1.4433 - dense_465_loss: 1.5228 - dense_466_loss: 1.4139 - dense_467_loss: 1.6583 - dense_468_loss: 1.4847 - dense_469_loss: 1.5202 - dense_470_loss: 1.4469 - dense_471_loss: 1.3372 - dense_472_loss: 1.5438 - dense_463_accuracy: 0.5328 - dense_464_accuracy: 0.4876 - dense_465_accuracy: 0.4582 - dense_466_accuracy: 0.4714 - dense_467_accuracy: 0.4422 - dense_468_accuracy: 0.4574 - dense_469_accuracy: 0.4648 - dense_470_accuracy: 0.4636 - dense_471_accuracy: 0.5102 - dense_472_accuracy: 0.4392\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 14.6546 - dense_463_loss: 1.3489 - dense_464_loss: 1.4424 - dense_465_loss: 1.5187 - dense_466_loss: 1.4053 - dense_467_loss: 1.6469 - dense_468_loss: 1.4831 - dense_469_loss: 1.5061 - dense_470_loss: 1.4413 - dense_471_loss: 1.3318 - dense_472_loss: 1.5303 - dense_463_accuracy: 0.5398 - dense_464_accuracy: 0.4844 - dense_465_accuracy: 0.4600 - dense_466_accuracy: 0.4816 - dense_467_accuracy: 0.4436 - dense_468_accuracy: 0.4640 - dense_469_accuracy: 0.4710 - dense_470_accuracy: 0.4652 - dense_471_accuracy: 0.5238 - dense_472_accuracy: 0.4436\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 14.6233 - dense_463_loss: 1.3439 - dense_464_loss: 1.4435 - dense_465_loss: 1.5135 - dense_466_loss: 1.3997 - dense_467_loss: 1.6422 - dense_468_loss: 1.4775 - dense_469_loss: 1.5045 - dense_470_loss: 1.4383 - dense_471_loss: 1.3282 - dense_472_loss: 1.5321 - dense_463_accuracy: 0.5468 - dense_464_accuracy: 0.4910 - dense_465_accuracy: 0.4630 - dense_466_accuracy: 0.4828 - dense_467_accuracy: 0.4484 - dense_468_accuracy: 0.4740 - dense_469_accuracy: 0.4784 - dense_470_accuracy: 0.4734 - dense_471_accuracy: 0.5160 - dense_472_accuracy: 0.4492\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D3011E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D3011E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3431DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3431DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 3s 7ms/step - loss: 19.7806 - dense_473_loss: 1.8685 - dense_474_loss: 1.9225 - dense_475_loss: 2.0296 - dense_476_loss: 1.8846 - dense_477_loss: 2.2820 - dense_478_loss: 2.0169 - dense_479_loss: 2.0151 - dense_480_loss: 1.9380 - dense_481_loss: 1.7600 - dense_482_loss: 2.0634 - dense_473_accuracy: 0.3416 - dense_474_accuracy: 0.2812 - dense_475_accuracy: 0.2212 - dense_476_accuracy: 0.2598 - dense_477_accuracy: 0.1776 - dense_478_accuracy: 0.2238 - dense_479_accuracy: 0.2412 - dense_480_accuracy: 0.2448 - dense_481_accuracy: 0.3348 - dense_482_accuracy: 0.1850\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 17.3211 - dense_473_loss: 1.5975 - dense_474_loss: 1.6935 - dense_475_loss: 1.7909 - dense_476_loss: 1.6718 - dense_477_loss: 1.9697 - dense_478_loss: 1.7619 - dense_479_loss: 1.7702 - dense_480_loss: 1.7013 - dense_481_loss: 1.5482 - dense_482_loss: 1.8161 - dense_473_accuracy: 0.4112 - dense_474_accuracy: 0.3230 - dense_475_accuracy: 0.2574 - dense_476_accuracy: 0.2948 - dense_477_accuracy: 0.2194 - dense_478_accuracy: 0.2688 - dense_479_accuracy: 0.2788 - dense_480_accuracy: 0.2898 - dense_481_accuracy: 0.3842 - dense_482_accuracy: 0.2328\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 17.2671 - dense_473_loss: 1.5880 - dense_474_loss: 1.6877 - dense_475_loss: 1.7894 - dense_476_loss: 1.6644 - dense_477_loss: 1.9653 - dense_478_loss: 1.7538 - dense_479_loss: 1.7698 - dense_480_loss: 1.7008 - dense_481_loss: 1.5448 - dense_482_loss: 1.8029 - dense_473_accuracy: 0.4108 - dense_474_accuracy: 0.3198 - dense_475_accuracy: 0.2566 - dense_476_accuracy: 0.2886 - dense_477_accuracy: 0.2198 - dense_478_accuracy: 0.2650 - dense_479_accuracy: 0.2800 - dense_480_accuracy: 0.2898 - dense_481_accuracy: 0.3860 - dense_482_accuracy: 0.2250\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 17.1741 - dense_473_loss: 1.5764 - dense_474_loss: 1.6779 - dense_475_loss: 1.7797 - dense_476_loss: 1.6589 - dense_477_loss: 1.9543 - dense_478_loss: 1.7437 - dense_479_loss: 1.7614 - dense_480_loss: 1.6898 - dense_481_loss: 1.5370 - dense_482_loss: 1.7951 - dense_473_accuracy: 0.4134 - dense_474_accuracy: 0.3204 - dense_475_accuracy: 0.2642 - dense_476_accuracy: 0.2846 - dense_477_accuracy: 0.2156 - dense_478_accuracy: 0.2640 - dense_479_accuracy: 0.2812 - dense_480_accuracy: 0.2860 - dense_481_accuracy: 0.3912 - dense_482_accuracy: 0.2344\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 17.0766 - dense_473_loss: 1.5626 - dense_474_loss: 1.6706 - dense_475_loss: 1.7711 - dense_476_loss: 1.6466 - dense_477_loss: 1.9438 - dense_478_loss: 1.7372 - dense_479_loss: 1.7470 - dense_480_loss: 1.6817 - dense_481_loss: 1.5298 - dense_482_loss: 1.7862 - dense_473_accuracy: 0.4176 - dense_474_accuracy: 0.3270 - dense_475_accuracy: 0.2684 - dense_476_accuracy: 0.2992 - dense_477_accuracy: 0.2222 - dense_478_accuracy: 0.2678 - dense_479_accuracy: 0.2836 - dense_480_accuracy: 0.2934 - dense_481_accuracy: 0.3932 - dense_482_accuracy: 0.2398\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 17.0312 - dense_473_loss: 1.5619 - dense_474_loss: 1.6680 - dense_475_loss: 1.7656 - dense_476_loss: 1.6427 - dense_477_loss: 1.9364 - dense_478_loss: 1.7284 - dense_479_loss: 1.7441 - dense_480_loss: 1.6770 - dense_481_loss: 1.5248 - dense_482_loss: 1.7822 - dense_473_accuracy: 0.4136 - dense_474_accuracy: 0.3260 - dense_475_accuracy: 0.2708 - dense_476_accuracy: 0.3020 - dense_477_accuracy: 0.2308 - dense_478_accuracy: 0.2810 - dense_479_accuracy: 0.2866 - dense_480_accuracy: 0.2964 - dense_481_accuracy: 0.4010 - dense_482_accuracy: 0.2376\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 17.0382 - dense_473_loss: 1.5608 - dense_474_loss: 1.6657 - dense_475_loss: 1.7658 - dense_476_loss: 1.6454 - dense_477_loss: 1.9373 - dense_478_loss: 1.7299 - dense_479_loss: 1.7458 - dense_480_loss: 1.6788 - dense_481_loss: 1.5283 - dense_482_loss: 1.7804 - dense_473_accuracy: 0.4210 - dense_474_accuracy: 0.3222 - dense_475_accuracy: 0.2680 - dense_476_accuracy: 0.2984 - dense_477_accuracy: 0.2152 - dense_478_accuracy: 0.2742 - dense_479_accuracy: 0.2834 - dense_480_accuracy: 0.2966 - dense_481_accuracy: 0.3928 - dense_482_accuracy: 0.2440\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 17.0269 - dense_473_loss: 1.5631 - dense_474_loss: 1.6645 - dense_475_loss: 1.7620 - dense_476_loss: 1.6432 - dense_477_loss: 1.9375 - dense_478_loss: 1.7282 - dense_479_loss: 1.7452 - dense_480_loss: 1.6751 - dense_481_loss: 1.5256 - dense_482_loss: 1.7826 - dense_473_accuracy: 0.4156 - dense_474_accuracy: 0.3292 - dense_475_accuracy: 0.2714 - dense_476_accuracy: 0.2984 - dense_477_accuracy: 0.2314 - dense_478_accuracy: 0.2756 - dense_479_accuracy: 0.2902 - dense_480_accuracy: 0.3012 - dense_481_accuracy: 0.3958 - dense_482_accuracy: 0.2452\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 16.9809 - dense_473_loss: 1.5553 - dense_474_loss: 1.6578 - dense_475_loss: 1.7607 - dense_476_loss: 1.6415 - dense_477_loss: 1.9300 - dense_478_loss: 1.7260 - dense_479_loss: 1.7379 - dense_480_loss: 1.6728 - dense_481_loss: 1.5213 - dense_482_loss: 1.7777 - dense_473_accuracy: 0.4190 - dense_474_accuracy: 0.3310 - dense_475_accuracy: 0.2680 - dense_476_accuracy: 0.3008 - dense_477_accuracy: 0.2204 - dense_478_accuracy: 0.2756 - dense_479_accuracy: 0.2826 - dense_480_accuracy: 0.2990 - dense_481_accuracy: 0.3948 - dense_482_accuracy: 0.2386\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 16.9496 - dense_473_loss: 1.5529 - dense_474_loss: 1.6568 - dense_475_loss: 1.7603 - dense_476_loss: 1.6379 - dense_477_loss: 1.9254 - dense_478_loss: 1.7203 - dense_479_loss: 1.7360 - dense_480_loss: 1.6682 - dense_481_loss: 1.5186 - dense_482_loss: 1.7733 - dense_473_accuracy: 0.4226 - dense_474_accuracy: 0.3318 - dense_475_accuracy: 0.2648 - dense_476_accuracy: 0.3004 - dense_477_accuracy: 0.2276 - dense_478_accuracy: 0.2814 - dense_479_accuracy: 0.2840 - dense_480_accuracy: 0.3046 - dense_481_accuracy: 0.3980 - dense_482_accuracy: 0.2448\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 16.9323 - dense_473_loss: 1.5507 - dense_474_loss: 1.6551 - dense_475_loss: 1.7551 - dense_476_loss: 1.6328 - dense_477_loss: 1.9266 - dense_478_loss: 1.7190 - dense_479_loss: 1.7359 - dense_480_loss: 1.6675 - dense_481_loss: 1.5173 - dense_482_loss: 1.7722 - dense_473_accuracy: 0.4200 - dense_474_accuracy: 0.3374 - dense_475_accuracy: 0.2682 - dense_476_accuracy: 0.3048 - dense_477_accuracy: 0.2336 - dense_478_accuracy: 0.2818 - dense_479_accuracy: 0.2818 - dense_480_accuracy: 0.2994 - dense_481_accuracy: 0.3974 - dense_482_accuracy: 0.2454\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 16.9352 - dense_473_loss: 1.5499 - dense_474_loss: 1.6563 - dense_475_loss: 1.7550 - dense_476_loss: 1.6335 - dense_477_loss: 1.9281 - dense_478_loss: 1.7167 - dense_479_loss: 1.7363 - dense_480_loss: 1.6658 - dense_481_loss: 1.5222 - dense_482_loss: 1.7715 - dense_473_accuracy: 0.4192 - dense_474_accuracy: 0.3370 - dense_475_accuracy: 0.2824 - dense_476_accuracy: 0.3050 - dense_477_accuracy: 0.2382 - dense_478_accuracy: 0.2784 - dense_479_accuracy: 0.2954 - dense_480_accuracy: 0.3006 - dense_481_accuracy: 0.3942 - dense_482_accuracy: 0.2530\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 16.8772 - dense_473_loss: 1.5463 - dense_474_loss: 1.6517 - dense_475_loss: 1.7471 - dense_476_loss: 1.6284 - dense_477_loss: 1.9190 - dense_478_loss: 1.7133 - dense_479_loss: 1.7313 - dense_480_loss: 1.6541 - dense_481_loss: 1.5185 - dense_482_loss: 1.7674 - dense_473_accuracy: 0.4184 - dense_474_accuracy: 0.3384 - dense_475_accuracy: 0.2930 - dense_476_accuracy: 0.3212 - dense_477_accuracy: 0.2466 - dense_478_accuracy: 0.2880 - dense_479_accuracy: 0.2932 - dense_480_accuracy: 0.3244 - dense_481_accuracy: 0.3974 - dense_482_accuracy: 0.2642\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 16.8624 - dense_473_loss: 1.5467 - dense_474_loss: 1.6511 - dense_475_loss: 1.7472 - dense_476_loss: 1.6284 - dense_477_loss: 1.9170 - dense_478_loss: 1.7107 - dense_479_loss: 1.7268 - dense_480_loss: 1.6529 - dense_481_loss: 1.5169 - dense_482_loss: 1.7647 - dense_473_accuracy: 0.4234 - dense_474_accuracy: 0.3474 - dense_475_accuracy: 0.2912 - dense_476_accuracy: 0.3146 - dense_477_accuracy: 0.2532 - dense_478_accuracy: 0.2868 - dense_479_accuracy: 0.3020 - dense_480_accuracy: 0.3156 - dense_481_accuracy: 0.4056 - dense_482_accuracy: 0.2672\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 16.8132 - dense_473_loss: 1.5427 - dense_474_loss: 1.6444 - dense_475_loss: 1.7413 - dense_476_loss: 1.6225 - dense_477_loss: 1.9115 - dense_478_loss: 1.7052 - dense_479_loss: 1.7241 - dense_480_loss: 1.6531 - dense_481_loss: 1.5124 - dense_482_loss: 1.7560 - dense_473_accuracy: 0.4194 - dense_474_accuracy: 0.3424 - dense_475_accuracy: 0.2970 - dense_476_accuracy: 0.3186 - dense_477_accuracy: 0.2648 - dense_478_accuracy: 0.3006 - dense_479_accuracy: 0.3120 - dense_480_accuracy: 0.3152 - dense_481_accuracy: 0.3998 - dense_482_accuracy: 0.2760\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 16.6953 - dense_473_loss: 1.5301 - dense_474_loss: 1.6348 - dense_475_loss: 1.7266 - dense_476_loss: 1.6129 - dense_477_loss: 1.8963 - dense_478_loss: 1.6945 - dense_479_loss: 1.7121 - dense_480_loss: 1.6427 - dense_481_loss: 1.4996 - dense_482_loss: 1.7456 - dense_473_accuracy: 0.4326 - dense_474_accuracy: 0.3490 - dense_475_accuracy: 0.3078 - dense_476_accuracy: 0.3230 - dense_477_accuracy: 0.2700 - dense_478_accuracy: 0.3082 - dense_479_accuracy: 0.3248 - dense_480_accuracy: 0.3224 - dense_481_accuracy: 0.4112 - dense_482_accuracy: 0.2884\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 16.5945 - dense_473_loss: 1.5200 - dense_474_loss: 1.6269 - dense_475_loss: 1.7159 - dense_476_loss: 1.6031 - dense_477_loss: 1.8830 - dense_478_loss: 1.6838 - dense_479_loss: 1.7015 - dense_480_loss: 1.6285 - dense_481_loss: 1.4941 - dense_482_loss: 1.7377 - dense_473_accuracy: 0.4342 - dense_474_accuracy: 0.3584 - dense_475_accuracy: 0.3244 - dense_476_accuracy: 0.3316 - dense_477_accuracy: 0.2930 - dense_478_accuracy: 0.3238 - dense_479_accuracy: 0.3328 - dense_480_accuracy: 0.3330 - dense_481_accuracy: 0.4104 - dense_482_accuracy: 0.2996\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 16.4872 - dense_473_loss: 1.5111 - dense_474_loss: 1.6150 - dense_475_loss: 1.7068 - dense_476_loss: 1.5926 - dense_477_loss: 1.8707 - dense_478_loss: 1.6734 - dense_479_loss: 1.6898 - dense_480_loss: 1.6201 - dense_481_loss: 1.4854 - dense_482_loss: 1.7222 - dense_473_accuracy: 0.4412 - dense_474_accuracy: 0.3696 - dense_475_accuracy: 0.3320 - dense_476_accuracy: 0.3418 - dense_477_accuracy: 0.2982 - dense_478_accuracy: 0.3230 - dense_479_accuracy: 0.3496 - dense_480_accuracy: 0.3480 - dense_481_accuracy: 0.4234 - dense_482_accuracy: 0.3148\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 16.3917 - dense_473_loss: 1.5029 - dense_474_loss: 1.6053 - dense_475_loss: 1.6919 - dense_476_loss: 1.5831 - dense_477_loss: 1.8648 - dense_478_loss: 1.6609 - dense_479_loss: 1.6802 - dense_480_loss: 1.6096 - dense_481_loss: 1.4751 - dense_482_loss: 1.7181 - dense_473_accuracy: 0.4466 - dense_474_accuracy: 0.3718 - dense_475_accuracy: 0.3462 - dense_476_accuracy: 0.3512 - dense_477_accuracy: 0.3098 - dense_478_accuracy: 0.3338 - dense_479_accuracy: 0.3556 - dense_480_accuracy: 0.3568 - dense_481_accuracy: 0.4222 - dense_482_accuracy: 0.3216\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 16.2253 - dense_473_loss: 1.4909 - dense_474_loss: 1.5879 - dense_475_loss: 1.6776 - dense_476_loss: 1.5630 - dense_477_loss: 1.8401 - dense_478_loss: 1.6471 - dense_479_loss: 1.6645 - dense_480_loss: 1.5924 - dense_481_loss: 1.4652 - dense_482_loss: 1.6966 - dense_473_accuracy: 0.4570 - dense_474_accuracy: 0.3922 - dense_475_accuracy: 0.3620 - dense_476_accuracy: 0.3562 - dense_477_accuracy: 0.3252 - dense_478_accuracy: 0.3448 - dense_479_accuracy: 0.3638 - dense_480_accuracy: 0.3668 - dense_481_accuracy: 0.4370 - dense_482_accuracy: 0.3296\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 16.1024 - dense_473_loss: 1.4848 - dense_474_loss: 1.5799 - dense_475_loss: 1.6659 - dense_476_loss: 1.5489 - dense_477_loss: 1.8279 - dense_478_loss: 1.6338 - dense_479_loss: 1.6501 - dense_480_loss: 1.5765 - dense_481_loss: 1.4545 - dense_482_loss: 1.6802 - dense_473_accuracy: 0.4532 - dense_474_accuracy: 0.3946 - dense_475_accuracy: 0.3610 - dense_476_accuracy: 0.3674 - dense_477_accuracy: 0.3300 - dense_478_accuracy: 0.3550 - dense_479_accuracy: 0.3700 - dense_480_accuracy: 0.3756 - dense_481_accuracy: 0.4378 - dense_482_accuracy: 0.3456\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 16.1132 - dense_473_loss: 1.4755 - dense_474_loss: 1.5817 - dense_475_loss: 1.6656 - dense_476_loss: 1.5558 - dense_477_loss: 1.8260 - dense_478_loss: 1.6323 - dense_479_loss: 1.6521 - dense_480_loss: 1.5769 - dense_481_loss: 1.4602 - dense_482_loss: 1.6871 - dense_473_accuracy: 0.4594 - dense_474_accuracy: 0.3902 - dense_475_accuracy: 0.3642 - dense_476_accuracy: 0.3754 - dense_477_accuracy: 0.3428 - dense_478_accuracy: 0.3668 - dense_479_accuracy: 0.3778 - dense_480_accuracy: 0.3796 - dense_481_accuracy: 0.4338 - dense_482_accuracy: 0.3464\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 15.9602 - dense_473_loss: 1.4640 - dense_474_loss: 1.5658 - dense_475_loss: 1.6493 - dense_476_loss: 1.5354 - dense_477_loss: 1.8100 - dense_478_loss: 1.6269 - dense_479_loss: 1.6382 - dense_480_loss: 1.5627 - dense_481_loss: 1.4435 - dense_482_loss: 1.6642 - dense_473_accuracy: 0.4682 - dense_474_accuracy: 0.4028 - dense_475_accuracy: 0.3814 - dense_476_accuracy: 0.3928 - dense_477_accuracy: 0.3530 - dense_478_accuracy: 0.3722 - dense_479_accuracy: 0.3932 - dense_480_accuracy: 0.3848 - dense_481_accuracy: 0.4444 - dense_482_accuracy: 0.3674\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 15.8612 - dense_473_loss: 1.4634 - dense_474_loss: 1.5503 - dense_475_loss: 1.6399 - dense_476_loss: 1.5259 - dense_477_loss: 1.7977 - dense_478_loss: 1.6094 - dense_479_loss: 1.6291 - dense_480_loss: 1.5527 - dense_481_loss: 1.4384 - dense_482_loss: 1.6546 - dense_473_accuracy: 0.4680 - dense_474_accuracy: 0.4154 - dense_475_accuracy: 0.3856 - dense_476_accuracy: 0.3986 - dense_477_accuracy: 0.3600 - dense_478_accuracy: 0.3762 - dense_479_accuracy: 0.3894 - dense_480_accuracy: 0.3984 - dense_481_accuracy: 0.4512 - dense_482_accuracy: 0.3714\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 15.7080 - dense_473_loss: 1.4426 - dense_474_loss: 1.5397 - dense_475_loss: 1.6264 - dense_476_loss: 1.5165 - dense_477_loss: 1.7766 - dense_478_loss: 1.5922 - dense_479_loss: 1.6116 - dense_480_loss: 1.5441 - dense_481_loss: 1.4213 - dense_482_loss: 1.6369 - dense_473_accuracy: 0.4892 - dense_474_accuracy: 0.4238 - dense_475_accuracy: 0.4032 - dense_476_accuracy: 0.4108 - dense_477_accuracy: 0.3786 - dense_478_accuracy: 0.3980 - dense_479_accuracy: 0.4098 - dense_480_accuracy: 0.4022 - dense_481_accuracy: 0.4604 - dense_482_accuracy: 0.3798\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D0BD4DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D0BD4DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3BD8EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3BD8EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 3s 27ms/step - loss: 0.1840\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 0.0104\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0056\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 0.0052\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0049\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0046\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 0.0041\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0037\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0033\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0031\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0029\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0029\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0028\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0028\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0027\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0027\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0027\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 0.0027\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0027\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0026\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0026\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0026\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 2s 29ms/step - loss: 0.0025\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 2s 28ms/step - loss: 0.0025\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0025\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D38B1DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D38B1DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 5s 11ms/step - loss: 19.8915 - dense_486_loss: 1.8746 - dense_487_loss: 2.2651 - dense_488_loss: 1.9035 - dense_489_loss: 1.9350 - dense_490_loss: 2.2814 - dense_491_loss: 2.2760 - dense_492_loss: 1.8780 - dense_493_loss: 1.8730 - dense_494_loss: 1.8870 - dense_495_loss: 1.7178 - dense_486_accuracy: 0.2506 - dense_487_accuracy: 0.1574 - dense_488_accuracy: 0.2232 - dense_489_accuracy: 0.2012 - dense_490_accuracy: 0.1508 - dense_491_accuracy: 0.1566 - dense_492_accuracy: 0.3032 - dense_493_accuracy: 0.2884 - dense_494_accuracy: 0.2814 - dense_495_accuracy: 0.3176\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 14.7347 - dense_486_loss: 1.4068 - dense_487_loss: 1.6400 - dense_488_loss: 1.4021 - dense_489_loss: 1.5272 - dense_490_loss: 1.6430 - dense_491_loss: 1.6250 - dense_492_loss: 1.4137 - dense_493_loss: 1.3482 - dense_494_loss: 1.3753 - dense_495_loss: 1.3535 - dense_486_accuracy: 0.3482 - dense_487_accuracy: 0.2400 - dense_488_accuracy: 0.3486 - dense_489_accuracy: 0.2694 - dense_490_accuracy: 0.2270 - dense_491_accuracy: 0.2376 - dense_492_accuracy: 0.3540 - dense_493_accuracy: 0.3568 - dense_494_accuracy: 0.3474 - dense_495_accuracy: 0.3618\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 13.9515 - dense_486_loss: 1.3320 - dense_487_loss: 1.5505 - dense_488_loss: 1.3411 - dense_489_loss: 1.4604 - dense_490_loss: 1.5519 - dense_491_loss: 1.5365 - dense_492_loss: 1.3356 - dense_493_loss: 1.2690 - dense_494_loss: 1.2862 - dense_495_loss: 1.2883 - dense_486_accuracy: 0.3574 - dense_487_accuracy: 0.2390 - dense_488_accuracy: 0.3628 - dense_489_accuracy: 0.2808 - dense_490_accuracy: 0.2504 - dense_491_accuracy: 0.2394 - dense_492_accuracy: 0.3602 - dense_493_accuracy: 0.3628 - dense_494_accuracy: 0.3640 - dense_495_accuracy: 0.3686\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 13.7663 - dense_486_loss: 1.3239 - dense_487_loss: 1.5276 - dense_488_loss: 1.3218 - dense_489_loss: 1.4376 - dense_490_loss: 1.5285 - dense_491_loss: 1.5149 - dense_492_loss: 1.3250 - dense_493_loss: 1.2444 - dense_494_loss: 1.2687 - dense_495_loss: 1.2740 - dense_486_accuracy: 0.3584 - dense_487_accuracy: 0.2382 - dense_488_accuracy: 0.3654 - dense_489_accuracy: 0.2798 - dense_490_accuracy: 0.2448 - dense_491_accuracy: 0.2418 - dense_492_accuracy: 0.3646 - dense_493_accuracy: 0.3786 - dense_494_accuracy: 0.3674 - dense_495_accuracy: 0.3808\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 13.6038 - dense_486_loss: 1.3058 - dense_487_loss: 1.5073 - dense_488_loss: 1.3131 - dense_489_loss: 1.4218 - dense_490_loss: 1.5117 - dense_491_loss: 1.4984 - dense_492_loss: 1.3071 - dense_493_loss: 1.2304 - dense_494_loss: 1.2551 - dense_495_loss: 1.2532 - dense_486_accuracy: 0.3552 - dense_487_accuracy: 0.2502 - dense_488_accuracy: 0.3746 - dense_489_accuracy: 0.2898 - dense_490_accuracy: 0.2556 - dense_491_accuracy: 0.2610 - dense_492_accuracy: 0.3784 - dense_493_accuracy: 0.3902 - dense_494_accuracy: 0.3682 - dense_495_accuracy: 0.3782\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 13.5869 - dense_486_loss: 1.3085 - dense_487_loss: 1.5054 - dense_488_loss: 1.3035 - dense_489_loss: 1.4223 - dense_490_loss: 1.5083 - dense_491_loss: 1.4965 - dense_492_loss: 1.3012 - dense_493_loss: 1.2243 - dense_494_loss: 1.2566 - dense_495_loss: 1.2602 - dense_486_accuracy: 0.3662 - dense_487_accuracy: 0.2616 - dense_488_accuracy: 0.3788 - dense_489_accuracy: 0.2958 - dense_490_accuracy: 0.2626 - dense_491_accuracy: 0.2642 - dense_492_accuracy: 0.3752 - dense_493_accuracy: 0.3886 - dense_494_accuracy: 0.3796 - dense_495_accuracy: 0.3802\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 13.5347 - dense_486_loss: 1.3008 - dense_487_loss: 1.4977 - dense_488_loss: 1.3026 - dense_489_loss: 1.4172 - dense_490_loss: 1.5048 - dense_491_loss: 1.4900 - dense_492_loss: 1.2957 - dense_493_loss: 1.2209 - dense_494_loss: 1.2494 - dense_495_loss: 1.2556 - dense_486_accuracy: 0.3658 - dense_487_accuracy: 0.2584 - dense_488_accuracy: 0.3764 - dense_489_accuracy: 0.2950 - dense_490_accuracy: 0.2600 - dense_491_accuracy: 0.2590 - dense_492_accuracy: 0.3856 - dense_493_accuracy: 0.3910 - dense_494_accuracy: 0.3768 - dense_495_accuracy: 0.3784\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 13.4928 - dense_486_loss: 1.3008 - dense_487_loss: 1.4952 - dense_488_loss: 1.2985 - dense_489_loss: 1.4097 - dense_490_loss: 1.5018 - dense_491_loss: 1.4862 - dense_492_loss: 1.2907 - dense_493_loss: 1.2116 - dense_494_loss: 1.2473 - dense_495_loss: 1.2508 - dense_486_accuracy: 0.3688 - dense_487_accuracy: 0.2580 - dense_488_accuracy: 0.3840 - dense_489_accuracy: 0.3114 - dense_490_accuracy: 0.2620 - dense_491_accuracy: 0.2568 - dense_492_accuracy: 0.3746 - dense_493_accuracy: 0.3972 - dense_494_accuracy: 0.3820 - dense_495_accuracy: 0.3808\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 13.6428 - dense_486_loss: 1.3157 - dense_487_loss: 1.5115 - dense_488_loss: 1.3103 - dense_489_loss: 1.4268 - dense_490_loss: 1.5125 - dense_491_loss: 1.5020 - dense_492_loss: 1.3120 - dense_493_loss: 1.2266 - dense_494_loss: 1.2600 - dense_495_loss: 1.2654 - dense_486_accuracy: 0.3622 - dense_487_accuracy: 0.2582 - dense_488_accuracy: 0.3730 - dense_489_accuracy: 0.2922 - dense_490_accuracy: 0.2600 - dense_491_accuracy: 0.2564 - dense_492_accuracy: 0.3776 - dense_493_accuracy: 0.3986 - dense_494_accuracy: 0.3788 - dense_495_accuracy: 0.3826\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 13.5337 - dense_486_loss: 1.3018 - dense_487_loss: 1.4959 - dense_488_loss: 1.3057 - dense_489_loss: 1.4160 - dense_490_loss: 1.5045 - dense_491_loss: 1.4899 - dense_492_loss: 1.2944 - dense_493_loss: 1.2220 - dense_494_loss: 1.2457 - dense_495_loss: 1.2576 - dense_486_accuracy: 0.3630 - dense_487_accuracy: 0.2682 - dense_488_accuracy: 0.3762 - dense_489_accuracy: 0.3048 - dense_490_accuracy: 0.2684 - dense_491_accuracy: 0.2690 - dense_492_accuracy: 0.3876 - dense_493_accuracy: 0.3952 - dense_494_accuracy: 0.3854 - dense_495_accuracy: 0.3888\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 13.5295 - dense_486_loss: 1.3027 - dense_487_loss: 1.4961 - dense_488_loss: 1.3038 - dense_489_loss: 1.4148 - dense_490_loss: 1.5035 - dense_491_loss: 1.4887 - dense_492_loss: 1.2990 - dense_493_loss: 1.2201 - dense_494_loss: 1.2476 - dense_495_loss: 1.2532 - dense_486_accuracy: 0.3582 - dense_487_accuracy: 0.2608 - dense_488_accuracy: 0.3756 - dense_489_accuracy: 0.2992 - dense_490_accuracy: 0.2616 - dense_491_accuracy: 0.2722 - dense_492_accuracy: 0.3796 - dense_493_accuracy: 0.3968 - dense_494_accuracy: 0.3820 - dense_495_accuracy: 0.3836\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 13.4881 - dense_486_loss: 1.3005 - dense_487_loss: 1.4914 - dense_488_loss: 1.2983 - dense_489_loss: 1.4081 - dense_490_loss: 1.4993 - dense_491_loss: 1.4818 - dense_492_loss: 1.2928 - dense_493_loss: 1.2184 - dense_494_loss: 1.2474 - dense_495_loss: 1.2503 - dense_486_accuracy: 0.3582 - dense_487_accuracy: 0.2686 - dense_488_accuracy: 0.3772 - dense_489_accuracy: 0.3128 - dense_490_accuracy: 0.2662 - dense_491_accuracy: 0.2646 - dense_492_accuracy: 0.3764 - dense_493_accuracy: 0.3910 - dense_494_accuracy: 0.3784 - dense_495_accuracy: 0.3768\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 13.3916 - dense_486_loss: 1.2902 - dense_487_loss: 1.4799 - dense_488_loss: 1.2879 - dense_489_loss: 1.3992 - dense_490_loss: 1.4882 - dense_491_loss: 1.4737 - dense_492_loss: 1.2846 - dense_493_loss: 1.2077 - dense_494_loss: 1.2396 - dense_495_loss: 1.2407 - dense_486_accuracy: 0.3720 - dense_487_accuracy: 0.2718 - dense_488_accuracy: 0.3864 - dense_489_accuracy: 0.3024 - dense_490_accuracy: 0.2698 - dense_491_accuracy: 0.2732 - dense_492_accuracy: 0.3910 - dense_493_accuracy: 0.4052 - dense_494_accuracy: 0.3788 - dense_495_accuracy: 0.3862\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 1s 13ms/step - loss: 13.3716 - dense_486_loss: 1.2931 - dense_487_loss: 1.4782 - dense_488_loss: 1.2870 - dense_489_loss: 1.3959 - dense_490_loss: 1.4844 - dense_491_loss: 1.4723 - dense_492_loss: 1.2815 - dense_493_loss: 1.2061 - dense_494_loss: 1.2344 - dense_495_loss: 1.2387 - dense_486_accuracy: 0.3688 - dense_487_accuracy: 0.2830 - dense_488_accuracy: 0.3876 - dense_489_accuracy: 0.3144 - dense_490_accuracy: 0.2830 - dense_491_accuracy: 0.2832 - dense_492_accuracy: 0.3884 - dense_493_accuracy: 0.4090 - dense_494_accuracy: 0.3890 - dense_495_accuracy: 0.3970\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 13.3766 - dense_486_loss: 1.2923 - dense_487_loss: 1.4790 - dense_488_loss: 1.2860 - dense_489_loss: 1.3996 - dense_490_loss: 1.4853 - dense_491_loss: 1.4734 - dense_492_loss: 1.2839 - dense_493_loss: 1.2011 - dense_494_loss: 1.2353 - dense_495_loss: 1.2405 - dense_486_accuracy: 0.3682 - dense_487_accuracy: 0.2790 - dense_488_accuracy: 0.3766 - dense_489_accuracy: 0.3106 - dense_490_accuracy: 0.2808 - dense_491_accuracy: 0.2770 - dense_492_accuracy: 0.3952 - dense_493_accuracy: 0.4112 - dense_494_accuracy: 0.3846 - dense_495_accuracy: 0.3856\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 13.3021 - dense_486_loss: 1.2850 - dense_487_loss: 1.4706 - dense_488_loss: 1.2819 - dense_489_loss: 1.3911 - dense_490_loss: 1.4772 - dense_491_loss: 1.4652 - dense_492_loss: 1.2742 - dense_493_loss: 1.1962 - dense_494_loss: 1.2287 - dense_495_loss: 1.2321 - dense_486_accuracy: 0.3734 - dense_487_accuracy: 0.2906 - dense_488_accuracy: 0.3828 - dense_489_accuracy: 0.3206 - dense_490_accuracy: 0.2906 - dense_491_accuracy: 0.2912 - dense_492_accuracy: 0.3980 - dense_493_accuracy: 0.4126 - dense_494_accuracy: 0.3906 - dense_495_accuracy: 0.3998\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 13.2311 - dense_486_loss: 1.2782 - dense_487_loss: 1.4635 - dense_488_loss: 1.2772 - dense_489_loss: 1.3833 - dense_490_loss: 1.4690 - dense_491_loss: 1.4542 - dense_492_loss: 1.2667 - dense_493_loss: 1.1866 - dense_494_loss: 1.2235 - dense_495_loss: 1.2290 - dense_486_accuracy: 0.3788 - dense_487_accuracy: 0.2934 - dense_488_accuracy: 0.3868 - dense_489_accuracy: 0.3228 - dense_490_accuracy: 0.2920 - dense_491_accuracy: 0.3062 - dense_492_accuracy: 0.3996 - dense_493_accuracy: 0.4268 - dense_494_accuracy: 0.4066 - dense_495_accuracy: 0.4076\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 13.2720 - dense_486_loss: 1.2851 - dense_487_loss: 1.4669 - dense_488_loss: 1.2843 - dense_489_loss: 1.3839 - dense_490_loss: 1.4702 - dense_491_loss: 1.4597 - dense_492_loss: 1.2696 - dense_493_loss: 1.1957 - dense_494_loss: 1.2279 - dense_495_loss: 1.2288 - dense_486_accuracy: 0.3800 - dense_487_accuracy: 0.3004 - dense_488_accuracy: 0.3940 - dense_489_accuracy: 0.3252 - dense_490_accuracy: 0.3068 - dense_491_accuracy: 0.3092 - dense_492_accuracy: 0.4042 - dense_493_accuracy: 0.4260 - dense_494_accuracy: 0.4064 - dense_495_accuracy: 0.4094\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 13.3145 - dense_486_loss: 1.2879 - dense_487_loss: 1.4685 - dense_488_loss: 1.2830 - dense_489_loss: 1.3922 - dense_490_loss: 1.4758 - dense_491_loss: 1.4638 - dense_492_loss: 1.2776 - dense_493_loss: 1.2025 - dense_494_loss: 1.2298 - dense_495_loss: 1.2334 - dense_486_accuracy: 0.3830 - dense_487_accuracy: 0.3048 - dense_488_accuracy: 0.3902 - dense_489_accuracy: 0.3248 - dense_490_accuracy: 0.3042 - dense_491_accuracy: 0.3058 - dense_492_accuracy: 0.4022 - dense_493_accuracy: 0.4174 - dense_494_accuracy: 0.4046 - dense_495_accuracy: 0.4048\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 1s 13ms/step - loss: 13.1866 - dense_486_loss: 1.2727 - dense_487_loss: 1.4564 - dense_488_loss: 1.2721 - dense_489_loss: 1.3759 - dense_490_loss: 1.4619 - dense_491_loss: 1.4486 - dense_492_loss: 1.2636 - dense_493_loss: 1.1884 - dense_494_loss: 1.2214 - dense_495_loss: 1.2254 - dense_486_accuracy: 0.3936 - dense_487_accuracy: 0.3224 - dense_488_accuracy: 0.3994 - dense_489_accuracy: 0.3396 - dense_490_accuracy: 0.3128 - dense_491_accuracy: 0.3232 - dense_492_accuracy: 0.4066 - dense_493_accuracy: 0.4248 - dense_494_accuracy: 0.4104 - dense_495_accuracy: 0.4090\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 13.1710 - dense_486_loss: 1.2734 - dense_487_loss: 1.4535 - dense_488_loss: 1.2679 - dense_489_loss: 1.3778 - dense_490_loss: 1.4604 - dense_491_loss: 1.4457 - dense_492_loss: 1.2671 - dense_493_loss: 1.1857 - dense_494_loss: 1.2164 - dense_495_loss: 1.2231 - dense_486_accuracy: 0.3876 - dense_487_accuracy: 0.3158 - dense_488_accuracy: 0.4048 - dense_489_accuracy: 0.3318 - dense_490_accuracy: 0.3082 - dense_491_accuracy: 0.3128 - dense_492_accuracy: 0.4014 - dense_493_accuracy: 0.4282 - dense_494_accuracy: 0.4152 - dense_495_accuracy: 0.4122\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 1s 13ms/step - loss: 13.1633 - dense_486_loss: 1.2697 - dense_487_loss: 1.4540 - dense_488_loss: 1.2723 - dense_489_loss: 1.3779 - dense_490_loss: 1.4585 - dense_491_loss: 1.4453 - dense_492_loss: 1.2620 - dense_493_loss: 1.1806 - dense_494_loss: 1.2234 - dense_495_loss: 1.2195 - dense_486_accuracy: 0.3952 - dense_487_accuracy: 0.3008 - dense_488_accuracy: 0.4008 - dense_489_accuracy: 0.3354 - dense_490_accuracy: 0.3104 - dense_491_accuracy: 0.3182 - dense_492_accuracy: 0.4072 - dense_493_accuracy: 0.4328 - dense_494_accuracy: 0.4100 - dense_495_accuracy: 0.4166\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.1376 - dense_486_loss: 1.2708 - dense_487_loss: 1.4509 - dense_488_loss: 1.2676 - dense_489_loss: 1.3683 - dense_490_loss: 1.4558 - dense_491_loss: 1.4447 - dense_492_loss: 1.2628 - dense_493_loss: 1.1825 - dense_494_loss: 1.2166 - dense_495_loss: 1.2175 - dense_486_accuracy: 0.3982 - dense_487_accuracy: 0.3184 - dense_488_accuracy: 0.4038 - dense_489_accuracy: 0.3422 - dense_490_accuracy: 0.3148 - dense_491_accuracy: 0.3100 - dense_492_accuracy: 0.4038 - dense_493_accuracy: 0.4254 - dense_494_accuracy: 0.4168 - dense_495_accuracy: 0.4176\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.2346 - dense_486_loss: 1.2790 - dense_487_loss: 1.4636 - dense_488_loss: 1.2812 - dense_489_loss: 1.3798 - dense_490_loss: 1.4703 - dense_491_loss: 1.4524 - dense_492_loss: 1.2676 - dense_493_loss: 1.1900 - dense_494_loss: 1.2226 - dense_495_loss: 1.2282 - dense_486_accuracy: 0.3902 - dense_487_accuracy: 0.3038 - dense_488_accuracy: 0.3826 - dense_489_accuracy: 0.3314 - dense_490_accuracy: 0.3062 - dense_491_accuracy: 0.3106 - dense_492_accuracy: 0.4094 - dense_493_accuracy: 0.4314 - dense_494_accuracy: 0.4150 - dense_495_accuracy: 0.4130\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.0883 - dense_486_loss: 1.2681 - dense_487_loss: 1.4440 - dense_488_loss: 1.2649 - dense_489_loss: 1.3657 - dense_490_loss: 1.4485 - dense_491_loss: 1.4368 - dense_492_loss: 1.2526 - dense_493_loss: 1.1782 - dense_494_loss: 1.2090 - dense_495_loss: 1.2205 - dense_486_accuracy: 0.4026 - dense_487_accuracy: 0.3216 - dense_488_accuracy: 0.4070 - dense_489_accuracy: 0.3516 - dense_490_accuracy: 0.3226 - dense_491_accuracy: 0.3298 - dense_492_accuracy: 0.4184 - dense_493_accuracy: 0.4346 - dense_494_accuracy: 0.4294 - dense_495_accuracy: 0.4238\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D3117318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D3117318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4C3B168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4C3B168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 4s 10ms/step - loss: 18.6918 - dense_496_loss: 1.7668 - dense_497_loss: 2.1321 - dense_498_loss: 1.7413 - dense_499_loss: 1.8014 - dense_500_loss: 2.1495 - dense_501_loss: 2.1155 - dense_502_loss: 1.7745 - dense_503_loss: 1.7597 - dense_504_loss: 1.7601 - dense_505_loss: 1.6909 - dense_496_accuracy: 0.2740 - dense_497_accuracy: 0.1818 - dense_498_accuracy: 0.2964 - dense_499_accuracy: 0.2424 - dense_500_accuracy: 0.1782 - dense_501_accuracy: 0.1918 - dense_502_accuracy: 0.2946 - dense_503_accuracy: 0.3018 - dense_504_accuracy: 0.2926 - dense_505_accuracy: 0.3034\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 14.3258 - dense_496_loss: 1.3551 - dense_497_loss: 1.5863 - dense_498_loss: 1.3754 - dense_499_loss: 1.4812 - dense_500_loss: 1.5979 - dense_501_loss: 1.5837 - dense_502_loss: 1.3777 - dense_503_loss: 1.3099 - dense_504_loss: 1.3379 - dense_505_loss: 1.3206 - dense_496_accuracy: 0.3562 - dense_497_accuracy: 0.2456 - dense_498_accuracy: 0.3606 - dense_499_accuracy: 0.2874 - dense_500_accuracy: 0.2518 - dense_501_accuracy: 0.2486 - dense_502_accuracy: 0.3670 - dense_503_accuracy: 0.3740 - dense_504_accuracy: 0.3660 - dense_505_accuracy: 0.3724\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 14.1213 - dense_496_loss: 1.3364 - dense_497_loss: 1.5659 - dense_498_loss: 1.3619 - dense_499_loss: 1.4661 - dense_500_loss: 1.5748 - dense_501_loss: 1.5587 - dense_502_loss: 1.3586 - dense_503_loss: 1.2798 - dense_504_loss: 1.3174 - dense_505_loss: 1.3018 - dense_496_accuracy: 0.3524 - dense_497_accuracy: 0.2430 - dense_498_accuracy: 0.3556 - dense_499_accuracy: 0.2868 - dense_500_accuracy: 0.2438 - dense_501_accuracy: 0.2448 - dense_502_accuracy: 0.3698 - dense_503_accuracy: 0.3752 - dense_504_accuracy: 0.3668 - dense_505_accuracy: 0.3660\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 13.7983 - dense_496_loss: 1.3147 - dense_497_loss: 1.5279 - dense_498_loss: 1.3302 - dense_499_loss: 1.4380 - dense_500_loss: 1.5383 - dense_501_loss: 1.5219 - dense_502_loss: 1.3205 - dense_503_loss: 1.2539 - dense_504_loss: 1.2778 - dense_505_loss: 1.2751 - dense_496_accuracy: 0.3504 - dense_497_accuracy: 0.2530 - dense_498_accuracy: 0.3642 - dense_499_accuracy: 0.2790 - dense_500_accuracy: 0.2388 - dense_501_accuracy: 0.2356 - dense_502_accuracy: 0.3648 - dense_503_accuracy: 0.3694 - dense_504_accuracy: 0.3628 - dense_505_accuracy: 0.3650\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 13.6433 - dense_496_loss: 1.3091 - dense_497_loss: 1.5120 - dense_498_loss: 1.3100 - dense_499_loss: 1.4260 - dense_500_loss: 1.5201 - dense_501_loss: 1.5054 - dense_502_loss: 1.3033 - dense_503_loss: 1.2328 - dense_504_loss: 1.2629 - dense_505_loss: 1.2616 - dense_496_accuracy: 0.3672 - dense_497_accuracy: 0.2510 - dense_498_accuracy: 0.3696 - dense_499_accuracy: 0.2866 - dense_500_accuracy: 0.2444 - dense_501_accuracy: 0.2512 - dense_502_accuracy: 0.3762 - dense_503_accuracy: 0.3812 - dense_504_accuracy: 0.3626 - dense_505_accuracy: 0.3694\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 13.7604 - dense_496_loss: 1.3185 - dense_497_loss: 1.5243 - dense_498_loss: 1.3257 - dense_499_loss: 1.4343 - dense_500_loss: 1.5350 - dense_501_loss: 1.5194 - dense_502_loss: 1.3225 - dense_503_loss: 1.2458 - dense_504_loss: 1.2708 - dense_505_loss: 1.2641 - dense_496_accuracy: 0.3624 - dense_497_accuracy: 0.2476 - dense_498_accuracy: 0.3720 - dense_499_accuracy: 0.2830 - dense_500_accuracy: 0.2470 - dense_501_accuracy: 0.2468 - dense_502_accuracy: 0.3676 - dense_503_accuracy: 0.3782 - dense_504_accuracy: 0.3672 - dense_505_accuracy: 0.3734\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.7004 - dense_496_loss: 1.3079 - dense_497_loss: 1.5194 - dense_498_loss: 1.3205 - dense_499_loss: 1.4300 - dense_500_loss: 1.5266 - dense_501_loss: 1.5083 - dense_502_loss: 1.3156 - dense_503_loss: 1.2409 - dense_504_loss: 1.2708 - dense_505_loss: 1.2605 - dense_496_accuracy: 0.3528 - dense_497_accuracy: 0.2566 - dense_498_accuracy: 0.3714 - dense_499_accuracy: 0.2834 - dense_500_accuracy: 0.2498 - dense_501_accuracy: 0.2572 - dense_502_accuracy: 0.3752 - dense_503_accuracy: 0.3788 - dense_504_accuracy: 0.3666 - dense_505_accuracy: 0.3772\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.5942 - dense_496_loss: 1.3035 - dense_497_loss: 1.5035 - dense_498_loss: 1.3084 - dense_499_loss: 1.4235 - dense_500_loss: 1.5144 - dense_501_loss: 1.4992 - dense_502_loss: 1.3022 - dense_503_loss: 1.2273 - dense_504_loss: 1.2563 - dense_505_loss: 1.2558 - dense_496_accuracy: 0.3662 - dense_497_accuracy: 0.2524 - dense_498_accuracy: 0.3668 - dense_499_accuracy: 0.2874 - dense_500_accuracy: 0.2474 - dense_501_accuracy: 0.2490 - dense_502_accuracy: 0.3704 - dense_503_accuracy: 0.3782 - dense_504_accuracy: 0.3706 - dense_505_accuracy: 0.3720\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 13.5948 - dense_496_loss: 1.3015 - dense_497_loss: 1.5053 - dense_498_loss: 1.3084 - dense_499_loss: 1.4201 - dense_500_loss: 1.5128 - dense_501_loss: 1.4995 - dense_502_loss: 1.3009 - dense_503_loss: 1.2296 - dense_504_loss: 1.2573 - dense_505_loss: 1.2595 - dense_496_accuracy: 0.3542 - dense_497_accuracy: 0.2552 - dense_498_accuracy: 0.3766 - dense_499_accuracy: 0.2910 - dense_500_accuracy: 0.2532 - dense_501_accuracy: 0.2554 - dense_502_accuracy: 0.3794 - dense_503_accuracy: 0.3850 - dense_504_accuracy: 0.3672 - dense_505_accuracy: 0.3672\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 13.5740 - dense_496_loss: 1.3036 - dense_497_loss: 1.5010 - dense_498_loss: 1.3060 - dense_499_loss: 1.4237 - dense_500_loss: 1.5102 - dense_501_loss: 1.4941 - dense_502_loss: 1.2988 - dense_503_loss: 1.2298 - dense_504_loss: 1.2518 - dense_505_loss: 1.2552 - dense_496_accuracy: 0.3656 - dense_497_accuracy: 0.2466 - dense_498_accuracy: 0.3738 - dense_499_accuracy: 0.2818 - dense_500_accuracy: 0.2444 - dense_501_accuracy: 0.2462 - dense_502_accuracy: 0.3670 - dense_503_accuracy: 0.3740 - dense_504_accuracy: 0.3646 - dense_505_accuracy: 0.3720\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 13.5535 - dense_496_loss: 1.3028 - dense_497_loss: 1.5002 - dense_498_loss: 1.3061 - dense_499_loss: 1.4164 - dense_500_loss: 1.5091 - dense_501_loss: 1.4927 - dense_502_loss: 1.2964 - dense_503_loss: 1.2255 - dense_504_loss: 1.2512 - dense_505_loss: 1.2530 - dense_496_accuracy: 0.3758 - dense_497_accuracy: 0.2616 - dense_498_accuracy: 0.3790 - dense_499_accuracy: 0.2950 - dense_500_accuracy: 0.2596 - dense_501_accuracy: 0.2532 - dense_502_accuracy: 0.3764 - dense_503_accuracy: 0.3790 - dense_504_accuracy: 0.3780 - dense_505_accuracy: 0.3850\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 1s 13ms/step - loss: 13.6136 - dense_496_loss: 1.3077 - dense_497_loss: 1.5090 - dense_498_loss: 1.3093 - dense_499_loss: 1.4219 - dense_500_loss: 1.5163 - dense_501_loss: 1.5008 - dense_502_loss: 1.3026 - dense_503_loss: 1.2306 - dense_504_loss: 1.2564 - dense_505_loss: 1.2592 - dense_496_accuracy: 0.3580 - dense_497_accuracy: 0.2398 - dense_498_accuracy: 0.3704 - dense_499_accuracy: 0.2858 - dense_500_accuracy: 0.2452 - dense_501_accuracy: 0.2436 - dense_502_accuracy: 0.3706 - dense_503_accuracy: 0.3778 - dense_504_accuracy: 0.3658 - dense_505_accuracy: 0.3770\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 13.4614 - dense_496_loss: 1.2928 - dense_497_loss: 1.4909 - dense_498_loss: 1.2979 - dense_499_loss: 1.4115 - dense_500_loss: 1.4969 - dense_501_loss: 1.4834 - dense_502_loss: 1.2869 - dense_503_loss: 1.2134 - dense_504_loss: 1.2423 - dense_505_loss: 1.2453 - dense_496_accuracy: 0.3648 - dense_497_accuracy: 0.2538 - dense_498_accuracy: 0.3742 - dense_499_accuracy: 0.2878 - dense_500_accuracy: 0.2516 - dense_501_accuracy: 0.2508 - dense_502_accuracy: 0.3700 - dense_503_accuracy: 0.3752 - dense_504_accuracy: 0.3714 - dense_505_accuracy: 0.3804\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 13.4725 - dense_496_loss: 1.2947 - dense_497_loss: 1.4933 - dense_498_loss: 1.2966 - dense_499_loss: 1.4103 - dense_500_loss: 1.4981 - dense_501_loss: 1.4849 - dense_502_loss: 1.2846 - dense_503_loss: 1.2160 - dense_504_loss: 1.2467 - dense_505_loss: 1.2474 - dense_496_accuracy: 0.3610 - dense_497_accuracy: 0.2486 - dense_498_accuracy: 0.3690 - dense_499_accuracy: 0.2946 - dense_500_accuracy: 0.2524 - dense_501_accuracy: 0.2540 - dense_502_accuracy: 0.3750 - dense_503_accuracy: 0.3874 - dense_504_accuracy: 0.3700 - dense_505_accuracy: 0.3792\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.4530 - dense_496_loss: 1.2927 - dense_497_loss: 1.4896 - dense_498_loss: 1.2954 - dense_499_loss: 1.4106 - dense_500_loss: 1.4951 - dense_501_loss: 1.4815 - dense_502_loss: 1.2876 - dense_503_loss: 1.2138 - dense_504_loss: 1.2412 - dense_505_loss: 1.2454 - dense_496_accuracy: 0.3694 - dense_497_accuracy: 0.2466 - dense_498_accuracy: 0.3746 - dense_499_accuracy: 0.2834 - dense_500_accuracy: 0.2432 - dense_501_accuracy: 0.2512 - dense_502_accuracy: 0.3786 - dense_503_accuracy: 0.3798 - dense_504_accuracy: 0.3594 - dense_505_accuracy: 0.3686\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.4260 - dense_496_loss: 1.2901 - dense_497_loss: 1.4861 - dense_498_loss: 1.2898 - dense_499_loss: 1.4080 - dense_500_loss: 1.4936 - dense_501_loss: 1.4780 - dense_502_loss: 1.2835 - dense_503_loss: 1.2134 - dense_504_loss: 1.2412 - dense_505_loss: 1.2422 - dense_496_accuracy: 0.3654 - dense_497_accuracy: 0.2522 - dense_498_accuracy: 0.3742 - dense_499_accuracy: 0.2870 - dense_500_accuracy: 0.2508 - dense_501_accuracy: 0.2478 - dense_502_accuracy: 0.3764 - dense_503_accuracy: 0.3734 - dense_504_accuracy: 0.3628 - dense_505_accuracy: 0.3730\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.4500 - dense_496_loss: 1.2931 - dense_497_loss: 1.4884 - dense_498_loss: 1.2941 - dense_499_loss: 1.4090 - dense_500_loss: 1.4960 - dense_501_loss: 1.4811 - dense_502_loss: 1.2865 - dense_503_loss: 1.2149 - dense_504_loss: 1.2409 - dense_505_loss: 1.2461 - dense_496_accuracy: 0.3564 - dense_497_accuracy: 0.2474 - dense_498_accuracy: 0.3698 - dense_499_accuracy: 0.2834 - dense_500_accuracy: 0.2444 - dense_501_accuracy: 0.2452 - dense_502_accuracy: 0.3768 - dense_503_accuracy: 0.3754 - dense_504_accuracy: 0.3638 - dense_505_accuracy: 0.3764\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.4170 - dense_496_loss: 1.2915 - dense_497_loss: 1.4844 - dense_498_loss: 1.2901 - dense_499_loss: 1.4079 - dense_500_loss: 1.4918 - dense_501_loss: 1.4774 - dense_502_loss: 1.2827 - dense_503_loss: 1.2115 - dense_504_loss: 1.2385 - dense_505_loss: 1.2412 - dense_496_accuracy: 0.3540 - dense_497_accuracy: 0.2508 - dense_498_accuracy: 0.3684 - dense_499_accuracy: 0.2828 - dense_500_accuracy: 0.2426 - dense_501_accuracy: 0.2436 - dense_502_accuracy: 0.3746 - dense_503_accuracy: 0.3796 - dense_504_accuracy: 0.3652 - dense_505_accuracy: 0.3788\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 13.4264 - dense_496_loss: 1.2928 - dense_497_loss: 1.4853 - dense_498_loss: 1.2915 - dense_499_loss: 1.4063 - dense_500_loss: 1.4915 - dense_501_loss: 1.4780 - dense_502_loss: 1.2863 - dense_503_loss: 1.2116 - dense_504_loss: 1.2406 - dense_505_loss: 1.2425 - dense_496_accuracy: 0.3724 - dense_497_accuracy: 0.2624 - dense_498_accuracy: 0.3834 - dense_499_accuracy: 0.3028 - dense_500_accuracy: 0.2626 - dense_501_accuracy: 0.2654 - dense_502_accuracy: 0.3788 - dense_503_accuracy: 0.3912 - dense_504_accuracy: 0.3786 - dense_505_accuracy: 0.3860\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.4017 - dense_496_loss: 1.2898 - dense_497_loss: 1.4821 - dense_498_loss: 1.2911 - dense_499_loss: 1.4044 - dense_500_loss: 1.4901 - dense_501_loss: 1.4748 - dense_502_loss: 1.2828 - dense_503_loss: 1.2075 - dense_504_loss: 1.2375 - dense_505_loss: 1.2417 - dense_496_accuracy: 0.3584 - dense_497_accuracy: 0.2558 - dense_498_accuracy: 0.3712 - dense_499_accuracy: 0.2912 - dense_500_accuracy: 0.2512 - dense_501_accuracy: 0.2540 - dense_502_accuracy: 0.3782 - dense_503_accuracy: 0.3872 - dense_504_accuracy: 0.3644 - dense_505_accuracy: 0.3874\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.4420 - dense_496_loss: 1.2945 - dense_497_loss: 1.4848 - dense_498_loss: 1.2942 - dense_499_loss: 1.4060 - dense_500_loss: 1.4928 - dense_501_loss: 1.4805 - dense_502_loss: 1.2874 - dense_503_loss: 1.2141 - dense_504_loss: 1.2444 - dense_505_loss: 1.2433 - dense_496_accuracy: 0.3640 - dense_497_accuracy: 0.2652 - dense_498_accuracy: 0.3774 - dense_499_accuracy: 0.2878 - dense_500_accuracy: 0.2624 - dense_501_accuracy: 0.2588 - dense_502_accuracy: 0.3806 - dense_503_accuracy: 0.3884 - dense_504_accuracy: 0.3712 - dense_505_accuracy: 0.3834\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.3677 - dense_496_loss: 1.2850 - dense_497_loss: 1.4791 - dense_498_loss: 1.2868 - dense_499_loss: 1.4025 - dense_500_loss: 1.4855 - dense_501_loss: 1.4717 - dense_502_loss: 1.2789 - dense_503_loss: 1.2028 - dense_504_loss: 1.2381 - dense_505_loss: 1.2372 - dense_496_accuracy: 0.3690 - dense_497_accuracy: 0.2600 - dense_498_accuracy: 0.3790 - dense_499_accuracy: 0.2952 - dense_500_accuracy: 0.2588 - dense_501_accuracy: 0.2620 - dense_502_accuracy: 0.3820 - dense_503_accuracy: 0.3908 - dense_504_accuracy: 0.3690 - dense_505_accuracy: 0.3804\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.3478 - dense_496_loss: 1.2872 - dense_497_loss: 1.4773 - dense_498_loss: 1.2845 - dense_499_loss: 1.3983 - dense_500_loss: 1.4848 - dense_501_loss: 1.4690 - dense_502_loss: 1.2747 - dense_503_loss: 1.2017 - dense_504_loss: 1.2358 - dense_505_loss: 1.2345 - dense_496_accuracy: 0.3800 - dense_497_accuracy: 0.2616 - dense_498_accuracy: 0.3840 - dense_499_accuracy: 0.3052 - dense_500_accuracy: 0.2624 - dense_501_accuracy: 0.2614 - dense_502_accuracy: 0.3818 - dense_503_accuracy: 0.3920 - dense_504_accuracy: 0.3640 - dense_505_accuracy: 0.3824\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.2621 - dense_496_loss: 1.2797 - dense_497_loss: 1.4664 - dense_498_loss: 1.2782 - dense_499_loss: 1.3875 - dense_500_loss: 1.4724 - dense_501_loss: 1.4583 - dense_502_loss: 1.2666 - dense_503_loss: 1.1932 - dense_504_loss: 1.2286 - dense_505_loss: 1.2312 - dense_496_accuracy: 0.3804 - dense_497_accuracy: 0.2856 - dense_498_accuracy: 0.3902 - dense_499_accuracy: 0.3106 - dense_500_accuracy: 0.2766 - dense_501_accuracy: 0.2776 - dense_502_accuracy: 0.3948 - dense_503_accuracy: 0.4054 - dense_504_accuracy: 0.3842 - dense_505_accuracy: 0.3980\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.2533 - dense_496_loss: 1.2781 - dense_497_loss: 1.4649 - dense_498_loss: 1.2778 - dense_499_loss: 1.3868 - dense_500_loss: 1.4720 - dense_501_loss: 1.4575 - dense_502_loss: 1.2664 - dense_503_loss: 1.1917 - dense_504_loss: 1.2290 - dense_505_loss: 1.2292 - dense_496_accuracy: 0.3706 - dense_497_accuracy: 0.2648 - dense_498_accuracy: 0.3824 - dense_499_accuracy: 0.3080 - dense_500_accuracy: 0.2706 - dense_501_accuracy: 0.2628 - dense_502_accuracy: 0.3914 - dense_503_accuracy: 0.3990 - dense_504_accuracy: 0.3710 - dense_505_accuracy: 0.3840\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4DC7948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4DC7948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4B8FEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4B8FEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 14ms/step - loss: 0.2486\n",
      "Epoch 2/25\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2436\n",
      "Epoch 3/25\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2336\n",
      "Epoch 4/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2133\n",
      "Epoch 5/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1790\n",
      "Epoch 6/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1300\n",
      "Epoch 7/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0777\n",
      "Epoch 8/25\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0400\n",
      "Epoch 9/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0225\n",
      "Epoch 10/25\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0141\n",
      "Epoch 11/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0112\n",
      "Epoch 12/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0097\n",
      "Epoch 13/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0083\n",
      "Epoch 14/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0076\n",
      "Epoch 15/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0073\n",
      "Epoch 16/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0069\n",
      "Epoch 17/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0068\n",
      "Epoch 18/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0065\n",
      "Epoch 19/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0064\n",
      "Epoch 20/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0063\n",
      "Epoch 21/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0062\n",
      "Epoch 22/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0062\n",
      "Epoch 23/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0061\n",
      "Epoch 24/25\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0060\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0060\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4F929D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4F929D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - 4s 8ms/step - loss: 23.2745 - dense_509_loss: 1.9781 - dense_510_loss: 2.7207 - dense_511_loss: 2.2661 - dense_512_loss: 2.2182 - dense_513_loss: 2.7564 - dense_514_loss: 2.7144 - dense_515_loss: 2.2976 - dense_516_loss: 2.3363 - dense_517_loss: 2.1240 - dense_518_loss: 1.8628 - dense_509_accuracy: 0.2830 - dense_510_accuracy: 0.0910 - dense_511_accuracy: 0.1940 - dense_512_accuracy: 0.1350 - dense_513_accuracy: 0.0840 - dense_514_accuracy: 0.1060 - dense_515_accuracy: 0.1240 - dense_516_accuracy: 0.1300 - dense_517_accuracy: 0.3030 - dense_518_accuracy: 0.3860\n",
      "Epoch 2/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 18.7268 - dense_509_loss: 1.6862 - dense_510_loss: 2.1505 - dense_511_loss: 1.8004 - dense_512_loss: 1.8501 - dense_513_loss: 2.2044 - dense_514_loss: 2.2267 - dense_515_loss: 1.8964 - dense_516_loss: 1.9700 - dense_517_loss: 1.5176 - dense_518_loss: 1.4245 - dense_509_accuracy: 0.3340 - dense_510_accuracy: 0.1880 - dense_511_accuracy: 0.3350 - dense_512_accuracy: 0.2070 - dense_513_accuracy: 0.1770 - dense_514_accuracy: 0.2030 - dense_515_accuracy: 0.2430 - dense_516_accuracy: 0.2010 - dense_517_accuracy: 0.4270 - dense_518_accuracy: 0.4830\n",
      "Epoch 3/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 16.0924 - dense_509_loss: 1.5544 - dense_510_loss: 1.7705 - dense_511_loss: 1.5191 - dense_512_loss: 1.6851 - dense_513_loss: 1.8178 - dense_514_loss: 1.8469 - dense_515_loss: 1.6335 - dense_516_loss: 1.7475 - dense_517_loss: 1.2367 - dense_518_loss: 1.2809 - dense_509_accuracy: 0.3610 - dense_510_accuracy: 0.2040 - dense_511_accuracy: 0.3610 - dense_512_accuracy: 0.2190 - dense_513_accuracy: 0.2290 - dense_514_accuracy: 0.2240 - dense_515_accuracy: 0.2780 - dense_516_accuracy: 0.2050 - dense_517_accuracy: 0.4990 - dense_518_accuracy: 0.5020\n",
      "Epoch 4/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 15.3341 - dense_509_loss: 1.4690 - dense_510_loss: 1.6799 - dense_511_loss: 1.4685 - dense_512_loss: 1.6295 - dense_513_loss: 1.7403 - dense_514_loss: 1.7569 - dense_515_loss: 1.5702 - dense_516_loss: 1.6380 - dense_517_loss: 1.1792 - dense_518_loss: 1.2026 - dense_509_accuracy: 0.3330 - dense_510_accuracy: 0.2660 - dense_511_accuracy: 0.3770 - dense_512_accuracy: 0.2380 - dense_513_accuracy: 0.2440 - dense_514_accuracy: 0.2540 - dense_515_accuracy: 0.2730 - dense_516_accuracy: 0.2310 - dense_517_accuracy: 0.5100 - dense_518_accuracy: 0.5300\n",
      "Epoch 5/25\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 15.0087 - dense_509_loss: 1.4256 - dense_510_loss: 1.6430 - dense_511_loss: 1.4383 - dense_512_loss: 1.6013 - dense_513_loss: 1.7083 - dense_514_loss: 1.7114 - dense_515_loss: 1.5454 - dense_516_loss: 1.6004 - dense_517_loss: 1.1526 - dense_518_loss: 1.1824 - dense_509_accuracy: 0.3770 - dense_510_accuracy: 0.2100 - dense_511_accuracy: 0.3780 - dense_512_accuracy: 0.2570 - dense_513_accuracy: 0.2460 - dense_514_accuracy: 0.2610 - dense_515_accuracy: 0.2970 - dense_516_accuracy: 0.2320 - dense_517_accuracy: 0.5090 - dense_518_accuracy: 0.5280\n",
      "Epoch 6/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.7946 - dense_509_loss: 1.4057 - dense_510_loss: 1.6207 - dense_511_loss: 1.4339 - dense_512_loss: 1.5738 - dense_513_loss: 1.6793 - dense_514_loss: 1.6833 - dense_515_loss: 1.5324 - dense_516_loss: 1.5801 - dense_517_loss: 1.1375 - dense_518_loss: 1.1479 - dense_509_accuracy: 0.3580 - dense_510_accuracy: 0.2580 - dense_511_accuracy: 0.3780 - dense_512_accuracy: 0.2520 - dense_513_accuracy: 0.2510 - dense_514_accuracy: 0.2490 - dense_515_accuracy: 0.2860 - dense_516_accuracy: 0.2530 - dense_517_accuracy: 0.5040 - dense_518_accuracy: 0.5370\n",
      "Epoch 7/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.6037 - dense_509_loss: 1.4002 - dense_510_loss: 1.6068 - dense_511_loss: 1.4125 - dense_512_loss: 1.5506 - dense_513_loss: 1.6583 - dense_514_loss: 1.6622 - dense_515_loss: 1.5005 - dense_516_loss: 1.5658 - dense_517_loss: 1.1180 - dense_518_loss: 1.1288 - dense_509_accuracy: 0.3730 - dense_510_accuracy: 0.2640 - dense_511_accuracy: 0.3850 - dense_512_accuracy: 0.2820 - dense_513_accuracy: 0.2590 - dense_514_accuracy: 0.2710 - dense_515_accuracy: 0.2990 - dense_516_accuracy: 0.2720 - dense_517_accuracy: 0.5250 - dense_518_accuracy: 0.5340\n",
      "Epoch 8/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.4487 - dense_509_loss: 1.3962 - dense_510_loss: 1.5829 - dense_511_loss: 1.3933 - dense_512_loss: 1.5339 - dense_513_loss: 1.6396 - dense_514_loss: 1.6470 - dense_515_loss: 1.4798 - dense_516_loss: 1.5601 - dense_517_loss: 1.1097 - dense_518_loss: 1.1060 - dense_509_accuracy: 0.3810 - dense_510_accuracy: 0.2760 - dense_511_accuracy: 0.3930 - dense_512_accuracy: 0.2890 - dense_513_accuracy: 0.2840 - dense_514_accuracy: 0.2720 - dense_515_accuracy: 0.3170 - dense_516_accuracy: 0.2570 - dense_517_accuracy: 0.5320 - dense_518_accuracy: 0.5550\n",
      "Epoch 9/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.3458 - dense_509_loss: 1.3907 - dense_510_loss: 1.5684 - dense_511_loss: 1.3811 - dense_512_loss: 1.5220 - dense_513_loss: 1.6339 - dense_514_loss: 1.6381 - dense_515_loss: 1.4640 - dense_516_loss: 1.5448 - dense_517_loss: 1.1004 - dense_518_loss: 1.1023 - dense_509_accuracy: 0.3740 - dense_510_accuracy: 0.3060 - dense_511_accuracy: 0.4070 - dense_512_accuracy: 0.2970 - dense_513_accuracy: 0.2990 - dense_514_accuracy: 0.3040 - dense_515_accuracy: 0.3370 - dense_516_accuracy: 0.2880 - dense_517_accuracy: 0.5390 - dense_518_accuracy: 0.5600\n",
      "Epoch 10/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.2450 - dense_509_loss: 1.3788 - dense_510_loss: 1.5550 - dense_511_loss: 1.3793 - dense_512_loss: 1.5092 - dense_513_loss: 1.6117 - dense_514_loss: 1.6241 - dense_515_loss: 1.4602 - dense_516_loss: 1.5283 - dense_517_loss: 1.0992 - dense_518_loss: 1.0991 - dense_509_accuracy: 0.3990 - dense_510_accuracy: 0.3140 - dense_511_accuracy: 0.3920 - dense_512_accuracy: 0.3290 - dense_513_accuracy: 0.2980 - dense_514_accuracy: 0.3120 - dense_515_accuracy: 0.3320 - dense_516_accuracy: 0.2940 - dense_517_accuracy: 0.5370 - dense_518_accuracy: 0.5530\n",
      "Epoch 11/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.1869 - dense_509_loss: 1.3763 - dense_510_loss: 1.5484 - dense_511_loss: 1.3818 - dense_512_loss: 1.5017 - dense_513_loss: 1.6003 - dense_514_loss: 1.6113 - dense_515_loss: 1.4573 - dense_516_loss: 1.5247 - dense_517_loss: 1.0974 - dense_518_loss: 1.0877 - dense_509_accuracy: 0.3930 - dense_510_accuracy: 0.3090 - dense_511_accuracy: 0.3940 - dense_512_accuracy: 0.3160 - dense_513_accuracy: 0.3180 - dense_514_accuracy: 0.3050 - dense_515_accuracy: 0.3330 - dense_516_accuracy: 0.3080 - dense_517_accuracy: 0.5370 - dense_518_accuracy: 0.5610\n",
      "Epoch 12/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.1426 - dense_509_loss: 1.3785 - dense_510_loss: 1.5447 - dense_511_loss: 1.3730 - dense_512_loss: 1.5007 - dense_513_loss: 1.5934 - dense_514_loss: 1.6099 - dense_515_loss: 1.4482 - dense_516_loss: 1.5127 - dense_517_loss: 1.0913 - dense_518_loss: 1.0901 - dense_509_accuracy: 0.3880 - dense_510_accuracy: 0.3190 - dense_511_accuracy: 0.3950 - dense_512_accuracy: 0.3320 - dense_513_accuracy: 0.3180 - dense_514_accuracy: 0.3280 - dense_515_accuracy: 0.3660 - dense_516_accuracy: 0.3220 - dense_517_accuracy: 0.5450 - dense_518_accuracy: 0.5560\n",
      "Epoch 13/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.1230 - dense_509_loss: 1.3761 - dense_510_loss: 1.5399 - dense_511_loss: 1.3680 - dense_512_loss: 1.4993 - dense_513_loss: 1.5904 - dense_514_loss: 1.6127 - dense_515_loss: 1.4398 - dense_516_loss: 1.5109 - dense_517_loss: 1.0923 - dense_518_loss: 1.0937 - dense_509_accuracy: 0.4120 - dense_510_accuracy: 0.3250 - dense_511_accuracy: 0.4210 - dense_512_accuracy: 0.3200 - dense_513_accuracy: 0.3090 - dense_514_accuracy: 0.3160 - dense_515_accuracy: 0.3600 - dense_516_accuracy: 0.3280 - dense_517_accuracy: 0.5460 - dense_518_accuracy: 0.5490\n",
      "Epoch 14/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 13.8262 - dense_509_loss: 1.3485 - dense_510_loss: 1.4968 - dense_511_loss: 1.3361 - dense_512_loss: 1.4713 - dense_513_loss: 1.5590 - dense_514_loss: 1.5760 - dense_515_loss: 1.4169 - dense_516_loss: 1.4880 - dense_517_loss: 1.0657 - dense_518_loss: 1.0679 - dense_509_accuracy: 0.4160 - dense_510_accuracy: 0.3460 - dense_511_accuracy: 0.4240 - dense_512_accuracy: 0.3430 - dense_513_accuracy: 0.3410 - dense_514_accuracy: 0.3450 - dense_515_accuracy: 0.3670 - dense_516_accuracy: 0.3350 - dense_517_accuracy: 0.5730 - dense_518_accuracy: 0.5710\n",
      "Epoch 15/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 13.6431 - dense_509_loss: 1.3287 - dense_510_loss: 1.4768 - dense_511_loss: 1.3292 - dense_512_loss: 1.4522 - dense_513_loss: 1.5393 - dense_514_loss: 1.5507 - dense_515_loss: 1.3965 - dense_516_loss: 1.4628 - dense_517_loss: 1.0537 - dense_518_loss: 1.0531 - dense_509_accuracy: 0.4340 - dense_510_accuracy: 0.3580 - dense_511_accuracy: 0.4480 - dense_512_accuracy: 0.3540 - dense_513_accuracy: 0.3660 - dense_514_accuracy: 0.3620 - dense_515_accuracy: 0.4060 - dense_516_accuracy: 0.3640 - dense_517_accuracy: 0.5740 - dense_518_accuracy: 0.5790\n",
      "Epoch 16/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 13.7632 - dense_509_loss: 1.3406 - dense_510_loss: 1.4803 - dense_511_loss: 1.3309 - dense_512_loss: 1.4743 - dense_513_loss: 1.5510 - dense_514_loss: 1.5645 - dense_515_loss: 1.4012 - dense_516_loss: 1.4759 - dense_517_loss: 1.0752 - dense_518_loss: 1.0694 - dense_509_accuracy: 0.4460 - dense_510_accuracy: 0.3660 - dense_511_accuracy: 0.4520 - dense_512_accuracy: 0.3610 - dense_513_accuracy: 0.3680 - dense_514_accuracy: 0.3600 - dense_515_accuracy: 0.3970 - dense_516_accuracy: 0.3510 - dense_517_accuracy: 0.5480 - dense_518_accuracy: 0.5840\n",
      "Epoch 17/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 13.5104 - dense_509_loss: 1.3189 - dense_510_loss: 1.4584 - dense_511_loss: 1.2968 - dense_512_loss: 1.4443 - dense_513_loss: 1.5206 - dense_514_loss: 1.5372 - dense_515_loss: 1.3800 - dense_516_loss: 1.4572 - dense_517_loss: 1.0545 - dense_518_loss: 1.0426 - dense_509_accuracy: 0.4280 - dense_510_accuracy: 0.3740 - dense_511_accuracy: 0.4560 - dense_512_accuracy: 0.3580 - dense_513_accuracy: 0.3740 - dense_514_accuracy: 0.3680 - dense_515_accuracy: 0.4050 - dense_516_accuracy: 0.3750 - dense_517_accuracy: 0.5700 - dense_518_accuracy: 0.5920\n",
      "Epoch 18/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 13.3154 - dense_509_loss: 1.2893 - dense_510_loss: 1.4373 - dense_511_loss: 1.2831 - dense_512_loss: 1.4298 - dense_513_loss: 1.5021 - dense_514_loss: 1.5166 - dense_515_loss: 1.3642 - dense_516_loss: 1.4340 - dense_517_loss: 1.0351 - dense_518_loss: 1.0239 - dense_509_accuracy: 0.4630 - dense_510_accuracy: 0.3910 - dense_511_accuracy: 0.4710 - dense_512_accuracy: 0.3800 - dense_513_accuracy: 0.3910 - dense_514_accuracy: 0.3880 - dense_515_accuracy: 0.4060 - dense_516_accuracy: 0.3880 - dense_517_accuracy: 0.5890 - dense_518_accuracy: 0.5820\n",
      "Epoch 19/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 13.1746 - dense_509_loss: 1.2785 - dense_510_loss: 1.4194 - dense_511_loss: 1.2687 - dense_512_loss: 1.4107 - dense_513_loss: 1.4818 - dense_514_loss: 1.4973 - dense_515_loss: 1.3555 - dense_516_loss: 1.4247 - dense_517_loss: 1.0283 - dense_518_loss: 1.0098 - dense_509_accuracy: 0.4700 - dense_510_accuracy: 0.4030 - dense_511_accuracy: 0.4790 - dense_512_accuracy: 0.3930 - dense_513_accuracy: 0.3870 - dense_514_accuracy: 0.4100 - dense_515_accuracy: 0.4300 - dense_516_accuracy: 0.4010 - dense_517_accuracy: 0.5970 - dense_518_accuracy: 0.6110\n",
      "Epoch 20/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 12.9325 - dense_509_loss: 1.2539 - dense_510_loss: 1.3883 - dense_511_loss: 1.2414 - dense_512_loss: 1.3766 - dense_513_loss: 1.4571 - dense_514_loss: 1.4674 - dense_515_loss: 1.3385 - dense_516_loss: 1.4053 - dense_517_loss: 1.0091 - dense_518_loss: 0.9950 - dense_509_accuracy: 0.4840 - dense_510_accuracy: 0.4270 - dense_511_accuracy: 0.4990 - dense_512_accuracy: 0.4140 - dense_513_accuracy: 0.4120 - dense_514_accuracy: 0.4230 - dense_515_accuracy: 0.4370 - dense_516_accuracy: 0.4150 - dense_517_accuracy: 0.5990 - dense_518_accuracy: 0.6070\n",
      "Epoch 21/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 12.6814 - dense_509_loss: 1.2286 - dense_510_loss: 1.3552 - dense_511_loss: 1.2155 - dense_512_loss: 1.3653 - dense_513_loss: 1.4281 - dense_514_loss: 1.4377 - dense_515_loss: 1.2992 - dense_516_loss: 1.3746 - dense_517_loss: 0.9973 - dense_518_loss: 0.9800 - dense_509_accuracy: 0.5040 - dense_510_accuracy: 0.4450 - dense_511_accuracy: 0.5140 - dense_512_accuracy: 0.4370 - dense_513_accuracy: 0.4460 - dense_514_accuracy: 0.4450 - dense_515_accuracy: 0.4680 - dense_516_accuracy: 0.4320 - dense_517_accuracy: 0.5990 - dense_518_accuracy: 0.6230\n",
      "Epoch 22/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 12.4846 - dense_509_loss: 1.2207 - dense_510_loss: 1.3332 - dense_511_loss: 1.1992 - dense_512_loss: 1.3335 - dense_513_loss: 1.4046 - dense_514_loss: 1.4205 - dense_515_loss: 1.2838 - dense_516_loss: 1.3487 - dense_517_loss: 0.9785 - dense_518_loss: 0.9621 - dense_509_accuracy: 0.4950 - dense_510_accuracy: 0.4630 - dense_511_accuracy: 0.5110 - dense_512_accuracy: 0.4430 - dense_513_accuracy: 0.4590 - dense_514_accuracy: 0.4400 - dense_515_accuracy: 0.4590 - dense_516_accuracy: 0.4460 - dense_517_accuracy: 0.6280 - dense_518_accuracy: 0.6350\n",
      "Epoch 23/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 12.3736 - dense_509_loss: 1.2062 - dense_510_loss: 1.3257 - dense_511_loss: 1.1936 - dense_512_loss: 1.3252 - dense_513_loss: 1.3914 - dense_514_loss: 1.3993 - dense_515_loss: 1.2748 - dense_516_loss: 1.3291 - dense_517_loss: 0.9744 - dense_518_loss: 0.9539 - dense_509_accuracy: 0.4900 - dense_510_accuracy: 0.4620 - dense_511_accuracy: 0.5330 - dense_512_accuracy: 0.4650 - dense_513_accuracy: 0.4690 - dense_514_accuracy: 0.4560 - dense_515_accuracy: 0.4640 - dense_516_accuracy: 0.4490 - dense_517_accuracy: 0.6270 - dense_518_accuracy: 0.6430\n",
      "Epoch 24/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 12.3412 - dense_509_loss: 1.1985 - dense_510_loss: 1.3207 - dense_511_loss: 1.1868 - dense_512_loss: 1.3168 - dense_513_loss: 1.3945 - dense_514_loss: 1.3996 - dense_515_loss: 1.2594 - dense_516_loss: 1.3409 - dense_517_loss: 0.9731 - dense_518_loss: 0.9508 - dense_509_accuracy: 0.5200 - dense_510_accuracy: 0.4720 - dense_511_accuracy: 0.5310 - dense_512_accuracy: 0.4550 - dense_513_accuracy: 0.4570 - dense_514_accuracy: 0.4660 - dense_515_accuracy: 0.4810 - dense_516_accuracy: 0.4570 - dense_517_accuracy: 0.6220 - dense_518_accuracy: 0.6490\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 12.0369 - dense_509_loss: 1.1681 - dense_510_loss: 1.2882 - dense_511_loss: 1.1610 - dense_512_loss: 1.2957 - dense_513_loss: 1.3561 - dense_514_loss: 1.3604 - dense_515_loss: 1.2290 - dense_516_loss: 1.2972 - dense_517_loss: 0.9526 - dense_518_loss: 0.9284 - dense_509_accuracy: 0.5290 - dense_510_accuracy: 0.4860 - dense_511_accuracy: 0.5450 - dense_512_accuracy: 0.4700 - dense_513_accuracy: 0.4950 - dense_514_accuracy: 0.4890 - dense_515_accuracy: 0.5110 - dense_516_accuracy: 0.4810 - dense_517_accuracy: 0.6320 - dense_518_accuracy: 0.6460\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D38B15E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D38B15E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3717948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3717948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - 3s 7ms/step - loss: 23.3011 - dense_519_loss: 1.9770 - dense_520_loss: 2.7200 - dense_521_loss: 2.2870 - dense_522_loss: 2.2187 - dense_523_loss: 2.7133 - dense_524_loss: 2.7765 - dense_525_loss: 2.2684 - dense_526_loss: 2.3334 - dense_527_loss: 2.1225 - dense_528_loss: 1.8844 - dense_519_accuracy: 0.2700 - dense_520_accuracy: 0.0930 - dense_521_accuracy: 0.1870 - dense_522_accuracy: 0.1620 - dense_523_accuracy: 0.1010 - dense_524_accuracy: 0.0980 - dense_525_accuracy: 0.1870 - dense_526_accuracy: 0.1150 - dense_527_accuracy: 0.3290 - dense_528_accuracy: 0.4000\n",
      "Epoch 2/25\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 18.1580 - dense_519_loss: 1.6746 - dense_520_loss: 2.0903 - dense_521_loss: 1.7662 - dense_522_loss: 1.8600 - dense_523_loss: 2.0649 - dense_524_loss: 2.1954 - dense_525_loss: 1.7963 - dense_526_loss: 1.8802 - dense_527_loss: 1.4460 - dense_528_loss: 1.3842 - dense_519_accuracy: 0.3410 - dense_520_accuracy: 0.2180 - dense_521_accuracy: 0.3570 - dense_522_accuracy: 0.2310 - dense_523_accuracy: 0.1840 - dense_524_accuracy: 0.2090 - dense_525_accuracy: 0.2570 - dense_526_accuracy: 0.1950 - dense_527_accuracy: 0.4660 - dense_528_accuracy: 0.4880\n",
      "Epoch 3/25\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 15.7677 - dense_519_loss: 1.5096 - dense_520_loss: 1.7402 - dense_521_loss: 1.4973 - dense_522_loss: 1.6500 - dense_523_loss: 1.7879 - dense_524_loss: 1.8165 - dense_525_loss: 1.6181 - dense_526_loss: 1.7008 - dense_527_loss: 1.2199 - dense_528_loss: 1.2274 - dense_519_accuracy: 0.3590 - dense_520_accuracy: 0.2360 - dense_521_accuracy: 0.3740 - dense_522_accuracy: 0.2400 - dense_523_accuracy: 0.2230 - dense_524_accuracy: 0.2180 - dense_525_accuracy: 0.2650 - dense_526_accuracy: 0.2500 - dense_527_accuracy: 0.5020 - dense_528_accuracy: 0.5320\n",
      "Epoch 4/25\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 15.1250 - dense_519_loss: 1.4392 - dense_520_loss: 1.6615 - dense_521_loss: 1.4388 - dense_522_loss: 1.6082 - dense_523_loss: 1.7174 - dense_524_loss: 1.7301 - dense_525_loss: 1.5511 - dense_526_loss: 1.6226 - dense_527_loss: 1.1646 - dense_528_loss: 1.1915 - dense_519_accuracy: 0.3770 - dense_520_accuracy: 0.2370 - dense_521_accuracy: 0.3850 - dense_522_accuracy: 0.2280 - dense_523_accuracy: 0.2440 - dense_524_accuracy: 0.2480 - dense_525_accuracy: 0.2820 - dense_526_accuracy: 0.2460 - dense_527_accuracy: 0.5040 - dense_528_accuracy: 0.5040\n",
      "Epoch 5/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.7845 - dense_519_loss: 1.4141 - dense_520_loss: 1.6147 - dense_521_loss: 1.4183 - dense_522_loss: 1.5810 - dense_523_loss: 1.6744 - dense_524_loss: 1.6896 - dense_525_loss: 1.5140 - dense_526_loss: 1.5800 - dense_527_loss: 1.1415 - dense_528_loss: 1.1571 - dense_519_accuracy: 0.3410 - dense_520_accuracy: 0.2580 - dense_521_accuracy: 0.3640 - dense_522_accuracy: 0.2400 - dense_523_accuracy: 0.2620 - dense_524_accuracy: 0.2600 - dense_525_accuracy: 0.2990 - dense_526_accuracy: 0.2530 - dense_527_accuracy: 0.5110 - dense_528_accuracy: 0.5360\n",
      "Epoch 6/25\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 14.7068 - dense_519_loss: 1.4023 - dense_520_loss: 1.6133 - dense_521_loss: 1.4172 - dense_522_loss: 1.5617 - dense_523_loss: 1.6708 - dense_524_loss: 1.6790 - dense_525_loss: 1.5075 - dense_526_loss: 1.5764 - dense_527_loss: 1.1392 - dense_528_loss: 1.1394 - dense_519_accuracy: 0.3740 - dense_520_accuracy: 0.2290 - dense_521_accuracy: 0.3390 - dense_522_accuracy: 0.2230 - dense_523_accuracy: 0.2300 - dense_524_accuracy: 0.2190 - dense_525_accuracy: 0.2910 - dense_526_accuracy: 0.2340 - dense_527_accuracy: 0.4850 - dense_528_accuracy: 0.5370\n",
      "Epoch 7/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.6619 - dense_519_loss: 1.4015 - dense_520_loss: 1.6091 - dense_521_loss: 1.4151 - dense_522_loss: 1.5562 - dense_523_loss: 1.6654 - dense_524_loss: 1.6763 - dense_525_loss: 1.5027 - dense_526_loss: 1.5698 - dense_527_loss: 1.1351 - dense_528_loss: 1.1306 - dense_519_accuracy: 0.3620 - dense_520_accuracy: 0.2500 - dense_521_accuracy: 0.3800 - dense_522_accuracy: 0.2480 - dense_523_accuracy: 0.2510 - dense_524_accuracy: 0.2640 - dense_525_accuracy: 0.2890 - dense_526_accuracy: 0.2510 - dense_527_accuracy: 0.5100 - dense_528_accuracy: 0.5420\n",
      "Epoch 8/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.5927 - dense_519_loss: 1.4045 - dense_520_loss: 1.6046 - dense_521_loss: 1.4125 - dense_522_loss: 1.5621 - dense_523_loss: 1.6449 - dense_524_loss: 1.6637 - dense_525_loss: 1.4855 - dense_526_loss: 1.5663 - dense_527_loss: 1.1313 - dense_528_loss: 1.1175 - dense_519_accuracy: 0.3660 - dense_520_accuracy: 0.2280 - dense_521_accuracy: 0.3750 - dense_522_accuracy: 0.2380 - dense_523_accuracy: 0.2440 - dense_524_accuracy: 0.2100 - dense_525_accuracy: 0.2890 - dense_526_accuracy: 0.2470 - dense_527_accuracy: 0.4900 - dense_528_accuracy: 0.5400\n",
      "Epoch 9/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.5381 - dense_519_loss: 1.3995 - dense_520_loss: 1.5982 - dense_521_loss: 1.3995 - dense_522_loss: 1.5522 - dense_523_loss: 1.6415 - dense_524_loss: 1.6577 - dense_525_loss: 1.4934 - dense_526_loss: 1.5563 - dense_527_loss: 1.1184 - dense_528_loss: 1.1214 - dense_519_accuracy: 0.3680 - dense_520_accuracy: 0.2420 - dense_521_accuracy: 0.3770 - dense_522_accuracy: 0.2390 - dense_523_accuracy: 0.2440 - dense_524_accuracy: 0.2460 - dense_525_accuracy: 0.2910 - dense_526_accuracy: 0.2630 - dense_527_accuracy: 0.5080 - dense_528_accuracy: 0.5340\n",
      "Epoch 10/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.4919 - dense_519_loss: 1.3963 - dense_520_loss: 1.5889 - dense_521_loss: 1.3973 - dense_522_loss: 1.5453 - dense_523_loss: 1.6392 - dense_524_loss: 1.6531 - dense_525_loss: 1.4852 - dense_526_loss: 1.5550 - dense_527_loss: 1.1105 - dense_528_loss: 1.1211 - dense_519_accuracy: 0.3580 - dense_520_accuracy: 0.2280 - dense_521_accuracy: 0.3790 - dense_522_accuracy: 0.2440 - dense_523_accuracy: 0.2410 - dense_524_accuracy: 0.2360 - dense_525_accuracy: 0.2720 - dense_526_accuracy: 0.2390 - dense_527_accuracy: 0.5150 - dense_528_accuracy: 0.5380\n",
      "Epoch 11/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.4050 - dense_519_loss: 1.3875 - dense_520_loss: 1.5735 - dense_521_loss: 1.3915 - dense_522_loss: 1.5383 - dense_523_loss: 1.6295 - dense_524_loss: 1.6451 - dense_525_loss: 1.4794 - dense_526_loss: 1.5455 - dense_527_loss: 1.1052 - dense_528_loss: 1.1094 - dense_519_accuracy: 0.3650 - dense_520_accuracy: 0.2610 - dense_521_accuracy: 0.3740 - dense_522_accuracy: 0.2710 - dense_523_accuracy: 0.2680 - dense_524_accuracy: 0.2590 - dense_525_accuracy: 0.2810 - dense_526_accuracy: 0.2480 - dense_527_accuracy: 0.5200 - dense_528_accuracy: 0.5470\n",
      "Epoch 12/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.4178 - dense_519_loss: 1.3892 - dense_520_loss: 1.5741 - dense_521_loss: 1.3916 - dense_522_loss: 1.5435 - dense_523_loss: 1.6323 - dense_524_loss: 1.6449 - dense_525_loss: 1.4812 - dense_526_loss: 1.5489 - dense_527_loss: 1.1032 - dense_528_loss: 1.1089 - dense_519_accuracy: 0.3810 - dense_520_accuracy: 0.2310 - dense_521_accuracy: 0.3830 - dense_522_accuracy: 0.2580 - dense_523_accuracy: 0.2350 - dense_524_accuracy: 0.2530 - dense_525_accuracy: 0.2910 - dense_526_accuracy: 0.2670 - dense_527_accuracy: 0.5130 - dense_528_accuracy: 0.5460\n",
      "Epoch 13/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.4357 - dense_519_loss: 1.3951 - dense_520_loss: 1.5814 - dense_521_loss: 1.3847 - dense_522_loss: 1.5426 - dense_523_loss: 1.6336 - dense_524_loss: 1.6488 - dense_525_loss: 1.4795 - dense_526_loss: 1.5503 - dense_527_loss: 1.1107 - dense_528_loss: 1.1090 - dense_519_accuracy: 0.3600 - dense_520_accuracy: 0.2630 - dense_521_accuracy: 0.3810 - dense_522_accuracy: 0.2740 - dense_523_accuracy: 0.2600 - dense_524_accuracy: 0.2620 - dense_525_accuracy: 0.3060 - dense_526_accuracy: 0.2630 - dense_527_accuracy: 0.5120 - dense_528_accuracy: 0.5420\n",
      "Epoch 14/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.4038 - dense_519_loss: 1.3845 - dense_520_loss: 1.5772 - dense_521_loss: 1.3981 - dense_522_loss: 1.5405 - dense_523_loss: 1.6328 - dense_524_loss: 1.6450 - dense_525_loss: 1.4720 - dense_526_loss: 1.5393 - dense_527_loss: 1.1088 - dense_528_loss: 1.1056 - dense_519_accuracy: 0.3730 - dense_520_accuracy: 0.2530 - dense_521_accuracy: 0.3730 - dense_522_accuracy: 0.2450 - dense_523_accuracy: 0.2760 - dense_524_accuracy: 0.2440 - dense_525_accuracy: 0.2840 - dense_526_accuracy: 0.2710 - dense_527_accuracy: 0.5250 - dense_528_accuracy: 0.5600\n",
      "Epoch 15/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.3539 - dense_519_loss: 1.3852 - dense_520_loss: 1.5669 - dense_521_loss: 1.3834 - dense_522_loss: 1.5350 - dense_523_loss: 1.6260 - dense_524_loss: 1.6365 - dense_525_loss: 1.4678 - dense_526_loss: 1.5414 - dense_527_loss: 1.1016 - dense_528_loss: 1.1101 - dense_519_accuracy: 0.3820 - dense_520_accuracy: 0.2640 - dense_521_accuracy: 0.3870 - dense_522_accuracy: 0.2670 - dense_523_accuracy: 0.2490 - dense_524_accuracy: 0.2680 - dense_525_accuracy: 0.3030 - dense_526_accuracy: 0.2620 - dense_527_accuracy: 0.5150 - dense_528_accuracy: 0.5500\n",
      "Epoch 16/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.3245 - dense_519_loss: 1.3838 - dense_520_loss: 1.5645 - dense_521_loss: 1.3810 - dense_522_loss: 1.5321 - dense_523_loss: 1.6174 - dense_524_loss: 1.6325 - dense_525_loss: 1.4701 - dense_526_loss: 1.5452 - dense_527_loss: 1.0965 - dense_528_loss: 1.1013 - dense_519_accuracy: 0.3760 - dense_520_accuracy: 0.2640 - dense_521_accuracy: 0.3940 - dense_522_accuracy: 0.2640 - dense_523_accuracy: 0.2840 - dense_524_accuracy: 0.2710 - dense_525_accuracy: 0.3160 - dense_526_accuracy: 0.2690 - dense_527_accuracy: 0.5270 - dense_528_accuracy: 0.5510\n",
      "Epoch 17/25\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 14.3906 - dense_519_loss: 1.3838 - dense_520_loss: 1.5705 - dense_521_loss: 1.3983 - dense_522_loss: 1.5356 - dense_523_loss: 1.6228 - dense_524_loss: 1.6415 - dense_525_loss: 1.4750 - dense_526_loss: 1.5570 - dense_527_loss: 1.1021 - dense_528_loss: 1.1041 - dense_519_accuracy: 0.3880 - dense_520_accuracy: 0.2470 - dense_521_accuracy: 0.3890 - dense_522_accuracy: 0.2740 - dense_523_accuracy: 0.2660 - dense_524_accuracy: 0.2520 - dense_525_accuracy: 0.3230 - dense_526_accuracy: 0.2520 - dense_527_accuracy: 0.5180 - dense_528_accuracy: 0.5430\n",
      "Epoch 18/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.2359 - dense_519_loss: 1.3696 - dense_520_loss: 1.5543 - dense_521_loss: 1.3819 - dense_522_loss: 1.5179 - dense_523_loss: 1.6075 - dense_524_loss: 1.6312 - dense_525_loss: 1.4611 - dense_526_loss: 1.5303 - dense_527_loss: 1.0875 - dense_528_loss: 1.0947 - dense_519_accuracy: 0.3950 - dense_520_accuracy: 0.2820 - dense_521_accuracy: 0.3900 - dense_522_accuracy: 0.2950 - dense_523_accuracy: 0.2880 - dense_524_accuracy: 0.2750 - dense_525_accuracy: 0.3280 - dense_526_accuracy: 0.2800 - dense_527_accuracy: 0.5340 - dense_528_accuracy: 0.5630\n",
      "Epoch 19/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.1951 - dense_519_loss: 1.3703 - dense_520_loss: 1.5408 - dense_521_loss: 1.3840 - dense_522_loss: 1.5192 - dense_523_loss: 1.5976 - dense_524_loss: 1.6184 - dense_525_loss: 1.4534 - dense_526_loss: 1.5334 - dense_527_loss: 1.0859 - dense_528_loss: 1.0920 - dense_519_accuracy: 0.4000 - dense_520_accuracy: 0.2870 - dense_521_accuracy: 0.4070 - dense_522_accuracy: 0.2890 - dense_523_accuracy: 0.3090 - dense_524_accuracy: 0.2840 - dense_525_accuracy: 0.3530 - dense_526_accuracy: 0.2660 - dense_527_accuracy: 0.5570 - dense_528_accuracy: 0.5650\n",
      "Epoch 20/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.1281 - dense_519_loss: 1.3690 - dense_520_loss: 1.5363 - dense_521_loss: 1.3729 - dense_522_loss: 1.5073 - dense_523_loss: 1.5926 - dense_524_loss: 1.6145 - dense_525_loss: 1.4515 - dense_526_loss: 1.5194 - dense_527_loss: 1.0801 - dense_528_loss: 1.0844 - dense_519_accuracy: 0.4110 - dense_520_accuracy: 0.2970 - dense_521_accuracy: 0.4170 - dense_522_accuracy: 0.3120 - dense_523_accuracy: 0.3200 - dense_524_accuracy: 0.3030 - dense_525_accuracy: 0.3500 - dense_526_accuracy: 0.2960 - dense_527_accuracy: 0.5320 - dense_528_accuracy: 0.5580\n",
      "Epoch 21/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.0857 - dense_519_loss: 1.3610 - dense_520_loss: 1.5305 - dense_521_loss: 1.3746 - dense_522_loss: 1.5023 - dense_523_loss: 1.5877 - dense_524_loss: 1.6127 - dense_525_loss: 1.4399 - dense_526_loss: 1.5220 - dense_527_loss: 1.0734 - dense_528_loss: 1.0816 - dense_519_accuracy: 0.4120 - dense_520_accuracy: 0.3110 - dense_521_accuracy: 0.4030 - dense_522_accuracy: 0.3060 - dense_523_accuracy: 0.2980 - dense_524_accuracy: 0.2820 - dense_525_accuracy: 0.3470 - dense_526_accuracy: 0.2920 - dense_527_accuracy: 0.5450 - dense_528_accuracy: 0.5680\n",
      "Epoch 22/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.0244 - dense_519_loss: 1.3454 - dense_520_loss: 1.5242 - dense_521_loss: 1.3622 - dense_522_loss: 1.4998 - dense_523_loss: 1.5820 - dense_524_loss: 1.6019 - dense_525_loss: 1.4344 - dense_526_loss: 1.5218 - dense_527_loss: 1.0835 - dense_528_loss: 1.0692 - dense_519_accuracy: 0.4290 - dense_520_accuracy: 0.3220 - dense_521_accuracy: 0.4290 - dense_522_accuracy: 0.3100 - dense_523_accuracy: 0.3130 - dense_524_accuracy: 0.3020 - dense_525_accuracy: 0.3600 - dense_526_accuracy: 0.3090 - dense_527_accuracy: 0.5290 - dense_528_accuracy: 0.5760\n",
      "Epoch 23/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 13.8699 - dense_519_loss: 1.3305 - dense_520_loss: 1.5087 - dense_521_loss: 1.3487 - dense_522_loss: 1.4794 - dense_523_loss: 1.5644 - dense_524_loss: 1.5821 - dense_525_loss: 1.4220 - dense_526_loss: 1.5000 - dense_527_loss: 1.0704 - dense_528_loss: 1.0637 - dense_519_accuracy: 0.4340 - dense_520_accuracy: 0.3360 - dense_521_accuracy: 0.4390 - dense_522_accuracy: 0.3500 - dense_523_accuracy: 0.3400 - dense_524_accuracy: 0.3210 - dense_525_accuracy: 0.3800 - dense_526_accuracy: 0.3200 - dense_527_accuracy: 0.5520 - dense_528_accuracy: 0.5950\n",
      "Epoch 24/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 13.6549 - dense_519_loss: 1.3085 - dense_520_loss: 1.4833 - dense_521_loss: 1.3284 - dense_522_loss: 1.4630 - dense_523_loss: 1.5435 - dense_524_loss: 1.5554 - dense_525_loss: 1.3931 - dense_526_loss: 1.4778 - dense_527_loss: 1.0646 - dense_528_loss: 1.0374 - dense_519_accuracy: 0.4520 - dense_520_accuracy: 0.3470 - dense_521_accuracy: 0.4480 - dense_522_accuracy: 0.3400 - dense_523_accuracy: 0.3460 - dense_524_accuracy: 0.3470 - dense_525_accuracy: 0.3970 - dense_526_accuracy: 0.3390 - dense_527_accuracy: 0.5440 - dense_528_accuracy: 0.5920\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 13.5384 - dense_519_loss: 1.3032 - dense_520_loss: 1.4631 - dense_521_loss: 1.3198 - dense_522_loss: 1.4489 - dense_523_loss: 1.5264 - dense_524_loss: 1.5412 - dense_525_loss: 1.3771 - dense_526_loss: 1.4678 - dense_527_loss: 1.0558 - dense_528_loss: 1.0350 - dense_519_accuracy: 0.4460 - dense_520_accuracy: 0.3710 - dense_521_accuracy: 0.4420 - dense_522_accuracy: 0.3610 - dense_523_accuracy: 0.3590 - dense_524_accuracy: 0.3540 - dense_525_accuracy: 0.4200 - dense_526_accuracy: 0.3690 - dense_527_accuracy: 0.5550 - dense_528_accuracy: 0.5840\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4B8F558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4B8F558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4A8BDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4A8BDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 12ms/step - loss: 0.2485\n",
      "Epoch 2/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2429\n",
      "Epoch 3/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2314\n",
      "Epoch 4/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2090\n",
      "Epoch 5/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1707\n",
      "Epoch 6/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1178\n",
      "Epoch 7/25\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0677\n",
      "Epoch 8/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0334\n",
      "Epoch 9/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0189\n",
      "Epoch 10/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0129\n",
      "Epoch 11/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0100\n",
      "Epoch 12/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0087\n",
      "Epoch 13/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0078\n",
      "Epoch 14/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0074\n",
      "Epoch 15/25\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0068\n",
      "Epoch 16/25\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0067\n",
      "Epoch 17/25\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0065\n",
      "Epoch 18/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0063\n",
      "Epoch 19/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0062\n",
      "Epoch 20/25\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0062\n",
      "Epoch 21/25\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0060\n",
      "Epoch 22/25\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0060\n",
      "Epoch 23/25\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0059\n",
      "Epoch 24/25\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0059\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0059\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3AEAC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3AEAC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - 4s 8ms/step - loss: 23.4986 - dense_532_loss: 1.9974 - dense_533_loss: 2.7620 - dense_534_loss: 2.2643 - dense_535_loss: 2.2214 - dense_536_loss: 2.8166 - dense_537_loss: 2.7782 - dense_538_loss: 2.3675 - dense_539_loss: 2.3373 - dense_540_loss: 2.1123 - dense_541_loss: 1.8416 - dense_532_accuracy: 0.2380 - dense_533_accuracy: 0.0850 - dense_534_accuracy: 0.2050 - dense_535_accuracy: 0.1510 - dense_536_accuracy: 0.0980 - dense_537_accuracy: 0.1000 - dense_538_accuracy: 0.1600 - dense_539_accuracy: 0.1650 - dense_540_accuracy: 0.2650 - dense_541_accuracy: 0.4110\n",
      "Epoch 2/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 18.9687 - dense_532_loss: 1.6518 - dense_533_loss: 2.2317 - dense_534_loss: 1.8252 - dense_535_loss: 1.9480 - dense_536_loss: 2.1453 - dense_537_loss: 2.3087 - dense_538_loss: 1.9399 - dense_539_loss: 2.0453 - dense_540_loss: 1.4748 - dense_541_loss: 1.3980 - dense_532_accuracy: 0.3440 - dense_533_accuracy: 0.1970 - dense_534_accuracy: 0.2770 - dense_535_accuracy: 0.1710 - dense_536_accuracy: 0.2030 - dense_537_accuracy: 0.1710 - dense_538_accuracy: 0.2340 - dense_539_accuracy: 0.2210 - dense_540_accuracy: 0.4380 - dense_541_accuracy: 0.4790\n",
      "Epoch 3/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 16.3673 - dense_532_loss: 1.4643 - dense_533_loss: 1.8299 - dense_534_loss: 1.5598 - dense_535_loss: 1.7181 - dense_536_loss: 1.8019 - dense_537_loss: 1.9822 - dense_538_loss: 1.6962 - dense_539_loss: 1.7653 - dense_540_loss: 1.2652 - dense_541_loss: 1.2843 - dense_532_accuracy: 0.3670 - dense_533_accuracy: 0.2240 - dense_534_accuracy: 0.3470 - dense_535_accuracy: 0.2380 - dense_536_accuracy: 0.2190 - dense_537_accuracy: 0.2120 - dense_538_accuracy: 0.2470 - dense_539_accuracy: 0.2240 - dense_540_accuracy: 0.5010 - dense_541_accuracy: 0.4710\n",
      "Epoch 4/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 15.8551 - dense_532_loss: 1.4277 - dense_533_loss: 1.7625 - dense_534_loss: 1.5306 - dense_535_loss: 1.6632 - dense_536_loss: 1.7263 - dense_537_loss: 1.9122 - dense_538_loss: 1.6755 - dense_539_loss: 1.6845 - dense_540_loss: 1.2269 - dense_541_loss: 1.2456 - dense_532_accuracy: 0.3850 - dense_533_accuracy: 0.2140 - dense_534_accuracy: 0.3610 - dense_535_accuracy: 0.2310 - dense_536_accuracy: 0.2250 - dense_537_accuracy: 0.2170 - dense_538_accuracy: 0.2330 - dense_539_accuracy: 0.2190 - dense_540_accuracy: 0.4870 - dense_541_accuracy: 0.5160\n",
      "Epoch 5/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 15.3817 - dense_532_loss: 1.3782 - dense_533_loss: 1.6939 - dense_534_loss: 1.4846 - dense_535_loss: 1.6399 - dense_536_loss: 1.6773 - dense_537_loss: 1.8474 - dense_538_loss: 1.6286 - dense_539_loss: 1.6343 - dense_540_loss: 1.1786 - dense_541_loss: 1.2191 - dense_532_accuracy: 0.3880 - dense_533_accuracy: 0.2510 - dense_534_accuracy: 0.3680 - dense_535_accuracy: 0.2550 - dense_536_accuracy: 0.2510 - dense_537_accuracy: 0.2340 - dense_538_accuracy: 0.2820 - dense_539_accuracy: 0.2440 - dense_540_accuracy: 0.5060 - dense_541_accuracy: 0.5160\n",
      "Epoch 6/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 15.1894 - dense_532_loss: 1.3677 - dense_533_loss: 1.6857 - dense_534_loss: 1.4660 - dense_535_loss: 1.6185 - dense_536_loss: 1.6545 - dense_537_loss: 1.8292 - dense_538_loss: 1.6054 - dense_539_loss: 1.6112 - dense_540_loss: 1.1589 - dense_541_loss: 1.1923 - dense_532_accuracy: 0.3900 - dense_533_accuracy: 0.2340 - dense_534_accuracy: 0.3550 - dense_535_accuracy: 0.2650 - dense_536_accuracy: 0.2360 - dense_537_accuracy: 0.2140 - dense_538_accuracy: 0.2620 - dense_539_accuracy: 0.2360 - dense_540_accuracy: 0.5040 - dense_541_accuracy: 0.5310\n",
      "Epoch 7/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 15.1105 - dense_532_loss: 1.3626 - dense_533_loss: 1.6666 - dense_534_loss: 1.4587 - dense_535_loss: 1.6252 - dense_536_loss: 1.6446 - dense_537_loss: 1.8228 - dense_538_loss: 1.6022 - dense_539_loss: 1.6011 - dense_540_loss: 1.1466 - dense_541_loss: 1.1802 - dense_532_accuracy: 0.3900 - dense_533_accuracy: 0.2500 - dense_534_accuracy: 0.3720 - dense_535_accuracy: 0.2430 - dense_536_accuracy: 0.2570 - dense_537_accuracy: 0.2480 - dense_538_accuracy: 0.2890 - dense_539_accuracy: 0.2530 - dense_540_accuracy: 0.5150 - dense_541_accuracy: 0.5260\n",
      "Epoch 8/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 15.0083 - dense_532_loss: 1.3622 - dense_533_loss: 1.6685 - dense_534_loss: 1.4524 - dense_535_loss: 1.6019 - dense_536_loss: 1.6328 - dense_537_loss: 1.8091 - dense_538_loss: 1.5864 - dense_539_loss: 1.5907 - dense_540_loss: 1.1463 - dense_541_loss: 1.1581 - dense_532_accuracy: 0.3930 - dense_533_accuracy: 0.2390 - dense_534_accuracy: 0.3640 - dense_535_accuracy: 0.2430 - dense_536_accuracy: 0.2380 - dense_537_accuracy: 0.2130 - dense_538_accuracy: 0.2770 - dense_539_accuracy: 0.2610 - dense_540_accuracy: 0.4870 - dense_541_accuracy: 0.5290\n",
      "Epoch 9/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.9256 - dense_532_loss: 1.3575 - dense_533_loss: 1.6488 - dense_534_loss: 1.4464 - dense_535_loss: 1.6082 - dense_536_loss: 1.6275 - dense_537_loss: 1.7932 - dense_538_loss: 1.5828 - dense_539_loss: 1.5909 - dense_540_loss: 1.1274 - dense_541_loss: 1.1429 - dense_532_accuracy: 0.3980 - dense_533_accuracy: 0.2610 - dense_534_accuracy: 0.3580 - dense_535_accuracy: 0.2620 - dense_536_accuracy: 0.2620 - dense_537_accuracy: 0.2800 - dense_538_accuracy: 0.2940 - dense_539_accuracy: 0.2590 - dense_540_accuracy: 0.5120 - dense_541_accuracy: 0.4980\n",
      "Epoch 10/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.7892 - dense_532_loss: 1.3464 - dense_533_loss: 1.6361 - dense_534_loss: 1.4382 - dense_535_loss: 1.5886 - dense_536_loss: 1.6123 - dense_537_loss: 1.7813 - dense_538_loss: 1.5583 - dense_539_loss: 1.5770 - dense_540_loss: 1.1281 - dense_541_loss: 1.1229 - dense_532_accuracy: 0.3840 - dense_533_accuracy: 0.2730 - dense_534_accuracy: 0.3640 - dense_535_accuracy: 0.2460 - dense_536_accuracy: 0.2610 - dense_537_accuracy: 0.2490 - dense_538_accuracy: 0.3020 - dense_539_accuracy: 0.2650 - dense_540_accuracy: 0.5050 - dense_541_accuracy: 0.5290\n",
      "Epoch 11/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.5957 - dense_532_loss: 1.3358 - dense_533_loss: 1.6157 - dense_534_loss: 1.4105 - dense_535_loss: 1.5664 - dense_536_loss: 1.5860 - dense_537_loss: 1.7533 - dense_538_loss: 1.5438 - dense_539_loss: 1.5628 - dense_540_loss: 1.1193 - dense_541_loss: 1.1022 - dense_532_accuracy: 0.3910 - dense_533_accuracy: 0.2730 - dense_534_accuracy: 0.4020 - dense_535_accuracy: 0.2930 - dense_536_accuracy: 0.3100 - dense_537_accuracy: 0.3100 - dense_538_accuracy: 0.3120 - dense_539_accuracy: 0.2830 - dense_540_accuracy: 0.5150 - dense_541_accuracy: 0.5450\n",
      "Epoch 12/25\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 14.3969 - dense_532_loss: 1.3195 - dense_533_loss: 1.5941 - dense_534_loss: 1.3968 - dense_535_loss: 1.5413 - dense_536_loss: 1.5675 - dense_537_loss: 1.7240 - dense_538_loss: 1.5134 - dense_539_loss: 1.5370 - dense_540_loss: 1.1136 - dense_541_loss: 1.0898 - dense_532_accuracy: 0.4180 - dense_533_accuracy: 0.3020 - dense_534_accuracy: 0.3970 - dense_535_accuracy: 0.3240 - dense_536_accuracy: 0.3050 - dense_537_accuracy: 0.3100 - dense_538_accuracy: 0.3330 - dense_539_accuracy: 0.3110 - dense_540_accuracy: 0.5070 - dense_541_accuracy: 0.5640\n",
      "Epoch 13/25\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 14.2229 - dense_532_loss: 1.2998 - dense_533_loss: 1.5689 - dense_534_loss: 1.3811 - dense_535_loss: 1.5248 - dense_536_loss: 1.5433 - dense_537_loss: 1.7082 - dense_538_loss: 1.4993 - dense_539_loss: 1.5191 - dense_540_loss: 1.0957 - dense_541_loss: 1.0826 - dense_532_accuracy: 0.4280 - dense_533_accuracy: 0.3280 - dense_534_accuracy: 0.4110 - dense_535_accuracy: 0.3410 - dense_536_accuracy: 0.3330 - dense_537_accuracy: 0.3320 - dense_538_accuracy: 0.3680 - dense_539_accuracy: 0.3290 - dense_540_accuracy: 0.5400 - dense_541_accuracy: 0.5540\n",
      "Epoch 14/25\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 13.9859 - dense_532_loss: 1.2796 - dense_533_loss: 1.5443 - dense_534_loss: 1.3664 - dense_535_loss: 1.5031 - dense_536_loss: 1.5064 - dense_537_loss: 1.6827 - dense_538_loss: 1.4674 - dense_539_loss: 1.4981 - dense_540_loss: 1.0813 - dense_541_loss: 1.0567 - dense_532_accuracy: 0.4340 - dense_533_accuracy: 0.3520 - dense_534_accuracy: 0.4280 - dense_535_accuracy: 0.3610 - dense_536_accuracy: 0.3790 - dense_537_accuracy: 0.3420 - dense_538_accuracy: 0.3890 - dense_539_accuracy: 0.3670 - dense_540_accuracy: 0.5500 - dense_541_accuracy: 0.5730\n",
      "Epoch 15/25\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 13.7937 - dense_532_loss: 1.2708 - dense_533_loss: 1.5141 - dense_534_loss: 1.3457 - dense_535_loss: 1.4741 - dense_536_loss: 1.4933 - dense_537_loss: 1.6562 - dense_538_loss: 1.4517 - dense_539_loss: 1.4812 - dense_540_loss: 1.0661 - dense_541_loss: 1.0406 - dense_532_accuracy: 0.4400 - dense_533_accuracy: 0.3890 - dense_534_accuracy: 0.4570 - dense_535_accuracy: 0.3840 - dense_536_accuracy: 0.4000 - dense_537_accuracy: 0.3870 - dense_538_accuracy: 0.3960 - dense_539_accuracy: 0.3810 - dense_540_accuracy: 0.5700 - dense_541_accuracy: 0.5810\n",
      "Epoch 16/25\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 13.6677 - dense_532_loss: 1.2600 - dense_533_loss: 1.5014 - dense_534_loss: 1.3325 - dense_535_loss: 1.4644 - dense_536_loss: 1.4813 - dense_537_loss: 1.6476 - dense_538_loss: 1.4379 - dense_539_loss: 1.4533 - dense_540_loss: 1.0514 - dense_541_loss: 1.0380 - dense_532_accuracy: 0.4690 - dense_533_accuracy: 0.3810 - dense_534_accuracy: 0.4550 - dense_535_accuracy: 0.3800 - dense_536_accuracy: 0.3890 - dense_537_accuracy: 0.3850 - dense_538_accuracy: 0.3970 - dense_539_accuracy: 0.3920 - dense_540_accuracy: 0.5830 - dense_541_accuracy: 0.5830\n",
      "Epoch 17/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 13.3915 - dense_532_loss: 1.2310 - dense_533_loss: 1.4662 - dense_534_loss: 1.3074 - dense_535_loss: 1.4343 - dense_536_loss: 1.4535 - dense_537_loss: 1.6121 - dense_538_loss: 1.4144 - dense_539_loss: 1.4225 - dense_540_loss: 1.0414 - dense_541_loss: 1.0085 - dense_532_accuracy: 0.4820 - dense_533_accuracy: 0.4110 - dense_534_accuracy: 0.4700 - dense_535_accuracy: 0.4040 - dense_536_accuracy: 0.4200 - dense_537_accuracy: 0.4130 - dense_538_accuracy: 0.4210 - dense_539_accuracy: 0.4240 - dense_540_accuracy: 0.6010 - dense_541_accuracy: 0.5980\n",
      "Epoch 18/25\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 13.2688 - dense_532_loss: 1.2184 - dense_533_loss: 1.4552 - dense_534_loss: 1.3010 - dense_535_loss: 1.4302 - dense_536_loss: 1.4386 - dense_537_loss: 1.6038 - dense_538_loss: 1.3907 - dense_539_loss: 1.4121 - dense_540_loss: 1.0188 - dense_541_loss: 1.0000 - dense_532_accuracy: 0.4950 - dense_533_accuracy: 0.4280 - dense_534_accuracy: 0.4660 - dense_535_accuracy: 0.4220 - dense_536_accuracy: 0.4210 - dense_537_accuracy: 0.4040 - dense_538_accuracy: 0.4480 - dense_539_accuracy: 0.4130 - dense_540_accuracy: 0.6000 - dense_541_accuracy: 0.6150\n",
      "Epoch 19/25\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 13.1171 - dense_532_loss: 1.2066 - dense_533_loss: 1.4379 - dense_534_loss: 1.2887 - dense_535_loss: 1.3948 - dense_536_loss: 1.4348 - dense_537_loss: 1.5831 - dense_538_loss: 1.3835 - dense_539_loss: 1.3859 - dense_540_loss: 1.0068 - dense_541_loss: 0.9950 - dense_532_accuracy: 0.5080 - dense_533_accuracy: 0.4420 - dense_534_accuracy: 0.4840 - dense_535_accuracy: 0.4310 - dense_536_accuracy: 0.4300 - dense_537_accuracy: 0.4150 - dense_538_accuracy: 0.4610 - dense_539_accuracy: 0.4420 - dense_540_accuracy: 0.6220 - dense_541_accuracy: 0.6080\n",
      "Epoch 20/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 12.8236 - dense_532_loss: 1.1871 - dense_533_loss: 1.4062 - dense_534_loss: 1.2627 - dense_535_loss: 1.3693 - dense_536_loss: 1.3886 - dense_537_loss: 1.5501 - dense_538_loss: 1.3551 - dense_539_loss: 1.3549 - dense_540_loss: 0.9810 - dense_541_loss: 0.9685 - dense_532_accuracy: 0.5140 - dense_533_accuracy: 0.4650 - dense_534_accuracy: 0.5110 - dense_535_accuracy: 0.4450 - dense_536_accuracy: 0.4580 - dense_537_accuracy: 0.4370 - dense_538_accuracy: 0.4740 - dense_539_accuracy: 0.4600 - dense_540_accuracy: 0.6290 - dense_541_accuracy: 0.6360\n",
      "Epoch 21/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 12.5669 - dense_532_loss: 1.1611 - dense_533_loss: 1.3734 - dense_534_loss: 1.2387 - dense_535_loss: 1.3403 - dense_536_loss: 1.3593 - dense_537_loss: 1.5205 - dense_538_loss: 1.3304 - dense_539_loss: 1.3290 - dense_540_loss: 0.9801 - dense_541_loss: 0.9341 - dense_532_accuracy: 0.5230 - dense_533_accuracy: 0.4710 - dense_534_accuracy: 0.5070 - dense_535_accuracy: 0.4510 - dense_536_accuracy: 0.4680 - dense_537_accuracy: 0.4560 - dense_538_accuracy: 0.4830 - dense_539_accuracy: 0.4750 - dense_540_accuracy: 0.6270 - dense_541_accuracy: 0.6400\n",
      "Epoch 22/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 12.2854 - dense_532_loss: 1.1331 - dense_533_loss: 1.3367 - dense_534_loss: 1.2121 - dense_535_loss: 1.3234 - dense_536_loss: 1.3345 - dense_537_loss: 1.4814 - dense_538_loss: 1.2917 - dense_539_loss: 1.2948 - dense_540_loss: 0.9599 - dense_541_loss: 0.9177 - dense_532_accuracy: 0.5440 - dense_533_accuracy: 0.4790 - dense_534_accuracy: 0.5220 - dense_535_accuracy: 0.4780 - dense_536_accuracy: 0.4820 - dense_537_accuracy: 0.4710 - dense_538_accuracy: 0.5130 - dense_539_accuracy: 0.4930 - dense_540_accuracy: 0.6390 - dense_541_accuracy: 0.6670\n",
      "Epoch 23/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 12.0629 - dense_532_loss: 1.1104 - dense_533_loss: 1.3157 - dense_534_loss: 1.1823 - dense_535_loss: 1.2969 - dense_536_loss: 1.3084 - dense_537_loss: 1.4671 - dense_538_loss: 1.2789 - dense_539_loss: 1.2762 - dense_540_loss: 0.9319 - dense_541_loss: 0.8952 - dense_532_accuracy: 0.5610 - dense_533_accuracy: 0.5030 - dense_534_accuracy: 0.5630 - dense_535_accuracy: 0.4860 - dense_536_accuracy: 0.4970 - dense_537_accuracy: 0.4870 - dense_538_accuracy: 0.5260 - dense_539_accuracy: 0.4970 - dense_540_accuracy: 0.6500 - dense_541_accuracy: 0.6760\n",
      "Epoch 24/25\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 11.7108 - dense_532_loss: 1.0947 - dense_533_loss: 1.2736 - dense_534_loss: 1.1430 - dense_535_loss: 1.2592 - dense_536_loss: 1.2681 - dense_537_loss: 1.4149 - dense_538_loss: 1.2395 - dense_539_loss: 1.2349 - dense_540_loss: 0.9139 - dense_541_loss: 0.8689 - dense_532_accuracy: 0.5670 - dense_533_accuracy: 0.5140 - dense_534_accuracy: 0.5710 - dense_535_accuracy: 0.5170 - dense_536_accuracy: 0.5300 - dense_537_accuracy: 0.5010 - dense_538_accuracy: 0.5270 - dense_539_accuracy: 0.5230 - dense_540_accuracy: 0.6810 - dense_541_accuracy: 0.6710\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 11.5425 - dense_532_loss: 1.0776 - dense_533_loss: 1.2507 - dense_534_loss: 1.1236 - dense_535_loss: 1.2386 - dense_536_loss: 1.2449 - dense_537_loss: 1.3952 - dense_538_loss: 1.2297 - dense_539_loss: 1.2194 - dense_540_loss: 0.9076 - dense_541_loss: 0.8553 - dense_532_accuracy: 0.5740 - dense_533_accuracy: 0.5370 - dense_534_accuracy: 0.5930 - dense_535_accuracy: 0.5340 - dense_536_accuracy: 0.5440 - dense_537_accuracy: 0.5310 - dense_538_accuracy: 0.5420 - dense_539_accuracy: 0.5480 - dense_540_accuracy: 0.6680 - dense_541_accuracy: 0.6850\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D427E558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D427E558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3FFA318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3FFA318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - 3s 9ms/step - loss: 23.2834 - dense_542_loss: 1.9372 - dense_543_loss: 2.7249 - dense_544_loss: 2.2597 - dense_545_loss: 2.2652 - dense_546_loss: 2.7090 - dense_547_loss: 2.7751 - dense_548_loss: 2.3551 - dense_549_loss: 2.2969 - dense_550_loss: 2.1043 - dense_551_loss: 1.8559 - dense_542_accuracy: 0.2410 - dense_543_accuracy: 0.0990 - dense_544_accuracy: 0.1680 - dense_545_accuracy: 0.1460 - dense_546_accuracy: 0.1050 - dense_547_accuracy: 0.0970 - dense_548_accuracy: 0.2020 - dense_549_accuracy: 0.1780 - dense_550_accuracy: 0.3330 - dense_551_accuracy: 0.4220\n",
      "Epoch 2/25\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 17.7570 - dense_542_loss: 1.5775 - dense_543_loss: 2.0297 - dense_544_loss: 1.7805 - dense_545_loss: 1.8625 - dense_546_loss: 1.9456 - dense_547_loss: 2.1707 - dense_548_loss: 1.8682 - dense_549_loss: 1.8161 - dense_550_loss: 1.3596 - dense_551_loss: 1.3466 - dense_542_accuracy: 0.3230 - dense_543_accuracy: 0.2040 - dense_544_accuracy: 0.3060 - dense_545_accuracy: 0.2320 - dense_546_accuracy: 0.2230 - dense_547_accuracy: 0.2170 - dense_548_accuracy: 0.2490 - dense_549_accuracy: 0.2040 - dense_550_accuracy: 0.4780 - dense_551_accuracy: 0.5040\n",
      "Epoch 3/25\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 16.3415 - dense_542_loss: 1.4934 - dense_543_loss: 1.8231 - dense_544_loss: 1.6099 - dense_545_loss: 1.6901 - dense_546_loss: 1.8010 - dense_547_loss: 1.9669 - dense_548_loss: 1.7147 - dense_549_loss: 1.7157 - dense_550_loss: 1.2536 - dense_551_loss: 1.2728 - dense_542_accuracy: 0.3740 - dense_543_accuracy: 0.2050 - dense_544_accuracy: 0.3320 - dense_545_accuracy: 0.2500 - dense_546_accuracy: 0.2050 - dense_547_accuracy: 0.1920 - dense_548_accuracy: 0.2420 - dense_549_accuracy: 0.2080 - dense_550_accuracy: 0.4920 - dense_551_accuracy: 0.5080\n",
      "Epoch 4/25\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 16.2033 - dense_542_loss: 1.4704 - dense_543_loss: 1.8075 - dense_544_loss: 1.5661 - dense_545_loss: 1.6863 - dense_546_loss: 1.7925 - dense_547_loss: 1.9442 - dense_548_loss: 1.6900 - dense_549_loss: 1.7005 - dense_550_loss: 1.2700 - dense_551_loss: 1.2757 - dense_542_accuracy: 0.3540 - dense_543_accuracy: 0.2100 - dense_544_accuracy: 0.3480 - dense_545_accuracy: 0.2350 - dense_546_accuracy: 0.2020 - dense_547_accuracy: 0.2090 - dense_548_accuracy: 0.2250 - dense_549_accuracy: 0.2260 - dense_550_accuracy: 0.5010 - dense_551_accuracy: 0.5050\n",
      "Epoch 5/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 15.7873 - dense_542_loss: 1.4420 - dense_543_loss: 1.7636 - dense_544_loss: 1.5232 - dense_545_loss: 1.6426 - dense_546_loss: 1.7393 - dense_547_loss: 1.8974 - dense_548_loss: 1.6607 - dense_549_loss: 1.6718 - dense_550_loss: 1.2164 - dense_551_loss: 1.2303 - dense_542_accuracy: 0.3690 - dense_543_accuracy: 0.2160 - dense_544_accuracy: 0.3530 - dense_545_accuracy: 0.2550 - dense_546_accuracy: 0.2310 - dense_547_accuracy: 0.2030 - dense_548_accuracy: 0.2490 - dense_549_accuracy: 0.2250 - dense_550_accuracy: 0.4810 - dense_551_accuracy: 0.5110\n",
      "Epoch 6/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 15.5411 - dense_542_loss: 1.4101 - dense_543_loss: 1.7327 - dense_544_loss: 1.4960 - dense_545_loss: 1.6291 - dense_546_loss: 1.7053 - dense_547_loss: 1.8762 - dense_548_loss: 1.6465 - dense_549_loss: 1.6620 - dense_550_loss: 1.1973 - dense_551_loss: 1.1858 - dense_542_accuracy: 0.3610 - dense_543_accuracy: 0.2270 - dense_544_accuracy: 0.3570 - dense_545_accuracy: 0.2600 - dense_546_accuracy: 0.2280 - dense_547_accuracy: 0.2150 - dense_548_accuracy: 0.2400 - dense_549_accuracy: 0.2510 - dense_550_accuracy: 0.5090 - dense_551_accuracy: 0.5240\n",
      "Epoch 7/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 15.3092 - dense_542_loss: 1.3911 - dense_543_loss: 1.7014 - dense_544_loss: 1.4741 - dense_545_loss: 1.6285 - dense_546_loss: 1.6687 - dense_547_loss: 1.8432 - dense_548_loss: 1.6188 - dense_549_loss: 1.6490 - dense_550_loss: 1.1795 - dense_551_loss: 1.1550 - dense_542_accuracy: 0.3740 - dense_543_accuracy: 0.2440 - dense_544_accuracy: 0.3640 - dense_545_accuracy: 0.2250 - dense_546_accuracy: 0.2380 - dense_547_accuracy: 0.2230 - dense_548_accuracy: 0.2800 - dense_549_accuracy: 0.2530 - dense_550_accuracy: 0.4960 - dense_551_accuracy: 0.5280\n",
      "Epoch 8/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 15.0488 - dense_542_loss: 1.3681 - dense_543_loss: 1.6751 - dense_544_loss: 1.4561 - dense_545_loss: 1.6096 - dense_546_loss: 1.6471 - dense_547_loss: 1.8042 - dense_548_loss: 1.5995 - dense_549_loss: 1.6048 - dense_550_loss: 1.1479 - dense_551_loss: 1.1363 - dense_542_accuracy: 0.3780 - dense_543_accuracy: 0.2300 - dense_544_accuracy: 0.3530 - dense_545_accuracy: 0.2360 - dense_546_accuracy: 0.2320 - dense_547_accuracy: 0.2340 - dense_548_accuracy: 0.2570 - dense_549_accuracy: 0.2320 - dense_550_accuracy: 0.4990 - dense_551_accuracy: 0.5250\n",
      "Epoch 9/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.9439 - dense_542_loss: 1.3584 - dense_543_loss: 1.6575 - dense_544_loss: 1.4445 - dense_545_loss: 1.5994 - dense_546_loss: 1.6350 - dense_547_loss: 1.7925 - dense_548_loss: 1.5955 - dense_549_loss: 1.5926 - dense_550_loss: 1.1399 - dense_551_loss: 1.1287 - dense_542_accuracy: 0.3870 - dense_543_accuracy: 0.2380 - dense_544_accuracy: 0.3620 - dense_545_accuracy: 0.2520 - dense_546_accuracy: 0.2360 - dense_547_accuracy: 0.2260 - dense_548_accuracy: 0.2760 - dense_549_accuracy: 0.2640 - dense_550_accuracy: 0.4760 - dense_551_accuracy: 0.5250\n",
      "Epoch 10/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.8826 - dense_542_loss: 1.3630 - dense_543_loss: 1.6514 - dense_544_loss: 1.4355 - dense_545_loss: 1.5939 - dense_546_loss: 1.6272 - dense_547_loss: 1.7848 - dense_548_loss: 1.5788 - dense_549_loss: 1.5890 - dense_550_loss: 1.1347 - dense_551_loss: 1.1243 - dense_542_accuracy: 0.3800 - dense_543_accuracy: 0.2370 - dense_544_accuracy: 0.3710 - dense_545_accuracy: 0.2400 - dense_546_accuracy: 0.2410 - dense_547_accuracy: 0.2400 - dense_548_accuracy: 0.2790 - dense_549_accuracy: 0.2510 - dense_550_accuracy: 0.5030 - dense_551_accuracy: 0.5290\n",
      "Epoch 11/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.8140 - dense_542_loss: 1.3544 - dense_543_loss: 1.6425 - dense_544_loss: 1.4349 - dense_545_loss: 1.5875 - dense_546_loss: 1.6165 - dense_547_loss: 1.7757 - dense_548_loss: 1.5735 - dense_549_loss: 1.5833 - dense_550_loss: 1.1290 - dense_551_loss: 1.1168 - dense_542_accuracy: 0.3860 - dense_543_accuracy: 0.2610 - dense_544_accuracy: 0.3760 - dense_545_accuracy: 0.2680 - dense_546_accuracy: 0.2510 - dense_547_accuracy: 0.2420 - dense_548_accuracy: 0.2890 - dense_549_accuracy: 0.2580 - dense_550_accuracy: 0.5020 - dense_551_accuracy: 0.5300\n",
      "Epoch 12/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.8047 - dense_542_loss: 1.3493 - dense_543_loss: 1.6354 - dense_544_loss: 1.4427 - dense_545_loss: 1.5845 - dense_546_loss: 1.6192 - dense_547_loss: 1.7750 - dense_548_loss: 1.5709 - dense_549_loss: 1.5841 - dense_550_loss: 1.1295 - dense_551_loss: 1.1142 - dense_542_accuracy: 0.3880 - dense_543_accuracy: 0.2490 - dense_544_accuracy: 0.3720 - dense_545_accuracy: 0.2580 - dense_546_accuracy: 0.2270 - dense_547_accuracy: 0.2290 - dense_548_accuracy: 0.2680 - dense_549_accuracy: 0.2370 - dense_550_accuracy: 0.4960 - dense_551_accuracy: 0.5310\n",
      "Epoch 13/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.7728 - dense_542_loss: 1.3533 - dense_543_loss: 1.6318 - dense_544_loss: 1.4398 - dense_545_loss: 1.5785 - dense_546_loss: 1.6129 - dense_547_loss: 1.7655 - dense_548_loss: 1.5628 - dense_549_loss: 1.5811 - dense_550_loss: 1.1271 - dense_551_loss: 1.1201 - dense_542_accuracy: 0.3840 - dense_543_accuracy: 0.2510 - dense_544_accuracy: 0.3660 - dense_545_accuracy: 0.2570 - dense_546_accuracy: 0.2430 - dense_547_accuracy: 0.2420 - dense_548_accuracy: 0.2810 - dense_549_accuracy: 0.2360 - dense_550_accuracy: 0.4890 - dense_551_accuracy: 0.5320\n",
      "Epoch 14/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.7088 - dense_542_loss: 1.3414 - dense_543_loss: 1.6262 - dense_544_loss: 1.4279 - dense_545_loss: 1.5716 - dense_546_loss: 1.6040 - dense_547_loss: 1.7674 - dense_548_loss: 1.5562 - dense_549_loss: 1.5809 - dense_550_loss: 1.1214 - dense_551_loss: 1.1117 - dense_542_accuracy: 0.4030 - dense_543_accuracy: 0.2720 - dense_544_accuracy: 0.3670 - dense_545_accuracy: 0.2690 - dense_546_accuracy: 0.2670 - dense_547_accuracy: 0.2680 - dense_548_accuracy: 0.3090 - dense_549_accuracy: 0.2420 - dense_550_accuracy: 0.5140 - dense_551_accuracy: 0.5440\n",
      "Epoch 15/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.7330 - dense_542_loss: 1.3477 - dense_543_loss: 1.6256 - dense_544_loss: 1.4338 - dense_545_loss: 1.5776 - dense_546_loss: 1.6095 - dense_547_loss: 1.7660 - dense_548_loss: 1.5597 - dense_549_loss: 1.5718 - dense_550_loss: 1.1228 - dense_551_loss: 1.1184 - dense_542_accuracy: 0.3880 - dense_543_accuracy: 0.2710 - dense_544_accuracy: 0.3680 - dense_545_accuracy: 0.2800 - dense_546_accuracy: 0.2520 - dense_547_accuracy: 0.2570 - dense_548_accuracy: 0.2780 - dense_549_accuracy: 0.2630 - dense_550_accuracy: 0.4940 - dense_551_accuracy: 0.5220\n",
      "Epoch 16/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.6122 - dense_542_loss: 1.3314 - dense_543_loss: 1.6139 - dense_544_loss: 1.4200 - dense_545_loss: 1.5609 - dense_546_loss: 1.5929 - dense_547_loss: 1.7504 - dense_548_loss: 1.5485 - dense_549_loss: 1.5684 - dense_550_loss: 1.1196 - dense_551_loss: 1.1063 - dense_542_accuracy: 0.4120 - dense_543_accuracy: 0.2730 - dense_544_accuracy: 0.3820 - dense_545_accuracy: 0.2750 - dense_546_accuracy: 0.2740 - dense_547_accuracy: 0.2700 - dense_548_accuracy: 0.3000 - dense_549_accuracy: 0.2700 - dense_550_accuracy: 0.5190 - dense_551_accuracy: 0.5340\n",
      "Epoch 17/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.6153 - dense_542_loss: 1.3344 - dense_543_loss: 1.6151 - dense_544_loss: 1.4205 - dense_545_loss: 1.5753 - dense_546_loss: 1.5917 - dense_547_loss: 1.7542 - dense_548_loss: 1.5482 - dense_549_loss: 1.5575 - dense_550_loss: 1.1211 - dense_551_loss: 1.0974 - dense_542_accuracy: 0.3930 - dense_543_accuracy: 0.2850 - dense_544_accuracy: 0.3880 - dense_545_accuracy: 0.2630 - dense_546_accuracy: 0.2880 - dense_547_accuracy: 0.2960 - dense_548_accuracy: 0.3170 - dense_549_accuracy: 0.2820 - dense_550_accuracy: 0.5280 - dense_551_accuracy: 0.5410\n",
      "Epoch 18/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.4770 - dense_542_loss: 1.3189 - dense_543_loss: 1.5993 - dense_544_loss: 1.4091 - dense_545_loss: 1.5452 - dense_546_loss: 1.5746 - dense_547_loss: 1.7395 - dense_548_loss: 1.5348 - dense_549_loss: 1.5466 - dense_550_loss: 1.1044 - dense_551_loss: 1.1046 - dense_542_accuracy: 0.4220 - dense_543_accuracy: 0.3090 - dense_544_accuracy: 0.4180 - dense_545_accuracy: 0.3300 - dense_546_accuracy: 0.3100 - dense_547_accuracy: 0.3010 - dense_548_accuracy: 0.3420 - dense_549_accuracy: 0.3180 - dense_550_accuracy: 0.5420 - dense_551_accuracy: 0.5510\n",
      "Epoch 19/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 14.4010 - dense_542_loss: 1.3133 - dense_543_loss: 1.5882 - dense_544_loss: 1.4182 - dense_545_loss: 1.5342 - dense_546_loss: 1.5712 - dense_547_loss: 1.7236 - dense_548_loss: 1.5247 - dense_549_loss: 1.5474 - dense_550_loss: 1.0923 - dense_551_loss: 1.0879 - dense_542_accuracy: 0.4290 - dense_543_accuracy: 0.3110 - dense_544_accuracy: 0.3930 - dense_545_accuracy: 0.3250 - dense_546_accuracy: 0.3120 - dense_547_accuracy: 0.3190 - dense_548_accuracy: 0.3370 - dense_549_accuracy: 0.3050 - dense_550_accuracy: 0.5490 - dense_551_accuracy: 0.5540\n",
      "Epoch 20/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.3304 - dense_542_loss: 1.3139 - dense_543_loss: 1.5776 - dense_544_loss: 1.4024 - dense_545_loss: 1.5212 - dense_546_loss: 1.5673 - dense_547_loss: 1.7146 - dense_548_loss: 1.5187 - dense_549_loss: 1.5291 - dense_550_loss: 1.0957 - dense_551_loss: 1.0899 - dense_542_accuracy: 0.4280 - dense_543_accuracy: 0.3020 - dense_544_accuracy: 0.4000 - dense_545_accuracy: 0.3360 - dense_546_accuracy: 0.2800 - dense_547_accuracy: 0.3130 - dense_548_accuracy: 0.3320 - dense_549_accuracy: 0.2950 - dense_550_accuracy: 0.5360 - dense_551_accuracy: 0.5380\n",
      "Epoch 21/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.1021 - dense_542_loss: 1.2910 - dense_543_loss: 1.5530 - dense_544_loss: 1.3767 - dense_545_loss: 1.4981 - dense_546_loss: 1.5394 - dense_547_loss: 1.6835 - dense_548_loss: 1.5030 - dense_549_loss: 1.5175 - dense_550_loss: 1.0827 - dense_551_loss: 1.0572 - dense_542_accuracy: 0.4350 - dense_543_accuracy: 0.3350 - dense_544_accuracy: 0.4210 - dense_545_accuracy: 0.3510 - dense_546_accuracy: 0.3410 - dense_547_accuracy: 0.3500 - dense_548_accuracy: 0.3620 - dense_549_accuracy: 0.3310 - dense_550_accuracy: 0.5570 - dense_551_accuracy: 0.5650\n",
      "Epoch 22/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14.0584 - dense_542_loss: 1.2912 - dense_543_loss: 1.5515 - dense_544_loss: 1.3789 - dense_545_loss: 1.4887 - dense_546_loss: 1.5300 - dense_547_loss: 1.6818 - dense_548_loss: 1.4904 - dense_549_loss: 1.5035 - dense_550_loss: 1.0761 - dense_551_loss: 1.0663 - dense_542_accuracy: 0.4390 - dense_543_accuracy: 0.3390 - dense_544_accuracy: 0.4100 - dense_545_accuracy: 0.3580 - dense_546_accuracy: 0.3490 - dense_547_accuracy: 0.3430 - dense_548_accuracy: 0.3590 - dense_549_accuracy: 0.3530 - dense_550_accuracy: 0.5610 - dense_551_accuracy: 0.5620\n",
      "Epoch 23/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 13.8770 - dense_542_loss: 1.2726 - dense_543_loss: 1.5279 - dense_544_loss: 1.3558 - dense_545_loss: 1.4752 - dense_546_loss: 1.5085 - dense_547_loss: 1.6623 - dense_548_loss: 1.4726 - dense_549_loss: 1.4816 - dense_550_loss: 1.0718 - dense_551_loss: 1.0486 - dense_542_accuracy: 0.4460 - dense_543_accuracy: 0.3750 - dense_544_accuracy: 0.4370 - dense_545_accuracy: 0.3860 - dense_546_accuracy: 0.3550 - dense_547_accuracy: 0.3550 - dense_548_accuracy: 0.3810 - dense_549_accuracy: 0.3500 - dense_550_accuracy: 0.5800 - dense_551_accuracy: 0.5620\n",
      "Epoch 24/25\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 13.7935 - dense_542_loss: 1.2624 - dense_543_loss: 1.5161 - dense_544_loss: 1.3542 - dense_545_loss: 1.4542 - dense_546_loss: 1.5000 - dense_547_loss: 1.6565 - dense_548_loss: 1.4613 - dense_549_loss: 1.4730 - dense_550_loss: 1.0644 - dense_551_loss: 1.0514 - dense_542_accuracy: 0.4590 - dense_543_accuracy: 0.3700 - dense_544_accuracy: 0.4280 - dense_545_accuracy: 0.3890 - dense_546_accuracy: 0.3830 - dense_547_accuracy: 0.3640 - dense_548_accuracy: 0.3860 - dense_549_accuracy: 0.3760 - dense_550_accuracy: 0.5760 - dense_551_accuracy: 0.5770\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 13.7492 - dense_542_loss: 1.2614 - dense_543_loss: 1.5145 - dense_544_loss: 1.3555 - dense_545_loss: 1.4517 - dense_546_loss: 1.4918 - dense_547_loss: 1.6427 - dense_548_loss: 1.4567 - dense_549_loss: 1.4722 - dense_550_loss: 1.0514 - dense_551_loss: 1.0515 - dense_542_accuracy: 0.4560 - dense_543_accuracy: 0.3680 - dense_544_accuracy: 0.4430 - dense_545_accuracy: 0.3970 - dense_546_accuracy: 0.3840 - dense_547_accuracy: 0.3780 - dense_548_accuracy: 0.4020 - dense_549_accuracy: 0.3650 - dense_550_accuracy: 0.5880 - dense_551_accuracy: 0.5610\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D273F438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D273F438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3E7FDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3E7FDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 11ms/step - loss: 0.2494\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2472\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2440\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2395\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2324\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2230\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2094\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1896\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1659\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1388\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1099\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0804\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0578\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0404\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0289\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0220\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0182\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0157\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0131\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0117\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0116\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0108\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0104\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0102\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0096\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3800C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3800C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "8/8 [==============================] - 4s 9ms/step - loss: 24.9219 - dense_555_loss: 2.4740 - dense_556_loss: 2.4212 - dense_557_loss: 2.4599 - dense_558_loss: 2.3371 - dense_559_loss: 2.9662 - dense_560_loss: 2.5436 - dense_561_loss: 2.5752 - dense_562_loss: 2.4186 - dense_563_loss: 2.2183 - dense_564_loss: 2.5078 - dense_555_accuracy: 0.1540 - dense_556_accuracy: 0.1540 - dense_557_accuracy: 0.1060 - dense_558_accuracy: 0.2400 - dense_559_accuracy: 0.1000 - dense_560_accuracy: 0.0740 - dense_561_accuracy: 0.1080 - dense_562_accuracy: 0.1460 - dense_563_accuracy: 0.1640 - dense_564_accuracy: 0.1280\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23.3072 - dense_555_loss: 2.3010 - dense_556_loss: 2.2542 - dense_557_loss: 2.2954 - dense_558_loss: 2.1744 - dense_559_loss: 2.7997 - dense_560_loss: 2.4466 - dense_561_loss: 2.4003 - dense_562_loss: 2.2346 - dense_563_loss: 2.0304 - dense_564_loss: 2.3706 - dense_555_accuracy: 0.1600 - dense_556_accuracy: 0.2180 - dense_557_accuracy: 0.1900 - dense_558_accuracy: 0.2640 - dense_559_accuracy: 0.1140 - dense_560_accuracy: 0.1620 - dense_561_accuracy: 0.1600 - dense_562_accuracy: 0.1600 - dense_563_accuracy: 0.1760 - dense_564_accuracy: 0.1460\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 22.1127 - dense_555_loss: 2.1888 - dense_556_loss: 2.1029 - dense_557_loss: 2.2305 - dense_558_loss: 2.0657 - dense_559_loss: 2.6143 - dense_560_loss: 2.3593 - dense_561_loss: 2.2835 - dense_562_loss: 2.0771 - dense_563_loss: 1.9143 - dense_564_loss: 2.2762 - dense_555_accuracy: 0.1820 - dense_556_accuracy: 0.2220 - dense_557_accuracy: 0.2220 - dense_558_accuracy: 0.2500 - dense_559_accuracy: 0.1300 - dense_560_accuracy: 0.1420 - dense_561_accuracy: 0.1480 - dense_562_accuracy: 0.2680 - dense_563_accuracy: 0.2400 - dense_564_accuracy: 0.2300\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 20.9261 - dense_555_loss: 2.1106 - dense_556_loss: 2.0148 - dense_557_loss: 2.0587 - dense_558_loss: 1.9512 - dense_559_loss: 2.4849 - dense_560_loss: 2.2154 - dense_561_loss: 2.2043 - dense_562_loss: 1.9442 - dense_563_loss: 1.8051 - dense_564_loss: 2.1370 - dense_555_accuracy: 0.2240 - dense_556_accuracy: 0.2400 - dense_557_accuracy: 0.2620 - dense_558_accuracy: 0.2920 - dense_559_accuracy: 0.1760 - dense_560_accuracy: 0.2180 - dense_561_accuracy: 0.1520 - dense_562_accuracy: 0.3180 - dense_563_accuracy: 0.3180 - dense_564_accuracy: 0.2500\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 19.9302 - dense_555_loss: 1.9324 - dense_556_loss: 1.9234 - dense_557_loss: 1.9472 - dense_558_loss: 1.8659 - dense_559_loss: 2.3438 - dense_560_loss: 2.1122 - dense_561_loss: 2.1065 - dense_562_loss: 1.8769 - dense_563_loss: 1.7251 - dense_564_loss: 2.0970 - dense_555_accuracy: 0.3260 - dense_556_accuracy: 0.2940 - dense_557_accuracy: 0.2780 - dense_558_accuracy: 0.3280 - dense_559_accuracy: 0.1900 - dense_560_accuracy: 0.1860 - dense_561_accuracy: 0.2180 - dense_562_accuracy: 0.2940 - dense_563_accuracy: 0.3680 - dense_564_accuracy: 0.2300\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 19.4122 - dense_555_loss: 1.8534 - dense_556_loss: 1.8814 - dense_557_loss: 1.9189 - dense_558_loss: 1.8244 - dense_559_loss: 2.2480 - dense_560_loss: 2.0581 - dense_561_loss: 2.0590 - dense_562_loss: 1.8251 - dense_563_loss: 1.6872 - dense_564_loss: 2.0567 - dense_555_accuracy: 0.2900 - dense_556_accuracy: 0.2960 - dense_557_accuracy: 0.2800 - dense_558_accuracy: 0.2960 - dense_559_accuracy: 0.2100 - dense_560_accuracy: 0.1960 - dense_561_accuracy: 0.2400 - dense_562_accuracy: 0.2820 - dense_563_accuracy: 0.3500 - dense_564_accuracy: 0.2620\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 18.7171 - dense_555_loss: 1.7498 - dense_556_loss: 1.8025 - dense_557_loss: 1.8630 - dense_558_loss: 1.7719 - dense_559_loss: 2.1324 - dense_560_loss: 1.9865 - dense_561_loss: 1.9762 - dense_562_loss: 1.7807 - dense_563_loss: 1.6613 - dense_564_loss: 1.9929 - dense_555_accuracy: 0.3600 - dense_556_accuracy: 0.3340 - dense_557_accuracy: 0.2840 - dense_558_accuracy: 0.3340 - dense_559_accuracy: 0.2640 - dense_560_accuracy: 0.2220 - dense_561_accuracy: 0.2380 - dense_562_accuracy: 0.3020 - dense_563_accuracy: 0.3360 - dense_564_accuracy: 0.2880\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 17.9579 - dense_555_loss: 1.6721 - dense_556_loss: 1.7024 - dense_557_loss: 1.8087 - dense_558_loss: 1.7195 - dense_559_loss: 2.0657 - dense_560_loss: 1.8899 - dense_561_loss: 1.9084 - dense_562_loss: 1.7051 - dense_563_loss: 1.6086 - dense_564_loss: 1.8775 - dense_555_accuracy: 0.3500 - dense_556_accuracy: 0.3460 - dense_557_accuracy: 0.2880 - dense_558_accuracy: 0.3280 - dense_559_accuracy: 0.2440 - dense_560_accuracy: 0.2620 - dense_561_accuracy: 0.2540 - dense_562_accuracy: 0.3220 - dense_563_accuracy: 0.3540 - dense_564_accuracy: 0.3000\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 17.1305 - dense_555_loss: 1.5768 - dense_556_loss: 1.6064 - dense_557_loss: 1.7516 - dense_558_loss: 1.6702 - dense_559_loss: 1.9602 - dense_560_loss: 1.8046 - dense_561_loss: 1.8248 - dense_562_loss: 1.6507 - dense_563_loss: 1.5429 - dense_564_loss: 1.7424 - dense_555_accuracy: 0.3440 - dense_556_accuracy: 0.3560 - dense_557_accuracy: 0.2620 - dense_558_accuracy: 0.3220 - dense_559_accuracy: 0.2640 - dense_560_accuracy: 0.2860 - dense_561_accuracy: 0.2680 - dense_562_accuracy: 0.3020 - dense_563_accuracy: 0.3880 - dense_564_accuracy: 0.3200\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 16.7735 - dense_555_loss: 1.5313 - dense_556_loss: 1.5739 - dense_557_loss: 1.6989 - dense_558_loss: 1.6370 - dense_559_loss: 1.9153 - dense_560_loss: 1.7801 - dense_561_loss: 1.7719 - dense_562_loss: 1.6260 - dense_563_loss: 1.5262 - dense_564_loss: 1.7129 - dense_555_accuracy: 0.3900 - dense_556_accuracy: 0.3720 - dense_557_accuracy: 0.3300 - dense_558_accuracy: 0.3180 - dense_559_accuracy: 0.2660 - dense_560_accuracy: 0.2720 - dense_561_accuracy: 0.2900 - dense_562_accuracy: 0.3100 - dense_563_accuracy: 0.3880 - dense_564_accuracy: 0.3180\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 16.5082 - dense_555_loss: 1.4994 - dense_556_loss: 1.5423 - dense_557_loss: 1.6759 - dense_558_loss: 1.6143 - dense_559_loss: 1.8719 - dense_560_loss: 1.7628 - dense_561_loss: 1.7464 - dense_562_loss: 1.5979 - dense_563_loss: 1.5108 - dense_564_loss: 1.6865 - dense_555_accuracy: 0.3860 - dense_556_accuracy: 0.3720 - dense_557_accuracy: 0.3240 - dense_558_accuracy: 0.3260 - dense_559_accuracy: 0.2280 - dense_560_accuracy: 0.2300 - dense_561_accuracy: 0.2540 - dense_562_accuracy: 0.3320 - dense_563_accuracy: 0.3940 - dense_564_accuracy: 0.2740\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 16.3031 - dense_555_loss: 1.4756 - dense_556_loss: 1.5282 - dense_557_loss: 1.6767 - dense_558_loss: 1.5574 - dense_559_loss: 1.8472 - dense_560_loss: 1.7310 - dense_561_loss: 1.7195 - dense_562_loss: 1.5921 - dense_563_loss: 1.5050 - dense_564_loss: 1.6704 - dense_555_accuracy: 0.3840 - dense_556_accuracy: 0.3320 - dense_557_accuracy: 0.2840 - dense_558_accuracy: 0.3520 - dense_559_accuracy: 0.3000 - dense_560_accuracy: 0.2840 - dense_561_accuracy: 0.2620 - dense_562_accuracy: 0.3320 - dense_563_accuracy: 0.3740 - dense_564_accuracy: 0.3240\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 16.1240 - dense_555_loss: 1.4662 - dense_556_loss: 1.5171 - dense_557_loss: 1.6564 - dense_558_loss: 1.5381 - dense_559_loss: 1.8276 - dense_560_loss: 1.7190 - dense_561_loss: 1.7076 - dense_562_loss: 1.5759 - dense_563_loss: 1.4645 - dense_564_loss: 1.6517 - dense_555_accuracy: 0.4020 - dense_556_accuracy: 0.3620 - dense_557_accuracy: 0.3400 - dense_558_accuracy: 0.3320 - dense_559_accuracy: 0.2920 - dense_560_accuracy: 0.2960 - dense_561_accuracy: 0.2740 - dense_562_accuracy: 0.3020 - dense_563_accuracy: 0.3580 - dense_564_accuracy: 0.2980\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 15.9171 - dense_555_loss: 1.4317 - dense_556_loss: 1.4946 - dense_557_loss: 1.6267 - dense_558_loss: 1.5257 - dense_559_loss: 1.8057 - dense_560_loss: 1.6922 - dense_561_loss: 1.6872 - dense_562_loss: 1.5626 - dense_563_loss: 1.4587 - dense_564_loss: 1.6321 - dense_555_accuracy: 0.3960 - dense_556_accuracy: 0.3760 - dense_557_accuracy: 0.3380 - dense_558_accuracy: 0.3580 - dense_559_accuracy: 0.3020 - dense_560_accuracy: 0.2960 - dense_561_accuracy: 0.2820 - dense_562_accuracy: 0.3180 - dense_563_accuracy: 0.4020 - dense_564_accuracy: 0.3060\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 15.8487 - dense_555_loss: 1.4359 - dense_556_loss: 1.4876 - dense_557_loss: 1.6240 - dense_558_loss: 1.5177 - dense_559_loss: 1.8028 - dense_560_loss: 1.6855 - dense_561_loss: 1.6754 - dense_562_loss: 1.5567 - dense_563_loss: 1.4392 - dense_564_loss: 1.6240 - dense_555_accuracy: 0.3960 - dense_556_accuracy: 0.3780 - dense_557_accuracy: 0.3220 - dense_558_accuracy: 0.3560 - dense_559_accuracy: 0.2900 - dense_560_accuracy: 0.2760 - dense_561_accuracy: 0.3140 - dense_562_accuracy: 0.3560 - dense_563_accuracy: 0.4060 - dense_564_accuracy: 0.3420\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 15.7585 - dense_555_loss: 1.4144 - dense_556_loss: 1.4693 - dense_557_loss: 1.6289 - dense_558_loss: 1.5130 - dense_559_loss: 1.7914 - dense_560_loss: 1.6786 - dense_561_loss: 1.6696 - dense_562_loss: 1.5459 - dense_563_loss: 1.4294 - dense_564_loss: 1.6179 - dense_555_accuracy: 0.4140 - dense_556_accuracy: 0.3980 - dense_557_accuracy: 0.3160 - dense_558_accuracy: 0.3680 - dense_559_accuracy: 0.2880 - dense_560_accuracy: 0.2840 - dense_561_accuracy: 0.2900 - dense_562_accuracy: 0.3500 - dense_563_accuracy: 0.3980 - dense_564_accuracy: 0.3400\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 15.6783 - dense_555_loss: 1.4074 - dense_556_loss: 1.4645 - dense_557_loss: 1.6058 - dense_558_loss: 1.5052 - dense_559_loss: 1.7810 - dense_560_loss: 1.6688 - dense_561_loss: 1.6564 - dense_562_loss: 1.5473 - dense_563_loss: 1.4286 - dense_564_loss: 1.6133 - dense_555_accuracy: 0.4200 - dense_556_accuracy: 0.3840 - dense_557_accuracy: 0.3520 - dense_558_accuracy: 0.3640 - dense_559_accuracy: 0.3180 - dense_560_accuracy: 0.3200 - dense_561_accuracy: 0.3300 - dense_562_accuracy: 0.3480 - dense_563_accuracy: 0.3760 - dense_564_accuracy: 0.3520\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 15.5825 - dense_555_loss: 1.4029 - dense_556_loss: 1.4566 - dense_557_loss: 1.5968 - dense_558_loss: 1.4954 - dense_559_loss: 1.7715 - dense_560_loss: 1.6615 - dense_561_loss: 1.6483 - dense_562_loss: 1.5303 - dense_563_loss: 1.4133 - dense_564_loss: 1.6060 - dense_555_accuracy: 0.4280 - dense_556_accuracy: 0.4200 - dense_557_accuracy: 0.3660 - dense_558_accuracy: 0.3780 - dense_559_accuracy: 0.3020 - dense_560_accuracy: 0.3420 - dense_561_accuracy: 0.3320 - dense_562_accuracy: 0.3580 - dense_563_accuracy: 0.4000 - dense_564_accuracy: 0.3440\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 15.4179 - dense_555_loss: 1.3821 - dense_556_loss: 1.4490 - dense_557_loss: 1.5834 - dense_558_loss: 1.4747 - dense_559_loss: 1.7529 - dense_560_loss: 1.6376 - dense_561_loss: 1.6291 - dense_562_loss: 1.5192 - dense_563_loss: 1.3978 - dense_564_loss: 1.5921 - dense_555_accuracy: 0.4400 - dense_556_accuracy: 0.4060 - dense_557_accuracy: 0.3660 - dense_558_accuracy: 0.3960 - dense_559_accuracy: 0.3160 - dense_560_accuracy: 0.3700 - dense_561_accuracy: 0.3520 - dense_562_accuracy: 0.3520 - dense_563_accuracy: 0.4360 - dense_564_accuracy: 0.3640\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 15.2953 - dense_555_loss: 1.3685 - dense_556_loss: 1.4428 - dense_557_loss: 1.5669 - dense_558_loss: 1.4613 - dense_559_loss: 1.7404 - dense_560_loss: 1.6302 - dense_561_loss: 1.6167 - dense_562_loss: 1.5097 - dense_563_loss: 1.3825 - dense_564_loss: 1.5765 - dense_555_accuracy: 0.4220 - dense_556_accuracy: 0.4100 - dense_557_accuracy: 0.3860 - dense_558_accuracy: 0.3940 - dense_559_accuracy: 0.3320 - dense_560_accuracy: 0.3620 - dense_561_accuracy: 0.3600 - dense_562_accuracy: 0.3840 - dense_563_accuracy: 0.4500 - dense_564_accuracy: 0.3640\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 15.2244 - dense_555_loss: 1.3624 - dense_556_loss: 1.4302 - dense_557_loss: 1.5672 - dense_558_loss: 1.4566 - dense_559_loss: 1.7256 - dense_560_loss: 1.6220 - dense_561_loss: 1.6067 - dense_562_loss: 1.4946 - dense_563_loss: 1.3857 - dense_564_loss: 1.5734 - dense_555_accuracy: 0.4500 - dense_556_accuracy: 0.4200 - dense_557_accuracy: 0.3740 - dense_558_accuracy: 0.4080 - dense_559_accuracy: 0.3640 - dense_560_accuracy: 0.3660 - dense_561_accuracy: 0.3620 - dense_562_accuracy: 0.4100 - dense_563_accuracy: 0.4260 - dense_564_accuracy: 0.3920\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 15.0835 - dense_555_loss: 1.3469 - dense_556_loss: 1.4232 - dense_557_loss: 1.5484 - dense_558_loss: 1.4379 - dense_559_loss: 1.7143 - dense_560_loss: 1.5931 - dense_561_loss: 1.5962 - dense_562_loss: 1.4871 - dense_563_loss: 1.3684 - dense_564_loss: 1.5681 - dense_555_accuracy: 0.4660 - dense_556_accuracy: 0.4600 - dense_557_accuracy: 0.3820 - dense_558_accuracy: 0.4280 - dense_559_accuracy: 0.3640 - dense_560_accuracy: 0.3740 - dense_561_accuracy: 0.3780 - dense_562_accuracy: 0.3780 - dense_563_accuracy: 0.4460 - dense_564_accuracy: 0.3780\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 14.8497 - dense_555_loss: 1.3204 - dense_556_loss: 1.3991 - dense_557_loss: 1.5248 - dense_558_loss: 1.4129 - dense_559_loss: 1.6834 - dense_560_loss: 1.5747 - dense_561_loss: 1.5759 - dense_562_loss: 1.4592 - dense_563_loss: 1.3536 - dense_564_loss: 1.5457 - dense_555_accuracy: 0.4760 - dense_556_accuracy: 0.4440 - dense_557_accuracy: 0.4080 - dense_558_accuracy: 0.4580 - dense_559_accuracy: 0.3900 - dense_560_accuracy: 0.4140 - dense_561_accuracy: 0.3800 - dense_562_accuracy: 0.4400 - dense_563_accuracy: 0.4620 - dense_564_accuracy: 0.3940\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 14.6829 - dense_555_loss: 1.3063 - dense_556_loss: 1.3923 - dense_557_loss: 1.5044 - dense_558_loss: 1.4012 - dense_559_loss: 1.6638 - dense_560_loss: 1.5555 - dense_561_loss: 1.5566 - dense_562_loss: 1.4401 - dense_563_loss: 1.3325 - dense_564_loss: 1.5301 - dense_555_accuracy: 0.4980 - dense_556_accuracy: 0.4640 - dense_557_accuracy: 0.4300 - dense_558_accuracy: 0.4800 - dense_559_accuracy: 0.4120 - dense_560_accuracy: 0.4240 - dense_561_accuracy: 0.4100 - dense_562_accuracy: 0.4300 - dense_563_accuracy: 0.4780 - dense_564_accuracy: 0.4160\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 14.4763 - dense_555_loss: 1.2924 - dense_556_loss: 1.3649 - dense_557_loss: 1.4912 - dense_558_loss: 1.3796 - dense_559_loss: 1.6362 - dense_560_loss: 1.5376 - dense_561_loss: 1.5401 - dense_562_loss: 1.4257 - dense_563_loss: 1.3062 - dense_564_loss: 1.5025 - dense_555_accuracy: 0.4880 - dense_556_accuracy: 0.4740 - dense_557_accuracy: 0.4460 - dense_558_accuracy: 0.4740 - dense_559_accuracy: 0.4280 - dense_560_accuracy: 0.4360 - dense_561_accuracy: 0.4220 - dense_562_accuracy: 0.4780 - dense_563_accuracy: 0.4880 - dense_564_accuracy: 0.4360\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D3AFBC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D3AFBC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4F929D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D4F929D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "8/8 [==============================] - 3s 9ms/step - loss: 24.7180 - dense_565_loss: 2.4608 - dense_566_loss: 2.3623 - dense_567_loss: 2.4661 - dense_568_loss: 2.3460 - dense_569_loss: 2.9405 - dense_570_loss: 2.5198 - dense_571_loss: 2.5678 - dense_572_loss: 2.3871 - dense_573_loss: 2.1493 - dense_574_loss: 2.5183 - dense_565_accuracy: 0.1380 - dense_566_accuracy: 0.1940 - dense_567_accuracy: 0.1500 - dense_568_accuracy: 0.2380 - dense_569_accuracy: 0.0680 - dense_570_accuracy: 0.1300 - dense_571_accuracy: 0.0980 - dense_572_accuracy: 0.1560 - dense_573_accuracy: 0.1660 - dense_574_accuracy: 0.1000\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 22.4930 - dense_565_loss: 2.2251 - dense_566_loss: 2.1779 - dense_567_loss: 2.2763 - dense_568_loss: 2.0993 - dense_569_loss: 2.7079 - dense_570_loss: 2.3525 - dense_571_loss: 2.3139 - dense_572_loss: 2.1397 - dense_573_loss: 1.8822 - dense_574_loss: 2.3181 - dense_565_accuracy: 0.2580 - dense_566_accuracy: 0.1860 - dense_567_accuracy: 0.1400 - dense_568_accuracy: 0.3040 - dense_569_accuracy: 0.1060 - dense_570_accuracy: 0.1540 - dense_571_accuracy: 0.1820 - dense_572_accuracy: 0.2180 - dense_573_accuracy: 0.2700 - dense_574_accuracy: 0.1520\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 20.8042 - dense_565_loss: 1.9953 - dense_566_loss: 2.0150 - dense_567_loss: 2.0685 - dense_568_loss: 1.9342 - dense_569_loss: 2.4796 - dense_570_loss: 2.2147 - dense_571_loss: 2.2036 - dense_572_loss: 1.9556 - dense_573_loss: 1.7927 - dense_574_loss: 2.1449 - dense_565_accuracy: 0.3220 - dense_566_accuracy: 0.2260 - dense_567_accuracy: 0.2620 - dense_568_accuracy: 0.3320 - dense_569_accuracy: 0.1380 - dense_570_accuracy: 0.1960 - dense_571_accuracy: 0.1960 - dense_572_accuracy: 0.2900 - dense_573_accuracy: 0.3360 - dense_574_accuracy: 0.2000\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 19.8723 - dense_565_loss: 1.8843 - dense_566_loss: 1.9415 - dense_567_loss: 1.9435 - dense_568_loss: 1.8584 - dense_569_loss: 2.3354 - dense_570_loss: 2.0856 - dense_571_loss: 2.1207 - dense_572_loss: 1.8652 - dense_573_loss: 1.7650 - dense_574_loss: 2.0728 - dense_565_accuracy: 0.3400 - dense_566_accuracy: 0.2780 - dense_567_accuracy: 0.2560 - dense_568_accuracy: 0.3400 - dense_569_accuracy: 0.2080 - dense_570_accuracy: 0.2280 - dense_571_accuracy: 0.1880 - dense_572_accuracy: 0.2900 - dense_573_accuracy: 0.3480 - dense_574_accuracy: 0.2440\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 19.0087 - dense_565_loss: 1.7886 - dense_566_loss: 1.8416 - dense_567_loss: 1.8845 - dense_568_loss: 1.8113 - dense_569_loss: 2.2125 - dense_570_loss: 1.9954 - dense_571_loss: 1.9965 - dense_572_loss: 1.7896 - dense_573_loss: 1.7010 - dense_574_loss: 1.9876 - dense_565_accuracy: 0.3400 - dense_566_accuracy: 0.3140 - dense_567_accuracy: 0.2800 - dense_568_accuracy: 0.3160 - dense_569_accuracy: 0.2000 - dense_570_accuracy: 0.2080 - dense_571_accuracy: 0.2260 - dense_572_accuracy: 0.2860 - dense_573_accuracy: 0.3500 - dense_574_accuracy: 0.2780\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 18.0971 - dense_565_loss: 1.6868 - dense_566_loss: 1.7223 - dense_567_loss: 1.7932 - dense_568_loss: 1.7562 - dense_569_loss: 2.1089 - dense_570_loss: 1.8831 - dense_571_loss: 1.9165 - dense_572_loss: 1.7194 - dense_573_loss: 1.6289 - dense_574_loss: 1.8817 - dense_565_accuracy: 0.3540 - dense_566_accuracy: 0.3380 - dense_567_accuracy: 0.2940 - dense_568_accuracy: 0.3400 - dense_569_accuracy: 0.2440 - dense_570_accuracy: 0.2440 - dense_571_accuracy: 0.2340 - dense_572_accuracy: 0.3420 - dense_573_accuracy: 0.3360 - dense_574_accuracy: 0.3000\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 17.4266 - dense_565_loss: 1.5969 - dense_566_loss: 1.6476 - dense_567_loss: 1.7539 - dense_568_loss: 1.6958 - dense_569_loss: 2.0172 - dense_570_loss: 1.8106 - dense_571_loss: 1.8595 - dense_572_loss: 1.6599 - dense_573_loss: 1.5631 - dense_574_loss: 1.8221 - dense_565_accuracy: 0.3680 - dense_566_accuracy: 0.3580 - dense_567_accuracy: 0.3140 - dense_568_accuracy: 0.3220 - dense_569_accuracy: 0.2460 - dense_570_accuracy: 0.2800 - dense_571_accuracy: 0.2580 - dense_572_accuracy: 0.3240 - dense_573_accuracy: 0.3680 - dense_574_accuracy: 0.3080\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 16.9580 - dense_565_loss: 1.5448 - dense_566_loss: 1.6088 - dense_567_loss: 1.7015 - dense_568_loss: 1.6318 - dense_569_loss: 1.9684 - dense_570_loss: 1.7835 - dense_571_loss: 1.8045 - dense_572_loss: 1.6337 - dense_573_loss: 1.5125 - dense_574_loss: 1.7685 - dense_565_accuracy: 0.3720 - dense_566_accuracy: 0.3480 - dense_567_accuracy: 0.3120 - dense_568_accuracy: 0.3480 - dense_569_accuracy: 0.2600 - dense_570_accuracy: 0.2840 - dense_571_accuracy: 0.2680 - dense_572_accuracy: 0.3140 - dense_573_accuracy: 0.3660 - dense_574_accuracy: 0.3120\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 16.4599 - dense_565_loss: 1.5104 - dense_566_loss: 1.5631 - dense_567_loss: 1.6667 - dense_568_loss: 1.5794 - dense_569_loss: 1.8963 - dense_570_loss: 1.7267 - dense_571_loss: 1.7453 - dense_572_loss: 1.5929 - dense_573_loss: 1.4661 - dense_574_loss: 1.7131 - dense_565_accuracy: 0.3700 - dense_566_accuracy: 0.3560 - dense_567_accuracy: 0.3080 - dense_568_accuracy: 0.3400 - dense_569_accuracy: 0.2820 - dense_570_accuracy: 0.3140 - dense_571_accuracy: 0.3100 - dense_572_accuracy: 0.3440 - dense_573_accuracy: 0.3820 - dense_574_accuracy: 0.3300\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 16.0535 - dense_565_loss: 1.4702 - dense_566_loss: 1.5127 - dense_567_loss: 1.6324 - dense_568_loss: 1.5500 - dense_569_loss: 1.8360 - dense_570_loss: 1.6945 - dense_571_loss: 1.6921 - dense_572_loss: 1.5636 - dense_573_loss: 1.4437 - dense_574_loss: 1.6582 - dense_565_accuracy: 0.3820 - dense_566_accuracy: 0.3680 - dense_567_accuracy: 0.3320 - dense_568_accuracy: 0.3460 - dense_569_accuracy: 0.2700 - dense_570_accuracy: 0.3040 - dense_571_accuracy: 0.3240 - dense_572_accuracy: 0.3400 - dense_573_accuracy: 0.3980 - dense_574_accuracy: 0.3420\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 15.9241 - dense_565_loss: 1.4481 - dense_566_loss: 1.5009 - dense_567_loss: 1.6264 - dense_568_loss: 1.5414 - dense_569_loss: 1.8217 - dense_570_loss: 1.6843 - dense_571_loss: 1.6706 - dense_572_loss: 1.5618 - dense_573_loss: 1.4343 - dense_574_loss: 1.6346 - dense_565_accuracy: 0.3960 - dense_566_accuracy: 0.3700 - dense_567_accuracy: 0.3340 - dense_568_accuracy: 0.3440 - dense_569_accuracy: 0.3060 - dense_570_accuracy: 0.3080 - dense_571_accuracy: 0.3240 - dense_572_accuracy: 0.3280 - dense_573_accuracy: 0.4120 - dense_574_accuracy: 0.3520\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 15.8250 - dense_565_loss: 1.4375 - dense_566_loss: 1.4920 - dense_567_loss: 1.6115 - dense_568_loss: 1.5396 - dense_569_loss: 1.8013 - dense_570_loss: 1.6724 - dense_571_loss: 1.6592 - dense_572_loss: 1.5554 - dense_573_loss: 1.4339 - dense_574_loss: 1.6223 - dense_565_accuracy: 0.3960 - dense_566_accuracy: 0.3800 - dense_567_accuracy: 0.3220 - dense_568_accuracy: 0.3540 - dense_569_accuracy: 0.2620 - dense_570_accuracy: 0.3020 - dense_571_accuracy: 0.2920 - dense_572_accuracy: 0.3460 - dense_573_accuracy: 0.4020 - dense_574_accuracy: 0.3240\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 15.7950 - dense_565_loss: 1.4388 - dense_566_loss: 1.4931 - dense_567_loss: 1.6136 - dense_568_loss: 1.5212 - dense_569_loss: 1.7884 - dense_570_loss: 1.6781 - dense_571_loss: 1.6670 - dense_572_loss: 1.5467 - dense_573_loss: 1.4246 - dense_574_loss: 1.6235 - dense_565_accuracy: 0.3800 - dense_566_accuracy: 0.3700 - dense_567_accuracy: 0.3240 - dense_568_accuracy: 0.3500 - dense_569_accuracy: 0.2840 - dense_570_accuracy: 0.3080 - dense_571_accuracy: 0.2900 - dense_572_accuracy: 0.3500 - dense_573_accuracy: 0.4060 - dense_574_accuracy: 0.3120\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 15.8764 - dense_565_loss: 1.4533 - dense_566_loss: 1.5144 - dense_567_loss: 1.6009 - dense_568_loss: 1.5231 - dense_569_loss: 1.7962 - dense_570_loss: 1.7156 - dense_571_loss: 1.6532 - dense_572_loss: 1.5661 - dense_573_loss: 1.4265 - dense_574_loss: 1.6271 - dense_565_accuracy: 0.3900 - dense_566_accuracy: 0.3540 - dense_567_accuracy: 0.3300 - dense_568_accuracy: 0.3440 - dense_569_accuracy: 0.2840 - dense_570_accuracy: 0.3020 - dense_571_accuracy: 0.3160 - dense_572_accuracy: 0.3240 - dense_573_accuracy: 0.4020 - dense_574_accuracy: 0.3520\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 15.7413 - dense_565_loss: 1.4327 - dense_566_loss: 1.4970 - dense_567_loss: 1.5991 - dense_568_loss: 1.5048 - dense_569_loss: 1.7725 - dense_570_loss: 1.6825 - dense_571_loss: 1.6433 - dense_572_loss: 1.5452 - dense_573_loss: 1.4425 - dense_574_loss: 1.6218 - dense_565_accuracy: 0.4080 - dense_566_accuracy: 0.3700 - dense_567_accuracy: 0.3080 - dense_568_accuracy: 0.3660 - dense_569_accuracy: 0.2820 - dense_570_accuracy: 0.3020 - dense_571_accuracy: 0.2960 - dense_572_accuracy: 0.3560 - dense_573_accuracy: 0.3920 - dense_574_accuracy: 0.3560\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 15.4659 - dense_565_loss: 1.4066 - dense_566_loss: 1.4605 - dense_567_loss: 1.5759 - dense_568_loss: 1.4903 - dense_569_loss: 1.7369 - dense_570_loss: 1.6621 - dense_571_loss: 1.6326 - dense_572_loss: 1.5122 - dense_573_loss: 1.4029 - dense_574_loss: 1.5860 - dense_565_accuracy: 0.3960 - dense_566_accuracy: 0.3680 - dense_567_accuracy: 0.3360 - dense_568_accuracy: 0.3660 - dense_569_accuracy: 0.2840 - dense_570_accuracy: 0.3160 - dense_571_accuracy: 0.3200 - dense_572_accuracy: 0.3660 - dense_573_accuracy: 0.3940 - dense_574_accuracy: 0.3600\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 15.2985 - dense_565_loss: 1.3939 - dense_566_loss: 1.4451 - dense_567_loss: 1.5611 - dense_568_loss: 1.4709 - dense_569_loss: 1.7248 - dense_570_loss: 1.6427 - dense_571_loss: 1.6032 - dense_572_loss: 1.4972 - dense_573_loss: 1.3794 - dense_574_loss: 1.5802 - dense_565_accuracy: 0.3860 - dense_566_accuracy: 0.3920 - dense_567_accuracy: 0.3540 - dense_568_accuracy: 0.3680 - dense_569_accuracy: 0.3240 - dense_570_accuracy: 0.3360 - dense_571_accuracy: 0.3240 - dense_572_accuracy: 0.3800 - dense_573_accuracy: 0.4120 - dense_574_accuracy: 0.3540\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 15.2615 - dense_565_loss: 1.3877 - dense_566_loss: 1.4386 - dense_567_loss: 1.5542 - dense_568_loss: 1.4760 - dense_569_loss: 1.7129 - dense_570_loss: 1.6429 - dense_571_loss: 1.6059 - dense_572_loss: 1.4895 - dense_573_loss: 1.3818 - dense_574_loss: 1.5719 - dense_565_accuracy: 0.4080 - dense_566_accuracy: 0.3840 - dense_567_accuracy: 0.3480 - dense_568_accuracy: 0.3800 - dense_569_accuracy: 0.3200 - dense_570_accuracy: 0.3260 - dense_571_accuracy: 0.3140 - dense_572_accuracy: 0.3820 - dense_573_accuracy: 0.4380 - dense_574_accuracy: 0.3280\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 15.2019 - dense_565_loss: 1.3827 - dense_566_loss: 1.4375 - dense_567_loss: 1.5437 - dense_568_loss: 1.4686 - dense_569_loss: 1.7143 - dense_570_loss: 1.6388 - dense_571_loss: 1.5867 - dense_572_loss: 1.4781 - dense_573_loss: 1.3728 - dense_574_loss: 1.5786 - dense_565_accuracy: 0.4140 - dense_566_accuracy: 0.4100 - dense_567_accuracy: 0.3660 - dense_568_accuracy: 0.3840 - dense_569_accuracy: 0.3060 - dense_570_accuracy: 0.3340 - dense_571_accuracy: 0.3300 - dense_572_accuracy: 0.3860 - dense_573_accuracy: 0.4200 - dense_574_accuracy: 0.3500\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 15.1123 - dense_565_loss: 1.3697 - dense_566_loss: 1.4382 - dense_567_loss: 1.5394 - dense_568_loss: 1.4634 - dense_569_loss: 1.6983 - dense_570_loss: 1.6306 - dense_571_loss: 1.5683 - dense_572_loss: 1.4744 - dense_573_loss: 1.3623 - dense_574_loss: 1.5677 - dense_565_accuracy: 0.4360 - dense_566_accuracy: 0.4080 - dense_567_accuracy: 0.3780 - dense_568_accuracy: 0.3820 - dense_569_accuracy: 0.3480 - dense_570_accuracy: 0.3280 - dense_571_accuracy: 0.3560 - dense_572_accuracy: 0.3880 - dense_573_accuracy: 0.4420 - dense_574_accuracy: 0.3720\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 14.9630 - dense_565_loss: 1.3501 - dense_566_loss: 1.4138 - dense_567_loss: 1.5297 - dense_568_loss: 1.4471 - dense_569_loss: 1.6884 - dense_570_loss: 1.6189 - dense_571_loss: 1.5650 - dense_572_loss: 1.4538 - dense_573_loss: 1.3461 - dense_574_loss: 1.5501 - dense_565_accuracy: 0.4440 - dense_566_accuracy: 0.3920 - dense_567_accuracy: 0.3740 - dense_568_accuracy: 0.3980 - dense_569_accuracy: 0.3280 - dense_570_accuracy: 0.3520 - dense_571_accuracy: 0.3560 - dense_572_accuracy: 0.3960 - dense_573_accuracy: 0.4580 - dense_574_accuracy: 0.3820\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 14.8326 - dense_565_loss: 1.3433 - dense_566_loss: 1.4010 - dense_567_loss: 1.5229 - dense_568_loss: 1.4317 - dense_569_loss: 1.6703 - dense_570_loss: 1.6011 - dense_571_loss: 1.5514 - dense_572_loss: 1.4394 - dense_573_loss: 1.3351 - dense_574_loss: 1.5365 - dense_565_accuracy: 0.4440 - dense_566_accuracy: 0.4320 - dense_567_accuracy: 0.3620 - dense_568_accuracy: 0.3920 - dense_569_accuracy: 0.3540 - dense_570_accuracy: 0.3660 - dense_571_accuracy: 0.3760 - dense_572_accuracy: 0.4180 - dense_573_accuracy: 0.4440 - dense_574_accuracy: 0.4040\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 14.8204 - dense_565_loss: 1.3586 - dense_566_loss: 1.4018 - dense_567_loss: 1.5204 - dense_568_loss: 1.4209 - dense_569_loss: 1.6701 - dense_570_loss: 1.6115 - dense_571_loss: 1.5324 - dense_572_loss: 1.4325 - dense_573_loss: 1.3336 - dense_574_loss: 1.5387 - dense_565_accuracy: 0.4440 - dense_566_accuracy: 0.4040 - dense_567_accuracy: 0.3780 - dense_568_accuracy: 0.3960 - dense_569_accuracy: 0.3760 - dense_570_accuracy: 0.3900 - dense_571_accuracy: 0.3980 - dense_572_accuracy: 0.4260 - dense_573_accuracy: 0.4660 - dense_574_accuracy: 0.4020\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 14.6949 - dense_565_loss: 1.3338 - dense_566_loss: 1.3758 - dense_567_loss: 1.5146 - dense_568_loss: 1.4125 - dense_569_loss: 1.6577 - dense_570_loss: 1.5993 - dense_571_loss: 1.5234 - dense_572_loss: 1.4291 - dense_573_loss: 1.3278 - dense_574_loss: 1.5210 - dense_565_accuracy: 0.4520 - dense_566_accuracy: 0.4360 - dense_567_accuracy: 0.3780 - dense_568_accuracy: 0.4060 - dense_569_accuracy: 0.3680 - dense_570_accuracy: 0.3560 - dense_571_accuracy: 0.3980 - dense_572_accuracy: 0.3920 - dense_573_accuracy: 0.4660 - dense_574_accuracy: 0.4100\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 14.8185 - dense_565_loss: 1.3657 - dense_566_loss: 1.3981 - dense_567_loss: 1.5221 - dense_568_loss: 1.4298 - dense_569_loss: 1.6615 - dense_570_loss: 1.6032 - dense_571_loss: 1.5340 - dense_572_loss: 1.4354 - dense_573_loss: 1.3418 - dense_574_loss: 1.5271 - dense_565_accuracy: 0.4320 - dense_566_accuracy: 0.4400 - dense_567_accuracy: 0.3780 - dense_568_accuracy: 0.3860 - dense_569_accuracy: 0.3620 - dense_570_accuracy: 0.3620 - dense_571_accuracy: 0.3940 - dense_572_accuracy: 0.4120 - dense_573_accuracy: 0.4620 - dense_574_accuracy: 0.3980\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4F460D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4F460D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D00F50D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D00F50D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 24ms/step - loss: 0.2076\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 0.0265\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 0.0058\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 0.0050\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.0048\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.0047\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.0047\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 0.0047\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.0046\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.0046\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.0045\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.0044\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.0042\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.0040\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.0038\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.0036\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.0035\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 0.0034\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.0033\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.0032\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 0.0032\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.0031\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.0031\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.0031\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 0.0030\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3B125E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D3B125E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 5s 11ms/step - loss: 17.4267 - dense_578_loss: 1.5455 - dense_579_loss: 1.7484 - dense_580_loss: 1.8405 - dense_581_loss: 1.6967 - dense_582_loss: 2.0024 - dense_583_loss: 1.7482 - dense_584_loss: 1.7010 - dense_585_loss: 1.7288 - dense_586_loss: 1.5952 - dense_587_loss: 1.8201 - dense_578_accuracy: 0.4210 - dense_579_accuracy: 0.2666 - dense_580_accuracy: 0.2076 - dense_581_accuracy: 0.2694 - dense_582_accuracy: 0.1936 - dense_583_accuracy: 0.2586 - dense_584_accuracy: 0.3304 - dense_585_accuracy: 0.2718 - dense_586_accuracy: 0.3608 - dense_587_accuracy: 0.2150\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 15.3541 - dense_578_loss: 1.3127 - dense_579_loss: 1.5478 - dense_580_loss: 1.6437 - dense_581_loss: 1.5141 - dense_582_loss: 1.7086 - dense_583_loss: 1.5471 - dense_584_loss: 1.4861 - dense_585_loss: 1.5559 - dense_586_loss: 1.4114 - dense_587_loss: 1.6265 - dense_578_accuracy: 0.4758 - dense_579_accuracy: 0.3142 - dense_580_accuracy: 0.2422 - dense_581_accuracy: 0.3100 - dense_582_accuracy: 0.2416 - dense_583_accuracy: 0.3002 - dense_584_accuracy: 0.3604 - dense_585_accuracy: 0.3102 - dense_586_accuracy: 0.4056 - dense_587_accuracy: 0.2416\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 15.3332 - dense_578_loss: 1.3127 - dense_579_loss: 1.5499 - dense_580_loss: 1.6389 - dense_581_loss: 1.5120 - dense_582_loss: 1.7051 - dense_583_loss: 1.5457 - dense_584_loss: 1.4859 - dense_585_loss: 1.5549 - dense_586_loss: 1.4078 - dense_587_loss: 1.6202 - dense_578_accuracy: 0.4724 - dense_579_accuracy: 0.3014 - dense_580_accuracy: 0.2428 - dense_581_accuracy: 0.2962 - dense_582_accuracy: 0.2324 - dense_583_accuracy: 0.2900 - dense_584_accuracy: 0.3556 - dense_585_accuracy: 0.2998 - dense_586_accuracy: 0.4032 - dense_587_accuracy: 0.2370\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 15.2835 - dense_578_loss: 1.3105 - dense_579_loss: 1.5382 - dense_580_loss: 1.6327 - dense_581_loss: 1.5071 - dense_582_loss: 1.7002 - dense_583_loss: 1.5381 - dense_584_loss: 1.4812 - dense_585_loss: 1.5519 - dense_586_loss: 1.4088 - dense_587_loss: 1.6151 - dense_578_accuracy: 0.4746 - dense_579_accuracy: 0.3046 - dense_580_accuracy: 0.2374 - dense_581_accuracy: 0.2958 - dense_582_accuracy: 0.2304 - dense_583_accuracy: 0.2944 - dense_584_accuracy: 0.3592 - dense_585_accuracy: 0.2968 - dense_586_accuracy: 0.3964 - dense_587_accuracy: 0.2388\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 15.2774 - dense_578_loss: 1.3052 - dense_579_loss: 1.5413 - dense_580_loss: 1.6309 - dense_581_loss: 1.5080 - dense_582_loss: 1.7003 - dense_583_loss: 1.5379 - dense_584_loss: 1.4819 - dense_585_loss: 1.5491 - dense_586_loss: 1.4061 - dense_587_loss: 1.6168 - dense_578_accuracy: 0.4742 - dense_579_accuracy: 0.3058 - dense_580_accuracy: 0.2466 - dense_581_accuracy: 0.3070 - dense_582_accuracy: 0.2358 - dense_583_accuracy: 0.3010 - dense_584_accuracy: 0.3516 - dense_585_accuracy: 0.2904 - dense_586_accuracy: 0.4004 - dense_587_accuracy: 0.2410\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 15.2849 - dense_578_loss: 1.3107 - dense_579_loss: 1.5361 - dense_580_loss: 1.6306 - dense_581_loss: 1.5103 - dense_582_loss: 1.7048 - dense_583_loss: 1.5373 - dense_584_loss: 1.4828 - dense_585_loss: 1.5465 - dense_586_loss: 1.4083 - dense_587_loss: 1.6175 - dense_578_accuracy: 0.4632 - dense_579_accuracy: 0.3094 - dense_580_accuracy: 0.2524 - dense_581_accuracy: 0.3058 - dense_582_accuracy: 0.2460 - dense_583_accuracy: 0.3006 - dense_584_accuracy: 0.3450 - dense_585_accuracy: 0.3090 - dense_586_accuracy: 0.4092 - dense_587_accuracy: 0.2506\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 1s 13ms/step - loss: 15.2135 - dense_578_loss: 1.3042 - dense_579_loss: 1.5340 - dense_580_loss: 1.6251 - dense_581_loss: 1.5007 - dense_582_loss: 1.6933 - dense_583_loss: 1.5278 - dense_584_loss: 1.4772 - dense_585_loss: 1.5416 - dense_586_loss: 1.4022 - dense_587_loss: 1.6075 - dense_578_accuracy: 0.4780 - dense_579_accuracy: 0.3068 - dense_580_accuracy: 0.2476 - dense_581_accuracy: 0.3118 - dense_582_accuracy: 0.2498 - dense_583_accuracy: 0.3126 - dense_584_accuracy: 0.3570 - dense_585_accuracy: 0.3014 - dense_586_accuracy: 0.4044 - dense_587_accuracy: 0.2566\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 15.1796 - dense_578_loss: 1.3001 - dense_579_loss: 1.5323 - dense_580_loss: 1.6188 - dense_581_loss: 1.4979 - dense_582_loss: 1.6890 - dense_583_loss: 1.5284 - dense_584_loss: 1.4723 - dense_585_loss: 1.5381 - dense_586_loss: 1.3971 - dense_587_loss: 1.6056 - dense_578_accuracy: 0.4794 - dense_579_accuracy: 0.3070 - dense_580_accuracy: 0.2478 - dense_581_accuracy: 0.3100 - dense_582_accuracy: 0.2508 - dense_583_accuracy: 0.3110 - dense_584_accuracy: 0.3698 - dense_585_accuracy: 0.3042 - dense_586_accuracy: 0.4050 - dense_587_accuracy: 0.2636\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 1s 13ms/step - loss: 15.1156 - dense_578_loss: 1.2936 - dense_579_loss: 1.5242 - dense_580_loss: 1.6129 - dense_581_loss: 1.4926 - dense_582_loss: 1.6820 - dense_583_loss: 1.5226 - dense_584_loss: 1.4678 - dense_585_loss: 1.5302 - dense_586_loss: 1.3890 - dense_587_loss: 1.6007 - dense_578_accuracy: 0.4780 - dense_579_accuracy: 0.3218 - dense_580_accuracy: 0.2694 - dense_581_accuracy: 0.3234 - dense_582_accuracy: 0.2636 - dense_583_accuracy: 0.3246 - dense_584_accuracy: 0.3716 - dense_585_accuracy: 0.3104 - dense_586_accuracy: 0.4126 - dense_587_accuracy: 0.2594\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 1s 13ms/step - loss: 15.0176 - dense_578_loss: 1.2873 - dense_579_loss: 1.5172 - dense_580_loss: 1.6001 - dense_581_loss: 1.4838 - dense_582_loss: 1.6724 - dense_583_loss: 1.5092 - dense_584_loss: 1.4567 - dense_585_loss: 1.5195 - dense_586_loss: 1.3854 - dense_587_loss: 1.5861 - dense_578_accuracy: 0.4846 - dense_579_accuracy: 0.3298 - dense_580_accuracy: 0.2720 - dense_581_accuracy: 0.3192 - dense_582_accuracy: 0.2634 - dense_583_accuracy: 0.3248 - dense_584_accuracy: 0.3772 - dense_585_accuracy: 0.3280 - dense_586_accuracy: 0.4188 - dense_587_accuracy: 0.2830\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 14.8876 - dense_578_loss: 1.2775 - dense_579_loss: 1.5030 - dense_580_loss: 1.5873 - dense_581_loss: 1.4683 - dense_582_loss: 1.6537 - dense_583_loss: 1.4975 - dense_584_loss: 1.4446 - dense_585_loss: 1.5089 - dense_586_loss: 1.3712 - dense_587_loss: 1.5756 - dense_578_accuracy: 0.4918 - dense_579_accuracy: 0.3346 - dense_580_accuracy: 0.2766 - dense_581_accuracy: 0.3370 - dense_582_accuracy: 0.2844 - dense_583_accuracy: 0.3366 - dense_584_accuracy: 0.3912 - dense_585_accuracy: 0.3362 - dense_586_accuracy: 0.4248 - dense_587_accuracy: 0.2822\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 14.7806 - dense_578_loss: 1.2690 - dense_579_loss: 1.4944 - dense_580_loss: 1.5729 - dense_581_loss: 1.4575 - dense_582_loss: 1.6390 - dense_583_loss: 1.4869 - dense_584_loss: 1.4331 - dense_585_loss: 1.4983 - dense_586_loss: 1.3647 - dense_587_loss: 1.5650 - dense_578_accuracy: 0.4930 - dense_579_accuracy: 0.3386 - dense_580_accuracy: 0.2962 - dense_581_accuracy: 0.3446 - dense_582_accuracy: 0.2856 - dense_583_accuracy: 0.3452 - dense_584_accuracy: 0.3964 - dense_585_accuracy: 0.3378 - dense_586_accuracy: 0.4292 - dense_587_accuracy: 0.2940\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 14.6811 - dense_578_loss: 1.2619 - dense_579_loss: 1.4868 - dense_580_loss: 1.5578 - dense_581_loss: 1.4516 - dense_582_loss: 1.6283 - dense_583_loss: 1.4764 - dense_584_loss: 1.4217 - dense_585_loss: 1.4883 - dense_586_loss: 1.3545 - dense_587_loss: 1.5538 - dense_578_accuracy: 0.4962 - dense_579_accuracy: 0.3502 - dense_580_accuracy: 0.2986 - dense_581_accuracy: 0.3420 - dense_582_accuracy: 0.2896 - dense_583_accuracy: 0.3390 - dense_584_accuracy: 0.4014 - dense_585_accuracy: 0.3450 - dense_586_accuracy: 0.4312 - dense_587_accuracy: 0.2968\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 14.5255 - dense_578_loss: 1.2464 - dense_579_loss: 1.4728 - dense_580_loss: 1.5417 - dense_581_loss: 1.4354 - dense_582_loss: 1.6123 - dense_583_loss: 1.4615 - dense_584_loss: 1.4083 - dense_585_loss: 1.4723 - dense_586_loss: 1.3388 - dense_587_loss: 1.5362 - dense_578_accuracy: 0.5060 - dense_579_accuracy: 0.3550 - dense_580_accuracy: 0.3156 - dense_581_accuracy: 0.3466 - dense_582_accuracy: 0.3044 - dense_583_accuracy: 0.3566 - dense_584_accuracy: 0.4080 - dense_585_accuracy: 0.3604 - dense_586_accuracy: 0.4392 - dense_587_accuracy: 0.3112\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 14.3805 - dense_578_loss: 1.2268 - dense_579_loss: 1.4604 - dense_580_loss: 1.5286 - dense_581_loss: 1.4221 - dense_582_loss: 1.5964 - dense_583_loss: 1.4475 - dense_584_loss: 1.3890 - dense_585_loss: 1.4582 - dense_586_loss: 1.3307 - dense_587_loss: 1.5208 - dense_578_accuracy: 0.5118 - dense_579_accuracy: 0.3588 - dense_580_accuracy: 0.3122 - dense_581_accuracy: 0.3618 - dense_582_accuracy: 0.3192 - dense_583_accuracy: 0.3654 - dense_584_accuracy: 0.4230 - dense_585_accuracy: 0.3628 - dense_586_accuracy: 0.4450 - dense_587_accuracy: 0.3210\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 14.3285 - dense_578_loss: 1.2272 - dense_579_loss: 1.4562 - dense_580_loss: 1.5170 - dense_581_loss: 1.4150 - dense_582_loss: 1.5909 - dense_583_loss: 1.4405 - dense_584_loss: 1.3883 - dense_585_loss: 1.4524 - dense_586_loss: 1.3260 - dense_587_loss: 1.5152 - dense_578_accuracy: 0.5142 - dense_579_accuracy: 0.3486 - dense_580_accuracy: 0.3164 - dense_581_accuracy: 0.3658 - dense_582_accuracy: 0.3170 - dense_583_accuracy: 0.3662 - dense_584_accuracy: 0.4296 - dense_585_accuracy: 0.3626 - dense_586_accuracy: 0.4482 - dense_587_accuracy: 0.3132\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 14.2658 - dense_578_loss: 1.2255 - dense_579_loss: 1.4482 - dense_580_loss: 1.5134 - dense_581_loss: 1.4045 - dense_582_loss: 1.5823 - dense_583_loss: 1.4322 - dense_584_loss: 1.3797 - dense_585_loss: 1.4482 - dense_586_loss: 1.3221 - dense_587_loss: 1.5097 - dense_578_accuracy: 0.5188 - dense_579_accuracy: 0.3590 - dense_580_accuracy: 0.3128 - dense_581_accuracy: 0.3590 - dense_582_accuracy: 0.3158 - dense_583_accuracy: 0.3666 - dense_584_accuracy: 0.4224 - dense_585_accuracy: 0.3662 - dense_586_accuracy: 0.4490 - dense_587_accuracy: 0.3070\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 14.1517 - dense_578_loss: 1.2131 - dense_579_loss: 1.4368 - dense_580_loss: 1.5028 - dense_581_loss: 1.3970 - dense_582_loss: 1.5720 - dense_583_loss: 1.4193 - dense_584_loss: 1.3652 - dense_585_loss: 1.4354 - dense_586_loss: 1.3119 - dense_587_loss: 1.4982 - dense_578_accuracy: 0.5160 - dense_579_accuracy: 0.3710 - dense_580_accuracy: 0.3326 - dense_581_accuracy: 0.3742 - dense_582_accuracy: 0.3324 - dense_583_accuracy: 0.3884 - dense_584_accuracy: 0.4256 - dense_585_accuracy: 0.3838 - dense_586_accuracy: 0.4512 - dense_587_accuracy: 0.3260\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 14.1149 - dense_578_loss: 1.2089 - dense_579_loss: 1.4322 - dense_580_loss: 1.4973 - dense_581_loss: 1.3896 - dense_582_loss: 1.5685 - dense_583_loss: 1.4166 - dense_584_loss: 1.3663 - dense_585_loss: 1.4286 - dense_586_loss: 1.3147 - dense_587_loss: 1.4921 - dense_578_accuracy: 0.5144 - dense_579_accuracy: 0.3724 - dense_580_accuracy: 0.3388 - dense_581_accuracy: 0.3798 - dense_582_accuracy: 0.3276 - dense_583_accuracy: 0.3816 - dense_584_accuracy: 0.4350 - dense_585_accuracy: 0.3766 - dense_586_accuracy: 0.4552 - dense_587_accuracy: 0.3334\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 14.0496 - dense_578_loss: 1.1995 - dense_579_loss: 1.4232 - dense_580_loss: 1.4938 - dense_581_loss: 1.3827 - dense_582_loss: 1.5573 - dense_583_loss: 1.4107 - dense_584_loss: 1.3562 - dense_585_loss: 1.4253 - dense_586_loss: 1.3060 - dense_587_loss: 1.4950 - dense_578_accuracy: 0.5286 - dense_579_accuracy: 0.3758 - dense_580_accuracy: 0.3352 - dense_581_accuracy: 0.3840 - dense_582_accuracy: 0.3314 - dense_583_accuracy: 0.3816 - dense_584_accuracy: 0.4444 - dense_585_accuracy: 0.3772 - dense_586_accuracy: 0.4622 - dense_587_accuracy: 0.3280\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 13.9845 - dense_578_loss: 1.1933 - dense_579_loss: 1.4178 - dense_580_loss: 1.4861 - dense_581_loss: 1.3788 - dense_582_loss: 1.5512 - dense_583_loss: 1.4058 - dense_584_loss: 1.3501 - dense_585_loss: 1.4184 - dense_586_loss: 1.3011 - dense_587_loss: 1.4820 - dense_578_accuracy: 0.5290 - dense_579_accuracy: 0.3818 - dense_580_accuracy: 0.3378 - dense_581_accuracy: 0.3866 - dense_582_accuracy: 0.3382 - dense_583_accuracy: 0.3848 - dense_584_accuracy: 0.4408 - dense_585_accuracy: 0.3818 - dense_586_accuracy: 0.4682 - dense_587_accuracy: 0.3402\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.9339 - dense_578_loss: 1.1942 - dense_579_loss: 1.4094 - dense_580_loss: 1.4797 - dense_581_loss: 1.3715 - dense_582_loss: 1.5440 - dense_583_loss: 1.4013 - dense_584_loss: 1.3447 - dense_585_loss: 1.4101 - dense_586_loss: 1.2983 - dense_587_loss: 1.4807 - dense_578_accuracy: 0.5250 - dense_579_accuracy: 0.3858 - dense_580_accuracy: 0.3522 - dense_581_accuracy: 0.3880 - dense_582_accuracy: 0.3454 - dense_583_accuracy: 0.3910 - dense_584_accuracy: 0.4374 - dense_585_accuracy: 0.3886 - dense_586_accuracy: 0.4652 - dense_587_accuracy: 0.3384\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.8673 - dense_578_loss: 1.1874 - dense_579_loss: 1.4043 - dense_580_loss: 1.4736 - dense_581_loss: 1.3645 - dense_582_loss: 1.5381 - dense_583_loss: 1.3968 - dense_584_loss: 1.3387 - dense_585_loss: 1.4036 - dense_586_loss: 1.2908 - dense_587_loss: 1.4696 - dense_578_accuracy: 0.5320 - dense_579_accuracy: 0.3904 - dense_580_accuracy: 0.3426 - dense_581_accuracy: 0.3928 - dense_582_accuracy: 0.3344 - dense_583_accuracy: 0.3954 - dense_584_accuracy: 0.4456 - dense_585_accuracy: 0.3948 - dense_586_accuracy: 0.4690 - dense_587_accuracy: 0.3508\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.8150 - dense_578_loss: 1.1812 - dense_579_loss: 1.4012 - dense_580_loss: 1.4665 - dense_581_loss: 1.3622 - dense_582_loss: 1.5287 - dense_583_loss: 1.3872 - dense_584_loss: 1.3337 - dense_585_loss: 1.4002 - dense_586_loss: 1.2906 - dense_587_loss: 1.4635 - dense_578_accuracy: 0.5304 - dense_579_accuracy: 0.3888 - dense_580_accuracy: 0.3554 - dense_581_accuracy: 0.3940 - dense_582_accuracy: 0.3546 - dense_583_accuracy: 0.3946 - dense_584_accuracy: 0.4512 - dense_585_accuracy: 0.3920 - dense_586_accuracy: 0.4710 - dense_587_accuracy: 0.3476\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 13.7989 - dense_578_loss: 1.1790 - dense_579_loss: 1.4001 - dense_580_loss: 1.4670 - dense_581_loss: 1.3569 - dense_582_loss: 1.5289 - dense_583_loss: 1.3865 - dense_584_loss: 1.3318 - dense_585_loss: 1.3996 - dense_586_loss: 1.2852 - dense_587_loss: 1.4639 - dense_578_accuracy: 0.5332 - dense_579_accuracy: 0.3792 - dense_580_accuracy: 0.3556 - dense_581_accuracy: 0.3914 - dense_582_accuracy: 0.3488 - dense_583_accuracy: 0.3958 - dense_584_accuracy: 0.4484 - dense_585_accuracy: 0.3930 - dense_586_accuracy: 0.4732 - dense_587_accuracy: 0.3500\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D2665438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D2665438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D45AC1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D45AC1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 5s 9ms/step - loss: 16.9587 - dense_588_loss: 1.4987 - dense_589_loss: 1.6927 - dense_590_loss: 1.7996 - dense_591_loss: 1.6559 - dense_592_loss: 1.9229 - dense_593_loss: 1.6962 - dense_594_loss: 1.6609 - dense_595_loss: 1.6826 - dense_596_loss: 1.5691 - dense_597_loss: 1.7800 - dense_588_accuracy: 0.4382 - dense_589_accuracy: 0.2786 - dense_590_accuracy: 0.2212 - dense_591_accuracy: 0.2902 - dense_592_accuracy: 0.2116 - dense_593_accuracy: 0.2830 - dense_594_accuracy: 0.3176 - dense_595_accuracy: 0.2778 - dense_596_accuracy: 0.3762 - dense_597_accuracy: 0.2098\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.2926 - dense_588_loss: 1.3103 - dense_589_loss: 1.5411 - dense_590_loss: 1.6324 - dense_591_loss: 1.5065 - dense_592_loss: 1.7055 - dense_593_loss: 1.5407 - dense_594_loss: 1.4807 - dense_595_loss: 1.5487 - dense_596_loss: 1.4091 - dense_597_loss: 1.6175 - dense_588_accuracy: 0.4754 - dense_589_accuracy: 0.3078 - dense_590_accuracy: 0.2406 - dense_591_accuracy: 0.3066 - dense_592_accuracy: 0.2388 - dense_593_accuracy: 0.3026 - dense_594_accuracy: 0.3642 - dense_595_accuracy: 0.3032 - dense_596_accuracy: 0.4064 - dense_597_accuracy: 0.2468\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 15.2892 - dense_588_loss: 1.3083 - dense_589_loss: 1.5442 - dense_590_loss: 1.6331 - dense_591_loss: 1.5063 - dense_592_loss: 1.7019 - dense_593_loss: 1.5389 - dense_594_loss: 1.4804 - dense_595_loss: 1.5480 - dense_596_loss: 1.4097 - dense_597_loss: 1.6184 - dense_588_accuracy: 0.4762 - dense_589_accuracy: 0.2942 - dense_590_accuracy: 0.2392 - dense_591_accuracy: 0.3092 - dense_592_accuracy: 0.2268 - dense_593_accuracy: 0.2890 - dense_594_accuracy: 0.3518 - dense_595_accuracy: 0.3008 - dense_596_accuracy: 0.4070 - dense_597_accuracy: 0.2314\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 15.2875 - dense_588_loss: 1.3089 - dense_589_loss: 1.5408 - dense_590_loss: 1.6340 - dense_591_loss: 1.5090 - dense_592_loss: 1.7033 - dense_593_loss: 1.5403 - dense_594_loss: 1.4788 - dense_595_loss: 1.5474 - dense_596_loss: 1.4072 - dense_597_loss: 1.6178 - dense_588_accuracy: 0.4748 - dense_589_accuracy: 0.3036 - dense_590_accuracy: 0.2366 - dense_591_accuracy: 0.3078 - dense_592_accuracy: 0.2284 - dense_593_accuracy: 0.2826 - dense_594_accuracy: 0.3504 - dense_595_accuracy: 0.2972 - dense_596_accuracy: 0.4026 - dense_597_accuracy: 0.2298\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 15.2744 - dense_588_loss: 1.3085 - dense_589_loss: 1.5401 - dense_590_loss: 1.6317 - dense_591_loss: 1.5067 - dense_592_loss: 1.6991 - dense_593_loss: 1.5383 - dense_594_loss: 1.4799 - dense_595_loss: 1.5498 - dense_596_loss: 1.4048 - dense_597_loss: 1.6156 - dense_588_accuracy: 0.4700 - dense_589_accuracy: 0.3020 - dense_590_accuracy: 0.2422 - dense_591_accuracy: 0.3014 - dense_592_accuracy: 0.2408 - dense_593_accuracy: 0.3058 - dense_594_accuracy: 0.3602 - dense_595_accuracy: 0.2988 - dense_596_accuracy: 0.4006 - dense_597_accuracy: 0.2320\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.2779 - dense_588_loss: 1.3071 - dense_589_loss: 1.5398 - dense_590_loss: 1.6306 - dense_591_loss: 1.5076 - dense_592_loss: 1.7012 - dense_593_loss: 1.5389 - dense_594_loss: 1.4798 - dense_595_loss: 1.5486 - dense_596_loss: 1.4078 - dense_597_loss: 1.6166 - dense_588_accuracy: 0.4762 - dense_589_accuracy: 0.3018 - dense_590_accuracy: 0.2376 - dense_591_accuracy: 0.3034 - dense_592_accuracy: 0.2334 - dense_593_accuracy: 0.2958 - dense_594_accuracy: 0.3634 - dense_595_accuracy: 0.3026 - dense_596_accuracy: 0.4032 - dense_597_accuracy: 0.2326\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 15.2805 - dense_588_loss: 1.3092 - dense_589_loss: 1.5381 - dense_590_loss: 1.6299 - dense_591_loss: 1.5077 - dense_592_loss: 1.7015 - dense_593_loss: 1.5389 - dense_594_loss: 1.4820 - dense_595_loss: 1.5474 - dense_596_loss: 1.4066 - dense_597_loss: 1.6192 - dense_588_accuracy: 0.4754 - dense_589_accuracy: 0.3058 - dense_590_accuracy: 0.2426 - dense_591_accuracy: 0.2964 - dense_592_accuracy: 0.2370 - dense_593_accuracy: 0.3044 - dense_594_accuracy: 0.3560 - dense_595_accuracy: 0.3044 - dense_596_accuracy: 0.4004 - dense_597_accuracy: 0.2436\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 15.2497 - dense_588_loss: 1.3071 - dense_589_loss: 1.5394 - dense_590_loss: 1.6287 - dense_591_loss: 1.5053 - dense_592_loss: 1.6965 - dense_593_loss: 1.5339 - dense_594_loss: 1.4758 - dense_595_loss: 1.5430 - dense_596_loss: 1.4061 - dense_597_loss: 1.6140 - dense_588_accuracy: 0.4760 - dense_589_accuracy: 0.2968 - dense_590_accuracy: 0.2318 - dense_591_accuracy: 0.3022 - dense_592_accuracy: 0.2464 - dense_593_accuracy: 0.2960 - dense_594_accuracy: 0.3586 - dense_595_accuracy: 0.3052 - dense_596_accuracy: 0.4056 - dense_597_accuracy: 0.2502\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.2368 - dense_588_loss: 1.3044 - dense_589_loss: 1.5368 - dense_590_loss: 1.6276 - dense_591_loss: 1.5028 - dense_592_loss: 1.6966 - dense_593_loss: 1.5339 - dense_594_loss: 1.4761 - dense_595_loss: 1.5431 - dense_596_loss: 1.4026 - dense_597_loss: 1.6129 - dense_588_accuracy: 0.4770 - dense_589_accuracy: 0.3026 - dense_590_accuracy: 0.2372 - dense_591_accuracy: 0.3006 - dense_592_accuracy: 0.2390 - dense_593_accuracy: 0.2988 - dense_594_accuracy: 0.3608 - dense_595_accuracy: 0.2990 - dense_596_accuracy: 0.4062 - dense_597_accuracy: 0.2382\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 15.2359 - dense_588_loss: 1.3063 - dense_589_loss: 1.5366 - dense_590_loss: 1.6278 - dense_591_loss: 1.5022 - dense_592_loss: 1.6960 - dense_593_loss: 1.5332 - dense_594_loss: 1.4755 - dense_595_loss: 1.5435 - dense_596_loss: 1.4015 - dense_597_loss: 1.6133 - dense_588_accuracy: 0.4762 - dense_589_accuracy: 0.2980 - dense_590_accuracy: 0.2324 - dense_591_accuracy: 0.2994 - dense_592_accuracy: 0.2358 - dense_593_accuracy: 0.2970 - dense_594_accuracy: 0.3598 - dense_595_accuracy: 0.2904 - dense_596_accuracy: 0.4050 - dense_597_accuracy: 0.2338\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 15.2105 - dense_588_loss: 1.3018 - dense_589_loss: 1.5331 - dense_590_loss: 1.6246 - dense_591_loss: 1.5006 - dense_592_loss: 1.6937 - dense_593_loss: 1.5311 - dense_594_loss: 1.4742 - dense_595_loss: 1.5403 - dense_596_loss: 1.4010 - dense_597_loss: 1.6103 - dense_588_accuracy: 0.4756 - dense_589_accuracy: 0.3032 - dense_590_accuracy: 0.2422 - dense_591_accuracy: 0.3058 - dense_592_accuracy: 0.2368 - dense_593_accuracy: 0.3034 - dense_594_accuracy: 0.3554 - dense_595_accuracy: 0.3072 - dense_596_accuracy: 0.4012 - dense_597_accuracy: 0.2458\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 15.2391 - dense_588_loss: 1.3041 - dense_589_loss: 1.5378 - dense_590_loss: 1.6270 - dense_591_loss: 1.5021 - dense_592_loss: 1.6974 - dense_593_loss: 1.5344 - dense_594_loss: 1.4777 - dense_595_loss: 1.5416 - dense_596_loss: 1.4025 - dense_597_loss: 1.6144 - dense_588_accuracy: 0.4756 - dense_589_accuracy: 0.2936 - dense_590_accuracy: 0.2342 - dense_591_accuracy: 0.3076 - dense_592_accuracy: 0.2330 - dense_593_accuracy: 0.2990 - dense_594_accuracy: 0.3556 - dense_595_accuracy: 0.3026 - dense_596_accuracy: 0.4000 - dense_597_accuracy: 0.2338\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.2069 - dense_588_loss: 1.3022 - dense_589_loss: 1.5349 - dense_590_loss: 1.6234 - dense_591_loss: 1.4977 - dense_592_loss: 1.6956 - dense_593_loss: 1.5293 - dense_594_loss: 1.4730 - dense_595_loss: 1.5423 - dense_596_loss: 1.3983 - dense_597_loss: 1.6103 - dense_588_accuracy: 0.4768 - dense_589_accuracy: 0.3020 - dense_590_accuracy: 0.2414 - dense_591_accuracy: 0.3036 - dense_592_accuracy: 0.2282 - dense_593_accuracy: 0.2982 - dense_594_accuracy: 0.3630 - dense_595_accuracy: 0.2988 - dense_596_accuracy: 0.4058 - dense_597_accuracy: 0.2452\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 15.2092 - dense_588_loss: 1.3027 - dense_589_loss: 1.5344 - dense_590_loss: 1.6237 - dense_591_loss: 1.4992 - dense_592_loss: 1.6945 - dense_593_loss: 1.5298 - dense_594_loss: 1.4731 - dense_595_loss: 1.5411 - dense_596_loss: 1.4005 - dense_597_loss: 1.6103 - dense_588_accuracy: 0.4764 - dense_589_accuracy: 0.3036 - dense_590_accuracy: 0.2382 - dense_591_accuracy: 0.3130 - dense_592_accuracy: 0.2382 - dense_593_accuracy: 0.2976 - dense_594_accuracy: 0.3602 - dense_595_accuracy: 0.3050 - dense_596_accuracy: 0.4048 - dense_597_accuracy: 0.2520\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.1750 - dense_588_loss: 1.2994 - dense_589_loss: 1.5295 - dense_590_loss: 1.6205 - dense_591_loss: 1.4964 - dense_592_loss: 1.6900 - dense_593_loss: 1.5259 - dense_594_loss: 1.4708 - dense_595_loss: 1.5385 - dense_596_loss: 1.3955 - dense_597_loss: 1.6086 - dense_588_accuracy: 0.4776 - dense_589_accuracy: 0.3092 - dense_590_accuracy: 0.2514 - dense_591_accuracy: 0.3102 - dense_592_accuracy: 0.2434 - dense_593_accuracy: 0.2998 - dense_594_accuracy: 0.3630 - dense_595_accuracy: 0.3024 - dense_596_accuracy: 0.4126 - dense_597_accuracy: 0.2454\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 15.1656 - dense_588_loss: 1.2992 - dense_589_loss: 1.5316 - dense_590_loss: 1.6211 - dense_591_loss: 1.4934 - dense_592_loss: 1.6895 - dense_593_loss: 1.5235 - dense_594_loss: 1.4687 - dense_595_loss: 1.5366 - dense_596_loss: 1.3968 - dense_597_loss: 1.6052 - dense_588_accuracy: 0.4786 - dense_589_accuracy: 0.3086 - dense_590_accuracy: 0.2590 - dense_591_accuracy: 0.3234 - dense_592_accuracy: 0.2468 - dense_593_accuracy: 0.3140 - dense_594_accuracy: 0.3650 - dense_595_accuracy: 0.3086 - dense_596_accuracy: 0.4116 - dense_597_accuracy: 0.2496\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 15.1866 - dense_588_loss: 1.3018 - dense_589_loss: 1.5375 - dense_590_loss: 1.6207 - dense_591_loss: 1.4946 - dense_592_loss: 1.6917 - dense_593_loss: 1.5265 - dense_594_loss: 1.4693 - dense_595_loss: 1.5402 - dense_596_loss: 1.3953 - dense_597_loss: 1.6089 - dense_588_accuracy: 0.4756 - dense_589_accuracy: 0.3006 - dense_590_accuracy: 0.2500 - dense_591_accuracy: 0.3150 - dense_592_accuracy: 0.2470 - dense_593_accuracy: 0.3034 - dense_594_accuracy: 0.3702 - dense_595_accuracy: 0.3026 - dense_596_accuracy: 0.4078 - dense_597_accuracy: 0.2484\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 15.1444 - dense_588_loss: 1.2960 - dense_589_loss: 1.5275 - dense_590_loss: 1.6156 - dense_591_loss: 1.4921 - dense_592_loss: 1.6892 - dense_593_loss: 1.5229 - dense_594_loss: 1.4680 - dense_595_loss: 1.5374 - dense_596_loss: 1.3937 - dense_597_loss: 1.6020 - dense_588_accuracy: 0.4790 - dense_589_accuracy: 0.3120 - dense_590_accuracy: 0.2492 - dense_591_accuracy: 0.3016 - dense_592_accuracy: 0.2456 - dense_593_accuracy: 0.3074 - dense_594_accuracy: 0.3688 - dense_595_accuracy: 0.3018 - dense_596_accuracy: 0.4120 - dense_597_accuracy: 0.2500\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 15.1107 - dense_588_loss: 1.2934 - dense_589_loss: 1.5276 - dense_590_loss: 1.6140 - dense_591_loss: 1.4900 - dense_592_loss: 1.6842 - dense_593_loss: 1.5179 - dense_594_loss: 1.4633 - dense_595_loss: 1.5301 - dense_596_loss: 1.3894 - dense_597_loss: 1.6009 - dense_588_accuracy: 0.4826 - dense_589_accuracy: 0.3032 - dense_590_accuracy: 0.2586 - dense_591_accuracy: 0.3058 - dense_592_accuracy: 0.2566 - dense_593_accuracy: 0.3102 - dense_594_accuracy: 0.3720 - dense_595_accuracy: 0.3038 - dense_596_accuracy: 0.4146 - dense_597_accuracy: 0.2572\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 15.0831 - dense_588_loss: 1.2891 - dense_589_loss: 1.5240 - dense_590_loss: 1.6077 - dense_591_loss: 1.4847 - dense_592_loss: 1.6805 - dense_593_loss: 1.5181 - dense_594_loss: 1.4619 - dense_595_loss: 1.5305 - dense_596_loss: 1.3883 - dense_597_loss: 1.5982 - dense_588_accuracy: 0.4848 - dense_589_accuracy: 0.3106 - dense_590_accuracy: 0.2706 - dense_591_accuracy: 0.3270 - dense_592_accuracy: 0.2648 - dense_593_accuracy: 0.3172 - dense_594_accuracy: 0.3800 - dense_595_accuracy: 0.3022 - dense_596_accuracy: 0.4206 - dense_597_accuracy: 0.2562\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 15.0777 - dense_588_loss: 1.2907 - dense_589_loss: 1.5210 - dense_590_loss: 1.6085 - dense_591_loss: 1.4887 - dense_592_loss: 1.6804 - dense_593_loss: 1.5177 - dense_594_loss: 1.4593 - dense_595_loss: 1.5307 - dense_596_loss: 1.3861 - dense_597_loss: 1.5948 - dense_588_accuracy: 0.4838 - dense_589_accuracy: 0.3116 - dense_590_accuracy: 0.2524 - dense_591_accuracy: 0.3068 - dense_592_accuracy: 0.2464 - dense_593_accuracy: 0.3090 - dense_594_accuracy: 0.3728 - dense_595_accuracy: 0.3018 - dense_596_accuracy: 0.4102 - dense_597_accuracy: 0.2624\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 15.0159 - dense_588_loss: 1.2840 - dense_589_loss: 1.5178 - dense_590_loss: 1.6010 - dense_591_loss: 1.4793 - dense_592_loss: 1.6736 - dense_593_loss: 1.5099 - dense_594_loss: 1.4532 - dense_595_loss: 1.5261 - dense_596_loss: 1.3811 - dense_597_loss: 1.5900 - dense_588_accuracy: 0.4908 - dense_589_accuracy: 0.3174 - dense_590_accuracy: 0.2730 - dense_591_accuracy: 0.3162 - dense_592_accuracy: 0.2552 - dense_593_accuracy: 0.3152 - dense_594_accuracy: 0.3806 - dense_595_accuracy: 0.3096 - dense_596_accuracy: 0.4172 - dense_597_accuracy: 0.2608\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 14.9734 - dense_588_loss: 1.2788 - dense_589_loss: 1.5136 - dense_590_loss: 1.5976 - dense_591_loss: 1.4776 - dense_592_loss: 1.6686 - dense_593_loss: 1.5060 - dense_594_loss: 1.4489 - dense_595_loss: 1.5221 - dense_596_loss: 1.3757 - dense_597_loss: 1.5844 - dense_588_accuracy: 0.4938 - dense_589_accuracy: 0.3166 - dense_590_accuracy: 0.2726 - dense_591_accuracy: 0.3284 - dense_592_accuracy: 0.2608 - dense_593_accuracy: 0.3238 - dense_594_accuracy: 0.3764 - dense_595_accuracy: 0.3102 - dense_596_accuracy: 0.4192 - dense_597_accuracy: 0.2636\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 14.9165 - dense_588_loss: 1.2756 - dense_589_loss: 1.5082 - dense_590_loss: 1.5900 - dense_591_loss: 1.4719 - dense_592_loss: 1.6633 - dense_593_loss: 1.4997 - dense_594_loss: 1.4444 - dense_595_loss: 1.5161 - dense_596_loss: 1.3705 - dense_597_loss: 1.5769 - dense_588_accuracy: 0.4920 - dense_589_accuracy: 0.3334 - dense_590_accuracy: 0.2728 - dense_591_accuracy: 0.3266 - dense_592_accuracy: 0.2754 - dense_593_accuracy: 0.3256 - dense_594_accuracy: 0.3858 - dense_595_accuracy: 0.3278 - dense_596_accuracy: 0.4272 - dense_597_accuracy: 0.2790\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 14.8785 - dense_588_loss: 1.2728 - dense_589_loss: 1.5024 - dense_590_loss: 1.5869 - dense_591_loss: 1.4697 - dense_592_loss: 1.6573 - dense_593_loss: 1.4945 - dense_594_loss: 1.4411 - dense_595_loss: 1.5108 - dense_596_loss: 1.3687 - dense_597_loss: 1.5742 - dense_588_accuracy: 0.4928 - dense_589_accuracy: 0.3322 - dense_590_accuracy: 0.2714 - dense_591_accuracy: 0.3274 - dense_592_accuracy: 0.2792 - dense_593_accuracy: 0.3260 - dense_594_accuracy: 0.3792 - dense_595_accuracy: 0.3220 - dense_596_accuracy: 0.4204 - dense_597_accuracy: 0.2822\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D07B8F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D07B8F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D38B1048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D38B1048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.1287\n",
      "Epoch 2/25\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.0062\n",
      "Epoch 3/25\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.0051\n",
      "Epoch 4/25\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.0049\n",
      "Epoch 5/25\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.0048\n",
      "Epoch 6/25\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.0046\n",
      "Epoch 7/25\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.0040\n",
      "Epoch 8/25\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.0036\n",
      "Epoch 9/25\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.0034\n",
      "Epoch 10/25\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.0033\n",
      "Epoch 11/25\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.0032\n",
      "Epoch 12/25\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.0032\n",
      "Epoch 13/25\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.0031\n",
      "Epoch 14/25\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.0031\n",
      "Epoch 15/25\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.0030\n",
      "Epoch 16/25\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.0030\n",
      "Epoch 17/25\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.0029\n",
      "Epoch 18/25\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.0029\n",
      "Epoch 19/25\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.0028\n",
      "Epoch 20/25\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.0028\n",
      "Epoch 21/25\n",
      "157/157 [==============================] - 3s 20ms/step - loss: 0.0028\n",
      "Epoch 22/25\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.0027\n",
      "Epoch 23/25\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.0027\n",
      "Epoch 24/25\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.0027\n",
      "Epoch 25/25\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.0027\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D450C9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D450C9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "157/157 [==============================] - 5s 8ms/step - loss: 16.7982 - dense_601_loss: 1.5140 - dense_602_loss: 1.9265 - dense_603_loss: 1.5357 - dense_604_loss: 1.6735 - dense_605_loss: 1.9233 - dense_606_loss: 1.9430 - dense_607_loss: 1.6952 - dense_608_loss: 1.5828 - dense_609_loss: 1.5135 - dense_610_loss: 1.4906 - dense_601_accuracy: 0.3671 - dense_602_accuracy: 0.2075 - dense_603_accuracy: 0.3799 - dense_604_accuracy: 0.2933 - dense_605_accuracy: 0.2072 - dense_606_accuracy: 0.2069 - dense_607_accuracy: 0.2702 - dense_608_accuracy: 0.2946 - dense_609_accuracy: 0.3711 - dense_610_accuracy: 0.3570\n",
      "Epoch 2/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 14.3675 - dense_601_loss: 1.3158 - dense_602_loss: 1.6290 - dense_603_loss: 1.3076 - dense_604_loss: 1.4587 - dense_605_loss: 1.6333 - dense_606_loss: 1.6416 - dense_607_loss: 1.4699 - dense_608_loss: 1.3751 - dense_609_loss: 1.2526 - dense_610_loss: 1.2838 - dense_601_accuracy: 0.4200 - dense_602_accuracy: 0.2420 - dense_603_accuracy: 0.4304 - dense_604_accuracy: 0.3176 - dense_605_accuracy: 0.2389 - dense_606_accuracy: 0.2445 - dense_607_accuracy: 0.3111 - dense_608_accuracy: 0.3109 - dense_609_accuracy: 0.4145 - dense_610_accuracy: 0.4015\n",
      "Epoch 3/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 14.2941 - dense_601_loss: 1.3074 - dense_602_loss: 1.6184 - dense_603_loss: 1.3017 - dense_604_loss: 1.4539 - dense_605_loss: 1.6223 - dense_606_loss: 1.6280 - dense_607_loss: 1.4638 - dense_608_loss: 1.3635 - dense_609_loss: 1.2501 - dense_610_loss: 1.2850 - dense_601_accuracy: 0.4206 - dense_602_accuracy: 0.2393 - dense_603_accuracy: 0.4328 - dense_604_accuracy: 0.3216 - dense_605_accuracy: 0.2454 - dense_606_accuracy: 0.2394 - dense_607_accuracy: 0.3083 - dense_608_accuracy: 0.3190 - dense_609_accuracy: 0.4100 - dense_610_accuracy: 0.3971\n",
      "Epoch 4/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.2088 - dense_601_loss: 1.2993 - dense_602_loss: 1.6098 - dense_603_loss: 1.2974 - dense_604_loss: 1.4433 - dense_605_loss: 1.6129 - dense_606_loss: 1.6199 - dense_607_loss: 1.4560 - dense_608_loss: 1.3555 - dense_609_loss: 1.2398 - dense_610_loss: 1.2750 - dense_601_accuracy: 0.4256 - dense_602_accuracy: 0.2476 - dense_603_accuracy: 0.4322 - dense_604_accuracy: 0.3234 - dense_605_accuracy: 0.2511 - dense_606_accuracy: 0.2492 - dense_607_accuracy: 0.3158 - dense_608_accuracy: 0.3270 - dense_609_accuracy: 0.4237 - dense_610_accuracy: 0.4068\n",
      "Epoch 5/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.1963 - dense_601_loss: 1.2979 - dense_602_loss: 1.6083 - dense_603_loss: 1.2951 - dense_604_loss: 1.4444 - dense_605_loss: 1.6099 - dense_606_loss: 1.6191 - dense_607_loss: 1.4541 - dense_608_loss: 1.3544 - dense_609_loss: 1.2397 - dense_610_loss: 1.2734 - dense_601_accuracy: 0.4235 - dense_602_accuracy: 0.2525 - dense_603_accuracy: 0.4339 - dense_604_accuracy: 0.3287 - dense_605_accuracy: 0.2478 - dense_606_accuracy: 0.2471 - dense_607_accuracy: 0.3086 - dense_608_accuracy: 0.3294 - dense_609_accuracy: 0.4194 - dense_610_accuracy: 0.4057\n",
      "Epoch 6/25\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 14.2095 - dense_601_loss: 1.2991 - dense_602_loss: 1.6083 - dense_603_loss: 1.2982 - dense_604_loss: 1.4449 - dense_605_loss: 1.6104 - dense_606_loss: 1.6210 - dense_607_loss: 1.4552 - dense_608_loss: 1.3559 - dense_609_loss: 1.2412 - dense_610_loss: 1.2753 - dense_601_accuracy: 0.4235 - dense_602_accuracy: 0.2515 - dense_603_accuracy: 0.4311 - dense_604_accuracy: 0.3227 - dense_605_accuracy: 0.2499 - dense_606_accuracy: 0.2539 - dense_607_accuracy: 0.3126 - dense_608_accuracy: 0.3327 - dense_609_accuracy: 0.4255 - dense_610_accuracy: 0.4048\n",
      "Epoch 7/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.1458 - dense_601_loss: 1.2929 - dense_602_loss: 1.6015 - dense_603_loss: 1.2926 - dense_604_loss: 1.4406 - dense_605_loss: 1.6029 - dense_606_loss: 1.6120 - dense_607_loss: 1.4481 - dense_608_loss: 1.3500 - dense_609_loss: 1.2365 - dense_610_loss: 1.2688 - dense_601_accuracy: 0.4257 - dense_602_accuracy: 0.2604 - dense_603_accuracy: 0.4348 - dense_604_accuracy: 0.3282 - dense_605_accuracy: 0.2611 - dense_606_accuracy: 0.2542 - dense_607_accuracy: 0.3211 - dense_608_accuracy: 0.3361 - dense_609_accuracy: 0.4282 - dense_610_accuracy: 0.4168\n",
      "Epoch 8/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 14.0565 - dense_601_loss: 1.2885 - dense_602_loss: 1.5882 - dense_603_loss: 1.2833 - dense_604_loss: 1.4305 - dense_605_loss: 1.5926 - dense_606_loss: 1.6022 - dense_607_loss: 1.4394 - dense_608_loss: 1.3414 - dense_609_loss: 1.2256 - dense_610_loss: 1.2650 - dense_601_accuracy: 0.4250 - dense_602_accuracy: 0.2671 - dense_603_accuracy: 0.4403 - dense_604_accuracy: 0.3320 - dense_605_accuracy: 0.2658 - dense_606_accuracy: 0.2679 - dense_607_accuracy: 0.3229 - dense_608_accuracy: 0.3398 - dense_609_accuracy: 0.4342 - dense_610_accuracy: 0.4158\n",
      "Epoch 9/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 14.0038 - dense_601_loss: 1.2832 - dense_602_loss: 1.5855 - dense_603_loss: 1.2764 - dense_604_loss: 1.4235 - dense_605_loss: 1.5859 - dense_606_loss: 1.5974 - dense_607_loss: 1.4319 - dense_608_loss: 1.3398 - dense_609_loss: 1.2206 - dense_610_loss: 1.2595 - dense_601_accuracy: 0.4320 - dense_602_accuracy: 0.2723 - dense_603_accuracy: 0.4455 - dense_604_accuracy: 0.3424 - dense_605_accuracy: 0.2699 - dense_606_accuracy: 0.2729 - dense_607_accuracy: 0.3398 - dense_608_accuracy: 0.3436 - dense_609_accuracy: 0.4332 - dense_610_accuracy: 0.4185\n",
      "Epoch 10/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.9390 - dense_601_loss: 1.2796 - dense_602_loss: 1.5757 - dense_603_loss: 1.2711 - dense_604_loss: 1.4151 - dense_605_loss: 1.5773 - dense_606_loss: 1.5902 - dense_607_loss: 1.4283 - dense_608_loss: 1.3343 - dense_609_loss: 1.2166 - dense_610_loss: 1.2507 - dense_601_accuracy: 0.4317 - dense_602_accuracy: 0.2823 - dense_603_accuracy: 0.4410 - dense_604_accuracy: 0.3444 - dense_605_accuracy: 0.2809 - dense_606_accuracy: 0.2831 - dense_607_accuracy: 0.3335 - dense_608_accuracy: 0.3426 - dense_609_accuracy: 0.4400 - dense_610_accuracy: 0.4287\n",
      "Epoch 11/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.8822 - dense_601_loss: 1.2747 - dense_602_loss: 1.5692 - dense_603_loss: 1.2684 - dense_604_loss: 1.4083 - dense_605_loss: 1.5724 - dense_606_loss: 1.5812 - dense_607_loss: 1.4218 - dense_608_loss: 1.3293 - dense_609_loss: 1.2106 - dense_610_loss: 1.2463 - dense_601_accuracy: 0.4388 - dense_602_accuracy: 0.2805 - dense_603_accuracy: 0.4480 - dense_604_accuracy: 0.3489 - dense_605_accuracy: 0.2816 - dense_606_accuracy: 0.2792 - dense_607_accuracy: 0.3360 - dense_608_accuracy: 0.3506 - dense_609_accuracy: 0.4407 - dense_610_accuracy: 0.4285\n",
      "Epoch 12/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.8102 - dense_601_loss: 1.2679 - dense_602_loss: 1.5613 - dense_603_loss: 1.2632 - dense_604_loss: 1.4030 - dense_605_loss: 1.5603 - dense_606_loss: 1.5713 - dense_607_loss: 1.4134 - dense_608_loss: 1.3185 - dense_609_loss: 1.2050 - dense_610_loss: 1.2463 - dense_601_accuracy: 0.4387 - dense_602_accuracy: 0.2850 - dense_603_accuracy: 0.4466 - dense_604_accuracy: 0.3542 - dense_605_accuracy: 0.2898 - dense_606_accuracy: 0.2869 - dense_607_accuracy: 0.3455 - dense_608_accuracy: 0.3567 - dense_609_accuracy: 0.4476 - dense_610_accuracy: 0.4328\n",
      "Epoch 13/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.7480 - dense_601_loss: 1.2638 - dense_602_loss: 1.5541 - dense_603_loss: 1.2567 - dense_604_loss: 1.3992 - dense_605_loss: 1.5543 - dense_606_loss: 1.5625 - dense_607_loss: 1.4076 - dense_608_loss: 1.3145 - dense_609_loss: 1.1977 - dense_610_loss: 1.2376 - dense_601_accuracy: 0.4453 - dense_602_accuracy: 0.2916 - dense_603_accuracy: 0.4556 - dense_604_accuracy: 0.3599 - dense_605_accuracy: 0.3016 - dense_606_accuracy: 0.2984 - dense_607_accuracy: 0.3449 - dense_608_accuracy: 0.3706 - dense_609_accuracy: 0.4511 - dense_610_accuracy: 0.4341\n",
      "Epoch 14/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 13.6992 - dense_601_loss: 1.2597 - dense_602_loss: 1.5476 - dense_603_loss: 1.2528 - dense_604_loss: 1.3934 - dense_605_loss: 1.5476 - dense_606_loss: 1.5582 - dense_607_loss: 1.4020 - dense_608_loss: 1.3100 - dense_609_loss: 1.1907 - dense_610_loss: 1.2372 - dense_601_accuracy: 0.4411 - dense_602_accuracy: 0.2970 - dense_603_accuracy: 0.4554 - dense_604_accuracy: 0.3631 - dense_605_accuracy: 0.3010 - dense_606_accuracy: 0.3004 - dense_607_accuracy: 0.3516 - dense_608_accuracy: 0.3727 - dense_609_accuracy: 0.4523 - dense_610_accuracy: 0.4346\n",
      "Epoch 15/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 13.6603 - dense_601_loss: 1.2561 - dense_602_loss: 1.5435 - dense_603_loss: 1.2499 - dense_604_loss: 1.3856 - dense_605_loss: 1.5431 - dense_606_loss: 1.5547 - dense_607_loss: 1.3989 - dense_608_loss: 1.3064 - dense_609_loss: 1.1893 - dense_610_loss: 1.2327 - dense_601_accuracy: 0.4448 - dense_602_accuracy: 0.2983 - dense_603_accuracy: 0.4563 - dense_604_accuracy: 0.3656 - dense_605_accuracy: 0.3018 - dense_606_accuracy: 0.2944 - dense_607_accuracy: 0.3495 - dense_608_accuracy: 0.3689 - dense_609_accuracy: 0.4566 - dense_610_accuracy: 0.4380\n",
      "Epoch 16/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 13.6395 - dense_601_loss: 1.2576 - dense_602_loss: 1.5396 - dense_603_loss: 1.2467 - dense_604_loss: 1.3841 - dense_605_loss: 1.5402 - dense_606_loss: 1.5509 - dense_607_loss: 1.3993 - dense_608_loss: 1.3025 - dense_609_loss: 1.1857 - dense_610_loss: 1.2329 - dense_601_accuracy: 0.4444 - dense_602_accuracy: 0.3035 - dense_603_accuracy: 0.4563 - dense_604_accuracy: 0.3691 - dense_605_accuracy: 0.3001 - dense_606_accuracy: 0.3010 - dense_607_accuracy: 0.3576 - dense_608_accuracy: 0.3671 - dense_609_accuracy: 0.4578 - dense_610_accuracy: 0.4404\n",
      "Epoch 17/25\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 13.6244 - dense_601_loss: 1.2532 - dense_602_loss: 1.5393 - dense_603_loss: 1.2469 - dense_604_loss: 1.3882 - dense_605_loss: 1.5397 - dense_606_loss: 1.5470 - dense_607_loss: 1.3948 - dense_608_loss: 1.3015 - dense_609_loss: 1.1847 - dense_610_loss: 1.2292 - dense_601_accuracy: 0.4491 - dense_602_accuracy: 0.3060 - dense_603_accuracy: 0.4562 - dense_604_accuracy: 0.3714 - dense_605_accuracy: 0.3082 - dense_606_accuracy: 0.3096 - dense_607_accuracy: 0.3585 - dense_608_accuracy: 0.3811 - dense_609_accuracy: 0.4638 - dense_610_accuracy: 0.4436\n",
      "Epoch 18/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.5369 - dense_601_loss: 1.2468 - dense_602_loss: 1.5295 - dense_603_loss: 1.2373 - dense_604_loss: 1.3761 - dense_605_loss: 1.5282 - dense_606_loss: 1.5396 - dense_607_loss: 1.3869 - dense_608_loss: 1.2969 - dense_609_loss: 1.1761 - dense_610_loss: 1.2196 - dense_601_accuracy: 0.4512 - dense_602_accuracy: 0.3045 - dense_603_accuracy: 0.4625 - dense_604_accuracy: 0.3704 - dense_605_accuracy: 0.3061 - dense_606_accuracy: 0.3029 - dense_607_accuracy: 0.3570 - dense_608_accuracy: 0.3711 - dense_609_accuracy: 0.4628 - dense_610_accuracy: 0.4462\n",
      "Epoch 19/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.5193 - dense_601_loss: 1.2456 - dense_602_loss: 1.5252 - dense_603_loss: 1.2385 - dense_604_loss: 1.3750 - dense_605_loss: 1.5260 - dense_606_loss: 1.5359 - dense_607_loss: 1.3861 - dense_608_loss: 1.2920 - dense_609_loss: 1.1762 - dense_610_loss: 1.2188 - dense_601_accuracy: 0.4518 - dense_602_accuracy: 0.3141 - dense_603_accuracy: 0.4626 - dense_604_accuracy: 0.3763 - dense_605_accuracy: 0.3098 - dense_606_accuracy: 0.3163 - dense_607_accuracy: 0.3603 - dense_608_accuracy: 0.3812 - dense_609_accuracy: 0.4669 - dense_610_accuracy: 0.4460\n",
      "Epoch 20/25\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 13.4359 - dense_601_loss: 1.2391 - dense_602_loss: 1.5149 - dense_603_loss: 1.2293 - dense_604_loss: 1.3651 - dense_605_loss: 1.5160 - dense_606_loss: 1.5266 - dense_607_loss: 1.3768 - dense_608_loss: 1.2860 - dense_609_loss: 1.1694 - dense_610_loss: 1.2127 - dense_601_accuracy: 0.4584 - dense_602_accuracy: 0.3225 - dense_603_accuracy: 0.4669 - dense_604_accuracy: 0.3854 - dense_605_accuracy: 0.3255 - dense_606_accuracy: 0.3247 - dense_607_accuracy: 0.3695 - dense_608_accuracy: 0.3903 - dense_609_accuracy: 0.4793 - dense_610_accuracy: 0.4513\n",
      "Epoch 21/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.4100 - dense_601_loss: 1.2401 - dense_602_loss: 1.5132 - dense_603_loss: 1.2252 - dense_604_loss: 1.3618 - dense_605_loss: 1.5140 - dense_606_loss: 1.5251 - dense_607_loss: 1.3751 - dense_608_loss: 1.2815 - dense_609_loss: 1.1671 - dense_610_loss: 1.2068 - dense_601_accuracy: 0.4590 - dense_602_accuracy: 0.3194 - dense_603_accuracy: 0.4740 - dense_604_accuracy: 0.3822 - dense_605_accuracy: 0.3207 - dense_606_accuracy: 0.3155 - dense_607_accuracy: 0.3714 - dense_608_accuracy: 0.3947 - dense_609_accuracy: 0.4684 - dense_610_accuracy: 0.4577\n",
      "Epoch 22/25\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 13.3825 - dense_601_loss: 1.2360 - dense_602_loss: 1.5097 - dense_603_loss: 1.2226 - dense_604_loss: 1.3602 - dense_605_loss: 1.5099 - dense_606_loss: 1.5201 - dense_607_loss: 1.3759 - dense_608_loss: 1.2766 - dense_609_loss: 1.1651 - dense_610_loss: 1.2064 - dense_601_accuracy: 0.4576 - dense_602_accuracy: 0.3203 - dense_603_accuracy: 0.4754 - dense_604_accuracy: 0.3872 - dense_605_accuracy: 0.3241 - dense_606_accuracy: 0.3245 - dense_607_accuracy: 0.3705 - dense_608_accuracy: 0.3932 - dense_609_accuracy: 0.4717 - dense_610_accuracy: 0.4515\n",
      "Epoch 23/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.3714 - dense_601_loss: 1.2347 - dense_602_loss: 1.5076 - dense_603_loss: 1.2242 - dense_604_loss: 1.3619 - dense_605_loss: 1.5086 - dense_606_loss: 1.5183 - dense_607_loss: 1.3682 - dense_608_loss: 1.2784 - dense_609_loss: 1.1622 - dense_610_loss: 1.2072 - dense_601_accuracy: 0.4593 - dense_602_accuracy: 0.3196 - dense_603_accuracy: 0.4722 - dense_604_accuracy: 0.3843 - dense_605_accuracy: 0.3176 - dense_606_accuracy: 0.3160 - dense_607_accuracy: 0.3736 - dense_608_accuracy: 0.3887 - dense_609_accuracy: 0.4672 - dense_610_accuracy: 0.4492\n",
      "Epoch 24/25\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 13.3788 - dense_601_loss: 1.2327 - dense_602_loss: 1.5061 - dense_603_loss: 1.2265 - dense_604_loss: 1.3598 - dense_605_loss: 1.5093 - dense_606_loss: 1.5205 - dense_607_loss: 1.3735 - dense_608_loss: 1.2760 - dense_609_loss: 1.1674 - dense_610_loss: 1.2069 - dense_601_accuracy: 0.4534 - dense_602_accuracy: 0.3275 - dense_603_accuracy: 0.4687 - dense_604_accuracy: 0.3822 - dense_605_accuracy: 0.3281 - dense_606_accuracy: 0.3189 - dense_607_accuracy: 0.3678 - dense_608_accuracy: 0.3924 - dense_609_accuracy: 0.4731 - dense_610_accuracy: 0.4509\n",
      "Epoch 25/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.3444 - dense_601_loss: 1.2301 - dense_602_loss: 1.5024 - dense_603_loss: 1.2227 - dense_604_loss: 1.3572 - dense_605_loss: 1.5062 - dense_606_loss: 1.5165 - dense_607_loss: 1.3669 - dense_608_loss: 1.2778 - dense_609_loss: 1.1604 - dense_610_loss: 1.2042 - dense_601_accuracy: 0.4632 - dense_602_accuracy: 0.3273 - dense_603_accuracy: 0.4723 - dense_604_accuracy: 0.3854 - dense_605_accuracy: 0.3272 - dense_606_accuracy: 0.3212 - dense_607_accuracy: 0.3719 - dense_608_accuracy: 0.3962 - dense_609_accuracy: 0.4745 - dense_610_accuracy: 0.4518\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4B8F4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D4B8F4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D1A8A4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D1A8A4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "157/157 [==============================] - 4s 7ms/step - loss: 16.2238 - dense_611_loss: 1.4720 - dense_612_loss: 1.8567 - dense_613_loss: 1.4698 - dense_614_loss: 1.6082 - dense_615_loss: 1.8772 - dense_616_loss: 1.8706 - dense_617_loss: 1.6409 - dense_618_loss: 1.5423 - dense_619_loss: 1.4567 - dense_620_loss: 1.4294 - dense_611_accuracy: 0.3924 - dense_612_accuracy: 0.2164 - dense_613_accuracy: 0.4030 - dense_614_accuracy: 0.3003 - dense_615_accuracy: 0.2166 - dense_616_accuracy: 0.2190 - dense_617_accuracy: 0.2860 - dense_618_accuracy: 0.3009 - dense_619_accuracy: 0.3775 - dense_620_accuracy: 0.3719\n",
      "Epoch 2/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.3167 - dense_611_loss: 1.3064 - dense_612_loss: 1.6234 - dense_613_loss: 1.3046 - dense_614_loss: 1.4539 - dense_615_loss: 1.6252 - dense_616_loss: 1.6337 - dense_617_loss: 1.4667 - dense_618_loss: 1.3653 - dense_619_loss: 1.2533 - dense_620_loss: 1.2841 - dense_611_accuracy: 0.4215 - dense_612_accuracy: 0.2423 - dense_613_accuracy: 0.4359 - dense_614_accuracy: 0.3188 - dense_615_accuracy: 0.2411 - dense_616_accuracy: 0.2371 - dense_617_accuracy: 0.3143 - dense_618_accuracy: 0.3192 - dense_619_accuracy: 0.4097 - dense_620_accuracy: 0.4020\n",
      "Epoch 3/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 14.2542 - dense_611_loss: 1.3022 - dense_612_loss: 1.6151 - dense_613_loss: 1.2979 - dense_614_loss: 1.4469 - dense_615_loss: 1.6180 - dense_616_loss: 1.6253 - dense_617_loss: 1.4620 - dense_618_loss: 1.3603 - dense_619_loss: 1.2485 - dense_620_loss: 1.2781 - dense_611_accuracy: 0.4232 - dense_612_accuracy: 0.2432 - dense_613_accuracy: 0.4360 - dense_614_accuracy: 0.3172 - dense_615_accuracy: 0.2425 - dense_616_accuracy: 0.2443 - dense_617_accuracy: 0.3099 - dense_618_accuracy: 0.3157 - dense_619_accuracy: 0.4048 - dense_620_accuracy: 0.4031\n",
      "Epoch 4/25\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 14.2252 - dense_611_loss: 1.3020 - dense_612_loss: 1.6123 - dense_613_loss: 1.2963 - dense_614_loss: 1.4443 - dense_615_loss: 1.6136 - dense_616_loss: 1.6211 - dense_617_loss: 1.4585 - dense_618_loss: 1.3566 - dense_619_loss: 1.2440 - dense_620_loss: 1.2765 - dense_611_accuracy: 0.4238 - dense_612_accuracy: 0.2371 - dense_613_accuracy: 0.4314 - dense_614_accuracy: 0.3155 - dense_615_accuracy: 0.2390 - dense_616_accuracy: 0.2368 - dense_617_accuracy: 0.3049 - dense_618_accuracy: 0.3135 - dense_619_accuracy: 0.4072 - dense_620_accuracy: 0.4008\n",
      "Epoch 5/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.2176 - dense_611_loss: 1.3001 - dense_612_loss: 1.6117 - dense_613_loss: 1.2958 - dense_614_loss: 1.4440 - dense_615_loss: 1.6140 - dense_616_loss: 1.6216 - dense_617_loss: 1.4559 - dense_618_loss: 1.3554 - dense_619_loss: 1.2431 - dense_620_loss: 1.2759 - dense_611_accuracy: 0.4240 - dense_612_accuracy: 0.2410 - dense_613_accuracy: 0.4321 - dense_614_accuracy: 0.3162 - dense_615_accuracy: 0.2445 - dense_616_accuracy: 0.2317 - dense_617_accuracy: 0.3091 - dense_618_accuracy: 0.3197 - dense_619_accuracy: 0.4039 - dense_620_accuracy: 0.4013\n",
      "Epoch 6/25\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 14.1938 - dense_611_loss: 1.2977 - dense_612_loss: 1.6085 - dense_613_loss: 1.2922 - dense_614_loss: 1.4435 - dense_615_loss: 1.6111 - dense_616_loss: 1.6191 - dense_617_loss: 1.4528 - dense_618_loss: 1.3543 - dense_619_loss: 1.2402 - dense_620_loss: 1.2744 - dense_611_accuracy: 0.4181 - dense_612_accuracy: 0.2376 - dense_613_accuracy: 0.4302 - dense_614_accuracy: 0.3099 - dense_615_accuracy: 0.2347 - dense_616_accuracy: 0.2330 - dense_617_accuracy: 0.3063 - dense_618_accuracy: 0.3111 - dense_619_accuracy: 0.4097 - dense_620_accuracy: 0.4032\n",
      "Epoch 7/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 14.1579 - dense_611_loss: 1.2942 - dense_612_loss: 1.6042 - dense_613_loss: 1.2893 - dense_614_loss: 1.4392 - dense_615_loss: 1.6057 - dense_616_loss: 1.6152 - dense_617_loss: 1.4497 - dense_618_loss: 1.3512 - dense_619_loss: 1.2383 - dense_620_loss: 1.2708 - dense_611_accuracy: 0.4215 - dense_612_accuracy: 0.2429 - dense_613_accuracy: 0.4333 - dense_614_accuracy: 0.3181 - dense_615_accuracy: 0.2416 - dense_616_accuracy: 0.2417 - dense_617_accuracy: 0.3086 - dense_618_accuracy: 0.3119 - dense_619_accuracy: 0.4081 - dense_620_accuracy: 0.4045\n",
      "Epoch 8/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 14.1197 - dense_611_loss: 1.2916 - dense_612_loss: 1.5999 - dense_613_loss: 1.2852 - dense_614_loss: 1.4345 - dense_615_loss: 1.6027 - dense_616_loss: 1.6114 - dense_617_loss: 1.4457 - dense_618_loss: 1.3479 - dense_619_loss: 1.2346 - dense_620_loss: 1.2664 - dense_611_accuracy: 0.4274 - dense_612_accuracy: 0.2478 - dense_613_accuracy: 0.4390 - dense_614_accuracy: 0.3225 - dense_615_accuracy: 0.2483 - dense_616_accuracy: 0.2441 - dense_617_accuracy: 0.3141 - dense_618_accuracy: 0.3208 - dense_619_accuracy: 0.4129 - dense_620_accuracy: 0.4052\n",
      "Epoch 9/25\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 14.1492 - dense_611_loss: 1.2933 - dense_612_loss: 1.6035 - dense_613_loss: 1.2883 - dense_614_loss: 1.4365 - dense_615_loss: 1.6061 - dense_616_loss: 1.6140 - dense_617_loss: 1.4490 - dense_618_loss: 1.3487 - dense_619_loss: 1.2397 - dense_620_loss: 1.2701 - dense_611_accuracy: 0.4247 - dense_612_accuracy: 0.2408 - dense_613_accuracy: 0.4347 - dense_614_accuracy: 0.3244 - dense_615_accuracy: 0.2432 - dense_616_accuracy: 0.2418 - dense_617_accuracy: 0.3043 - dense_618_accuracy: 0.3184 - dense_619_accuracy: 0.4078 - dense_620_accuracy: 0.4026\n",
      "Epoch 10/25\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 14.1471 - dense_611_loss: 1.2940 - dense_612_loss: 1.6033 - dense_613_loss: 1.2883 - dense_614_loss: 1.4372 - dense_615_loss: 1.6055 - dense_616_loss: 1.6140 - dense_617_loss: 1.4482 - dense_618_loss: 1.3485 - dense_619_loss: 1.2375 - dense_620_loss: 1.2705 - dense_611_accuracy: 0.4256 - dense_612_accuracy: 0.2450 - dense_613_accuracy: 0.4346 - dense_614_accuracy: 0.3221 - dense_615_accuracy: 0.2407 - dense_616_accuracy: 0.2379 - dense_617_accuracy: 0.3107 - dense_618_accuracy: 0.3187 - dense_619_accuracy: 0.4074 - dense_620_accuracy: 0.3969\n",
      "Epoch 11/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 14.1580 - dense_611_loss: 1.2952 - dense_612_loss: 1.6030 - dense_613_loss: 1.2893 - dense_614_loss: 1.4394 - dense_615_loss: 1.6067 - dense_616_loss: 1.6162 - dense_617_loss: 1.4494 - dense_618_loss: 1.3483 - dense_619_loss: 1.2386 - dense_620_loss: 1.2719 - dense_611_accuracy: 0.4230 - dense_612_accuracy: 0.2385 - dense_613_accuracy: 0.4349 - dense_614_accuracy: 0.3169 - dense_615_accuracy: 0.2418 - dense_616_accuracy: 0.2375 - dense_617_accuracy: 0.3083 - dense_618_accuracy: 0.3215 - dense_619_accuracy: 0.4053 - dense_620_accuracy: 0.4008\n",
      "Epoch 12/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 14.1045 - dense_611_loss: 1.2899 - dense_612_loss: 1.5973 - dense_613_loss: 1.2841 - dense_614_loss: 1.4341 - dense_615_loss: 1.6015 - dense_616_loss: 1.6085 - dense_617_loss: 1.4449 - dense_618_loss: 1.3441 - dense_619_loss: 1.2329 - dense_620_loss: 1.2670 - dense_611_accuracy: 0.4232 - dense_612_accuracy: 0.2470 - dense_613_accuracy: 0.4358 - dense_614_accuracy: 0.3240 - dense_615_accuracy: 0.2411 - dense_616_accuracy: 0.2456 - dense_617_accuracy: 0.3087 - dense_618_accuracy: 0.3196 - dense_619_accuracy: 0.4087 - dense_620_accuracy: 0.4040\n",
      "Epoch 13/25\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 14.0998 - dense_611_loss: 1.2900 - dense_612_loss: 1.5965 - dense_613_loss: 1.2850 - dense_614_loss: 1.4335 - dense_615_loss: 1.5996 - dense_616_loss: 1.6081 - dense_617_loss: 1.4436 - dense_618_loss: 1.3444 - dense_619_loss: 1.2326 - dense_620_loss: 1.2665 - dense_611_accuracy: 0.4252 - dense_612_accuracy: 0.2484 - dense_613_accuracy: 0.4375 - dense_614_accuracy: 0.3227 - dense_615_accuracy: 0.2470 - dense_616_accuracy: 0.2491 - dense_617_accuracy: 0.3110 - dense_618_accuracy: 0.3222 - dense_619_accuracy: 0.4165 - dense_620_accuracy: 0.4079\n",
      "Epoch 14/25\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 14.0852 - dense_611_loss: 1.2889 - dense_612_loss: 1.5945 - dense_613_loss: 1.2819 - dense_614_loss: 1.4317 - dense_615_loss: 1.5979 - dense_616_loss: 1.6075 - dense_617_loss: 1.4447 - dense_618_loss: 1.3423 - dense_619_loss: 1.2302 - dense_620_loss: 1.2657 - dense_611_accuracy: 0.4269 - dense_612_accuracy: 0.2493 - dense_613_accuracy: 0.4359 - dense_614_accuracy: 0.3247 - dense_615_accuracy: 0.2508 - dense_616_accuracy: 0.2475 - dense_617_accuracy: 0.3054 - dense_618_accuracy: 0.3273 - dense_619_accuracy: 0.4136 - dense_620_accuracy: 0.4046\n",
      "Epoch 15/25\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 14.0811 - dense_611_loss: 1.2907 - dense_612_loss: 1.5949 - dense_613_loss: 1.2826 - dense_614_loss: 1.4306 - dense_615_loss: 1.5975 - dense_616_loss: 1.6056 - dense_617_loss: 1.4433 - dense_618_loss: 1.3422 - dense_619_loss: 1.2293 - dense_620_loss: 1.2644 - dense_611_accuracy: 0.4274 - dense_612_accuracy: 0.2519 - dense_613_accuracy: 0.4382 - dense_614_accuracy: 0.3274 - dense_615_accuracy: 0.2526 - dense_616_accuracy: 0.2519 - dense_617_accuracy: 0.3148 - dense_618_accuracy: 0.3249 - dense_619_accuracy: 0.4194 - dense_620_accuracy: 0.4113\n",
      "Epoch 16/25\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 14.0791 - dense_611_loss: 1.2892 - dense_612_loss: 1.5946 - dense_613_loss: 1.2821 - dense_614_loss: 1.4309 - dense_615_loss: 1.5968 - dense_616_loss: 1.6057 - dense_617_loss: 1.4418 - dense_618_loss: 1.3423 - dense_619_loss: 1.2305 - dense_620_loss: 1.2651 - dense_611_accuracy: 0.4253 - dense_612_accuracy: 0.2514 - dense_613_accuracy: 0.4323 - dense_614_accuracy: 0.3229 - dense_615_accuracy: 0.2502 - dense_616_accuracy: 0.2529 - dense_617_accuracy: 0.3206 - dense_618_accuracy: 0.3275 - dense_619_accuracy: 0.4190 - dense_620_accuracy: 0.4110\n",
      "Epoch 17/25\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 14.0368 - dense_611_loss: 1.2858 - dense_612_loss: 1.5875 - dense_613_loss: 1.2783 - dense_614_loss: 1.4270 - dense_615_loss: 1.5920 - dense_616_loss: 1.5999 - dense_617_loss: 1.4389 - dense_618_loss: 1.3400 - dense_619_loss: 1.2262 - dense_620_loss: 1.2612 - dense_611_accuracy: 0.4277 - dense_612_accuracy: 0.2616 - dense_613_accuracy: 0.4388 - dense_614_accuracy: 0.3309 - dense_615_accuracy: 0.2602 - dense_616_accuracy: 0.2562 - dense_617_accuracy: 0.3166 - dense_618_accuracy: 0.3287 - dense_619_accuracy: 0.4209 - dense_620_accuracy: 0.4102\n",
      "Epoch 18/25\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 14.0287 - dense_611_loss: 1.2864 - dense_612_loss: 1.5880 - dense_613_loss: 1.2780 - dense_614_loss: 1.4250 - dense_615_loss: 1.5898 - dense_616_loss: 1.5989 - dense_617_loss: 1.4377 - dense_618_loss: 1.3382 - dense_619_loss: 1.2272 - dense_620_loss: 1.2597 - dense_611_accuracy: 0.4283 - dense_612_accuracy: 0.2564 - dense_613_accuracy: 0.4397 - dense_614_accuracy: 0.3350 - dense_615_accuracy: 0.2622 - dense_616_accuracy: 0.2601 - dense_617_accuracy: 0.3197 - dense_618_accuracy: 0.3335 - dense_619_accuracy: 0.4220 - dense_620_accuracy: 0.4146\n",
      "Epoch 19/25\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 14.0095 - dense_611_loss: 1.2829 - dense_612_loss: 1.5846 - dense_613_loss: 1.2779 - dense_614_loss: 1.4230 - dense_615_loss: 1.5891 - dense_616_loss: 1.5972 - dense_617_loss: 1.4353 - dense_618_loss: 1.3367 - dense_619_loss: 1.2248 - dense_620_loss: 1.2581 - dense_611_accuracy: 0.4299 - dense_612_accuracy: 0.2710 - dense_613_accuracy: 0.4412 - dense_614_accuracy: 0.3409 - dense_615_accuracy: 0.2674 - dense_616_accuracy: 0.2710 - dense_617_accuracy: 0.3247 - dense_618_accuracy: 0.3425 - dense_619_accuracy: 0.4303 - dense_620_accuracy: 0.4217\n",
      "Epoch 20/25\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 14.0334 - dense_611_loss: 1.2867 - dense_612_loss: 1.5874 - dense_613_loss: 1.2798 - dense_614_loss: 1.4240 - dense_615_loss: 1.5919 - dense_616_loss: 1.5983 - dense_617_loss: 1.4402 - dense_618_loss: 1.3389 - dense_619_loss: 1.2256 - dense_620_loss: 1.2608 - dense_611_accuracy: 0.4260 - dense_612_accuracy: 0.2697 - dense_613_accuracy: 0.4389 - dense_614_accuracy: 0.3396 - dense_615_accuracy: 0.2704 - dense_616_accuracy: 0.2658 - dense_617_accuracy: 0.3194 - dense_618_accuracy: 0.3366 - dense_619_accuracy: 0.4305 - dense_620_accuracy: 0.4126\n",
      "Epoch 21/25\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 14.0004 - dense_611_loss: 1.2846 - dense_612_loss: 1.5838 - dense_613_loss: 1.2767 - dense_614_loss: 1.4207 - dense_615_loss: 1.5865 - dense_616_loss: 1.5954 - dense_617_loss: 1.4336 - dense_618_loss: 1.3386 - dense_619_loss: 1.2220 - dense_620_loss: 1.2584 - dense_611_accuracy: 0.4291 - dense_612_accuracy: 0.2719 - dense_613_accuracy: 0.4415 - dense_614_accuracy: 0.3429 - dense_615_accuracy: 0.2736 - dense_616_accuracy: 0.2702 - dense_617_accuracy: 0.3255 - dense_618_accuracy: 0.3305 - dense_619_accuracy: 0.4329 - dense_620_accuracy: 0.4184\n",
      "Epoch 22/25\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 13.9780 - dense_611_loss: 1.2813 - dense_612_loss: 1.5817 - dense_613_loss: 1.2763 - dense_614_loss: 1.4207 - dense_615_loss: 1.5838 - dense_616_loss: 1.5918 - dense_617_loss: 1.4306 - dense_618_loss: 1.3349 - dense_619_loss: 1.2213 - dense_620_loss: 1.2555 - dense_611_accuracy: 0.4326 - dense_612_accuracy: 0.2732 - dense_613_accuracy: 0.4399 - dense_614_accuracy: 0.3404 - dense_615_accuracy: 0.2716 - dense_616_accuracy: 0.2767 - dense_617_accuracy: 0.3316 - dense_618_accuracy: 0.3401 - dense_619_accuracy: 0.4369 - dense_620_accuracy: 0.4196\n",
      "Epoch 23/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.9537 - dense_611_loss: 1.2798 - dense_612_loss: 1.5783 - dense_613_loss: 1.2738 - dense_614_loss: 1.4173 - dense_615_loss: 1.5809 - dense_616_loss: 1.5883 - dense_617_loss: 1.4288 - dense_618_loss: 1.3328 - dense_619_loss: 1.2204 - dense_620_loss: 1.2533 - dense_611_accuracy: 0.4301 - dense_612_accuracy: 0.2760 - dense_613_accuracy: 0.4449 - dense_614_accuracy: 0.3448 - dense_615_accuracy: 0.2731 - dense_616_accuracy: 0.2742 - dense_617_accuracy: 0.3317 - dense_618_accuracy: 0.3464 - dense_619_accuracy: 0.4284 - dense_620_accuracy: 0.4226\n",
      "Epoch 24/25\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 13.8980 - dense_611_loss: 1.2743 - dense_612_loss: 1.5724 - dense_613_loss: 1.2691 - dense_614_loss: 1.4096 - dense_615_loss: 1.5743 - dense_616_loss: 1.5837 - dense_617_loss: 1.4230 - dense_618_loss: 1.3267 - dense_619_loss: 1.2144 - dense_620_loss: 1.2504 - dense_611_accuracy: 0.4346 - dense_612_accuracy: 0.2816 - dense_613_accuracy: 0.4456 - dense_614_accuracy: 0.3515 - dense_615_accuracy: 0.2782 - dense_616_accuracy: 0.2798 - dense_617_accuracy: 0.3346 - dense_618_accuracy: 0.3491 - dense_619_accuracy: 0.4388 - dense_620_accuracy: 0.4255\n",
      "Epoch 25/25\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 13.8652 - dense_611_loss: 1.2734 - dense_612_loss: 1.5695 - dense_613_loss: 1.2657 - dense_614_loss: 1.4058 - dense_615_loss: 1.5707 - dense_616_loss: 1.5776 - dense_617_loss: 1.4207 - dense_618_loss: 1.3235 - dense_619_loss: 1.2112 - dense_620_loss: 1.2469 - dense_611_accuracy: 0.4323 - dense_612_accuracy: 0.2795 - dense_613_accuracy: 0.4477 - dense_614_accuracy: 0.3515 - dense_615_accuracy: 0.2843 - dense_616_accuracy: 0.2822 - dense_617_accuracy: 0.3357 - dense_618_accuracy: 0.3463 - dense_619_accuracy: 0.4441 - dense_620_accuracy: 0.4270\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D19EED38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D19EED38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D15B49D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D15B49D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jostm7\\Anaconda3\\envs\\replearn\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 16ms/step - loss: 0.2191\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.0473\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.0079\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0064\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.0060\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0059\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.0058\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 0.0058\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0057\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 0.0057\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 0.0057\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0057\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 0.0057\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.0056\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0055\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 0.0054\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 0.0053\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 0.0052\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.0052\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.0051\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 2s 24ms/step - loss: 0.0050\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 0.0049\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.0049\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.0048\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 0.0048\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D38B1DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215D38B1DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 5s 9ms/step - loss: 20.4974 - dense_624_loss: 1.9612 - dense_625_loss: 1.9734 - dense_626_loss: 2.0831 - dense_627_loss: 1.9636 - dense_628_loss: 2.3844 - dense_629_loss: 2.0811 - dense_630_loss: 2.0936 - dense_631_loss: 1.9970 - dense_632_loss: 1.8257 - dense_633_loss: 2.1343 - dense_624_accuracy: 0.2988 - dense_625_accuracy: 0.2506 - dense_626_accuracy: 0.2136 - dense_627_accuracy: 0.2520 - dense_628_accuracy: 0.1592 - dense_629_accuracy: 0.2144 - dense_630_accuracy: 0.2254 - dense_631_accuracy: 0.2542 - dense_632_accuracy: 0.3176 - dense_633_accuracy: 0.1886\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 17.3880 - dense_624_loss: 1.6011 - dense_625_loss: 1.6953 - dense_626_loss: 1.8041 - dense_627_loss: 1.6848 - dense_628_loss: 1.9811 - dense_629_loss: 1.7680 - dense_630_loss: 1.7759 - dense_631_loss: 1.7132 - dense_632_loss: 1.5534 - dense_633_loss: 1.8112 - dense_624_accuracy: 0.4052 - dense_625_accuracy: 0.3204 - dense_626_accuracy: 0.2634 - dense_627_accuracy: 0.2864 - dense_628_accuracy: 0.2222 - dense_629_accuracy: 0.2702 - dense_630_accuracy: 0.2752 - dense_631_accuracy: 0.2940 - dense_632_accuracy: 0.3848 - dense_633_accuracy: 0.2340\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 17.1640 - dense_624_loss: 1.5746 - dense_625_loss: 1.6771 - dense_626_loss: 1.7823 - dense_627_loss: 1.6608 - dense_628_loss: 1.9525 - dense_629_loss: 1.7426 - dense_630_loss: 1.7578 - dense_631_loss: 1.6897 - dense_632_loss: 1.5312 - dense_633_loss: 1.7955 - dense_624_accuracy: 0.4140 - dense_625_accuracy: 0.3248 - dense_626_accuracy: 0.2724 - dense_627_accuracy: 0.2920 - dense_628_accuracy: 0.2258 - dense_629_accuracy: 0.2684 - dense_630_accuracy: 0.2888 - dense_631_accuracy: 0.2968 - dense_632_accuracy: 0.3898 - dense_633_accuracy: 0.2358\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 17.2294 - dense_624_loss: 1.5815 - dense_625_loss: 1.6824 - dense_626_loss: 1.7865 - dense_627_loss: 1.6635 - dense_628_loss: 1.9534 - dense_629_loss: 1.7515 - dense_630_loss: 1.7727 - dense_631_loss: 1.6950 - dense_632_loss: 1.5435 - dense_633_loss: 1.7995 - dense_624_accuracy: 0.4072 - dense_625_accuracy: 0.3236 - dense_626_accuracy: 0.2702 - dense_627_accuracy: 0.2964 - dense_628_accuracy: 0.2312 - dense_629_accuracy: 0.2688 - dense_630_accuracy: 0.2822 - dense_631_accuracy: 0.2916 - dense_632_accuracy: 0.3966 - dense_633_accuracy: 0.2406\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 17.0406 - dense_624_loss: 1.5618 - dense_625_loss: 1.6672 - dense_626_loss: 1.7678 - dense_627_loss: 1.6423 - dense_628_loss: 1.9370 - dense_629_loss: 1.7313 - dense_630_loss: 1.7480 - dense_631_loss: 1.6768 - dense_632_loss: 1.5272 - dense_633_loss: 1.7810 - dense_624_accuracy: 0.4136 - dense_625_accuracy: 0.3368 - dense_626_accuracy: 0.2752 - dense_627_accuracy: 0.3056 - dense_628_accuracy: 0.2314 - dense_629_accuracy: 0.2834 - dense_630_accuracy: 0.2938 - dense_631_accuracy: 0.3054 - dense_632_accuracy: 0.3904 - dense_633_accuracy: 0.2550\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 16.9772 - dense_624_loss: 1.5563 - dense_625_loss: 1.6608 - dense_626_loss: 1.7615 - dense_627_loss: 1.6392 - dense_628_loss: 1.9309 - dense_629_loss: 1.7233 - dense_630_loss: 1.7389 - dense_631_loss: 1.6656 - dense_632_loss: 1.5239 - dense_633_loss: 1.7770 - dense_624_accuracy: 0.4094 - dense_625_accuracy: 0.3374 - dense_626_accuracy: 0.2864 - dense_627_accuracy: 0.3058 - dense_628_accuracy: 0.2446 - dense_629_accuracy: 0.2826 - dense_630_accuracy: 0.3054 - dense_631_accuracy: 0.3128 - dense_632_accuracy: 0.3914 - dense_633_accuracy: 0.2680\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 16.9147 - dense_624_loss: 1.5493 - dense_625_loss: 1.6559 - dense_626_loss: 1.7535 - dense_627_loss: 1.6362 - dense_628_loss: 1.9226 - dense_629_loss: 1.7175 - dense_630_loss: 1.7332 - dense_631_loss: 1.6640 - dense_632_loss: 1.5119 - dense_633_loss: 1.7705 - dense_624_accuracy: 0.4186 - dense_625_accuracy: 0.3468 - dense_626_accuracy: 0.3064 - dense_627_accuracy: 0.3186 - dense_628_accuracy: 0.2596 - dense_629_accuracy: 0.2958 - dense_630_accuracy: 0.3124 - dense_631_accuracy: 0.3174 - dense_632_accuracy: 0.4028 - dense_633_accuracy: 0.2720\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 16.7779 - dense_624_loss: 1.5440 - dense_625_loss: 1.6406 - dense_626_loss: 1.7333 - dense_627_loss: 1.6227 - dense_628_loss: 1.8998 - dense_629_loss: 1.7003 - dense_630_loss: 1.7193 - dense_631_loss: 1.6509 - dense_632_loss: 1.5079 - dense_633_loss: 1.7592 - dense_624_accuracy: 0.4184 - dense_625_accuracy: 0.3486 - dense_626_accuracy: 0.3168 - dense_627_accuracy: 0.3276 - dense_628_accuracy: 0.2792 - dense_629_accuracy: 0.3146 - dense_630_accuracy: 0.3232 - dense_631_accuracy: 0.3310 - dense_632_accuracy: 0.3966 - dense_633_accuracy: 0.2882\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 16.5820 - dense_624_loss: 1.5229 - dense_625_loss: 1.6249 - dense_626_loss: 1.7125 - dense_627_loss: 1.6037 - dense_628_loss: 1.8826 - dense_629_loss: 1.6808 - dense_630_loss: 1.6974 - dense_631_loss: 1.6329 - dense_632_loss: 1.4895 - dense_633_loss: 1.7349 - dense_624_accuracy: 0.4338 - dense_625_accuracy: 0.3608 - dense_626_accuracy: 0.3326 - dense_627_accuracy: 0.3434 - dense_628_accuracy: 0.2982 - dense_629_accuracy: 0.3454 - dense_630_accuracy: 0.3404 - dense_631_accuracy: 0.3416 - dense_632_accuracy: 0.4100 - dense_633_accuracy: 0.3122\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 16.4554 - dense_624_loss: 1.5112 - dense_625_loss: 1.6123 - dense_626_loss: 1.6986 - dense_627_loss: 1.5935 - dense_628_loss: 1.8665 - dense_629_loss: 1.6684 - dense_630_loss: 1.6855 - dense_631_loss: 1.6219 - dense_632_loss: 1.4779 - dense_633_loss: 1.7194 - dense_624_accuracy: 0.4356 - dense_625_accuracy: 0.3814 - dense_626_accuracy: 0.3434 - dense_627_accuracy: 0.3544 - dense_628_accuracy: 0.3120 - dense_629_accuracy: 0.3336 - dense_630_accuracy: 0.3556 - dense_631_accuracy: 0.3500 - dense_632_accuracy: 0.4192 - dense_633_accuracy: 0.3138\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 16.2211 - dense_624_loss: 1.4900 - dense_625_loss: 1.5944 - dense_626_loss: 1.6741 - dense_627_loss: 1.5688 - dense_628_loss: 1.8376 - dense_629_loss: 1.6471 - dense_630_loss: 1.6644 - dense_631_loss: 1.5989 - dense_632_loss: 1.4543 - dense_633_loss: 1.6915 - dense_624_accuracy: 0.4508 - dense_625_accuracy: 0.3872 - dense_626_accuracy: 0.3598 - dense_627_accuracy: 0.3636 - dense_628_accuracy: 0.3338 - dense_629_accuracy: 0.3606 - dense_630_accuracy: 0.3652 - dense_631_accuracy: 0.3638 - dense_632_accuracy: 0.4356 - dense_633_accuracy: 0.3374\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 16.1007 - dense_624_loss: 1.4859 - dense_625_loss: 1.5822 - dense_626_loss: 1.6619 - dense_627_loss: 1.5548 - dense_628_loss: 1.8213 - dense_629_loss: 1.6325 - dense_630_loss: 1.6514 - dense_631_loss: 1.5847 - dense_632_loss: 1.4494 - dense_633_loss: 1.6765 - dense_624_accuracy: 0.4536 - dense_625_accuracy: 0.3902 - dense_626_accuracy: 0.3668 - dense_627_accuracy: 0.3792 - dense_628_accuracy: 0.3372 - dense_629_accuracy: 0.3652 - dense_630_accuracy: 0.3664 - dense_631_accuracy: 0.3780 - dense_632_accuracy: 0.4406 - dense_633_accuracy: 0.3404\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.9643 - dense_624_loss: 1.4736 - dense_625_loss: 1.5663 - dense_626_loss: 1.6429 - dense_627_loss: 1.5410 - dense_628_loss: 1.8008 - dense_629_loss: 1.6214 - dense_630_loss: 1.6380 - dense_631_loss: 1.5748 - dense_632_loss: 1.4389 - dense_633_loss: 1.6666 - dense_624_accuracy: 0.4718 - dense_625_accuracy: 0.4062 - dense_626_accuracy: 0.3826 - dense_627_accuracy: 0.3902 - dense_628_accuracy: 0.3546 - dense_629_accuracy: 0.3782 - dense_630_accuracy: 0.3872 - dense_631_accuracy: 0.3874 - dense_632_accuracy: 0.4486 - dense_633_accuracy: 0.3566\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 15.8194 - dense_624_loss: 1.4571 - dense_625_loss: 1.5533 - dense_626_loss: 1.6292 - dense_627_loss: 1.5271 - dense_628_loss: 1.7913 - dense_629_loss: 1.6058 - dense_630_loss: 1.6242 - dense_631_loss: 1.5596 - dense_632_loss: 1.4260 - dense_633_loss: 1.6458 - dense_624_accuracy: 0.4780 - dense_625_accuracy: 0.4120 - dense_626_accuracy: 0.3888 - dense_627_accuracy: 0.3954 - dense_628_accuracy: 0.3618 - dense_629_accuracy: 0.3872 - dense_630_accuracy: 0.3944 - dense_631_accuracy: 0.3938 - dense_632_accuracy: 0.4522 - dense_633_accuracy: 0.3714\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 15.5711 - dense_624_loss: 1.4417 - dense_625_loss: 1.5448 - dense_626_loss: 1.6012 - dense_627_loss: 1.4953 - dense_628_loss: 1.7585 - dense_629_loss: 1.5822 - dense_630_loss: 1.5939 - dense_631_loss: 1.5353 - dense_632_loss: 1.3975 - dense_633_loss: 1.6207 - dense_624_accuracy: 0.4830 - dense_625_accuracy: 0.4224 - dense_626_accuracy: 0.4078 - dense_627_accuracy: 0.4188 - dense_628_accuracy: 0.3794 - dense_629_accuracy: 0.4030 - dense_630_accuracy: 0.4104 - dense_631_accuracy: 0.4124 - dense_632_accuracy: 0.4764 - dense_633_accuracy: 0.3896\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.4258 - dense_624_loss: 1.4237 - dense_625_loss: 1.5212 - dense_626_loss: 1.5874 - dense_627_loss: 1.4860 - dense_628_loss: 1.7364 - dense_629_loss: 1.5626 - dense_630_loss: 1.5842 - dense_631_loss: 1.5245 - dense_632_loss: 1.3928 - dense_633_loss: 1.6069 - dense_624_accuracy: 0.4938 - dense_625_accuracy: 0.4350 - dense_626_accuracy: 0.4176 - dense_627_accuracy: 0.4238 - dense_628_accuracy: 0.3966 - dense_629_accuracy: 0.4142 - dense_630_accuracy: 0.4156 - dense_631_accuracy: 0.4264 - dense_632_accuracy: 0.4764 - dense_633_accuracy: 0.4016\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 15.3378 - dense_624_loss: 1.4134 - dense_625_loss: 1.5134 - dense_626_loss: 1.5783 - dense_627_loss: 1.4767 - dense_628_loss: 1.7325 - dense_629_loss: 1.5568 - dense_630_loss: 1.5739 - dense_631_loss: 1.5164 - dense_632_loss: 1.3833 - dense_633_loss: 1.5932 - dense_624_accuracy: 0.4960 - dense_625_accuracy: 0.4386 - dense_626_accuracy: 0.4242 - dense_627_accuracy: 0.4272 - dense_628_accuracy: 0.4002 - dense_629_accuracy: 0.4178 - dense_630_accuracy: 0.4276 - dense_631_accuracy: 0.4246 - dense_632_accuracy: 0.4814 - dense_633_accuracy: 0.4066\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 15.1397 - dense_624_loss: 1.3942 - dense_625_loss: 1.4936 - dense_626_loss: 1.5591 - dense_627_loss: 1.4526 - dense_628_loss: 1.7089 - dense_629_loss: 1.5346 - dense_630_loss: 1.5586 - dense_631_loss: 1.4963 - dense_632_loss: 1.3707 - dense_633_loss: 1.5712 - dense_624_accuracy: 0.5110 - dense_625_accuracy: 0.4522 - dense_626_accuracy: 0.4350 - dense_627_accuracy: 0.4468 - dense_628_accuracy: 0.4094 - dense_629_accuracy: 0.4318 - dense_630_accuracy: 0.4280 - dense_631_accuracy: 0.4338 - dense_632_accuracy: 0.4894 - dense_633_accuracy: 0.4198\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.1276 - dense_624_loss: 1.3956 - dense_625_loss: 1.4958 - dense_626_loss: 1.5612 - dense_627_loss: 1.4544 - dense_628_loss: 1.6981 - dense_629_loss: 1.5342 - dense_630_loss: 1.5524 - dense_631_loss: 1.4937 - dense_632_loss: 1.3703 - dense_633_loss: 1.5718 - dense_624_accuracy: 0.5094 - dense_625_accuracy: 0.4584 - dense_626_accuracy: 0.4338 - dense_627_accuracy: 0.4440 - dense_628_accuracy: 0.4164 - dense_629_accuracy: 0.4326 - dense_630_accuracy: 0.4418 - dense_631_accuracy: 0.4450 - dense_632_accuracy: 0.4884 - dense_633_accuracy: 0.4224\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 14.9129 - dense_624_loss: 1.3858 - dense_625_loss: 1.4755 - dense_626_loss: 1.5386 - dense_627_loss: 1.4317 - dense_628_loss: 1.6749 - dense_629_loss: 1.5101 - dense_630_loss: 1.5316 - dense_631_loss: 1.4728 - dense_632_loss: 1.3497 - dense_633_loss: 1.5421 - dense_624_accuracy: 0.5150 - dense_625_accuracy: 0.4684 - dense_626_accuracy: 0.4460 - dense_627_accuracy: 0.4592 - dense_628_accuracy: 0.4340 - dense_629_accuracy: 0.4454 - dense_630_accuracy: 0.4506 - dense_631_accuracy: 0.4598 - dense_632_accuracy: 0.4954 - dense_633_accuracy: 0.4338\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 14.8259 - dense_624_loss: 1.3642 - dense_625_loss: 1.4715 - dense_626_loss: 1.5304 - dense_627_loss: 1.4315 - dense_628_loss: 1.6661 - dense_629_loss: 1.5032 - dense_630_loss: 1.5200 - dense_631_loss: 1.4588 - dense_632_loss: 1.3412 - dense_633_loss: 1.5389 - dense_624_accuracy: 0.5246 - dense_625_accuracy: 0.4724 - dense_626_accuracy: 0.4456 - dense_627_accuracy: 0.4562 - dense_628_accuracy: 0.4270 - dense_629_accuracy: 0.4544 - dense_630_accuracy: 0.4524 - dense_631_accuracy: 0.4610 - dense_632_accuracy: 0.4988 - dense_633_accuracy: 0.4362\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 14.7231 - dense_624_loss: 1.3567 - dense_625_loss: 1.4602 - dense_626_loss: 1.5202 - dense_627_loss: 1.4214 - dense_628_loss: 1.6503 - dense_629_loss: 1.4917 - dense_630_loss: 1.5146 - dense_631_loss: 1.4464 - dense_632_loss: 1.3372 - dense_633_loss: 1.5243 - dense_624_accuracy: 0.5354 - dense_625_accuracy: 0.4672 - dense_626_accuracy: 0.4590 - dense_627_accuracy: 0.4608 - dense_628_accuracy: 0.4472 - dense_629_accuracy: 0.4586 - dense_630_accuracy: 0.4608 - dense_631_accuracy: 0.4602 - dense_632_accuracy: 0.5136 - dense_633_accuracy: 0.4438\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 14.5436 - dense_624_loss: 1.3394 - dense_625_loss: 1.4418 - dense_626_loss: 1.4965 - dense_627_loss: 1.3955 - dense_628_loss: 1.6351 - dense_629_loss: 1.4715 - dense_630_loss: 1.4934 - dense_631_loss: 1.4431 - dense_632_loss: 1.3241 - dense_633_loss: 1.5034 - dense_624_accuracy: 0.5438 - dense_625_accuracy: 0.4898 - dense_626_accuracy: 0.4654 - dense_627_accuracy: 0.4792 - dense_628_accuracy: 0.4494 - dense_629_accuracy: 0.4722 - dense_630_accuracy: 0.4684 - dense_631_accuracy: 0.4684 - dense_632_accuracy: 0.5172 - dense_633_accuracy: 0.4592\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 14.5415 - dense_624_loss: 1.3457 - dense_625_loss: 1.4359 - dense_626_loss: 1.4985 - dense_627_loss: 1.4013 - dense_628_loss: 1.6277 - dense_629_loss: 1.4803 - dense_630_loss: 1.4940 - dense_631_loss: 1.4344 - dense_632_loss: 1.3204 - dense_633_loss: 1.5034 - dense_624_accuracy: 0.5416 - dense_625_accuracy: 0.4896 - dense_626_accuracy: 0.4684 - dense_627_accuracy: 0.4850 - dense_628_accuracy: 0.4640 - dense_629_accuracy: 0.4752 - dense_630_accuracy: 0.4754 - dense_631_accuracy: 0.4770 - dense_632_accuracy: 0.5206 - dense_633_accuracy: 0.4604\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 14.4242 - dense_624_loss: 1.3321 - dense_625_loss: 1.4303 - dense_626_loss: 1.4909 - dense_627_loss: 1.3795 - dense_628_loss: 1.6206 - dense_629_loss: 1.4645 - dense_630_loss: 1.4775 - dense_631_loss: 1.4271 - dense_632_loss: 1.3116 - dense_633_loss: 1.4901 - dense_624_accuracy: 0.5466 - dense_625_accuracy: 0.4944 - dense_626_accuracy: 0.4720 - dense_627_accuracy: 0.4882 - dense_628_accuracy: 0.4672 - dense_629_accuracy: 0.4714 - dense_630_accuracy: 0.4834 - dense_631_accuracy: 0.4818 - dense_632_accuracy: 0.5300 - dense_633_accuracy: 0.4648\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D3F87798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D3F87798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215CFFA98B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000215CFFA98B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "79/79 [==============================] - 5s 9ms/step - loss: 20.0213 - dense_634_loss: 1.9084 - dense_635_loss: 1.9495 - dense_636_loss: 2.0568 - dense_637_loss: 1.9040 - dense_638_loss: 2.3206 - dense_639_loss: 2.0238 - dense_640_loss: 2.0529 - dense_641_loss: 1.9371 - dense_642_loss: 1.7936 - dense_643_loss: 2.0745 - dense_634_accuracy: 0.3296 - dense_635_accuracy: 0.2598 - dense_636_accuracy: 0.2230 - dense_637_accuracy: 0.2558 - dense_638_accuracy: 0.1750 - dense_639_accuracy: 0.2280 - dense_640_accuracy: 0.2314 - dense_641_accuracy: 0.2566 - dense_642_accuracy: 0.3256 - dense_643_accuracy: 0.1998\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 17.2689 - dense_634_loss: 1.5910 - dense_635_loss: 1.6908 - dense_636_loss: 1.7885 - dense_637_loss: 1.6671 - dense_638_loss: 1.9671 - dense_639_loss: 1.7528 - dense_640_loss: 1.7718 - dense_641_loss: 1.6948 - dense_642_loss: 1.5420 - dense_643_loss: 1.8029 - dense_634_accuracy: 0.4054 - dense_635_accuracy: 0.3150 - dense_636_accuracy: 0.2662 - dense_637_accuracy: 0.2934 - dense_638_accuracy: 0.2186 - dense_639_accuracy: 0.2680 - dense_640_accuracy: 0.2812 - dense_641_accuracy: 0.2936 - dense_642_accuracy: 0.3884 - dense_643_accuracy: 0.2338\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 17.1734 - dense_634_loss: 1.5818 - dense_635_loss: 1.6775 - dense_636_loss: 1.7832 - dense_637_loss: 1.6532 - dense_638_loss: 1.9491 - dense_639_loss: 1.7463 - dense_640_loss: 1.7584 - dense_641_loss: 1.6923 - dense_642_loss: 1.5349 - dense_643_loss: 1.7967 - dense_634_accuracy: 0.4130 - dense_635_accuracy: 0.3216 - dense_636_accuracy: 0.2580 - dense_637_accuracy: 0.2924 - dense_638_accuracy: 0.2116 - dense_639_accuracy: 0.2722 - dense_640_accuracy: 0.2724 - dense_641_accuracy: 0.2820 - dense_642_accuracy: 0.3948 - dense_643_accuracy: 0.2334\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 17.1757 - dense_634_loss: 1.5735 - dense_635_loss: 1.6792 - dense_636_loss: 1.7771 - dense_637_loss: 1.6596 - dense_638_loss: 1.9543 - dense_639_loss: 1.7427 - dense_640_loss: 1.7620 - dense_641_loss: 1.6903 - dense_642_loss: 1.5386 - dense_643_loss: 1.7984 - dense_634_accuracy: 0.4170 - dense_635_accuracy: 0.3226 - dense_636_accuracy: 0.2622 - dense_637_accuracy: 0.2876 - dense_638_accuracy: 0.2232 - dense_639_accuracy: 0.2654 - dense_640_accuracy: 0.2864 - dense_641_accuracy: 0.2894 - dense_642_accuracy: 0.3884 - dense_643_accuracy: 0.2352\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 17.0589 - dense_634_loss: 1.5605 - dense_635_loss: 1.6679 - dense_636_loss: 1.7720 - dense_637_loss: 1.6456 - dense_638_loss: 1.9406 - dense_639_loss: 1.7329 - dense_640_loss: 1.7491 - dense_641_loss: 1.6810 - dense_642_loss: 1.5260 - dense_643_loss: 1.7833 - dense_634_accuracy: 0.4140 - dense_635_accuracy: 0.3352 - dense_636_accuracy: 0.2620 - dense_637_accuracy: 0.2952 - dense_638_accuracy: 0.2242 - dense_639_accuracy: 0.2656 - dense_640_accuracy: 0.2762 - dense_641_accuracy: 0.2900 - dense_642_accuracy: 0.3952 - dense_643_accuracy: 0.2360\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 17.0581 - dense_634_loss: 1.5646 - dense_635_loss: 1.6673 - dense_636_loss: 1.7689 - dense_637_loss: 1.6463 - dense_638_loss: 1.9385 - dense_639_loss: 1.7322 - dense_640_loss: 1.7494 - dense_641_loss: 1.6796 - dense_642_loss: 1.5258 - dense_643_loss: 1.7857 - dense_634_accuracy: 0.4164 - dense_635_accuracy: 0.3280 - dense_636_accuracy: 0.2658 - dense_637_accuracy: 0.2988 - dense_638_accuracy: 0.2204 - dense_639_accuracy: 0.2642 - dense_640_accuracy: 0.2794 - dense_641_accuracy: 0.2954 - dense_642_accuracy: 0.3928 - dense_643_accuracy: 0.2394\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 17.0791 - dense_634_loss: 1.5675 - dense_635_loss: 1.6709 - dense_636_loss: 1.7690 - dense_637_loss: 1.6469 - dense_638_loss: 1.9443 - dense_639_loss: 1.7336 - dense_640_loss: 1.7495 - dense_641_loss: 1.6835 - dense_642_loss: 1.5304 - dense_643_loss: 1.7836 - dense_634_accuracy: 0.4148 - dense_635_accuracy: 0.3328 - dense_636_accuracy: 0.2608 - dense_637_accuracy: 0.2972 - dense_638_accuracy: 0.2160 - dense_639_accuracy: 0.2648 - dense_640_accuracy: 0.2784 - dense_641_accuracy: 0.2890 - dense_642_accuracy: 0.3962 - dense_643_accuracy: 0.2424\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 17.0273 - dense_634_loss: 1.5616 - dense_635_loss: 1.6658 - dense_636_loss: 1.7652 - dense_637_loss: 1.6444 - dense_638_loss: 1.9356 - dense_639_loss: 1.7288 - dense_640_loss: 1.7438 - dense_641_loss: 1.6782 - dense_642_loss: 1.5256 - dense_643_loss: 1.7783 - dense_634_accuracy: 0.4152 - dense_635_accuracy: 0.3252 - dense_636_accuracy: 0.2748 - dense_637_accuracy: 0.2898 - dense_638_accuracy: 0.2302 - dense_639_accuracy: 0.2718 - dense_640_accuracy: 0.2820 - dense_641_accuracy: 0.2912 - dense_642_accuracy: 0.3948 - dense_643_accuracy: 0.2412\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 17.0058 - dense_634_loss: 1.5558 - dense_635_loss: 1.6627 - dense_636_loss: 1.7627 - dense_637_loss: 1.6438 - dense_638_loss: 1.9312 - dense_639_loss: 1.7246 - dense_640_loss: 1.7455 - dense_641_loss: 1.6761 - dense_642_loss: 1.5230 - dense_643_loss: 1.7804 - dense_634_accuracy: 0.4196 - dense_635_accuracy: 0.3302 - dense_636_accuracy: 0.2678 - dense_637_accuracy: 0.2966 - dense_638_accuracy: 0.2210 - dense_639_accuracy: 0.2666 - dense_640_accuracy: 0.2816 - dense_641_accuracy: 0.2928 - dense_642_accuracy: 0.3914 - dense_643_accuracy: 0.2438\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 16.9866 - dense_634_loss: 1.5566 - dense_635_loss: 1.6608 - dense_636_loss: 1.7620 - dense_637_loss: 1.6406 - dense_638_loss: 1.9298 - dense_639_loss: 1.7266 - dense_640_loss: 1.7417 - dense_641_loss: 1.6723 - dense_642_loss: 1.5208 - dense_643_loss: 1.7754 - dense_634_accuracy: 0.4200 - dense_635_accuracy: 0.3324 - dense_636_accuracy: 0.2740 - dense_637_accuracy: 0.3026 - dense_638_accuracy: 0.2332 - dense_639_accuracy: 0.2712 - dense_640_accuracy: 0.2860 - dense_641_accuracy: 0.3058 - dense_642_accuracy: 0.3974 - dense_643_accuracy: 0.2592\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 16.9644 - dense_634_loss: 1.5549 - dense_635_loss: 1.6618 - dense_636_loss: 1.7595 - dense_637_loss: 1.6364 - dense_638_loss: 1.9280 - dense_639_loss: 1.7222 - dense_640_loss: 1.7412 - dense_641_loss: 1.6688 - dense_642_loss: 1.5190 - dense_643_loss: 1.7726 - dense_634_accuracy: 0.4218 - dense_635_accuracy: 0.3338 - dense_636_accuracy: 0.2786 - dense_637_accuracy: 0.3096 - dense_638_accuracy: 0.2294 - dense_639_accuracy: 0.2680 - dense_640_accuracy: 0.2910 - dense_641_accuracy: 0.3108 - dense_642_accuracy: 0.4008 - dense_643_accuracy: 0.2476\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 16.9298 - dense_634_loss: 1.5500 - dense_635_loss: 1.6568 - dense_636_loss: 1.7579 - dense_637_loss: 1.6311 - dense_638_loss: 1.9231 - dense_639_loss: 1.7203 - dense_640_loss: 1.7379 - dense_641_loss: 1.6666 - dense_642_loss: 1.5152 - dense_643_loss: 1.7709 - dense_634_accuracy: 0.4228 - dense_635_accuracy: 0.3370 - dense_636_accuracy: 0.2758 - dense_637_accuracy: 0.3132 - dense_638_accuracy: 0.2396 - dense_639_accuracy: 0.2736 - dense_640_accuracy: 0.2926 - dense_641_accuracy: 0.3012 - dense_642_accuracy: 0.4056 - dense_643_accuracy: 0.2558\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 16.8761 - dense_634_loss: 1.5445 - dense_635_loss: 1.6514 - dense_636_loss: 1.7507 - dense_637_loss: 1.6264 - dense_638_loss: 1.9181 - dense_639_loss: 1.7137 - dense_640_loss: 1.7337 - dense_641_loss: 1.6609 - dense_642_loss: 1.5109 - dense_643_loss: 1.7658 - dense_634_accuracy: 0.4150 - dense_635_accuracy: 0.3432 - dense_636_accuracy: 0.2902 - dense_637_accuracy: 0.3122 - dense_638_accuracy: 0.2446 - dense_639_accuracy: 0.2724 - dense_640_accuracy: 0.3006 - dense_641_accuracy: 0.3126 - dense_642_accuracy: 0.4068 - dense_643_accuracy: 0.2706\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 16.8299 - dense_634_loss: 1.5415 - dense_635_loss: 1.6478 - dense_636_loss: 1.7421 - dense_637_loss: 1.6263 - dense_638_loss: 1.9138 - dense_639_loss: 1.7093 - dense_640_loss: 1.7263 - dense_641_loss: 1.6546 - dense_642_loss: 1.5045 - dense_643_loss: 1.7637 - dense_634_accuracy: 0.4242 - dense_635_accuracy: 0.3466 - dense_636_accuracy: 0.2996 - dense_637_accuracy: 0.3170 - dense_638_accuracy: 0.2464 - dense_639_accuracy: 0.2838 - dense_640_accuracy: 0.3036 - dense_641_accuracy: 0.3152 - dense_642_accuracy: 0.4120 - dense_643_accuracy: 0.2614\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 16.7249 - dense_634_loss: 1.5331 - dense_635_loss: 1.6355 - dense_636_loss: 1.7324 - dense_637_loss: 1.6135 - dense_638_loss: 1.8999 - dense_639_loss: 1.7023 - dense_640_loss: 1.7152 - dense_641_loss: 1.6454 - dense_642_loss: 1.4977 - dense_643_loss: 1.7500 - dense_634_accuracy: 0.4248 - dense_635_accuracy: 0.3578 - dense_636_accuracy: 0.3066 - dense_637_accuracy: 0.3180 - dense_638_accuracy: 0.2640 - dense_639_accuracy: 0.2794 - dense_640_accuracy: 0.3158 - dense_641_accuracy: 0.3144 - dense_642_accuracy: 0.4182 - dense_643_accuracy: 0.2748\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 16.7138 - dense_634_loss: 1.5322 - dense_635_loss: 1.6383 - dense_636_loss: 1.7317 - dense_637_loss: 1.6118 - dense_638_loss: 1.9003 - dense_639_loss: 1.6983 - dense_640_loss: 1.7133 - dense_641_loss: 1.6411 - dense_642_loss: 1.4991 - dense_643_loss: 1.7478 - dense_634_accuracy: 0.4282 - dense_635_accuracy: 0.3512 - dense_636_accuracy: 0.3040 - dense_637_accuracy: 0.3244 - dense_638_accuracy: 0.2614 - dense_639_accuracy: 0.2970 - dense_640_accuracy: 0.3132 - dense_641_accuracy: 0.3258 - dense_642_accuracy: 0.4080 - dense_643_accuracy: 0.2858\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 16.6635 - dense_634_loss: 1.5306 - dense_635_loss: 1.6300 - dense_636_loss: 1.7247 - dense_637_loss: 1.6109 - dense_638_loss: 1.8944 - dense_639_loss: 1.6902 - dense_640_loss: 1.7110 - dense_641_loss: 1.6396 - dense_642_loss: 1.4911 - dense_643_loss: 1.7409 - dense_634_accuracy: 0.4308 - dense_635_accuracy: 0.3596 - dense_636_accuracy: 0.3164 - dense_637_accuracy: 0.3220 - dense_638_accuracy: 0.2738 - dense_639_accuracy: 0.3094 - dense_640_accuracy: 0.3228 - dense_641_accuracy: 0.3268 - dense_642_accuracy: 0.4132 - dense_643_accuracy: 0.2930\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 16.5402 - dense_634_loss: 1.5186 - dense_635_loss: 1.6206 - dense_636_loss: 1.7103 - dense_637_loss: 1.5979 - dense_638_loss: 1.8789 - dense_639_loss: 1.6833 - dense_640_loss: 1.6981 - dense_641_loss: 1.6273 - dense_642_loss: 1.4763 - dense_643_loss: 1.7289 - dense_634_accuracy: 0.4348 - dense_635_accuracy: 0.3674 - dense_636_accuracy: 0.3238 - dense_637_accuracy: 0.3464 - dense_638_accuracy: 0.2926 - dense_639_accuracy: 0.3254 - dense_640_accuracy: 0.3342 - dense_641_accuracy: 0.3436 - dense_642_accuracy: 0.4282 - dense_643_accuracy: 0.3090\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 16.3777 - dense_634_loss: 1.5010 - dense_635_loss: 1.6083 - dense_636_loss: 1.6881 - dense_637_loss: 1.5825 - dense_638_loss: 1.8616 - dense_639_loss: 1.6615 - dense_640_loss: 1.6808 - dense_641_loss: 1.6126 - dense_642_loss: 1.4661 - dense_643_loss: 1.7153 - dense_634_accuracy: 0.4442 - dense_635_accuracy: 0.3714 - dense_636_accuracy: 0.3482 - dense_637_accuracy: 0.3596 - dense_638_accuracy: 0.3138 - dense_639_accuracy: 0.3394 - dense_640_accuracy: 0.3584 - dense_641_accuracy: 0.3534 - dense_642_accuracy: 0.4282 - dense_643_accuracy: 0.3242\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 16.3091 - dense_634_loss: 1.5000 - dense_635_loss: 1.6028 - dense_636_loss: 1.6862 - dense_637_loss: 1.5774 - dense_638_loss: 1.8518 - dense_639_loss: 1.6556 - dense_640_loss: 1.6714 - dense_641_loss: 1.6027 - dense_642_loss: 1.4561 - dense_643_loss: 1.7051 - dense_634_accuracy: 0.4452 - dense_635_accuracy: 0.3744 - dense_636_accuracy: 0.3514 - dense_637_accuracy: 0.3638 - dense_638_accuracy: 0.3214 - dense_639_accuracy: 0.3504 - dense_640_accuracy: 0.3614 - dense_641_accuracy: 0.3682 - dense_642_accuracy: 0.4394 - dense_643_accuracy: 0.3278\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 16.1907 - dense_634_loss: 1.4869 - dense_635_loss: 1.5891 - dense_636_loss: 1.6792 - dense_637_loss: 1.5648 - dense_638_loss: 1.8348 - dense_639_loss: 1.6429 - dense_640_loss: 1.6602 - dense_641_loss: 1.5911 - dense_642_loss: 1.4457 - dense_643_loss: 1.6960 - dense_634_accuracy: 0.4520 - dense_635_accuracy: 0.3834 - dense_636_accuracy: 0.3538 - dense_637_accuracy: 0.3690 - dense_638_accuracy: 0.3368 - dense_639_accuracy: 0.3520 - dense_640_accuracy: 0.3698 - dense_641_accuracy: 0.3686 - dense_642_accuracy: 0.4384 - dense_643_accuracy: 0.3374\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 16.0445 - dense_634_loss: 1.4734 - dense_635_loss: 1.5794 - dense_636_loss: 1.6572 - dense_637_loss: 1.5526 - dense_638_loss: 1.8227 - dense_639_loss: 1.6285 - dense_640_loss: 1.6423 - dense_641_loss: 1.5775 - dense_642_loss: 1.4347 - dense_643_loss: 1.6761 - dense_634_accuracy: 0.4638 - dense_635_accuracy: 0.3992 - dense_636_accuracy: 0.3716 - dense_637_accuracy: 0.3778 - dense_638_accuracy: 0.3458 - dense_639_accuracy: 0.3614 - dense_640_accuracy: 0.3762 - dense_641_accuracy: 0.3808 - dense_642_accuracy: 0.4506 - dense_643_accuracy: 0.3550\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 15.8740 - dense_634_loss: 1.4612 - dense_635_loss: 1.5645 - dense_636_loss: 1.6376 - dense_637_loss: 1.5320 - dense_638_loss: 1.8009 - dense_639_loss: 1.6128 - dense_640_loss: 1.6253 - dense_641_loss: 1.5611 - dense_642_loss: 1.4165 - dense_643_loss: 1.6621 - dense_634_accuracy: 0.4666 - dense_635_accuracy: 0.4076 - dense_636_accuracy: 0.3830 - dense_637_accuracy: 0.4024 - dense_638_accuracy: 0.3470 - dense_639_accuracy: 0.3832 - dense_640_accuracy: 0.3970 - dense_641_accuracy: 0.3950 - dense_642_accuracy: 0.4648 - dense_643_accuracy: 0.3668\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.8309 - dense_634_loss: 1.4561 - dense_635_loss: 1.5556 - dense_636_loss: 1.6361 - dense_637_loss: 1.5331 - dense_638_loss: 1.7935 - dense_639_loss: 1.6121 - dense_640_loss: 1.6244 - dense_641_loss: 1.5570 - dense_642_loss: 1.4105 - dense_643_loss: 1.6526 - dense_634_accuracy: 0.4692 - dense_635_accuracy: 0.4056 - dense_636_accuracy: 0.3890 - dense_637_accuracy: 0.3894 - dense_638_accuracy: 0.3640 - dense_639_accuracy: 0.3890 - dense_640_accuracy: 0.3988 - dense_641_accuracy: 0.3974 - dense_642_accuracy: 0.4572 - dense_643_accuracy: 0.3772\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 15.6932 - dense_634_loss: 1.4413 - dense_635_loss: 1.5471 - dense_636_loss: 1.6199 - dense_637_loss: 1.5158 - dense_638_loss: 1.7781 - dense_639_loss: 1.5953 - dense_640_loss: 1.6106 - dense_641_loss: 1.5449 - dense_642_loss: 1.4032 - dense_643_loss: 1.6370 - dense_634_accuracy: 0.4820 - dense_635_accuracy: 0.4120 - dense_636_accuracy: 0.4068 - dense_637_accuracy: 0.4088 - dense_638_accuracy: 0.3770 - dense_639_accuracy: 0.3926 - dense_640_accuracy: 0.4030 - dense_641_accuracy: 0.4046 - dense_642_accuracy: 0.4668 - dense_643_accuracy: 0.3890\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D08A9798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000215D08A9798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get all files from Folder Iteration ending with 'json.gz'\n",
    "event_log_path = '/logs/iteration/*.json.gz'\n",
    "git_path = git.Repo(\".\", search_parent_directories=True).git.rev_parse(\"--show-toplevel\")\n",
    "final_path = git_path+event_log_path\n",
    "files = glob.glob(final_path)\n",
    "\n",
    "column_names = {    0:'Method', \n",
    "                    1:'ari',\n",
    "                    2:'nmi',\n",
    "                    3:'b3',\n",
    "                    4:'0',\n",
    "                    5:'homogeneity',\n",
    "                    6:'completeness',\n",
    "                    7:'distribution'}\n",
    "\n",
    "\n",
    "for n in [10,25]:\n",
    "    for cluster in ['agglomerative','k_means']:\n",
    "\n",
    "        combined_results = pd.DataFrame()\n",
    "        combined_results.rename(columns = column_names, inplace = True) \n",
    "\n",
    "        for filepath in files:\n",
    "\n",
    "            # load eventlog \n",
    "            # event log configuration\n",
    "            event_log_path = filepath\n",
    "            file_name = os.path.basename(filepath)\n",
    "\n",
    "            case_attributes = None # auto-detect attributes\n",
    "            event_attributes = ['concept:name', 'user'] # use activity name and user\n",
    "            true_cluster_label = 'cluster'\n",
    "\n",
    "            # load file\n",
    "            event_log = EventLog(file_name, case_attributes=case_attributes, event_attributes=event_attributes, true_cluster_label=true_cluster_label)\n",
    "            event_log.load(event_log_path, False)\n",
    "            event_log.preprocess()\n",
    "\n",
    "\n",
    "            # hyperparameters\n",
    "            n_epochs = n\n",
    "            n_batch_size = 64\n",
    "            n_clusters = 5\n",
    "            vector_size = 32\n",
    "            cluster_method = cluster\n",
    "            hyperparameters = [n_epochs,n_batch_size,n_clusters,vector_size,cluster_method]\n",
    "            \n",
    "            # get combined results for current file and add filename as first column \n",
    "            current_combined_results = Iteration.get_combined_results(event_log,hyperparameters,column_names)\n",
    "            current_combined_results.insert(loc=0, column='Filename', value=file_name)\n",
    "\n",
    "            # add current_combined_results to overall combined results df \n",
    "            combined_results = combined_results.append(current_combined_results)\n",
    "\n",
    "        combined_results.to_csv(f'tab2_2018_{cluster_method}_{n_epochs}_epochs', encoding='utf-8', index=False, sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Method</th>\n",
       "      <th>ari</th>\n",
       "      <th>nmi</th>\n",
       "      <th>b3</th>\n",
       "      <th>0</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>completeness</th>\n",
       "      <th>distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>large_5000_10_20_5_3_1-0.1-1.json.gz</td>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>0.400293</td>\n",
       "      <td>0.510637</td>\n",
       "      <td>0.562871</td>\n",
       "      <td>0</td>\n",
       "      <td>0.513821</td>\n",
       "      <td>0.507492</td>\n",
       "      <td>{0: 814, 1: 1618, 2: 897, 3: 1060, 4: 611}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>large_5000_10_20_5_3_1-0.1-1.json.gz</td>\n",
       "      <td>TRACE2VEC</td>\n",
       "      <td>0.429616</td>\n",
       "      <td>0.558614</td>\n",
       "      <td>0.584783</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561189</td>\n",
       "      <td>0.556063</td>\n",
       "      <td>{0: 1600, 1: 1107, 2: 895, 3: 854, 4: 544}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>large_5000_10_20_5_3_1-0.1-1.json.gz</td>\n",
       "      <td>CASE2VEC E</td>\n",
       "      <td>0.391098</td>\n",
       "      <td>0.498172</td>\n",
       "      <td>0.547603</td>\n",
       "      <td>0</td>\n",
       "      <td>0.495853</td>\n",
       "      <td>0.500513</td>\n",
       "      <td>{0: 1600, 1: 355, 2: 1107, 3: 895, 4: 1043}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>large_5000_10_20_5_3_1-0.1-1.json.gz</td>\n",
       "      <td>CASE2VEC E+C</td>\n",
       "      <td>0.051325</td>\n",
       "      <td>0.257755</td>\n",
       "      <td>0.455715</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23105</td>\n",
       "      <td>0.291441</td>\n",
       "      <td>{0: 701, 1: 443, 2: 2999, 3: 465, 4: 392}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>large_5000_10_20_5_3_1-0.1-1.json.gz</td>\n",
       "      <td>GRU</td>\n",
       "      <td>0.999346</td>\n",
       "      <td>0.998025</td>\n",
       "      <td>0.999201</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997982</td>\n",
       "      <td>0.998069</td>\n",
       "      <td>{0: 898, 1: 1788, 2: 898, 3: 807, 4: 609}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>large_5000_10_20_5_3_1-0.1-1.json.gz</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.997731</td>\n",
       "      <td>0.994417</td>\n",
       "      <td>0.997607</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994439</td>\n",
       "      <td>0.994395</td>\n",
       "      <td>{0: 1787, 1: 898, 2: 896, 3: 810, 4: 609}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.4-1.json.gz</td>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>0.339104</td>\n",
       "      <td>0.405504</td>\n",
       "      <td>0.533378</td>\n",
       "      <td>0</td>\n",
       "      <td>0.465662</td>\n",
       "      <td>0.359112</td>\n",
       "      <td>{0: 222, 1: 266, 2: 163, 3: 275, 4: 74}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.4-1.json.gz</td>\n",
       "      <td>TRACE2VEC</td>\n",
       "      <td>0.534373</td>\n",
       "      <td>0.629377</td>\n",
       "      <td>0.691777</td>\n",
       "      <td>0</td>\n",
       "      <td>0.692504</td>\n",
       "      <td>0.576797</td>\n",
       "      <td>{0: 94, 1: 308, 2: 42, 3: 217, 4: 339}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.4-1.json.gz</td>\n",
       "      <td>CASE2VEC E</td>\n",
       "      <td>0.615007</td>\n",
       "      <td>0.693608</td>\n",
       "      <td>0.730323</td>\n",
       "      <td>0</td>\n",
       "      <td>0.785835</td>\n",
       "      <td>0.620754</td>\n",
       "      <td>{0: 142, 1: 367, 2: 241, 3: 167, 4: 83}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.4-1.json.gz</td>\n",
       "      <td>CASE2VEC E+C</td>\n",
       "      <td>-0.038589</td>\n",
       "      <td>0.187439</td>\n",
       "      <td>0.5433</td>\n",
       "      <td>0</td>\n",
       "      <td>0.153753</td>\n",
       "      <td>0.240026</td>\n",
       "      <td>{0: 807, 1: 60, 2: 50, 3: 40, 4: 43}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.4-1.json.gz</td>\n",
       "      <td>GRU</td>\n",
       "      <td>0.847786</td>\n",
       "      <td>0.895397</td>\n",
       "      <td>0.901188</td>\n",
       "      <td>0</td>\n",
       "      <td>0.983192</td>\n",
       "      <td>0.821996</td>\n",
       "      <td>{0: 144, 1: 435, 2: 138, 3: 55, 4: 228}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.4-1.json.gz</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.849784</td>\n",
       "      <td>0.909242</td>\n",
       "      <td>0.918471</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995279</td>\n",
       "      <td>0.836896</td>\n",
       "      <td>{0: 336, 1: 366, 2: 144, 3: 57, 4: 97}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.5-1.json.gz</td>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>0.322316</td>\n",
       "      <td>0.387559</td>\n",
       "      <td>0.520726</td>\n",
       "      <td>0</td>\n",
       "      <td>0.446845</td>\n",
       "      <td>0.342162</td>\n",
       "      <td>{0: 273, 1: 175, 2: 207, 3: 81, 4: 264}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.5-1.json.gz</td>\n",
       "      <td>TRACE2VEC</td>\n",
       "      <td>0.389859</td>\n",
       "      <td>0.530884</td>\n",
       "      <td>0.60157</td>\n",
       "      <td>0</td>\n",
       "      <td>0.608562</td>\n",
       "      <td>0.470791</td>\n",
       "      <td>{0: 305, 1: 243, 2: 237, 3: 121, 4: 94}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.5-1.json.gz</td>\n",
       "      <td>CASE2VEC E</td>\n",
       "      <td>0.603773</td>\n",
       "      <td>0.678427</td>\n",
       "      <td>0.723105</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769943</td>\n",
       "      <td>0.606355</td>\n",
       "      <td>{0: 142, 1: 241, 2: 362, 3: 171, 4: 84}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.5-1.json.gz</td>\n",
       "      <td>CASE2VEC E+C</td>\n",
       "      <td>-0.034752</td>\n",
       "      <td>0.140389</td>\n",
       "      <td>0.50685</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119488</td>\n",
       "      <td>0.170153</td>\n",
       "      <td>{0: 775, 1: 48, 2: 45, 3: 37, 4: 95}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.5-1.json.gz</td>\n",
       "      <td>GRU</td>\n",
       "      <td>0.784667</td>\n",
       "      <td>0.887168</td>\n",
       "      <td>0.88171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995718</td>\n",
       "      <td>0.799959</td>\n",
       "      <td>{0: 251, 1: 366, 2: 144, 3: 58, 4: 181}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.5-1.json.gz</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.805429</td>\n",
       "      <td>0.889992</td>\n",
       "      <td>0.8927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.991421</td>\n",
       "      <td>0.80739</td>\n",
       "      <td>{0: 292, 1: 365, 2: 144, 3: 59, 4: 140}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p2p_500_10_20_5_1_1-0.8-1.json.gz</td>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>0.319741</td>\n",
       "      <td>0.353742</td>\n",
       "      <td>0.511793</td>\n",
       "      <td>0</td>\n",
       "      <td>0.368369</td>\n",
       "      <td>0.340231</td>\n",
       "      <td>{0: 121, 1: 127, 2: 137, 3: 102, 4: 13}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p2p_500_10_20_5_1_1-0.8-1.json.gz</td>\n",
       "      <td>TRACE2VEC</td>\n",
       "      <td>0.37536</td>\n",
       "      <td>0.513876</td>\n",
       "      <td>0.571283</td>\n",
       "      <td>0</td>\n",
       "      <td>0.529255</td>\n",
       "      <td>0.499365</td>\n",
       "      <td>{0: 213, 1: 76, 2: 57, 3: 39, 4: 115}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p2p_500_10_20_5_1_1-0.8-1.json.gz</td>\n",
       "      <td>CASE2VEC E</td>\n",
       "      <td>0.244933</td>\n",
       "      <td>0.334114</td>\n",
       "      <td>0.434491</td>\n",
       "      <td>0</td>\n",
       "      <td>0.356371</td>\n",
       "      <td>0.314474</td>\n",
       "      <td>{0: 66, 1: 66, 2: 106, 3: 176, 4: 86}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p2p_500_10_20_5_1_1-0.8-1.json.gz</td>\n",
       "      <td>CASE2VEC E+C</td>\n",
       "      <td>0.016194</td>\n",
       "      <td>0.150286</td>\n",
       "      <td>0.487853</td>\n",
       "      <td>0</td>\n",
       "      <td>0.107223</td>\n",
       "      <td>0.251156</td>\n",
       "      <td>{0: 35, 1: 14, 2: 9, 3: 12, 4: 430}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p2p_500_10_20_5_1_1-0.8-1.json.gz</td>\n",
       "      <td>GRU</td>\n",
       "      <td>0.805466</td>\n",
       "      <td>0.896468</td>\n",
       "      <td>0.892301</td>\n",
       "      <td>0</td>\n",
       "      <td>0.96964</td>\n",
       "      <td>0.833565</td>\n",
       "      <td>{0: 133, 1: 125, 2: 101, 3: 71, 4: 70}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p2p_500_10_20_5_1_1-0.8-1.json.gz</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.964079</td>\n",
       "      <td>0.938044</td>\n",
       "      <td>0.949762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.960285</td>\n",
       "      <td>0.916809</td>\n",
       "      <td>{0: 134, 1: 195, 2: 100, 3: 36, 4: 35}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small_5000_10_20_5_1_1-0.5-1.json.gz</td>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>0.509642</td>\n",
       "      <td>0.559503</td>\n",
       "      <td>0.631566</td>\n",
       "      <td>0</td>\n",
       "      <td>0.693905</td>\n",
       "      <td>0.468717</td>\n",
       "      <td>{0: 975, 1: 1660, 2: 944, 3: 739, 4: 682}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small_5000_10_20_5_1_1-0.5-1.json.gz</td>\n",
       "      <td>TRACE2VEC</td>\n",
       "      <td>0.894109</td>\n",
       "      <td>0.873951</td>\n",
       "      <td>0.903792</td>\n",
       "      <td>0</td>\n",
       "      <td>0.992639</td>\n",
       "      <td>0.780614</td>\n",
       "      <td>{0: 1232, 1: 2420, 2: 297, 3: 613, 4: 438}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small_5000_10_20_5_1_1-0.5-1.json.gz</td>\n",
       "      <td>CASE2VEC E</td>\n",
       "      <td>0.660296</td>\n",
       "      <td>0.795826</td>\n",
       "      <td>0.781145</td>\n",
       "      <td>0</td>\n",
       "      <td>0.98573</td>\n",
       "      <td>0.667273</td>\n",
       "      <td>{0: 739, 1: 1563, 2: 1233, 3: 846, 4: 619}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small_5000_10_20_5_1_1-0.5-1.json.gz</td>\n",
       "      <td>CASE2VEC E+C</td>\n",
       "      <td>-0.031813</td>\n",
       "      <td>0.235047</td>\n",
       "      <td>0.570784</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220251</td>\n",
       "      <td>0.251974</td>\n",
       "      <td>{0: 3732, 1: 336, 2: 323, 3: 318, 4: 291}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small_5000_10_20_5_1_1-0.5-1.json.gz</td>\n",
       "      <td>GRU</td>\n",
       "      <td>0.884598</td>\n",
       "      <td>0.889892</td>\n",
       "      <td>0.909845</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.801626</td>\n",
       "      <td>{0: 2331, 1: 1230, 2: 556, 3: 793, 4: 90}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small_5000_10_20_5_1_1-0.5-1.json.gz</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.956768</td>\n",
       "      <td>0.935202</td>\n",
       "      <td>0.959892</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.878291</td>\n",
       "      <td>{0: 2421, 1: 1247, 2: 1122, 3: 108, 4: 102}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_10000_10_20_5_3_1-0.3-1.json.gz</td>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>0.21623</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.431942</td>\n",
       "      <td>0</td>\n",
       "      <td>0.317813</td>\n",
       "      <td>0.295954</td>\n",
       "      <td>{0: 894, 1: 3598, 2: 1343, 3: 2566, 4: 1599}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_10000_10_20_5_3_1-0.3-1.json.gz</td>\n",
       "      <td>TRACE2VEC</td>\n",
       "      <td>0.352059</td>\n",
       "      <td>0.482524</td>\n",
       "      <td>0.526605</td>\n",
       "      <td>0</td>\n",
       "      <td>0.510995</td>\n",
       "      <td>0.457059</td>\n",
       "      <td>{0: 2469, 1: 2820, 2: 1723, 3: 1003, 4: 1985}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_10000_10_20_5_3_1-0.3-1.json.gz</td>\n",
       "      <td>CASE2VEC E</td>\n",
       "      <td>0.331501</td>\n",
       "      <td>0.43004</td>\n",
       "      <td>0.489774</td>\n",
       "      <td>0</td>\n",
       "      <td>0.460037</td>\n",
       "      <td>0.403715</td>\n",
       "      <td>{0: 2813, 1: 1555, 2: 2019, 3: 1703, 4: 1910}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_10000_10_20_5_3_1-0.3-1.json.gz</td>\n",
       "      <td>CASE2VEC E+C</td>\n",
       "      <td>0.052067</td>\n",
       "      <td>0.119699</td>\n",
       "      <td>0.35862</td>\n",
       "      <td>0</td>\n",
       "      <td>0.114231</td>\n",
       "      <td>0.125718</td>\n",
       "      <td>{0: 358, 1: 1382, 2: 2016, 3: 890, 4: 5354}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_10000_10_20_5_3_1-0.3-1.json.gz</td>\n",
       "      <td>GRU</td>\n",
       "      <td>0.99579</td>\n",
       "      <td>0.991168</td>\n",
       "      <td>0.996612</td>\n",
       "      <td>0</td>\n",
       "      <td>0.991016</td>\n",
       "      <td>0.991321</td>\n",
       "      <td>{0: 36, 1: 2664, 2: 2262, 3: 1988, 4: 3050}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_10000_10_20_5_3_1-0.3-1.json.gz</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.994446</td>\n",
       "      <td>0.987361</td>\n",
       "      <td>0.993674</td>\n",
       "      <td>0</td>\n",
       "      <td>0.991662</td>\n",
       "      <td>0.983096</td>\n",
       "      <td>{0: 67, 1: 2660, 2: 2251, 3: 3028, 4: 1994}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_5000_10_20_5_1_1-1.0-1.json.gz</td>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>0.078265</td>\n",
       "      <td>0.118215</td>\n",
       "      <td>0.298026</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119949</td>\n",
       "      <td>0.116531</td>\n",
       "      <td>{0: 711, 1: 1262, 2: 675, 3: 1493, 4: 859}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_5000_10_20_5_1_1-1.0-1.json.gz</td>\n",
       "      <td>TRACE2VEC</td>\n",
       "      <td>0.285965</td>\n",
       "      <td>0.433947</td>\n",
       "      <td>0.502545</td>\n",
       "      <td>0</td>\n",
       "      <td>0.427512</td>\n",
       "      <td>0.440579</td>\n",
       "      <td>{0: 629, 1: 1885, 2: 576, 3: 1387, 4: 523}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_5000_10_20_5_1_1-1.0-1.json.gz</td>\n",
       "      <td>CASE2VEC E</td>\n",
       "      <td>0.348071</td>\n",
       "      <td>0.514149</td>\n",
       "      <td>0.564568</td>\n",
       "      <td>0</td>\n",
       "      <td>0.516126</td>\n",
       "      <td>0.512186</td>\n",
       "      <td>{0: 1027, 1: 1726, 2: 603, 3: 575, 4: 1069}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_5000_10_20_5_1_1-1.0-1.json.gz</td>\n",
       "      <td>CASE2VEC E+C</td>\n",
       "      <td>-0.003723</td>\n",
       "      <td>0.017695</td>\n",
       "      <td>0.384362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>0.125088</td>\n",
       "      <td>{0: 4907, 1: 48, 2: 17, 3: 15, 4: 13}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_5000_10_20_5_1_1-1.0-1.json.gz</td>\n",
       "      <td>GRU</td>\n",
       "      <td>0.984437</td>\n",
       "      <td>0.97527</td>\n",
       "      <td>0.987357</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974451</td>\n",
       "      <td>0.97609</td>\n",
       "      <td>{0: 861, 1: 1424, 2: 1403, 3: 1002, 4: 310}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_5000_10_20_5_1_1-1.0-1.json.gz</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.986792</td>\n",
       "      <td>0.97818</td>\n",
       "      <td>0.989282</td>\n",
       "      <td>0</td>\n",
       "      <td>0.97833</td>\n",
       "      <td>0.978031</td>\n",
       "      <td>{0: 1390, 1: 1423, 2: 877, 3: 317, 4: 993}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Filename        Method       ari       nmi  \\\n",
       "0   large_5000_10_20_5_3_1-0.1-1.json.gz   Autoencoder  0.400293  0.510637   \n",
       "0   large_5000_10_20_5_3_1-0.1-1.json.gz     TRACE2VEC  0.429616  0.558614   \n",
       "0   large_5000_10_20_5_3_1-0.1-1.json.gz    CASE2VEC E  0.391098  0.498172   \n",
       "0   large_5000_10_20_5_3_1-0.1-1.json.gz  CASE2VEC E+C  0.051325  0.257755   \n",
       "0   large_5000_10_20_5_3_1-0.1-1.json.gz           GRU  0.999346  0.998025   \n",
       "0   large_5000_10_20_5_3_1-0.1-1.json.gz          LSTM  0.997731  0.994417   \n",
       "0  medium_1000_10_20_5_3_1-0.4-1.json.gz   Autoencoder  0.339104  0.405504   \n",
       "0  medium_1000_10_20_5_3_1-0.4-1.json.gz     TRACE2VEC  0.534373  0.629377   \n",
       "0  medium_1000_10_20_5_3_1-0.4-1.json.gz    CASE2VEC E  0.615007  0.693608   \n",
       "0  medium_1000_10_20_5_3_1-0.4-1.json.gz  CASE2VEC E+C -0.038589  0.187439   \n",
       "0  medium_1000_10_20_5_3_1-0.4-1.json.gz           GRU  0.847786  0.895397   \n",
       "0  medium_1000_10_20_5_3_1-0.4-1.json.gz          LSTM  0.849784  0.909242   \n",
       "0  medium_1000_10_20_5_3_1-0.5-1.json.gz   Autoencoder  0.322316  0.387559   \n",
       "0  medium_1000_10_20_5_3_1-0.5-1.json.gz     TRACE2VEC  0.389859  0.530884   \n",
       "0  medium_1000_10_20_5_3_1-0.5-1.json.gz    CASE2VEC E  0.603773  0.678427   \n",
       "0  medium_1000_10_20_5_3_1-0.5-1.json.gz  CASE2VEC E+C -0.034752  0.140389   \n",
       "0  medium_1000_10_20_5_3_1-0.5-1.json.gz           GRU  0.784667  0.887168   \n",
       "0  medium_1000_10_20_5_3_1-0.5-1.json.gz          LSTM  0.805429  0.889992   \n",
       "0      p2p_500_10_20_5_1_1-0.8-1.json.gz   Autoencoder  0.319741  0.353742   \n",
       "0      p2p_500_10_20_5_1_1-0.8-1.json.gz     TRACE2VEC   0.37536  0.513876   \n",
       "0      p2p_500_10_20_5_1_1-0.8-1.json.gz    CASE2VEC E  0.244933  0.334114   \n",
       "0      p2p_500_10_20_5_1_1-0.8-1.json.gz  CASE2VEC E+C  0.016194  0.150286   \n",
       "0      p2p_500_10_20_5_1_1-0.8-1.json.gz           GRU  0.805466  0.896468   \n",
       "0      p2p_500_10_20_5_1_1-0.8-1.json.gz          LSTM  0.964079  0.938044   \n",
       "0   small_5000_10_20_5_1_1-0.5-1.json.gz   Autoencoder  0.509642  0.559503   \n",
       "0   small_5000_10_20_5_1_1-0.5-1.json.gz     TRACE2VEC  0.894109  0.873951   \n",
       "0   small_5000_10_20_5_1_1-0.5-1.json.gz    CASE2VEC E  0.660296  0.795826   \n",
       "0   small_5000_10_20_5_1_1-0.5-1.json.gz  CASE2VEC E+C -0.031813  0.235047   \n",
       "0   small_5000_10_20_5_1_1-0.5-1.json.gz           GRU  0.884598  0.889892   \n",
       "0   small_5000_10_20_5_1_1-0.5-1.json.gz          LSTM  0.956768  0.935202   \n",
       "0   wide_10000_10_20_5_3_1-0.3-1.json.gz   Autoencoder   0.21623  0.306495   \n",
       "0   wide_10000_10_20_5_3_1-0.3-1.json.gz     TRACE2VEC  0.352059  0.482524   \n",
       "0   wide_10000_10_20_5_3_1-0.3-1.json.gz    CASE2VEC E  0.331501   0.43004   \n",
       "0   wide_10000_10_20_5_3_1-0.3-1.json.gz  CASE2VEC E+C  0.052067  0.119699   \n",
       "0   wide_10000_10_20_5_3_1-0.3-1.json.gz           GRU   0.99579  0.991168   \n",
       "0   wide_10000_10_20_5_3_1-0.3-1.json.gz          LSTM  0.994446  0.987361   \n",
       "0    wide_5000_10_20_5_1_1-1.0-1.json.gz   Autoencoder  0.078265  0.118215   \n",
       "0    wide_5000_10_20_5_1_1-1.0-1.json.gz     TRACE2VEC  0.285965  0.433947   \n",
       "0    wide_5000_10_20_5_1_1-1.0-1.json.gz    CASE2VEC E  0.348071  0.514149   \n",
       "0    wide_5000_10_20_5_1_1-1.0-1.json.gz  CASE2VEC E+C -0.003723  0.017695   \n",
       "0    wide_5000_10_20_5_1_1-1.0-1.json.gz           GRU  0.984437   0.97527   \n",
       "0    wide_5000_10_20_5_1_1-1.0-1.json.gz          LSTM  0.986792   0.97818   \n",
       "\n",
       "         b3  0 homogeneity completeness  \\\n",
       "0  0.562871  0    0.513821     0.507492   \n",
       "0  0.584783  0    0.561189     0.556063   \n",
       "0  0.547603  0    0.495853     0.500513   \n",
       "0  0.455715  0     0.23105     0.291441   \n",
       "0  0.999201  0    0.997982     0.998069   \n",
       "0  0.997607  0    0.994439     0.994395   \n",
       "0  0.533378  0    0.465662     0.359112   \n",
       "0  0.691777  0    0.692504     0.576797   \n",
       "0  0.730323  0    0.785835     0.620754   \n",
       "0    0.5433  0    0.153753     0.240026   \n",
       "0  0.901188  0    0.983192     0.821996   \n",
       "0  0.918471  0    0.995279     0.836896   \n",
       "0  0.520726  0    0.446845     0.342162   \n",
       "0   0.60157  0    0.608562     0.470791   \n",
       "0  0.723105  0    0.769943     0.606355   \n",
       "0   0.50685  0    0.119488     0.170153   \n",
       "0   0.88171  0    0.995718     0.799959   \n",
       "0    0.8927  0    0.991421      0.80739   \n",
       "0  0.511793  0    0.368369     0.340231   \n",
       "0  0.571283  0    0.529255     0.499365   \n",
       "0  0.434491  0    0.356371     0.314474   \n",
       "0  0.487853  0    0.107223     0.251156   \n",
       "0  0.892301  0     0.96964     0.833565   \n",
       "0  0.949762  0    0.960285     0.916809   \n",
       "0  0.631566  0    0.693905     0.468717   \n",
       "0  0.903792  0    0.992639     0.780614   \n",
       "0  0.781145  0     0.98573     0.667273   \n",
       "0  0.570784  0    0.220251     0.251974   \n",
       "0  0.909845  0         1.0     0.801626   \n",
       "0  0.959892  0         1.0     0.878291   \n",
       "0  0.431942  0    0.317813     0.295954   \n",
       "0  0.526605  0    0.510995     0.457059   \n",
       "0  0.489774  0    0.460037     0.403715   \n",
       "0   0.35862  0    0.114231     0.125718   \n",
       "0  0.996612  0    0.991016     0.991321   \n",
       "0  0.993674  0    0.991662     0.983096   \n",
       "0  0.298026  0    0.119949     0.116531   \n",
       "0  0.502545  0    0.427512     0.440579   \n",
       "0  0.564568  0    0.516126     0.512186   \n",
       "0  0.384362  0    0.009521     0.125088   \n",
       "0  0.987357  0    0.974451      0.97609   \n",
       "0  0.989282  0     0.97833     0.978031   \n",
       "\n",
       "                                    distribution  \n",
       "0     {0: 814, 1: 1618, 2: 897, 3: 1060, 4: 611}  \n",
       "0     {0: 1600, 1: 1107, 2: 895, 3: 854, 4: 544}  \n",
       "0    {0: 1600, 1: 355, 2: 1107, 3: 895, 4: 1043}  \n",
       "0      {0: 701, 1: 443, 2: 2999, 3: 465, 4: 392}  \n",
       "0      {0: 898, 1: 1788, 2: 898, 3: 807, 4: 609}  \n",
       "0      {0: 1787, 1: 898, 2: 896, 3: 810, 4: 609}  \n",
       "0        {0: 222, 1: 266, 2: 163, 3: 275, 4: 74}  \n",
       "0         {0: 94, 1: 308, 2: 42, 3: 217, 4: 339}  \n",
       "0        {0: 142, 1: 367, 2: 241, 3: 167, 4: 83}  \n",
       "0           {0: 807, 1: 60, 2: 50, 3: 40, 4: 43}  \n",
       "0        {0: 144, 1: 435, 2: 138, 3: 55, 4: 228}  \n",
       "0         {0: 336, 1: 366, 2: 144, 3: 57, 4: 97}  \n",
       "0        {0: 273, 1: 175, 2: 207, 3: 81, 4: 264}  \n",
       "0        {0: 305, 1: 243, 2: 237, 3: 121, 4: 94}  \n",
       "0        {0: 142, 1: 241, 2: 362, 3: 171, 4: 84}  \n",
       "0           {0: 775, 1: 48, 2: 45, 3: 37, 4: 95}  \n",
       "0        {0: 251, 1: 366, 2: 144, 3: 58, 4: 181}  \n",
       "0        {0: 292, 1: 365, 2: 144, 3: 59, 4: 140}  \n",
       "0        {0: 121, 1: 127, 2: 137, 3: 102, 4: 13}  \n",
       "0          {0: 213, 1: 76, 2: 57, 3: 39, 4: 115}  \n",
       "0          {0: 66, 1: 66, 2: 106, 3: 176, 4: 86}  \n",
       "0            {0: 35, 1: 14, 2: 9, 3: 12, 4: 430}  \n",
       "0         {0: 133, 1: 125, 2: 101, 3: 71, 4: 70}  \n",
       "0         {0: 134, 1: 195, 2: 100, 3: 36, 4: 35}  \n",
       "0      {0: 975, 1: 1660, 2: 944, 3: 739, 4: 682}  \n",
       "0     {0: 1232, 1: 2420, 2: 297, 3: 613, 4: 438}  \n",
       "0     {0: 739, 1: 1563, 2: 1233, 3: 846, 4: 619}  \n",
       "0      {0: 3732, 1: 336, 2: 323, 3: 318, 4: 291}  \n",
       "0      {0: 2331, 1: 1230, 2: 556, 3: 793, 4: 90}  \n",
       "0    {0: 2421, 1: 1247, 2: 1122, 3: 108, 4: 102}  \n",
       "0   {0: 894, 1: 3598, 2: 1343, 3: 2566, 4: 1599}  \n",
       "0  {0: 2469, 1: 2820, 2: 1723, 3: 1003, 4: 1985}  \n",
       "0  {0: 2813, 1: 1555, 2: 2019, 3: 1703, 4: 1910}  \n",
       "0    {0: 358, 1: 1382, 2: 2016, 3: 890, 4: 5354}  \n",
       "0    {0: 36, 1: 2664, 2: 2262, 3: 1988, 4: 3050}  \n",
       "0    {0: 67, 1: 2660, 2: 2251, 3: 3028, 4: 1994}  \n",
       "0     {0: 711, 1: 1262, 2: 675, 3: 1493, 4: 859}  \n",
       "0     {0: 629, 1: 1885, 2: 576, 3: 1387, 4: 523}  \n",
       "0    {0: 1027, 1: 1726, 2: 603, 3: 575, 4: 1069}  \n",
       "0          {0: 4907, 1: 48, 2: 17, 3: 15, 4: 13}  \n",
       "0    {0: 861, 1: 1424, 2: 1403, 3: 1002, 4: 310}  \n",
       "0     {0: 1390, 1: 1423, 2: 877, 3: 317, 4: 993}  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e6a4c907d9d4f71bfd38b2a3a6a6661b67eece1ce5a60357bdd48dba7898a5a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('replearn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import git\n",
    "from pm4py.objects.log.importer.xes import factory as xes_import_factory\n",
    "from replearn.eventlog import EventLog\n",
    "from log_iteration import Iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pm4py in c:\\users\\ayham\\anaconda3\\lib\\site-packages (1.5.2.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pm4py) (1.4.1)\n",
      "Requirement already satisfied: pydotplus in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pm4py) (2.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pm4py) (1.7.3)\n",
      "Requirement already satisfied: lxml in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pm4py) (4.8.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pm4py) (2.6.3)\n",
      "Requirement already satisfied: pulp<=2.1 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pm4py) (2.1)\n",
      "Requirement already satisfied: jsonpickle in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pm4py) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pm4py) (1.21.6)\n",
      "Requirement already satisfied: intervaltree in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pm4py) (3.1.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pm4py) (0.19.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pm4py) (1.0.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pm4py) (3.5.1)\n",
      "Requirement already satisfied: stringdist in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pm4py) (1.0.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pm4py) (4.63.0)\n",
      "Requirement already satisfied: pyvis in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pm4py) (0.1.9)\n",
      "Requirement already satisfied: deprecation in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pm4py) (2.1.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pm4py) (1.9)\n",
      "Requirement already satisfied: pytz in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pm4py) (2021.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pulp<=2.1->pm4py) (3.0.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from deprecation->pm4py) (21.3)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from intervaltree->pm4py) (2.4.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from matplotlib->pm4py) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from matplotlib->pm4py) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from matplotlib->pm4py) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from matplotlib->pm4py) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from matplotlib->pm4py) (2.8.2)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pyvis->pm4py) (3.1.1)\n",
      "Requirement already satisfied: ipython>=5.3.0 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from pyvis->pm4py) (8.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from scikit-learn->pm4py) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from scikit-learn->pm4py) (1.1.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from sympy->pm4py) (1.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from tqdm->pm4py) (0.4.4)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis->pm4py) (0.18.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis->pm4py) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis->pm4py) (5.1.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis->pm4py) (58.0.4)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis->pm4py) (2.11.2)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis->pm4py) (0.7.5)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis->pm4py) (0.1.2)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis->pm4py) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis->pm4py) (3.0.20)\n",
      "Requirement already satisfied: stack-data in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from ipython>=5.3.0->pyvis->pm4py) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from jinja2>=2.9.6->pyvis->pm4py) (2.1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->pm4py) (1.16.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis->pm4py) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis->pm4py) (0.2.5)\n",
      "Requirement already satisfied: executing in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from stack-data->ipython>=5.3.0->pyvis->pm4py) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from stack-data->ipython>=5.3.0->pyvis->pm4py) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\ayham\\anaconda3\\lib\\site-packages (from stack-data->ipython>=5.3.0->pyvis->pm4py) (0.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pm4py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sys' has no attribute 'excutable'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexcutable\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'sys' has no attribute 'excutable'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.excutable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall pm4py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 2s 8ms/step - loss: 0.2482\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2418\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2288\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2047\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1643\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1127\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0631\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0331\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0186\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:55: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 8s 29ms/step - loss: 23.3859 - dense_3_loss: 1.9827 - dense_4_loss: 2.7120 - dense_5_loss: 2.2678 - dense_6_loss: 2.2440 - dense_7_loss: 2.7748 - dense_8_loss: 2.7538 - dense_9_loss: 2.3047 - dense_10_loss: 2.3350 - dense_11_loss: 2.1443 - dense_12_loss: 1.8667 - dense_3_accuracy: 0.2800 - dense_4_accuracy: 0.1020 - dense_5_accuracy: 0.1540 - dense_6_accuracy: 0.1600 - dense_7_accuracy: 0.1270 - dense_8_accuracy: 0.0820 - dense_9_accuracy: 0.1870 - dense_10_accuracy: 0.1440 - dense_11_accuracy: 0.2810 - dense_12_accuracy: 0.3890\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 19.1018 - dense_3_loss: 1.7394 - dense_4_loss: 2.2039 - dense_5_loss: 1.7998 - dense_6_loss: 1.9095 - dense_7_loss: 2.2423 - dense_8_loss: 2.2155 - dense_9_loss: 1.9379 - dense_10_loss: 2.0166 - dense_11_loss: 1.6171 - dense_12_loss: 1.4199 - dense_3_accuracy: 0.3320 - dense_4_accuracy: 0.1980 - dense_5_accuracy: 0.2980 - dense_6_accuracy: 0.2220 - dense_7_accuracy: 0.2020 - dense_8_accuracy: 0.2010 - dense_9_accuracy: 0.2520 - dense_10_accuracy: 0.1990 - dense_11_accuracy: 0.4140 - dense_12_accuracy: 0.4750\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 16.3576 - dense_3_loss: 1.5833 - dense_4_loss: 1.8062 - dense_5_loss: 1.5390 - dense_6_loss: 1.7073 - dense_7_loss: 1.8453 - dense_8_loss: 1.8714 - dense_9_loss: 1.6823 - dense_10_loss: 1.7787 - dense_11_loss: 1.2846 - dense_12_loss: 1.2597 - dense_3_accuracy: 0.3450 - dense_4_accuracy: 0.2240 - dense_5_accuracy: 0.3590 - dense_6_accuracy: 0.2390 - dense_7_accuracy: 0.2210 - dense_8_accuracy: 0.2450 - dense_9_accuracy: 0.2600 - dense_10_accuracy: 0.2200 - dense_11_accuracy: 0.5110 - dense_12_accuracy: 0.5160\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 15.7013 - dense_3_loss: 1.5135 - dense_4_loss: 1.7296 - dense_5_loss: 1.5014 - dense_6_loss: 1.6480 - dense_7_loss: 1.7767 - dense_8_loss: 1.7968 - dense_9_loss: 1.6014 - dense_10_loss: 1.6674 - dense_11_loss: 1.2302 - dense_12_loss: 1.2364 - dense_3_accuracy: 0.3440 - dense_4_accuracy: 0.2200 - dense_5_accuracy: 0.3680 - dense_6_accuracy: 0.2390 - dense_7_accuracy: 0.2290 - dense_8_accuracy: 0.2270 - dense_9_accuracy: 0.2700 - dense_10_accuracy: 0.2240 - dense_11_accuracy: 0.4950 - dense_12_accuracy: 0.5240\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 15.2559 - dense_3_loss: 1.4497 - dense_4_loss: 1.6716 - dense_5_loss: 1.4403 - dense_6_loss: 1.6328 - dense_7_loss: 1.7411 - dense_8_loss: 1.7231 - dense_9_loss: 1.5596 - dense_10_loss: 1.6122 - dense_11_loss: 1.1965 - dense_12_loss: 1.2290 - dense_3_accuracy: 0.3690 - dense_4_accuracy: 0.2150 - dense_5_accuracy: 0.3840 - dense_6_accuracy: 0.2370 - dense_7_accuracy: 0.2280 - dense_8_accuracy: 0.2370 - dense_9_accuracy: 0.2730 - dense_10_accuracy: 0.2260 - dense_11_accuracy: 0.4980 - dense_12_accuracy: 0.5280\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 14.9291 - dense_3_loss: 1.4220 - dense_4_loss: 1.6337 - dense_5_loss: 1.4239 - dense_6_loss: 1.5942 - dense_7_loss: 1.6960 - dense_8_loss: 1.6858 - dense_9_loss: 1.5304 - dense_10_loss: 1.5885 - dense_11_loss: 1.1639 - dense_12_loss: 1.1909 - dense_3_accuracy: 0.3420 - dense_4_accuracy: 0.2270 - dense_5_accuracy: 0.3810 - dense_6_accuracy: 0.2390 - dense_7_accuracy: 0.2250 - dense_8_accuracy: 0.2400 - dense_9_accuracy: 0.2720 - dense_10_accuracy: 0.2310 - dense_11_accuracy: 0.5050 - dense_12_accuracy: 0.5440\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 14.7460 - dense_3_loss: 1.4050 - dense_4_loss: 1.6147 - dense_5_loss: 1.4070 - dense_6_loss: 1.5690 - dense_7_loss: 1.6758 - dense_8_loss: 1.6854 - dense_9_loss: 1.5153 - dense_10_loss: 1.5733 - dense_11_loss: 1.1415 - dense_12_loss: 1.1591 - dense_3_accuracy: 0.3890 - dense_4_accuracy: 0.2390 - dense_5_accuracy: 0.3930 - dense_6_accuracy: 0.2540 - dense_7_accuracy: 0.2400 - dense_8_accuracy: 0.2380 - dense_9_accuracy: 0.3060 - dense_10_accuracy: 0.2580 - dense_11_accuracy: 0.4920 - dense_12_accuracy: 0.5380\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 14.5778 - dense_3_loss: 1.3920 - dense_4_loss: 1.6029 - dense_5_loss: 1.4063 - dense_6_loss: 1.5534 - dense_7_loss: 1.6564 - dense_8_loss: 1.6636 - dense_9_loss: 1.4964 - dense_10_loss: 1.5515 - dense_11_loss: 1.1203 - dense_12_loss: 1.1350 - dense_3_accuracy: 0.3780 - dense_4_accuracy: 0.2530 - dense_5_accuracy: 0.3850 - dense_6_accuracy: 0.2750 - dense_7_accuracy: 0.2750 - dense_8_accuracy: 0.2650 - dense_9_accuracy: 0.3320 - dense_10_accuracy: 0.2580 - dense_11_accuracy: 0.5270 - dense_12_accuracy: 0.5460\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 14.6494 - dense_3_loss: 1.3934 - dense_4_loss: 1.6130 - dense_5_loss: 1.4170 - dense_6_loss: 1.5624 - dense_7_loss: 1.6727 - dense_8_loss: 1.6647 - dense_9_loss: 1.5006 - dense_10_loss: 1.5633 - dense_11_loss: 1.1261 - dense_12_loss: 1.1363 - dense_3_accuracy: 0.3750 - dense_4_accuracy: 0.2350 - dense_5_accuracy: 0.3770 - dense_6_accuracy: 0.2470 - dense_7_accuracy: 0.2360 - dense_8_accuracy: 0.2570 - dense_9_accuracy: 0.3060 - dense_10_accuracy: 0.2640 - dense_11_accuracy: 0.5040 - dense_12_accuracy: 0.5420\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 14.4448 - dense_3_loss: 1.3813 - dense_4_loss: 1.5895 - dense_5_loss: 1.3961 - dense_6_loss: 1.5339 - dense_7_loss: 1.6414 - dense_8_loss: 1.6546 - dense_9_loss: 1.4742 - dense_10_loss: 1.5486 - dense_11_loss: 1.1104 - dense_12_loss: 1.1148 - dense_3_accuracy: 0.3830 - dense_4_accuracy: 0.2770 - dense_5_accuracy: 0.4010 - dense_6_accuracy: 0.2880 - dense_7_accuracy: 0.2700 - dense_8_accuracy: 0.2680 - dense_9_accuracy: 0.3210 - dense_10_accuracy: 0.2680 - dense_11_accuracy: 0.5250 - dense_12_accuracy: 0.5600\n",
      "32/32 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 7s 26ms/step - loss: 23.3043 - dense_13_loss: 2.0588 - dense_14_loss: 2.7296 - dense_15_loss: 2.2568 - dense_16_loss: 2.2064 - dense_17_loss: 2.7207 - dense_18_loss: 2.7797 - dense_19_loss: 2.2740 - dense_20_loss: 2.3000 - dense_21_loss: 2.0958 - dense_22_loss: 1.8823 - dense_13_accuracy: 0.2880 - dense_14_accuracy: 0.1230 - dense_15_accuracy: 0.1840 - dense_16_accuracy: 0.1740 - dense_17_accuracy: 0.1360 - dense_18_accuracy: 0.1240 - dense_19_accuracy: 0.1330 - dense_20_accuracy: 0.1810 - dense_21_accuracy: 0.3390 - dense_22_accuracy: 0.4070\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 17.5968 - dense_13_loss: 1.6396 - dense_14_loss: 2.0257 - dense_15_loss: 1.7070 - dense_16_loss: 1.8065 - dense_17_loss: 1.9963 - dense_18_loss: 2.0527 - dense_19_loss: 1.7820 - dense_20_loss: 1.8901 - dense_21_loss: 1.3556 - dense_22_loss: 1.3413 - dense_13_accuracy: 0.3410 - dense_14_accuracy: 0.1960 - dense_15_accuracy: 0.3550 - dense_16_accuracy: 0.2100 - dense_17_accuracy: 0.2180 - dense_18_accuracy: 0.2120 - dense_19_accuracy: 0.2480 - dense_20_accuracy: 0.2090 - dense_21_accuracy: 0.4940 - dense_22_accuracy: 0.5090\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 15.7902 - dense_13_loss: 1.4966 - dense_14_loss: 1.7516 - dense_15_loss: 1.5135 - dense_16_loss: 1.6797 - dense_17_loss: 1.7846 - dense_18_loss: 1.8138 - dense_19_loss: 1.5994 - dense_20_loss: 1.7129 - dense_21_loss: 1.2237 - dense_22_loss: 1.2143 - dense_13_accuracy: 0.3360 - dense_14_accuracy: 0.2410 - dense_15_accuracy: 0.3610 - dense_16_accuracy: 0.2100 - dense_17_accuracy: 0.2150 - dense_18_accuracy: 0.2310 - dense_19_accuracy: 0.2510 - dense_20_accuracy: 0.2350 - dense_21_accuracy: 0.5010 - dense_22_accuracy: 0.5320\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 15.2510 - dense_13_loss: 1.4568 - dense_14_loss: 1.6637 - dense_15_loss: 1.4579 - dense_16_loss: 1.6356 - dense_17_loss: 1.7247 - dense_18_loss: 1.7349 - dense_19_loss: 1.5534 - dense_20_loss: 1.6463 - dense_21_loss: 1.1860 - dense_22_loss: 1.1915 - dense_13_accuracy: 0.3520 - dense_14_accuracy: 0.2500 - dense_15_accuracy: 0.3850 - dense_16_accuracy: 0.2240 - dense_17_accuracy: 0.2330 - dense_18_accuracy: 0.2280 - dense_19_accuracy: 0.2750 - dense_20_accuracy: 0.2100 - dense_21_accuracy: 0.4980 - dense_22_accuracy: 0.5350\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 14.8847 - dense_13_loss: 1.4321 - dense_14_loss: 1.6322 - dense_15_loss: 1.4347 - dense_16_loss: 1.5878 - dense_17_loss: 1.6841 - dense_18_loss: 1.6940 - dense_19_loss: 1.5179 - dense_20_loss: 1.5930 - dense_21_loss: 1.1413 - dense_22_loss: 1.1675 - dense_13_accuracy: 0.3460 - dense_14_accuracy: 0.2350 - dense_15_accuracy: 0.3810 - dense_16_accuracy: 0.2450 - dense_17_accuracy: 0.2450 - dense_18_accuracy: 0.2410 - dense_19_accuracy: 0.2840 - dense_20_accuracy: 0.2470 - dense_21_accuracy: 0.5090 - dense_22_accuracy: 0.5440\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 14.7219 - dense_13_loss: 1.4165 - dense_14_loss: 1.6091 - dense_15_loss: 1.4172 - dense_16_loss: 1.5778 - dense_17_loss: 1.6663 - dense_18_loss: 1.6834 - dense_19_loss: 1.5077 - dense_20_loss: 1.5760 - dense_21_loss: 1.1331 - dense_22_loss: 1.1349 - dense_13_accuracy: 0.3670 - dense_14_accuracy: 0.2460 - dense_15_accuracy: 0.3810 - dense_16_accuracy: 0.2330 - dense_17_accuracy: 0.2520 - dense_18_accuracy: 0.2410 - dense_19_accuracy: 0.2770 - dense_20_accuracy: 0.2370 - dense_21_accuracy: 0.5070 - dense_22_accuracy: 0.5410\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 14.5838 - dense_13_loss: 1.4002 - dense_14_loss: 1.5972 - dense_15_loss: 1.4087 - dense_16_loss: 1.5604 - dense_17_loss: 1.6529 - dense_18_loss: 1.6647 - dense_19_loss: 1.4936 - dense_20_loss: 1.5586 - dense_21_loss: 1.1221 - dense_22_loss: 1.1251 - dense_13_accuracy: 0.3680 - dense_14_accuracy: 0.2630 - dense_15_accuracy: 0.3850 - dense_16_accuracy: 0.2660 - dense_17_accuracy: 0.2550 - dense_18_accuracy: 0.2520 - dense_19_accuracy: 0.2970 - dense_20_accuracy: 0.2710 - dense_21_accuracy: 0.5270 - dense_22_accuracy: 0.5450\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 14.5002 - dense_13_loss: 1.3906 - dense_14_loss: 1.5886 - dense_15_loss: 1.4080 - dense_16_loss: 1.5500 - dense_17_loss: 1.6431 - dense_18_loss: 1.6553 - dense_19_loss: 1.4845 - dense_20_loss: 1.5582 - dense_21_loss: 1.1069 - dense_22_loss: 1.1150 - dense_13_accuracy: 0.3650 - dense_14_accuracy: 0.2350 - dense_15_accuracy: 0.3750 - dense_16_accuracy: 0.2440 - dense_17_accuracy: 0.2480 - dense_18_accuracy: 0.2500 - dense_19_accuracy: 0.2940 - dense_20_accuracy: 0.2410 - dense_21_accuracy: 0.5240 - dense_22_accuracy: 0.5520\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 14.4775 - dense_13_loss: 1.3941 - dense_14_loss: 1.5832 - dense_15_loss: 1.4036 - dense_16_loss: 1.5489 - dense_17_loss: 1.6426 - dense_18_loss: 1.6501 - dense_19_loss: 1.4845 - dense_20_loss: 1.5519 - dense_21_loss: 1.1064 - dense_22_loss: 1.1122 - dense_13_accuracy: 0.3660 - dense_14_accuracy: 0.2530 - dense_15_accuracy: 0.3770 - dense_16_accuracy: 0.2470 - dense_17_accuracy: 0.2560 - dense_18_accuracy: 0.2530 - dense_19_accuracy: 0.3000 - dense_20_accuracy: 0.2600 - dense_21_accuracy: 0.5190 - dense_22_accuracy: 0.5480\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 14.4462 - dense_13_loss: 1.3911 - dense_14_loss: 1.5822 - dense_15_loss: 1.3962 - dense_16_loss: 1.5468 - dense_17_loss: 1.6385 - dense_18_loss: 1.6493 - dense_19_loss: 1.4802 - dense_20_loss: 1.5541 - dense_21_loss: 1.1006 - dense_22_loss: 1.1074 - dense_13_accuracy: 0.3740 - dense_14_accuracy: 0.2430 - dense_15_accuracy: 0.3880 - dense_16_accuracy: 0.2340 - dense_17_accuracy: 0.2730 - dense_18_accuracy: 0.2510 - dense_19_accuracy: 0.3000 - dense_20_accuracy: 0.2390 - dense_21_accuracy: 0.5120 - dense_22_accuracy: 0.5380\n",
      "32/32 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\AppData\\Local\\Temp\\ipykernel_5552\\3844863450.py:53: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(current_combined_results)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 5ms/step - loss: 0.2484\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2425\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2299\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2044\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1607\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1037\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0546\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0278\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0162\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:55: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 8s 24ms/step - loss: 23.4145 - dense_26_loss: 2.0255 - dense_27_loss: 2.7246 - dense_28_loss: 2.2688 - dense_29_loss: 2.2860 - dense_30_loss: 2.7022 - dense_31_loss: 2.7658 - dense_32_loss: 2.3295 - dense_33_loss: 2.3348 - dense_34_loss: 2.1147 - dense_35_loss: 1.8628 - dense_26_accuracy: 0.2670 - dense_27_accuracy: 0.0890 - dense_28_accuracy: 0.2000 - dense_29_accuracy: 0.1500 - dense_30_accuracy: 0.1040 - dense_31_accuracy: 0.0980 - dense_32_accuracy: 0.1680 - dense_33_accuracy: 0.1650 - dense_34_accuracy: 0.2820 - dense_35_accuracy: 0.4180\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 19.5711 - dense_26_loss: 1.6549 - dense_27_loss: 2.2573 - dense_28_loss: 1.8776 - dense_29_loss: 1.9582 - dense_30_loss: 2.2497 - dense_31_loss: 2.4068 - dense_32_loss: 2.0018 - dense_33_loss: 2.1067 - dense_34_loss: 1.6160 - dense_35_loss: 1.4420 - dense_26_accuracy: 0.3170 - dense_27_accuracy: 0.1940 - dense_28_accuracy: 0.2530 - dense_29_accuracy: 0.2230 - dense_30_accuracy: 0.1620 - dense_31_accuracy: 0.1410 - dense_32_accuracy: 0.2120 - dense_33_accuracy: 0.1770 - dense_34_accuracy: 0.4090 - dense_35_accuracy: 0.4600\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 16.5551 - dense_26_loss: 1.5157 - dense_27_loss: 1.8598 - dense_28_loss: 1.5860 - dense_29_loss: 1.7127 - dense_30_loss: 1.8242 - dense_31_loss: 2.0034 - dense_32_loss: 1.7228 - dense_33_loss: 1.7739 - dense_34_loss: 1.2834 - dense_35_loss: 1.2733 - dense_26_accuracy: 0.3750 - dense_27_accuracy: 0.2060 - dense_28_accuracy: 0.3550 - dense_29_accuracy: 0.2330 - dense_30_accuracy: 0.2250 - dense_31_accuracy: 0.2140 - dense_32_accuracy: 0.2230 - dense_33_accuracy: 0.2350 - dense_34_accuracy: 0.4850 - dense_35_accuracy: 0.5120\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 15.8203 - dense_26_loss: 1.4238 - dense_27_loss: 1.7698 - dense_28_loss: 1.5326 - dense_29_loss: 1.6610 - dense_30_loss: 1.7418 - dense_31_loss: 1.9059 - dense_32_loss: 1.6603 - dense_33_loss: 1.6705 - dense_34_loss: 1.2181 - dense_35_loss: 1.2364 - dense_26_accuracy: 0.3690 - dense_27_accuracy: 0.2420 - dense_28_accuracy: 0.3420 - dense_29_accuracy: 0.2670 - dense_30_accuracy: 0.2350 - dense_31_accuracy: 0.2310 - dense_32_accuracy: 0.2390 - dense_33_accuracy: 0.2470 - dense_34_accuracy: 0.5070 - dense_35_accuracy: 0.5220\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 15.4039 - dense_26_loss: 1.3885 - dense_27_loss: 1.7110 - dense_28_loss: 1.4875 - dense_29_loss: 1.6523 - dense_30_loss: 1.6825 - dense_31_loss: 1.8598 - dense_32_loss: 1.6197 - dense_33_loss: 1.6302 - dense_34_loss: 1.1791 - dense_35_loss: 1.1933 - dense_26_accuracy: 0.3810 - dense_27_accuracy: 0.2510 - dense_28_accuracy: 0.3690 - dense_29_accuracy: 0.2310 - dense_30_accuracy: 0.2580 - dense_31_accuracy: 0.2280 - dense_32_accuracy: 0.2720 - dense_33_accuracy: 0.2230 - dense_34_accuracy: 0.5070 - dense_35_accuracy: 0.5160\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 15.1593 - dense_26_loss: 1.3760 - dense_27_loss: 1.6802 - dense_28_loss: 1.4579 - dense_29_loss: 1.6315 - dense_30_loss: 1.6559 - dense_31_loss: 1.8228 - dense_32_loss: 1.6037 - dense_33_loss: 1.6019 - dense_34_loss: 1.1655 - dense_35_loss: 1.1639 - dense_26_accuracy: 0.3970 - dense_27_accuracy: 0.2460 - dense_28_accuracy: 0.3850 - dense_29_accuracy: 0.2600 - dense_30_accuracy: 0.2760 - dense_31_accuracy: 0.2540 - dense_32_accuracy: 0.2960 - dense_33_accuracy: 0.2620 - dense_34_accuracy: 0.5130 - dense_35_accuracy: 0.5260\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 15.0071 - dense_26_loss: 1.3639 - dense_27_loss: 1.6611 - dense_28_loss: 1.4463 - dense_29_loss: 1.6125 - dense_30_loss: 1.6435 - dense_31_loss: 1.8075 - dense_32_loss: 1.5969 - dense_33_loss: 1.5855 - dense_34_loss: 1.1509 - dense_35_loss: 1.1389 - dense_26_accuracy: 0.3930 - dense_27_accuracy: 0.2740 - dense_28_accuracy: 0.3690 - dense_29_accuracy: 0.2760 - dense_30_accuracy: 0.2570 - dense_31_accuracy: 0.2430 - dense_32_accuracy: 0.2700 - dense_33_accuracy: 0.2740 - dense_34_accuracy: 0.5250 - dense_35_accuracy: 0.5410\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 15.0043 - dense_26_loss: 1.3681 - dense_27_loss: 1.6640 - dense_28_loss: 1.4388 - dense_29_loss: 1.6058 - dense_30_loss: 1.6429 - dense_31_loss: 1.8093 - dense_32_loss: 1.6021 - dense_33_loss: 1.5899 - dense_34_loss: 1.1431 - dense_35_loss: 1.1403 - dense_26_accuracy: 0.3900 - dense_27_accuracy: 0.2600 - dense_28_accuracy: 0.3800 - dense_29_accuracy: 0.2790 - dense_30_accuracy: 0.2570 - dense_31_accuracy: 0.2570 - dense_32_accuracy: 0.2900 - dense_33_accuracy: 0.2760 - dense_34_accuracy: 0.5030 - dense_35_accuracy: 0.4980\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 14.8884 - dense_26_loss: 1.3543 - dense_27_loss: 1.6548 - dense_28_loss: 1.4362 - dense_29_loss: 1.5955 - dense_30_loss: 1.6300 - dense_31_loss: 1.7986 - dense_32_loss: 1.5839 - dense_33_loss: 1.5723 - dense_34_loss: 1.1353 - dense_35_loss: 1.1276 - dense_26_accuracy: 0.3880 - dense_27_accuracy: 0.2710 - dense_28_accuracy: 0.3720 - dense_29_accuracy: 0.2810 - dense_30_accuracy: 0.2630 - dense_31_accuracy: 0.2620 - dense_32_accuracy: 0.2920 - dense_33_accuracy: 0.2780 - dense_34_accuracy: 0.5120 - dense_35_accuracy: 0.5290\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 14.8654 - dense_26_loss: 1.3547 - dense_27_loss: 1.6516 - dense_28_loss: 1.4306 - dense_29_loss: 1.5835 - dense_30_loss: 1.6201 - dense_31_loss: 1.7924 - dense_32_loss: 1.5848 - dense_33_loss: 1.5806 - dense_34_loss: 1.1350 - dense_35_loss: 1.1320 - dense_26_accuracy: 0.3800 - dense_27_accuracy: 0.2620 - dense_28_accuracy: 0.3830 - dense_29_accuracy: 0.2810 - dense_30_accuracy: 0.2530 - dense_31_accuracy: 0.2380 - dense_32_accuracy: 0.2670 - dense_33_accuracy: 0.2790 - dense_34_accuracy: 0.5170 - dense_35_accuracy: 0.5250\n",
      "32/32 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 6s 23ms/step - loss: 23.3355 - dense_36_loss: 2.0145 - dense_37_loss: 2.6972 - dense_38_loss: 2.2453 - dense_39_loss: 2.2654 - dense_40_loss: 2.7122 - dense_41_loss: 2.7937 - dense_42_loss: 2.3140 - dense_43_loss: 2.2974 - dense_44_loss: 2.1149 - dense_45_loss: 1.8810 - dense_36_accuracy: 0.2060 - dense_37_accuracy: 0.1060 - dense_38_accuracy: 0.2080 - dense_39_accuracy: 0.1410 - dense_40_accuracy: 0.1150 - dense_41_accuracy: 0.1010 - dense_42_accuracy: 0.2070 - dense_43_accuracy: 0.1600 - dense_44_accuracy: 0.3260 - dense_45_accuracy: 0.3800\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 18.3230 - dense_36_loss: 1.6433 - dense_37_loss: 2.0726 - dense_38_loss: 1.7815 - dense_39_loss: 1.8985 - dense_40_loss: 2.0639 - dense_41_loss: 2.2361 - dense_42_loss: 1.8738 - dense_43_loss: 1.9206 - dense_44_loss: 1.4660 - dense_45_loss: 1.3669 - dense_36_accuracy: 0.3470 - dense_37_accuracy: 0.2190 - dense_38_accuracy: 0.3150 - dense_39_accuracy: 0.2210 - dense_40_accuracy: 0.2020 - dense_41_accuracy: 0.1950 - dense_42_accuracy: 0.2200 - dense_43_accuracy: 0.2080 - dense_44_accuracy: 0.4480 - dense_45_accuracy: 0.4610\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 16.4064 - dense_36_loss: 1.4985 - dense_37_loss: 1.8214 - dense_38_loss: 1.5800 - dense_39_loss: 1.7175 - dense_40_loss: 1.7997 - dense_41_loss: 1.9796 - dense_42_loss: 1.7104 - dense_43_loss: 1.7578 - dense_44_loss: 1.2803 - dense_45_loss: 1.2612 - dense_36_accuracy: 0.3670 - dense_37_accuracy: 0.2370 - dense_38_accuracy: 0.3620 - dense_39_accuracy: 0.2280 - dense_40_accuracy: 0.2340 - dense_41_accuracy: 0.1940 - dense_42_accuracy: 0.2410 - dense_43_accuracy: 0.2590 - dense_44_accuracy: 0.4950 - dense_45_accuracy: 0.5060\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 15.8340 - dense_36_loss: 1.4375 - dense_37_loss: 1.7652 - dense_38_loss: 1.5276 - dense_39_loss: 1.6760 - dense_40_loss: 1.7296 - dense_41_loss: 1.9119 - dense_42_loss: 1.6684 - dense_43_loss: 1.6756 - dense_44_loss: 1.2134 - dense_45_loss: 1.2288 - dense_36_accuracy: 0.3390 - dense_37_accuracy: 0.2300 - dense_38_accuracy: 0.3680 - dense_39_accuracy: 0.2470 - dense_40_accuracy: 0.2320 - dense_41_accuracy: 0.2120 - dense_42_accuracy: 0.2420 - dense_43_accuracy: 0.2180 - dense_44_accuracy: 0.5020 - dense_45_accuracy: 0.5030\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 15.3684 - dense_36_loss: 1.3872 - dense_37_loss: 1.7059 - dense_38_loss: 1.4795 - dense_39_loss: 1.6375 - dense_40_loss: 1.6727 - dense_41_loss: 1.8607 - dense_42_loss: 1.6318 - dense_43_loss: 1.6315 - dense_44_loss: 1.1688 - dense_45_loss: 1.1928 - dense_36_accuracy: 0.3820 - dense_37_accuracy: 0.2100 - dense_38_accuracy: 0.3680 - dense_39_accuracy: 0.2430 - dense_40_accuracy: 0.2360 - dense_41_accuracy: 0.2230 - dense_42_accuracy: 0.2540 - dense_43_accuracy: 0.2420 - dense_44_accuracy: 0.4940 - dense_45_accuracy: 0.5200\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 15.1288 - dense_36_loss: 1.3685 - dense_37_loss: 1.6809 - dense_38_loss: 1.4564 - dense_39_loss: 1.6227 - dense_40_loss: 1.6514 - dense_41_loss: 1.8243 - dense_42_loss: 1.6016 - dense_43_loss: 1.6046 - dense_44_loss: 1.1487 - dense_45_loss: 1.1697 - dense_36_accuracy: 0.3880 - dense_37_accuracy: 0.2240 - dense_38_accuracy: 0.3620 - dense_39_accuracy: 0.2760 - dense_40_accuracy: 0.2310 - dense_41_accuracy: 0.2400 - dense_42_accuracy: 0.2880 - dense_43_accuracy: 0.2370 - dense_44_accuracy: 0.5050 - dense_45_accuracy: 0.5160\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 15.0853 - dense_36_loss: 1.3720 - dense_37_loss: 1.6733 - dense_38_loss: 1.4498 - dense_39_loss: 1.6186 - dense_40_loss: 1.6474 - dense_41_loss: 1.8165 - dense_42_loss: 1.5953 - dense_43_loss: 1.6108 - dense_44_loss: 1.1492 - dense_45_loss: 1.1521 - dense_36_accuracy: 0.3800 - dense_37_accuracy: 0.2520 - dense_38_accuracy: 0.3680 - dense_39_accuracy: 0.2470 - dense_40_accuracy: 0.2470 - dense_41_accuracy: 0.2530 - dense_42_accuracy: 0.2790 - dense_43_accuracy: 0.2310 - dense_44_accuracy: 0.5050 - dense_45_accuracy: 0.5260\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 15.1621 - dense_36_loss: 1.3879 - dense_37_loss: 1.6902 - dense_38_loss: 1.4584 - dense_39_loss: 1.6182 - dense_40_loss: 1.6548 - dense_41_loss: 1.8261 - dense_42_loss: 1.6010 - dense_43_loss: 1.6139 - dense_44_loss: 1.1521 - dense_45_loss: 1.1596 - dense_36_accuracy: 0.3650 - dense_37_accuracy: 0.2380 - dense_38_accuracy: 0.3610 - dense_39_accuracy: 0.2520 - dense_40_accuracy: 0.2600 - dense_41_accuracy: 0.2420 - dense_42_accuracy: 0.2890 - dense_43_accuracy: 0.2490 - dense_44_accuracy: 0.5210 - dense_45_accuracy: 0.5250\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 15.1230 - dense_36_loss: 1.3779 - dense_37_loss: 1.6800 - dense_38_loss: 1.4678 - dense_39_loss: 1.6203 - dense_40_loss: 1.6561 - dense_41_loss: 1.8104 - dense_42_loss: 1.6043 - dense_43_loss: 1.6065 - dense_44_loss: 1.1471 - dense_45_loss: 1.1526 - dense_36_accuracy: 0.3860 - dense_37_accuracy: 0.2430 - dense_38_accuracy: 0.3730 - dense_39_accuracy: 0.2450 - dense_40_accuracy: 0.2510 - dense_41_accuracy: 0.2310 - dense_42_accuracy: 0.2960 - dense_43_accuracy: 0.2610 - dense_44_accuracy: 0.4890 - dense_45_accuracy: 0.5210\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 14.9410 - dense_36_loss: 1.3582 - dense_37_loss: 1.6606 - dense_38_loss: 1.4463 - dense_39_loss: 1.6019 - dense_40_loss: 1.6313 - dense_41_loss: 1.7973 - dense_42_loss: 1.5795 - dense_43_loss: 1.5908 - dense_44_loss: 1.1355 - dense_45_loss: 1.1397 - dense_36_accuracy: 0.3820 - dense_37_accuracy: 0.2330 - dense_38_accuracy: 0.3470 - dense_39_accuracy: 0.2270 - dense_40_accuracy: 0.2320 - dense_41_accuracy: 0.2120 - dense_42_accuracy: 0.2800 - dense_43_accuracy: 0.2390 - dense_44_accuracy: 0.4930 - dense_45_accuracy: 0.5210\n",
      "32/32 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\AppData\\Local\\Temp\\ipykernel_5552\\3844863450.py:53: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(current_combined_results)\n",
      "C:\\Users\\Ayham\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 1s 7ms/step - loss: 0.2492\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2468\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2434\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2385\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2319\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2218\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2080\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1904\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1678\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:55: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 7s 23ms/step - loss: 24.6508 - dense_49_loss: 2.4668 - dense_50_loss: 2.3864 - dense_51_loss: 2.4657 - dense_52_loss: 2.3189 - dense_53_loss: 2.9208 - dense_54_loss: 2.5466 - dense_55_loss: 2.5454 - dense_56_loss: 2.3744 - dense_57_loss: 2.1370 - dense_58_loss: 2.4888 - dense_49_accuracy: 0.1220 - dense_50_accuracy: 0.1660 - dense_51_accuracy: 0.1580 - dense_52_accuracy: 0.2220 - dense_53_accuracy: 0.1040 - dense_54_accuracy: 0.1040 - dense_55_accuracy: 0.0840 - dense_56_accuracy: 0.1600 - dense_57_accuracy: 0.1880 - dense_58_accuracy: 0.1140\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 22.8143 - dense_49_loss: 2.2550 - dense_50_loss: 2.2080 - dense_51_loss: 2.2379 - dense_52_loss: 2.1297 - dense_53_loss: 2.7135 - dense_54_loss: 2.4197 - dense_55_loss: 2.3310 - dense_56_loss: 2.1706 - dense_57_loss: 1.9680 - dense_58_loss: 2.3809 - dense_49_accuracy: 0.1960 - dense_50_accuracy: 0.2020 - dense_51_accuracy: 0.2040 - dense_52_accuracy: 0.2540 - dense_53_accuracy: 0.1280 - dense_54_accuracy: 0.1540 - dense_55_accuracy: 0.1540 - dense_56_accuracy: 0.1820 - dense_57_accuracy: 0.1700 - dense_58_accuracy: 0.1400\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 21.0619 - dense_49_loss: 2.0555 - dense_50_loss: 2.0566 - dense_51_loss: 2.0412 - dense_52_loss: 1.9687 - dense_53_loss: 2.4924 - dense_54_loss: 2.2303 - dense_55_loss: 2.1880 - dense_56_loss: 1.9945 - dense_57_loss: 1.8324 - dense_58_loss: 2.2022 - dense_49_accuracy: 0.3020 - dense_50_accuracy: 0.2380 - dense_51_accuracy: 0.2760 - dense_52_accuracy: 0.3160 - dense_53_accuracy: 0.1760 - dense_54_accuracy: 0.2060 - dense_55_accuracy: 0.1780 - dense_56_accuracy: 0.2520 - dense_57_accuracy: 0.3360 - dense_58_accuracy: 0.1860\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 20.0552 - dense_49_loss: 1.9306 - dense_50_loss: 1.9450 - dense_51_loss: 1.9675 - dense_52_loss: 1.8894 - dense_53_loss: 2.3561 - dense_54_loss: 2.1229 - dense_55_loss: 2.1463 - dense_56_loss: 1.8828 - dense_57_loss: 1.7408 - dense_58_loss: 2.0738 - dense_49_accuracy: 0.3140 - dense_50_accuracy: 0.2540 - dense_51_accuracy: 0.2580 - dense_52_accuracy: 0.3260 - dense_53_accuracy: 0.1840 - dense_54_accuracy: 0.1820 - dense_55_accuracy: 0.1700 - dense_56_accuracy: 0.2860 - dense_57_accuracy: 0.3500 - dense_58_accuracy: 0.2520\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 19.6656 - dense_49_loss: 1.8730 - dense_50_loss: 1.9041 - dense_51_loss: 1.9439 - dense_52_loss: 1.8671 - dense_53_loss: 2.3104 - dense_54_loss: 2.0620 - dense_55_loss: 2.1075 - dense_56_loss: 1.8479 - dense_57_loss: 1.7205 - dense_58_loss: 2.0292 - dense_49_accuracy: 0.3200 - dense_50_accuracy: 0.2580 - dense_51_accuracy: 0.2660 - dense_52_accuracy: 0.2800 - dense_53_accuracy: 0.1600 - dense_54_accuracy: 0.2340 - dense_55_accuracy: 0.2180 - dense_56_accuracy: 0.2200 - dense_57_accuracy: 0.3320 - dense_58_accuracy: 0.2320\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 19.1562 - dense_49_loss: 1.7974 - dense_50_loss: 1.8687 - dense_51_loss: 1.8922 - dense_52_loss: 1.8281 - dense_53_loss: 2.2166 - dense_54_loss: 2.0085 - dense_55_loss: 2.0759 - dense_56_loss: 1.7800 - dense_57_loss: 1.6887 - dense_58_loss: 1.9998 - dense_49_accuracy: 0.3580 - dense_50_accuracy: 0.2620 - dense_51_accuracy: 0.2920 - dense_52_accuracy: 0.3380 - dense_53_accuracy: 0.2060 - dense_54_accuracy: 0.2220 - dense_55_accuracy: 0.2180 - dense_56_accuracy: 0.3000 - dense_57_accuracy: 0.3540 - dense_58_accuracy: 0.2340\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 18.5859 - dense_49_loss: 1.7391 - dense_50_loss: 1.7833 - dense_51_loss: 1.8728 - dense_52_loss: 1.7749 - dense_53_loss: 2.1375 - dense_54_loss: 1.9461 - dense_55_loss: 2.0125 - dense_56_loss: 1.7201 - dense_57_loss: 1.6634 - dense_58_loss: 1.9361 - dense_49_accuracy: 0.3620 - dense_50_accuracy: 0.3100 - dense_51_accuracy: 0.3000 - dense_52_accuracy: 0.3300 - dense_53_accuracy: 0.2340 - dense_54_accuracy: 0.2460 - dense_55_accuracy: 0.2420 - dense_56_accuracy: 0.3320 - dense_57_accuracy: 0.3640 - dense_58_accuracy: 0.3160\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 18.0748 - dense_49_loss: 1.6852 - dense_50_loss: 1.7127 - dense_51_loss: 1.8281 - dense_52_loss: 1.7284 - dense_53_loss: 2.0939 - dense_54_loss: 1.8907 - dense_55_loss: 1.9514 - dense_56_loss: 1.6754 - dense_57_loss: 1.6375 - dense_58_loss: 1.8715 - dense_49_accuracy: 0.3640 - dense_50_accuracy: 0.3060 - dense_51_accuracy: 0.2900 - dense_52_accuracy: 0.3400 - dense_53_accuracy: 0.2560 - dense_54_accuracy: 0.2720 - dense_55_accuracy: 0.2920 - dense_56_accuracy: 0.3340 - dense_57_accuracy: 0.3580 - dense_58_accuracy: 0.3080\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 17.5528 - dense_49_loss: 1.6379 - dense_50_loss: 1.6364 - dense_51_loss: 1.7996 - dense_52_loss: 1.6936 - dense_53_loss: 2.0353 - dense_54_loss: 1.8401 - dense_55_loss: 1.8756 - dense_56_loss: 1.6521 - dense_57_loss: 1.5898 - dense_58_loss: 1.7924 - dense_49_accuracy: 0.3140 - dense_50_accuracy: 0.3680 - dense_51_accuracy: 0.2940 - dense_52_accuracy: 0.3580 - dense_53_accuracy: 0.2780 - dense_54_accuracy: 0.2700 - dense_55_accuracy: 0.3040 - dense_56_accuracy: 0.3180 - dense_57_accuracy: 0.3640 - dense_58_accuracy: 0.3120\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 16.9748 - dense_49_loss: 1.5609 - dense_50_loss: 1.5779 - dense_51_loss: 1.7430 - dense_52_loss: 1.6479 - dense_53_loss: 1.9649 - dense_54_loss: 1.7843 - dense_55_loss: 1.7975 - dense_56_loss: 1.6198 - dense_57_loss: 1.5418 - dense_58_loss: 1.7368 - dense_49_accuracy: 0.3580 - dense_50_accuracy: 0.3580 - dense_51_accuracy: 0.3200 - dense_52_accuracy: 0.3180 - dense_53_accuracy: 0.2780 - dense_54_accuracy: 0.2680 - dense_55_accuracy: 0.2960 - dense_56_accuracy: 0.3040 - dense_57_accuracy: 0.3760 - dense_58_accuracy: 0.2880\n",
      "16/16 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 6s 26ms/step - loss: 24.8713 - dense_59_loss: 2.4992 - dense_60_loss: 2.4168 - dense_61_loss: 2.4676 - dense_62_loss: 2.3705 - dense_63_loss: 2.9762 - dense_64_loss: 2.5110 - dense_65_loss: 2.5621 - dense_66_loss: 2.4024 - dense_67_loss: 2.1658 - dense_68_loss: 2.4997 - dense_59_accuracy: 0.1440 - dense_60_accuracy: 0.1320 - dense_61_accuracy: 0.1600 - dense_62_accuracy: 0.1500 - dense_63_accuracy: 0.0940 - dense_64_accuracy: 0.1380 - dense_65_accuracy: 0.0980 - dense_66_accuracy: 0.1620 - dense_67_accuracy: 0.1880 - dense_68_accuracy: 0.1100\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 23.4181 - dense_59_loss: 2.3144 - dense_60_loss: 2.2448 - dense_61_loss: 2.3052 - dense_62_loss: 2.2076 - dense_63_loss: 2.8278 - dense_64_loss: 2.4464 - dense_65_loss: 2.3944 - dense_66_loss: 2.2360 - dense_67_loss: 2.0316 - dense_68_loss: 2.4100 - dense_59_accuracy: 0.1860 - dense_60_accuracy: 0.2140 - dense_61_accuracy: 0.1720 - dense_62_accuracy: 0.2440 - dense_63_accuracy: 0.0940 - dense_64_accuracy: 0.1700 - dense_65_accuracy: 0.1620 - dense_66_accuracy: 0.1800 - dense_67_accuracy: 0.2380 - dense_68_accuracy: 0.1460\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 22.0172 - dense_59_loss: 2.1711 - dense_60_loss: 2.1279 - dense_61_loss: 2.2067 - dense_62_loss: 2.0506 - dense_63_loss: 2.6087 - dense_64_loss: 2.3344 - dense_65_loss: 2.2132 - dense_66_loss: 2.0875 - dense_67_loss: 1.9238 - dense_68_loss: 2.2932 - dense_59_accuracy: 0.2640 - dense_60_accuracy: 0.2200 - dense_61_accuracy: 0.1660 - dense_62_accuracy: 0.2680 - dense_63_accuracy: 0.1480 - dense_64_accuracy: 0.1940 - dense_65_accuracy: 0.1740 - dense_66_accuracy: 0.2360 - dense_67_accuracy: 0.2240 - dense_68_accuracy: 0.1800\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 20.4252 - dense_59_loss: 1.9981 - dense_60_loss: 1.9890 - dense_61_loss: 2.0357 - dense_62_loss: 1.8912 - dense_63_loss: 2.4046 - dense_64_loss: 2.1879 - dense_65_loss: 2.0712 - dense_66_loss: 1.9497 - dense_67_loss: 1.8040 - dense_68_loss: 2.0938 - dense_59_accuracy: 0.2920 - dense_60_accuracy: 0.2500 - dense_61_accuracy: 0.2520 - dense_62_accuracy: 0.3120 - dense_63_accuracy: 0.1960 - dense_64_accuracy: 0.2360 - dense_65_accuracy: 0.2540 - dense_66_accuracy: 0.2820 - dense_67_accuracy: 0.2680 - dense_68_accuracy: 0.2620\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 18.6985 - dense_59_loss: 1.7617 - dense_60_loss: 1.7943 - dense_61_loss: 1.8562 - dense_62_loss: 1.7445 - dense_63_loss: 2.1572 - dense_64_loss: 2.0243 - dense_65_loss: 1.9823 - dense_66_loss: 1.8029 - dense_67_loss: 1.7008 - dense_68_loss: 1.8743 - dense_59_accuracy: 0.3660 - dense_60_accuracy: 0.3340 - dense_61_accuracy: 0.2800 - dense_62_accuracy: 0.3180 - dense_63_accuracy: 0.2180 - dense_64_accuracy: 0.2320 - dense_65_accuracy: 0.2600 - dense_66_accuracy: 0.2860 - dense_67_accuracy: 0.3280 - dense_68_accuracy: 0.2740\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 17.2002 - dense_59_loss: 1.5903 - dense_60_loss: 1.6407 - dense_61_loss: 1.7254 - dense_62_loss: 1.5998 - dense_63_loss: 1.9576 - dense_64_loss: 1.8339 - dense_65_loss: 1.8588 - dense_66_loss: 1.6597 - dense_67_loss: 1.5964 - dense_68_loss: 1.7375 - dense_59_accuracy: 0.3600 - dense_60_accuracy: 0.3480 - dense_61_accuracy: 0.3240 - dense_62_accuracy: 0.3220 - dense_63_accuracy: 0.2740 - dense_64_accuracy: 0.3000 - dense_65_accuracy: 0.3000 - dense_66_accuracy: 0.3020 - dense_67_accuracy: 0.3640 - dense_68_accuracy: 0.3100\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 16.7526 - dense_59_loss: 1.5333 - dense_60_loss: 1.5778 - dense_61_loss: 1.6940 - dense_62_loss: 1.6012 - dense_63_loss: 1.9180 - dense_64_loss: 1.7880 - dense_65_loss: 1.7779 - dense_66_loss: 1.6317 - dense_67_loss: 1.5454 - dense_68_loss: 1.6852 - dense_59_accuracy: 0.3600 - dense_60_accuracy: 0.3520 - dense_61_accuracy: 0.2880 - dense_62_accuracy: 0.3120 - dense_63_accuracy: 0.2640 - dense_64_accuracy: 0.3000 - dense_65_accuracy: 0.2860 - dense_66_accuracy: 0.3200 - dense_67_accuracy: 0.3800 - dense_68_accuracy: 0.3300\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 16.3391 - dense_59_loss: 1.4896 - dense_60_loss: 1.5350 - dense_61_loss: 1.6689 - dense_62_loss: 1.5583 - dense_63_loss: 1.8613 - dense_64_loss: 1.7330 - dense_65_loss: 1.7237 - dense_66_loss: 1.5992 - dense_67_loss: 1.4980 - dense_68_loss: 1.6720 - dense_59_accuracy: 0.3820 - dense_60_accuracy: 0.3720 - dense_61_accuracy: 0.2940 - dense_62_accuracy: 0.3400 - dense_63_accuracy: 0.2400 - dense_64_accuracy: 0.2760 - dense_65_accuracy: 0.2620 - dense_66_accuracy: 0.3220 - dense_67_accuracy: 0.3880 - dense_68_accuracy: 0.3000\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 16.0839 - dense_59_loss: 1.4687 - dense_60_loss: 1.5124 - dense_61_loss: 1.6462 - dense_62_loss: 1.5363 - dense_63_loss: 1.8248 - dense_64_loss: 1.6983 - dense_65_loss: 1.6997 - dense_66_loss: 1.5772 - dense_67_loss: 1.4725 - dense_68_loss: 1.6479 - dense_59_accuracy: 0.3660 - dense_60_accuracy: 0.3440 - dense_61_accuracy: 0.3160 - dense_62_accuracy: 0.3520 - dense_63_accuracy: 0.2520 - dense_64_accuracy: 0.3060 - dense_65_accuracy: 0.2740 - dense_66_accuracy: 0.3280 - dense_67_accuracy: 0.3720 - dense_68_accuracy: 0.3100\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 15.9227 - dense_59_loss: 1.4466 - dense_60_loss: 1.4920 - dense_61_loss: 1.6260 - dense_62_loss: 1.5361 - dense_63_loss: 1.8061 - dense_64_loss: 1.6994 - dense_65_loss: 1.6696 - dense_66_loss: 1.5696 - dense_67_loss: 1.4557 - dense_68_loss: 1.6218 - dense_59_accuracy: 0.3780 - dense_60_accuracy: 0.3780 - dense_61_accuracy: 0.3420 - dense_62_accuracy: 0.3280 - dense_63_accuracy: 0.2760 - dense_64_accuracy: 0.2980 - dense_65_accuracy: 0.3240 - dense_66_accuracy: 0.3220 - dense_67_accuracy: 0.3840 - dense_68_accuracy: 0.3400\n",
      "16/16 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\AppData\\Local\\Temp\\ipykernel_5552\\3844863450.py:53: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(current_combined_results)\n",
      "C:\\Users\\Ayham\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 2s 7ms/step - loss: 0.2072\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0260\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.0058\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0050\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0048\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0047\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.0047\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0046\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0046\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:55: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 8s 26ms/step - loss: 17.5887 - dense_72_loss: 1.5809 - dense_73_loss: 1.7497 - dense_74_loss: 1.8543 - dense_75_loss: 1.7302 - dense_76_loss: 1.9767 - dense_77_loss: 1.7516 - dense_78_loss: 1.7273 - dense_79_loss: 1.7553 - dense_80_loss: 1.6090 - dense_81_loss: 1.8537 - dense_72_accuracy: 0.4106 - dense_73_accuracy: 0.2682 - dense_74_accuracy: 0.1940 - dense_75_accuracy: 0.2768 - dense_76_accuracy: 0.2100 - dense_77_accuracy: 0.2550 - dense_78_accuracy: 0.3052 - dense_79_accuracy: 0.2698 - dense_80_accuracy: 0.3598 - dense_81_accuracy: 0.2166\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 15.3854 - dense_72_loss: 1.3186 - dense_73_loss: 1.5527 - dense_74_loss: 1.6423 - dense_75_loss: 1.5135 - dense_76_loss: 1.7130 - dense_77_loss: 1.5495 - dense_78_loss: 1.4925 - dense_79_loss: 1.5572 - dense_80_loss: 1.4159 - dense_81_loss: 1.6300 - dense_72_accuracy: 0.4764 - dense_73_accuracy: 0.2908 - dense_74_accuracy: 0.2414 - dense_75_accuracy: 0.3068 - dense_76_accuracy: 0.2352 - dense_77_accuracy: 0.2986 - dense_78_accuracy: 0.3520 - dense_79_accuracy: 0.3000 - dense_80_accuracy: 0.3968 - dense_81_accuracy: 0.2460\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 15.3415 - dense_72_loss: 1.3171 - dense_73_loss: 1.5438 - dense_74_loss: 1.6356 - dense_75_loss: 1.5153 - dense_76_loss: 1.7077 - dense_77_loss: 1.5453 - dense_78_loss: 1.4853 - dense_79_loss: 1.5514 - dense_80_loss: 1.4165 - dense_81_loss: 1.6234 - dense_72_accuracy: 0.4698 - dense_73_accuracy: 0.3026 - dense_74_accuracy: 0.2400 - dense_75_accuracy: 0.2992 - dense_76_accuracy: 0.2248 - dense_77_accuracy: 0.2850 - dense_78_accuracy: 0.3568 - dense_79_accuracy: 0.2898 - dense_80_accuracy: 0.3978 - dense_81_accuracy: 0.2396\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 15.2693 - dense_72_loss: 1.3103 - dense_73_loss: 1.5380 - dense_74_loss: 1.6315 - dense_75_loss: 1.5067 - dense_76_loss: 1.6984 - dense_77_loss: 1.5336 - dense_78_loss: 1.4820 - dense_79_loss: 1.5469 - dense_80_loss: 1.4077 - dense_81_loss: 1.6141 - dense_72_accuracy: 0.4762 - dense_73_accuracy: 0.3126 - dense_74_accuracy: 0.2368 - dense_75_accuracy: 0.3120 - dense_76_accuracy: 0.2408 - dense_77_accuracy: 0.3040 - dense_78_accuracy: 0.3584 - dense_79_accuracy: 0.3086 - dense_80_accuracy: 0.4012 - dense_81_accuracy: 0.2470\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 15.2598 - dense_72_loss: 1.3092 - dense_73_loss: 1.5361 - dense_74_loss: 1.6296 - dense_75_loss: 1.5065 - dense_76_loss: 1.6986 - dense_77_loss: 1.5322 - dense_78_loss: 1.4826 - dense_79_loss: 1.5458 - dense_80_loss: 1.4078 - dense_81_loss: 1.6114 - dense_72_accuracy: 0.4752 - dense_73_accuracy: 0.3110 - dense_74_accuracy: 0.2496 - dense_75_accuracy: 0.3012 - dense_76_accuracy: 0.2436 - dense_77_accuracy: 0.3082 - dense_78_accuracy: 0.3516 - dense_79_accuracy: 0.3088 - dense_80_accuracy: 0.4032 - dense_81_accuracy: 0.2466\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 15.2409 - dense_72_loss: 1.3101 - dense_73_loss: 1.5352 - dense_74_loss: 1.6284 - dense_75_loss: 1.5060 - dense_76_loss: 1.6966 - dense_77_loss: 1.5313 - dense_78_loss: 1.4799 - dense_79_loss: 1.5416 - dense_80_loss: 1.4023 - dense_81_loss: 1.6095 - dense_72_accuracy: 0.4736 - dense_73_accuracy: 0.3056 - dense_74_accuracy: 0.2436 - dense_75_accuracy: 0.3108 - dense_76_accuracy: 0.2500 - dense_77_accuracy: 0.3028 - dense_78_accuracy: 0.3498 - dense_79_accuracy: 0.3058 - dense_80_accuracy: 0.4056 - dense_81_accuracy: 0.2462\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 15.2528 - dense_72_loss: 1.3090 - dense_73_loss: 1.5369 - dense_74_loss: 1.6264 - dense_75_loss: 1.5024 - dense_76_loss: 1.6981 - dense_77_loss: 1.5358 - dense_78_loss: 1.4833 - dense_79_loss: 1.5456 - dense_80_loss: 1.4029 - dense_81_loss: 1.6122 - dense_72_accuracy: 0.4732 - dense_73_accuracy: 0.3118 - dense_74_accuracy: 0.2496 - dense_75_accuracy: 0.3086 - dense_76_accuracy: 0.2482 - dense_77_accuracy: 0.3078 - dense_78_accuracy: 0.3584 - dense_79_accuracy: 0.3056 - dense_80_accuracy: 0.4010 - dense_81_accuracy: 0.2488\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 15.1581 - dense_72_loss: 1.3002 - dense_73_loss: 1.5284 - dense_74_loss: 1.6206 - dense_75_loss: 1.4928 - dense_76_loss: 1.6858 - dense_77_loss: 1.5249 - dense_78_loss: 1.4724 - dense_79_loss: 1.5329 - dense_80_loss: 1.3960 - dense_81_loss: 1.6042 - dense_72_accuracy: 0.4734 - dense_73_accuracy: 0.3226 - dense_74_accuracy: 0.2640 - dense_75_accuracy: 0.3280 - dense_76_accuracy: 0.2640 - dense_77_accuracy: 0.3190 - dense_78_accuracy: 0.3610 - dense_79_accuracy: 0.3204 - dense_80_accuracy: 0.4140 - dense_81_accuracy: 0.2610\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 15.0769 - dense_72_loss: 1.2923 - dense_73_loss: 1.5203 - dense_74_loss: 1.6147 - dense_75_loss: 1.4860 - dense_76_loss: 1.6716 - dense_77_loss: 1.5139 - dense_78_loss: 1.4665 - dense_79_loss: 1.5278 - dense_80_loss: 1.3887 - dense_81_loss: 1.5952 - dense_72_accuracy: 0.4824 - dense_73_accuracy: 0.3244 - dense_74_accuracy: 0.2698 - dense_75_accuracy: 0.3296 - dense_76_accuracy: 0.2670 - dense_77_accuracy: 0.3272 - dense_78_accuracy: 0.3758 - dense_79_accuracy: 0.3288 - dense_80_accuracy: 0.4182 - dense_81_accuracy: 0.2718\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 2s 21ms/step - loss: 15.0303 - dense_72_loss: 1.2929 - dense_73_loss: 1.5171 - dense_74_loss: 1.6032 - dense_75_loss: 1.4828 - dense_76_loss: 1.6704 - dense_77_loss: 1.5083 - dense_78_loss: 1.4606 - dense_79_loss: 1.5213 - dense_80_loss: 1.3829 - dense_81_loss: 1.5908 - dense_72_accuracy: 0.4846 - dense_73_accuracy: 0.3282 - dense_74_accuracy: 0.2676 - dense_75_accuracy: 0.3270 - dense_76_accuracy: 0.2654 - dense_77_accuracy: 0.3314 - dense_78_accuracy: 0.3736 - dense_79_accuracy: 0.3282 - dense_80_accuracy: 0.4220 - dense_81_accuracy: 0.2738\n",
      "157/157 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 10s 22ms/step - loss: 17.2148 - dense_82_loss: 1.5270 - dense_83_loss: 1.7320 - dense_84_loss: 1.8099 - dense_85_loss: 1.6902 - dense_86_loss: 1.9502 - dense_87_loss: 1.7391 - dense_88_loss: 1.6668 - dense_89_loss: 1.7090 - dense_90_loss: 1.5824 - dense_91_loss: 1.8083 - dense_82_accuracy: 0.4280 - dense_83_accuracy: 0.2718 - dense_84_accuracy: 0.2214 - dense_85_accuracy: 0.2876 - dense_86_accuracy: 0.2080 - dense_87_accuracy: 0.2618 - dense_88_accuracy: 0.3258 - dense_89_accuracy: 0.2788 - dense_90_accuracy: 0.3634 - dense_91_accuracy: 0.2170\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 15.3262 - dense_82_loss: 1.3161 - dense_83_loss: 1.5452 - dense_84_loss: 1.6393 - dense_85_loss: 1.5105 - dense_86_loss: 1.7051 - dense_87_loss: 1.5412 - dense_88_loss: 1.4839 - dense_89_loss: 1.5522 - dense_90_loss: 1.4106 - dense_91_loss: 1.6223 - dense_82_accuracy: 0.4660 - dense_83_accuracy: 0.2940 - dense_84_accuracy: 0.2334 - dense_85_accuracy: 0.3038 - dense_86_accuracy: 0.2300 - dense_87_accuracy: 0.2918 - dense_88_accuracy: 0.3598 - dense_89_accuracy: 0.2938 - dense_90_accuracy: 0.4000 - dense_91_accuracy: 0.2410\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 15.3074 - dense_82_loss: 1.3100 - dense_83_loss: 1.5430 - dense_84_loss: 1.6360 - dense_85_loss: 1.5100 - dense_86_loss: 1.7042 - dense_87_loss: 1.5419 - dense_88_loss: 1.4835 - dense_89_loss: 1.5519 - dense_90_loss: 1.4086 - dense_91_loss: 1.6183 - dense_82_accuracy: 0.4762 - dense_83_accuracy: 0.3000 - dense_84_accuracy: 0.2344 - dense_85_accuracy: 0.2978 - dense_86_accuracy: 0.2288 - dense_87_accuracy: 0.2970 - dense_88_accuracy: 0.3528 - dense_89_accuracy: 0.2970 - dense_90_accuracy: 0.3902 - dense_91_accuracy: 0.2442\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 15.2733 - dense_82_loss: 1.3086 - dense_83_loss: 1.5430 - dense_84_loss: 1.6318 - dense_85_loss: 1.5046 - dense_86_loss: 1.6988 - dense_87_loss: 1.5382 - dense_88_loss: 1.4783 - dense_89_loss: 1.5481 - dense_90_loss: 1.4050 - dense_91_loss: 1.6168 - dense_82_accuracy: 0.4702 - dense_83_accuracy: 0.3006 - dense_84_accuracy: 0.2382 - dense_85_accuracy: 0.3076 - dense_86_accuracy: 0.2340 - dense_87_accuracy: 0.3028 - dense_88_accuracy: 0.3564 - dense_89_accuracy: 0.2966 - dense_90_accuracy: 0.3996 - dense_91_accuracy: 0.2412\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 15.2913 - dense_82_loss: 1.3063 - dense_83_loss: 1.5421 - dense_84_loss: 1.6330 - dense_85_loss: 1.5086 - dense_86_loss: 1.7020 - dense_87_loss: 1.5406 - dense_88_loss: 1.4787 - dense_89_loss: 1.5521 - dense_90_loss: 1.4087 - dense_91_loss: 1.6192 - dense_82_accuracy: 0.4762 - dense_83_accuracy: 0.3028 - dense_84_accuracy: 0.2352 - dense_85_accuracy: 0.3012 - dense_86_accuracy: 0.2378 - dense_87_accuracy: 0.2900 - dense_88_accuracy: 0.3598 - dense_89_accuracy: 0.3032 - dense_90_accuracy: 0.4042 - dense_91_accuracy: 0.2412\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 2s 28ms/step - loss: 15.2507 - dense_82_loss: 1.3087 - dense_83_loss: 1.5395 - dense_84_loss: 1.6281 - dense_85_loss: 1.5044 - dense_86_loss: 1.6965 - dense_87_loss: 1.5354 - dense_88_loss: 1.4765 - dense_89_loss: 1.5430 - dense_90_loss: 1.4053 - dense_91_loss: 1.6134 - dense_82_accuracy: 0.4724 - dense_83_accuracy: 0.3082 - dense_84_accuracy: 0.2524 - dense_85_accuracy: 0.3118 - dense_86_accuracy: 0.2486 - dense_87_accuracy: 0.3090 - dense_88_accuracy: 0.3596 - dense_89_accuracy: 0.3134 - dense_90_accuracy: 0.4000 - dense_91_accuracy: 0.2554\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 15.2471 - dense_82_loss: 1.3057 - dense_83_loss: 1.5373 - dense_84_loss: 1.6290 - dense_85_loss: 1.5041 - dense_86_loss: 1.6968 - dense_87_loss: 1.5349 - dense_88_loss: 1.4760 - dense_89_loss: 1.5456 - dense_90_loss: 1.4035 - dense_91_loss: 1.6142 - dense_82_accuracy: 0.4762 - dense_83_accuracy: 0.3088 - dense_84_accuracy: 0.2232 - dense_85_accuracy: 0.3012 - dense_86_accuracy: 0.2304 - dense_87_accuracy: 0.2940 - dense_88_accuracy: 0.3586 - dense_89_accuracy: 0.2966 - dense_90_accuracy: 0.3982 - dense_91_accuracy: 0.2402\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 15.2488 - dense_82_loss: 1.3053 - dense_83_loss: 1.5356 - dense_84_loss: 1.6311 - dense_85_loss: 1.5058 - dense_86_loss: 1.6958 - dense_87_loss: 1.5347 - dense_88_loss: 1.4778 - dense_89_loss: 1.5458 - dense_90_loss: 1.4008 - dense_91_loss: 1.6162 - dense_82_accuracy: 0.4758 - dense_83_accuracy: 0.3050 - dense_84_accuracy: 0.2382 - dense_85_accuracy: 0.3032 - dense_86_accuracy: 0.2332 - dense_87_accuracy: 0.2934 - dense_88_accuracy: 0.3564 - dense_89_accuracy: 0.3032 - dense_90_accuracy: 0.4068 - dense_91_accuracy: 0.2436\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 2s 25ms/step - loss: 15.2368 - dense_82_loss: 1.3061 - dense_83_loss: 1.5368 - dense_84_loss: 1.6257 - dense_85_loss: 1.5019 - dense_86_loss: 1.6962 - dense_87_loss: 1.5331 - dense_88_loss: 1.4782 - dense_89_loss: 1.5456 - dense_90_loss: 1.4032 - dense_91_loss: 1.6100 - dense_82_accuracy: 0.4764 - dense_83_accuracy: 0.3086 - dense_84_accuracy: 0.2436 - dense_85_accuracy: 0.3148 - dense_86_accuracy: 0.2534 - dense_87_accuracy: 0.3042 - dense_88_accuracy: 0.3548 - dense_89_accuracy: 0.2994 - dense_90_accuracy: 0.4022 - dense_91_accuracy: 0.2522\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 15.2516 - dense_82_loss: 1.3066 - dense_83_loss: 1.5390 - dense_84_loss: 1.6275 - dense_85_loss: 1.5073 - dense_86_loss: 1.6983 - dense_87_loss: 1.5362 - dense_88_loss: 1.4787 - dense_89_loss: 1.5452 - dense_90_loss: 1.4000 - dense_91_loss: 1.6126 - dense_82_accuracy: 0.4754 - dense_83_accuracy: 0.3050 - dense_84_accuracy: 0.2476 - dense_85_accuracy: 0.3060 - dense_86_accuracy: 0.2422 - dense_87_accuracy: 0.2932 - dense_88_accuracy: 0.3636 - dense_89_accuracy: 0.3062 - dense_90_accuracy: 0.4082 - dense_91_accuracy: 0.2506\n",
      "157/157 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\AppData\\Local\\Temp\\ipykernel_5552\\3844863450.py:53: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(current_combined_results)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 5ms/step - loss: 0.1353\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0063\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0051\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0049\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0048\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0045\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0039\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0036\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0034\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:55: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 7s 19ms/step - loss: 16.6910 - dense_95_loss: 1.5157 - dense_96_loss: 1.9186 - dense_97_loss: 1.5466 - dense_98_loss: 1.6517 - dense_99_loss: 1.9171 - dense_100_loss: 1.9209 - dense_101_loss: 1.6788 - dense_102_loss: 1.5745 - dense_103_loss: 1.5101 - dense_104_loss: 1.4569 - dense_95_accuracy: 0.3690 - dense_96_accuracy: 0.2036 - dense_97_accuracy: 0.3668 - dense_98_accuracy: 0.2846 - dense_99_accuracy: 0.2036 - dense_100_accuracy: 0.2060 - dense_101_accuracy: 0.2784 - dense_102_accuracy: 0.2861 - dense_103_accuracy: 0.3648 - dense_104_accuracy: 0.3671\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 14.3487 - dense_95_loss: 1.3117 - dense_96_loss: 1.6261 - dense_97_loss: 1.3060 - dense_98_loss: 1.4536 - dense_99_loss: 1.6271 - dense_100_loss: 1.6393 - dense_101_loss: 1.4712 - dense_102_loss: 1.3707 - dense_103_loss: 1.2556 - dense_104_loss: 1.2872 - dense_95_accuracy: 0.4235 - dense_96_accuracy: 0.2441 - dense_97_accuracy: 0.4272 - dense_98_accuracy: 0.3188 - dense_99_accuracy: 0.2476 - dense_100_accuracy: 0.2412 - dense_101_accuracy: 0.3098 - dense_102_accuracy: 0.3208 - dense_103_accuracy: 0.4070 - dense_104_accuracy: 0.3974\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 14.2638 - dense_95_loss: 1.3053 - dense_96_loss: 1.6149 - dense_97_loss: 1.3007 - dense_98_loss: 1.4478 - dense_99_loss: 1.6179 - dense_100_loss: 1.6248 - dense_101_loss: 1.4633 - dense_102_loss: 1.3600 - dense_103_loss: 1.2474 - dense_104_loss: 1.2816 - dense_95_accuracy: 0.4231 - dense_96_accuracy: 0.2473 - dense_97_accuracy: 0.4319 - dense_98_accuracy: 0.3162 - dense_99_accuracy: 0.2420 - dense_100_accuracy: 0.2416 - dense_101_accuracy: 0.3062 - dense_102_accuracy: 0.3137 - dense_103_accuracy: 0.4105 - dense_104_accuracy: 0.4006\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 14.2489 - dense_95_loss: 1.3044 - dense_96_loss: 1.6129 - dense_97_loss: 1.2979 - dense_98_loss: 1.4468 - dense_99_loss: 1.6149 - dense_100_loss: 1.6249 - dense_101_loss: 1.4633 - dense_102_loss: 1.3588 - dense_103_loss: 1.2481 - dense_104_loss: 1.2769 - dense_95_accuracy: 0.4202 - dense_96_accuracy: 0.2496 - dense_97_accuracy: 0.4331 - dense_98_accuracy: 0.3225 - dense_99_accuracy: 0.2452 - dense_100_accuracy: 0.2407 - dense_101_accuracy: 0.3113 - dense_102_accuracy: 0.3206 - dense_103_accuracy: 0.4118 - dense_104_accuracy: 0.4002\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 14.1984 - dense_95_loss: 1.3003 - dense_96_loss: 1.6071 - dense_97_loss: 1.2950 - dense_98_loss: 1.4433 - dense_99_loss: 1.6090 - dense_100_loss: 1.6195 - dense_101_loss: 1.4556 - dense_102_loss: 1.3543 - dense_103_loss: 1.2412 - dense_104_loss: 1.2733 - dense_95_accuracy: 0.4245 - dense_96_accuracy: 0.2496 - dense_97_accuracy: 0.4311 - dense_98_accuracy: 0.3280 - dense_99_accuracy: 0.2492 - dense_100_accuracy: 0.2449 - dense_101_accuracy: 0.3086 - dense_102_accuracy: 0.3220 - dense_103_accuracy: 0.4168 - dense_104_accuracy: 0.4038\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 14.1554 - dense_95_loss: 1.2954 - dense_96_loss: 1.6023 - dense_97_loss: 1.2901 - dense_98_loss: 1.4389 - dense_99_loss: 1.6064 - dense_100_loss: 1.6151 - dense_101_loss: 1.4519 - dense_102_loss: 1.3477 - dense_103_loss: 1.2365 - dense_104_loss: 1.2711 - dense_95_accuracy: 0.4216 - dense_96_accuracy: 0.2608 - dense_97_accuracy: 0.4356 - dense_98_accuracy: 0.3252 - dense_99_accuracy: 0.2558 - dense_100_accuracy: 0.2527 - dense_101_accuracy: 0.3126 - dense_102_accuracy: 0.3270 - dense_103_accuracy: 0.4240 - dense_104_accuracy: 0.4073\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 14.1201 - dense_95_loss: 1.2932 - dense_96_loss: 1.5986 - dense_97_loss: 1.2879 - dense_98_loss: 1.4349 - dense_99_loss: 1.6003 - dense_100_loss: 1.6090 - dense_101_loss: 1.4485 - dense_102_loss: 1.3464 - dense_103_loss: 1.2334 - dense_104_loss: 1.2678 - dense_95_accuracy: 0.4285 - dense_96_accuracy: 0.2659 - dense_97_accuracy: 0.4381 - dense_98_accuracy: 0.3299 - dense_99_accuracy: 0.2615 - dense_100_accuracy: 0.2581 - dense_101_accuracy: 0.3169 - dense_102_accuracy: 0.3297 - dense_103_accuracy: 0.4212 - dense_104_accuracy: 0.4086\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 14.0734 - dense_95_loss: 1.2896 - dense_96_loss: 1.5923 - dense_97_loss: 1.2846 - dense_98_loss: 1.4278 - dense_99_loss: 1.5939 - dense_100_loss: 1.6049 - dense_101_loss: 1.4436 - dense_102_loss: 1.3411 - dense_103_loss: 1.2301 - dense_104_loss: 1.2652 - dense_95_accuracy: 0.4265 - dense_96_accuracy: 0.2680 - dense_97_accuracy: 0.4415 - dense_98_accuracy: 0.3367 - dense_99_accuracy: 0.2718 - dense_100_accuracy: 0.2665 - dense_101_accuracy: 0.3227 - dense_102_accuracy: 0.3342 - dense_103_accuracy: 0.4305 - dense_104_accuracy: 0.4126\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 14.0046 - dense_95_loss: 1.2845 - dense_96_loss: 1.5850 - dense_97_loss: 1.2784 - dense_98_loss: 1.4223 - dense_99_loss: 1.5869 - dense_100_loss: 1.5959 - dense_101_loss: 1.4378 - dense_102_loss: 1.3371 - dense_103_loss: 1.2207 - dense_104_loss: 1.2560 - dense_95_accuracy: 0.4320 - dense_96_accuracy: 0.2715 - dense_97_accuracy: 0.4413 - dense_98_accuracy: 0.3436 - dense_99_accuracy: 0.2718 - dense_100_accuracy: 0.2718 - dense_101_accuracy: 0.3251 - dense_102_accuracy: 0.3356 - dense_103_accuracy: 0.4334 - dense_104_accuracy: 0.4183\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 13.9342 - dense_95_loss: 1.2790 - dense_96_loss: 1.5760 - dense_97_loss: 1.2719 - dense_98_loss: 1.4184 - dense_99_loss: 1.5775 - dense_100_loss: 1.5854 - dense_101_loss: 1.4291 - dense_102_loss: 1.3286 - dense_103_loss: 1.2153 - dense_104_loss: 1.2530 - dense_95_accuracy: 0.4372 - dense_96_accuracy: 0.2849 - dense_97_accuracy: 0.4422 - dense_98_accuracy: 0.3423 - dense_99_accuracy: 0.2839 - dense_100_accuracy: 0.2823 - dense_101_accuracy: 0.3368 - dense_102_accuracy: 0.3476 - dense_103_accuracy: 0.4353 - dense_104_accuracy: 0.4196\n",
      "313/313 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 7s 19ms/step - loss: 16.1568 - dense_105_loss: 1.4645 - dense_106_loss: 1.8567 - dense_107_loss: 1.4850 - dense_108_loss: 1.5976 - dense_109_loss: 1.8539 - dense_110_loss: 1.8617 - dense_111_loss: 1.6368 - dense_112_loss: 1.5393 - dense_113_loss: 1.4324 - dense_114_loss: 1.4289 - dense_105_accuracy: 0.3871 - dense_106_accuracy: 0.2200 - dense_107_accuracy: 0.3965 - dense_108_accuracy: 0.2919 - dense_109_accuracy: 0.2149 - dense_110_accuracy: 0.2189 - dense_111_accuracy: 0.2954 - dense_112_accuracy: 0.2879 - dense_113_accuracy: 0.3850 - dense_114_accuracy: 0.3762\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 14.3706 - dense_105_loss: 1.3127 - dense_106_loss: 1.6301 - dense_107_loss: 1.3101 - dense_108_loss: 1.4598 - dense_109_loss: 1.6316 - dense_110_loss: 1.6406 - dense_111_loss: 1.4729 - dense_112_loss: 1.3666 - dense_113_loss: 1.2586 - dense_114_loss: 1.2875 - dense_105_accuracy: 0.4204 - dense_106_accuracy: 0.2446 - dense_107_accuracy: 0.4315 - dense_108_accuracy: 0.3146 - dense_109_accuracy: 0.2445 - dense_110_accuracy: 0.2426 - dense_111_accuracy: 0.3098 - dense_112_accuracy: 0.3143 - dense_113_accuracy: 0.4086 - dense_114_accuracy: 0.3984\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 14.2450 - dense_105_loss: 1.3034 - dense_106_loss: 1.6142 - dense_107_loss: 1.2994 - dense_108_loss: 1.4461 - dense_109_loss: 1.6174 - dense_110_loss: 1.6258 - dense_111_loss: 1.4583 - dense_112_loss: 1.3583 - dense_113_loss: 1.2442 - dense_114_loss: 1.2779 - dense_105_accuracy: 0.4208 - dense_106_accuracy: 0.2441 - dense_107_accuracy: 0.4313 - dense_108_accuracy: 0.3173 - dense_109_accuracy: 0.2411 - dense_110_accuracy: 0.2425 - dense_111_accuracy: 0.3075 - dense_112_accuracy: 0.3203 - dense_113_accuracy: 0.4181 - dense_114_accuracy: 0.4041\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 14.2186 - dense_105_loss: 1.2998 - dense_106_loss: 1.6116 - dense_107_loss: 1.2947 - dense_108_loss: 1.4468 - dense_109_loss: 1.6139 - dense_110_loss: 1.6235 - dense_111_loss: 1.4550 - dense_112_loss: 1.3536 - dense_113_loss: 1.2435 - dense_114_loss: 1.2762 - dense_105_accuracy: 0.4267 - dense_106_accuracy: 0.2412 - dense_107_accuracy: 0.4362 - dense_108_accuracy: 0.3175 - dense_109_accuracy: 0.2356 - dense_110_accuracy: 0.2426 - dense_111_accuracy: 0.3125 - dense_112_accuracy: 0.3210 - dense_113_accuracy: 0.4082 - dense_114_accuracy: 0.3930\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 14.2217 - dense_105_loss: 1.3008 - dense_106_loss: 1.6119 - dense_107_loss: 1.2952 - dense_108_loss: 1.4448 - dense_109_loss: 1.6149 - dense_110_loss: 1.6228 - dense_111_loss: 1.4559 - dense_112_loss: 1.3538 - dense_113_loss: 1.2443 - dense_114_loss: 1.2773 - dense_105_accuracy: 0.4239 - dense_106_accuracy: 0.2380 - dense_107_accuracy: 0.4323 - dense_108_accuracy: 0.3101 - dense_109_accuracy: 0.2355 - dense_110_accuracy: 0.2353 - dense_111_accuracy: 0.3087 - dense_112_accuracy: 0.3169 - dense_113_accuracy: 0.4048 - dense_114_accuracy: 0.3979\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 14.1635 - dense_105_loss: 1.2963 - dense_106_loss: 1.6052 - dense_107_loss: 1.2913 - dense_108_loss: 1.4384 - dense_109_loss: 1.6084 - dense_110_loss: 1.6157 - dense_111_loss: 1.4495 - dense_112_loss: 1.3506 - dense_113_loss: 1.2370 - dense_114_loss: 1.2711 - dense_105_accuracy: 0.4234 - dense_106_accuracy: 0.2364 - dense_107_accuracy: 0.4365 - dense_108_accuracy: 0.3157 - dense_109_accuracy: 0.2409 - dense_110_accuracy: 0.2414 - dense_111_accuracy: 0.3121 - dense_112_accuracy: 0.3142 - dense_113_accuracy: 0.4107 - dense_114_accuracy: 0.4017\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 14.1735 - dense_105_loss: 1.2977 - dense_106_loss: 1.6060 - dense_107_loss: 1.2915 - dense_108_loss: 1.4389 - dense_109_loss: 1.6083 - dense_110_loss: 1.6177 - dense_111_loss: 1.4510 - dense_112_loss: 1.3521 - dense_113_loss: 1.2391 - dense_114_loss: 1.2713 - dense_105_accuracy: 0.4246 - dense_106_accuracy: 0.2367 - dense_107_accuracy: 0.4334 - dense_108_accuracy: 0.3169 - dense_109_accuracy: 0.2394 - dense_110_accuracy: 0.2366 - dense_111_accuracy: 0.3114 - dense_112_accuracy: 0.3197 - dense_113_accuracy: 0.4068 - dense_114_accuracy: 0.3960\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 14.1793 - dense_105_loss: 1.2971 - dense_106_loss: 1.6069 - dense_107_loss: 1.2896 - dense_108_loss: 1.4399 - dense_109_loss: 1.6095 - dense_110_loss: 1.6186 - dense_111_loss: 1.4522 - dense_112_loss: 1.3508 - dense_113_loss: 1.2408 - dense_114_loss: 1.2740 - dense_105_accuracy: 0.4244 - dense_106_accuracy: 0.2389 - dense_107_accuracy: 0.4352 - dense_108_accuracy: 0.3174 - dense_109_accuracy: 0.2404 - dense_110_accuracy: 0.2349 - dense_111_accuracy: 0.3041 - dense_112_accuracy: 0.3186 - dense_113_accuracy: 0.4064 - dense_114_accuracy: 0.3990\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 3s 20ms/step - loss: 14.1706 - dense_105_loss: 1.2969 - dense_106_loss: 1.6041 - dense_107_loss: 1.2901 - dense_108_loss: 1.4390 - dense_109_loss: 1.6099 - dense_110_loss: 1.6170 - dense_111_loss: 1.4521 - dense_112_loss: 1.3498 - dense_113_loss: 1.2387 - dense_114_loss: 1.2730 - dense_105_accuracy: 0.4239 - dense_106_accuracy: 0.2481 - dense_107_accuracy: 0.4328 - dense_108_accuracy: 0.3229 - dense_109_accuracy: 0.2487 - dense_110_accuracy: 0.2479 - dense_111_accuracy: 0.3116 - dense_112_accuracy: 0.3245 - dense_113_accuracy: 0.4152 - dense_114_accuracy: 0.4018\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 14.1688 - dense_105_loss: 1.2963 - dense_106_loss: 1.6060 - dense_107_loss: 1.2912 - dense_108_loss: 1.4391 - dense_109_loss: 1.6080 - dense_110_loss: 1.6166 - dense_111_loss: 1.4519 - dense_112_loss: 1.3490 - dense_113_loss: 1.2382 - dense_114_loss: 1.2726 - dense_105_accuracy: 0.4249 - dense_106_accuracy: 0.2417 - dense_107_accuracy: 0.4344 - dense_108_accuracy: 0.3163 - dense_109_accuracy: 0.2419 - dense_110_accuracy: 0.2383 - dense_111_accuracy: 0.3058 - dense_112_accuracy: 0.3247 - dense_113_accuracy: 0.4104 - dense_114_accuracy: 0.3982\n",
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\AppData\\Local\\Temp\\ipykernel_5552\\3844863450.py:53: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(current_combined_results)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 1s 6ms/step - loss: 0.2205\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0469\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0078\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0064\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0060\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0059\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0058\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0058\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0058\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:55: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 6s 19ms/step - loss: 20.9003 - dense_118_loss: 2.0158 - dense_119_loss: 2.0274 - dense_120_loss: 2.1091 - dense_121_loss: 1.9944 - dense_122_loss: 2.4321 - dense_123_loss: 2.1079 - dense_124_loss: 2.1638 - dense_125_loss: 1.9992 - dense_126_loss: 1.8623 - dense_127_loss: 2.1883 - dense_118_accuracy: 0.2756 - dense_119_accuracy: 0.2446 - dense_120_accuracy: 0.2226 - dense_121_accuracy: 0.2696 - dense_122_accuracy: 0.1562 - dense_123_accuracy: 0.2148 - dense_124_accuracy: 0.2072 - dense_125_accuracy: 0.2528 - dense_126_accuracy: 0.3032 - dense_127_accuracy: 0.1750\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 17.3696 - dense_118_loss: 1.5972 - dense_119_loss: 1.6996 - dense_120_loss: 1.7979 - dense_121_loss: 1.6731 - dense_122_loss: 1.9821 - dense_123_loss: 1.7633 - dense_124_loss: 1.7816 - dense_125_loss: 1.7106 - dense_126_loss: 1.5546 - dense_127_loss: 1.8097 - dense_118_accuracy: 0.3958 - dense_119_accuracy: 0.3240 - dense_120_accuracy: 0.2562 - dense_121_accuracy: 0.2920 - dense_122_accuracy: 0.2174 - dense_123_accuracy: 0.2734 - dense_124_accuracy: 0.2768 - dense_125_accuracy: 0.2808 - dense_126_accuracy: 0.3832 - dense_127_accuracy: 0.2412\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 17.1778 - dense_118_loss: 1.5796 - dense_119_loss: 1.6797 - dense_120_loss: 1.7770 - dense_121_loss: 1.6568 - dense_122_loss: 1.9563 - dense_123_loss: 1.7441 - dense_124_loss: 1.7628 - dense_125_loss: 1.6918 - dense_126_loss: 1.5337 - dense_127_loss: 1.7961 - dense_118_accuracy: 0.4066 - dense_119_accuracy: 0.3264 - dense_120_accuracy: 0.2720 - dense_121_accuracy: 0.2970 - dense_122_accuracy: 0.2274 - dense_123_accuracy: 0.2842 - dense_124_accuracy: 0.2798 - dense_125_accuracy: 0.2974 - dense_126_accuracy: 0.3926 - dense_127_accuracy: 0.2524\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 17.1389 - dense_118_loss: 1.5740 - dense_119_loss: 1.6830 - dense_120_loss: 1.7784 - dense_121_loss: 1.6550 - dense_122_loss: 1.9496 - dense_123_loss: 1.7362 - dense_124_loss: 1.7551 - dense_125_loss: 1.6831 - dense_126_loss: 1.5327 - dense_127_loss: 1.7918 - dense_118_accuracy: 0.4136 - dense_119_accuracy: 0.3168 - dense_120_accuracy: 0.2746 - dense_121_accuracy: 0.2922 - dense_122_accuracy: 0.2254 - dense_123_accuracy: 0.2772 - dense_124_accuracy: 0.2864 - dense_125_accuracy: 0.2950 - dense_126_accuracy: 0.3898 - dense_127_accuracy: 0.2394\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 17.0599 - dense_118_loss: 1.5622 - dense_119_loss: 1.6719 - dense_120_loss: 1.7679 - dense_121_loss: 1.6502 - dense_122_loss: 1.9384 - dense_123_loss: 1.7270 - dense_124_loss: 1.7476 - dense_125_loss: 1.6772 - dense_126_loss: 1.5286 - dense_127_loss: 1.7889 - dense_118_accuracy: 0.4178 - dense_119_accuracy: 0.3210 - dense_120_accuracy: 0.2742 - dense_121_accuracy: 0.3000 - dense_122_accuracy: 0.2310 - dense_123_accuracy: 0.2870 - dense_124_accuracy: 0.2884 - dense_125_accuracy: 0.3016 - dense_126_accuracy: 0.3950 - dense_127_accuracy: 0.2456\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 17.0152 - dense_118_loss: 1.5622 - dense_119_loss: 1.6653 - dense_120_loss: 1.7596 - dense_121_loss: 1.6490 - dense_122_loss: 1.9354 - dense_123_loss: 1.7219 - dense_124_loss: 1.7457 - dense_125_loss: 1.6711 - dense_126_loss: 1.5207 - dense_127_loss: 1.7843 - dense_118_accuracy: 0.4064 - dense_119_accuracy: 0.3272 - dense_120_accuracy: 0.2770 - dense_121_accuracy: 0.2904 - dense_122_accuracy: 0.2386 - dense_123_accuracy: 0.2838 - dense_124_accuracy: 0.2956 - dense_125_accuracy: 0.3114 - dense_126_accuracy: 0.3984 - dense_127_accuracy: 0.2484\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 16.9204 - dense_118_loss: 1.5517 - dense_119_loss: 1.6603 - dense_120_loss: 1.7509 - dense_121_loss: 1.6384 - dense_122_loss: 1.9229 - dense_123_loss: 1.7145 - dense_124_loss: 1.7337 - dense_125_loss: 1.6640 - dense_126_loss: 1.5164 - dense_127_loss: 1.7676 - dense_118_accuracy: 0.4130 - dense_119_accuracy: 0.3382 - dense_120_accuracy: 0.2992 - dense_121_accuracy: 0.3104 - dense_122_accuracy: 0.2702 - dense_123_accuracy: 0.2908 - dense_124_accuracy: 0.3154 - dense_125_accuracy: 0.3194 - dense_126_accuracy: 0.4014 - dense_127_accuracy: 0.2836\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 16.8368 - dense_118_loss: 1.5477 - dense_119_loss: 1.6498 - dense_120_loss: 1.7436 - dense_121_loss: 1.6300 - dense_122_loss: 1.9136 - dense_123_loss: 1.7019 - dense_124_loss: 1.7280 - dense_125_loss: 1.6536 - dense_126_loss: 1.5115 - dense_127_loss: 1.7571 - dense_118_accuracy: 0.4160 - dense_119_accuracy: 0.3460 - dense_120_accuracy: 0.2982 - dense_121_accuracy: 0.3184 - dense_122_accuracy: 0.2664 - dense_123_accuracy: 0.3088 - dense_124_accuracy: 0.3118 - dense_125_accuracy: 0.3222 - dense_126_accuracy: 0.4008 - dense_127_accuracy: 0.2878\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 16.7246 - dense_118_loss: 1.5364 - dense_119_loss: 1.6404 - dense_120_loss: 1.7337 - dense_121_loss: 1.6165 - dense_122_loss: 1.9015 - dense_123_loss: 1.6934 - dense_124_loss: 1.7119 - dense_125_loss: 1.6429 - dense_126_loss: 1.4977 - dense_127_loss: 1.7501 - dense_118_accuracy: 0.4254 - dense_119_accuracy: 0.3486 - dense_120_accuracy: 0.3218 - dense_121_accuracy: 0.3232 - dense_122_accuracy: 0.2888 - dense_123_accuracy: 0.3152 - dense_124_accuracy: 0.3324 - dense_125_accuracy: 0.3334 - dense_126_accuracy: 0.4072 - dense_127_accuracy: 0.2892\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 16.5477 - dense_118_loss: 1.5250 - dense_119_loss: 1.6211 - dense_120_loss: 1.7138 - dense_121_loss: 1.6002 - dense_122_loss: 1.8802 - dense_123_loss: 1.6736 - dense_124_loss: 1.6974 - dense_125_loss: 1.6266 - dense_126_loss: 1.4807 - dense_127_loss: 1.7291 - dense_118_accuracy: 0.4242 - dense_119_accuracy: 0.3670 - dense_120_accuracy: 0.3288 - dense_121_accuracy: 0.3430 - dense_122_accuracy: 0.2996 - dense_123_accuracy: 0.3326 - dense_124_accuracy: 0.3404 - dense_125_accuracy: 0.3446 - dense_126_accuracy: 0.4216 - dense_127_accuracy: 0.3172\n",
      "157/157 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 6s 19ms/step - loss: 19.9676 - dense_128_loss: 1.9001 - dense_129_loss: 1.9346 - dense_130_loss: 2.0491 - dense_131_loss: 1.9248 - dense_132_loss: 2.3127 - dense_133_loss: 2.0300 - dense_134_loss: 2.0344 - dense_135_loss: 1.9299 - dense_136_loss: 1.7690 - dense_137_loss: 2.0831 - dense_128_accuracy: 0.3362 - dense_129_accuracy: 0.2638 - dense_130_accuracy: 0.2214 - dense_131_accuracy: 0.2736 - dense_132_accuracy: 0.1752 - dense_133_accuracy: 0.2354 - dense_134_accuracy: 0.2382 - dense_135_accuracy: 0.2572 - dense_136_accuracy: 0.3380 - dense_137_accuracy: 0.2068\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 17.4534 - dense_128_loss: 1.6084 - dense_129_loss: 1.7023 - dense_130_loss: 1.8030 - dense_131_loss: 1.6877 - dense_132_loss: 1.9917 - dense_133_loss: 1.7725 - dense_134_loss: 1.7820 - dense_135_loss: 1.7190 - dense_136_loss: 1.5623 - dense_137_loss: 1.8244 - dense_128_accuracy: 0.4054 - dense_129_accuracy: 0.3196 - dense_130_accuracy: 0.2444 - dense_131_accuracy: 0.2768 - dense_132_accuracy: 0.2160 - dense_133_accuracy: 0.2594 - dense_134_accuracy: 0.2710 - dense_135_accuracy: 0.2852 - dense_136_accuracy: 0.3856 - dense_137_accuracy: 0.2258\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 17.2215 - dense_128_loss: 1.5813 - dense_129_loss: 1.6853 - dense_130_loss: 1.7864 - dense_131_loss: 1.6622 - dense_132_loss: 1.9629 - dense_133_loss: 1.7468 - dense_134_loss: 1.7635 - dense_135_loss: 1.6916 - dense_136_loss: 1.5405 - dense_137_loss: 1.8009 - dense_128_accuracy: 0.4098 - dense_129_accuracy: 0.3194 - dense_130_accuracy: 0.2534 - dense_131_accuracy: 0.2794 - dense_132_accuracy: 0.2152 - dense_133_accuracy: 0.2690 - dense_134_accuracy: 0.2744 - dense_135_accuracy: 0.2840 - dense_136_accuracy: 0.3936 - dense_137_accuracy: 0.2346\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 2s 19ms/step - loss: 17.1799 - dense_128_loss: 1.5777 - dense_129_loss: 1.6778 - dense_130_loss: 1.7813 - dense_131_loss: 1.6547 - dense_132_loss: 1.9544 - dense_133_loss: 1.7490 - dense_134_loss: 1.7600 - dense_135_loss: 1.6909 - dense_136_loss: 1.5373 - dense_137_loss: 1.7967 - dense_128_accuracy: 0.4116 - dense_129_accuracy: 0.3234 - dense_130_accuracy: 0.2604 - dense_131_accuracy: 0.2890 - dense_132_accuracy: 0.2196 - dense_133_accuracy: 0.2598 - dense_134_accuracy: 0.2826 - dense_135_accuracy: 0.2842 - dense_136_accuracy: 0.3938 - dense_137_accuracy: 0.2326\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 17.0969 - dense_128_loss: 1.5690 - dense_129_loss: 1.6742 - dense_130_loss: 1.7700 - dense_131_loss: 1.6494 - dense_132_loss: 1.9447 - dense_133_loss: 1.7377 - dense_134_loss: 1.7535 - dense_135_loss: 1.6836 - dense_136_loss: 1.5271 - dense_137_loss: 1.7878 - dense_128_accuracy: 0.4138 - dense_129_accuracy: 0.3258 - dense_130_accuracy: 0.2640 - dense_131_accuracy: 0.2938 - dense_132_accuracy: 0.2214 - dense_133_accuracy: 0.2714 - dense_134_accuracy: 0.2832 - dense_135_accuracy: 0.2962 - dense_136_accuracy: 0.3956 - dense_137_accuracy: 0.2436\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 17.0970 - dense_128_loss: 1.5704 - dense_129_loss: 1.6718 - dense_130_loss: 1.7720 - dense_131_loss: 1.6502 - dense_132_loss: 1.9444 - dense_133_loss: 1.7367 - dense_134_loss: 1.7514 - dense_135_loss: 1.6827 - dense_136_loss: 1.5288 - dense_137_loss: 1.7887 - dense_128_accuracy: 0.4124 - dense_129_accuracy: 0.3280 - dense_130_accuracy: 0.2726 - dense_131_accuracy: 0.2904 - dense_132_accuracy: 0.2212 - dense_133_accuracy: 0.2732 - dense_134_accuracy: 0.2934 - dense_135_accuracy: 0.2814 - dense_136_accuracy: 0.3920 - dense_137_accuracy: 0.2486\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 17.0450 - dense_128_loss: 1.5631 - dense_129_loss: 1.6682 - dense_130_loss: 1.7667 - dense_131_loss: 1.6442 - dense_132_loss: 1.9365 - dense_133_loss: 1.7342 - dense_134_loss: 1.7463 - dense_135_loss: 1.6761 - dense_136_loss: 1.5268 - dense_137_loss: 1.7829 - dense_128_accuracy: 0.4154 - dense_129_accuracy: 0.3318 - dense_130_accuracy: 0.2644 - dense_131_accuracy: 0.2938 - dense_132_accuracy: 0.2274 - dense_133_accuracy: 0.2700 - dense_134_accuracy: 0.2842 - dense_135_accuracy: 0.3002 - dense_136_accuracy: 0.3922 - dense_137_accuracy: 0.2446\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 16.9836 - dense_128_loss: 1.5547 - dense_129_loss: 1.6622 - dense_130_loss: 1.7612 - dense_131_loss: 1.6358 - dense_132_loss: 1.9316 - dense_133_loss: 1.7257 - dense_134_loss: 1.7411 - dense_135_loss: 1.6733 - dense_136_loss: 1.5182 - dense_137_loss: 1.7798 - dense_128_accuracy: 0.4172 - dense_129_accuracy: 0.3238 - dense_130_accuracy: 0.2710 - dense_131_accuracy: 0.3140 - dense_132_accuracy: 0.2322 - dense_133_accuracy: 0.2808 - dense_134_accuracy: 0.2914 - dense_135_accuracy: 0.2950 - dense_136_accuracy: 0.3938 - dense_137_accuracy: 0.2424\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 17.0083 - dense_128_loss: 1.5589 - dense_129_loss: 1.6643 - dense_130_loss: 1.7655 - dense_131_loss: 1.6411 - dense_132_loss: 1.9302 - dense_133_loss: 1.7300 - dense_134_loss: 1.7436 - dense_135_loss: 1.6725 - dense_136_loss: 1.5216 - dense_137_loss: 1.7805 - dense_128_accuracy: 0.4222 - dense_129_accuracy: 0.3226 - dense_130_accuracy: 0.2630 - dense_131_accuracy: 0.2934 - dense_132_accuracy: 0.2238 - dense_133_accuracy: 0.2698 - dense_134_accuracy: 0.2824 - dense_135_accuracy: 0.2952 - dense_136_accuracy: 0.4032 - dense_137_accuracy: 0.2442\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 1s 19ms/step - loss: 16.9641 - dense_128_loss: 1.5519 - dense_129_loss: 1.6595 - dense_130_loss: 1.7612 - dense_131_loss: 1.6381 - dense_132_loss: 1.9268 - dense_133_loss: 1.7221 - dense_134_loss: 1.7388 - dense_135_loss: 1.6698 - dense_136_loss: 1.5187 - dense_137_loss: 1.7772 - dense_128_accuracy: 0.4214 - dense_129_accuracy: 0.3310 - dense_130_accuracy: 0.2668 - dense_131_accuracy: 0.2986 - dense_132_accuracy: 0.2310 - dense_133_accuracy: 0.2788 - dense_134_accuracy: 0.2902 - dense_135_accuracy: 0.3030 - dense_136_accuracy: 0.3990 - dense_137_accuracy: 0.2476\n",
      "157/157 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\Documents\\GitHub\\APM\\notebooks\\log_iteration.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append(temp_df)\n",
      "C:\\Users\\Ayham\\AppData\\Local\\Temp\\ipykernel_5552\\3844863450.py:53: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(current_combined_results)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get all files from Folder Iteration ending with 'json.gz'\n",
    "event_log_path = '/logs/iteration/*.json.gz'\n",
    "git_path = git.Repo(\".\", search_parent_directories=True).git.rev_parse(\"--show-toplevel\")\n",
    "final_path = git_path+event_log_path\n",
    "files = glob.glob(final_path)\n",
    "\n",
    "column_names = {    0:'Method', \n",
    "                    1:'ari',\n",
    "                    2:'nmi',\n",
    "                    3:'b3',\n",
    "                    4:'0',\n",
    "                    5:'homogeneity',\n",
    "                    6:'completeness',\n",
    "                    7:'distribution'}\n",
    "\n",
    "\n",
    "for n in [10]:\n",
    "    for cluster in ['agglomerative']:\n",
    "\n",
    "        combined_results = pd.DataFrame()\n",
    "        combined_results.rename(columns = column_names, inplace = True) \n",
    "\n",
    "        for filepath in files:\n",
    "\n",
    "            # load eventlog \n",
    "            # event log configuration\n",
    "            event_log_path = filepath\n",
    "            file_name = os.path.basename(filepath)\n",
    "\n",
    "            case_attributes = None # auto-detect attributes\n",
    "            event_attributes = ['concept:name', 'user'] # use activity name and user\n",
    "            true_cluster_label = 'cluster'\n",
    "\n",
    "            # load file\n",
    "            event_log = EventLog(file_name, case_attributes=case_attributes, event_attributes=event_attributes, true_cluster_label=true_cluster_label)\n",
    "            event_log.load(event_log_path, False)\n",
    "            event_log.preprocess()\n",
    "\n",
    "\n",
    "            # hyperparameters\n",
    "            n_epochs = n\n",
    "            n_batch_size = 64\n",
    "            n_clusters = 5\n",
    "            vector_size = 32\n",
    "            cluster_method = cluster\n",
    "            hyperparameters = [n_epochs,n_batch_size,n_clusters,vector_size,cluster_method]\n",
    "            \n",
    "            # get combined results for current file and add filename as first column \n",
    "            current_combined_results = Iteration.get_combined_results(event_log,hyperparameters,column_names)\n",
    "            current_combined_results.insert(loc=0, column='Filename', value=file_name)\n",
    "\n",
    "            # add current_combined_results to overall combined results df \n",
    "            combined_results = combined_results.append(current_combined_results)\n",
    "\n",
    "        combined_results.to_csv(f'tab2_2020_{cluster_method}_{n_epochs}_epochs', encoding='utf-8', index=False, sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Method</th>\n",
       "      <th>ari</th>\n",
       "      <th>nmi</th>\n",
       "      <th>b3</th>\n",
       "      <th>0</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>completeness</th>\n",
       "      <th>distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.4-1.json.gz</td>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>0.402615</td>\n",
       "      <td>0.423485</td>\n",
       "      <td>0.573741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.475172</td>\n",
       "      <td>0.381939</td>\n",
       "      <td>{1: 60, 2: 264, 3: 208, 4: 119, 5: 349}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.4-1.json.gz</td>\n",
       "      <td>TRACE2VEC</td>\n",
       "      <td>0.265702</td>\n",
       "      <td>0.393323</td>\n",
       "      <td>0.515302</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45508</td>\n",
       "      <td>0.346325</td>\n",
       "      <td>{1: 220, 2: 165, 3: 255, 4: 91, 5: 269}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.4-1.json.gz</td>\n",
       "      <td>CASE2VEC E</td>\n",
       "      <td>0.358569</td>\n",
       "      <td>0.406603</td>\n",
       "      <td>0.542741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.467833</td>\n",
       "      <td>0.359546</td>\n",
       "      <td>{1: 169, 2: 81, 3: 201, 4: 256, 5: 293}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.4-1.json.gz</td>\n",
       "      <td>CASE2VEC E+C</td>\n",
       "      <td>-0.000939</td>\n",
       "      <td>0.171583</td>\n",
       "      <td>0.54921</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12939</td>\n",
       "      <td>0.254606</td>\n",
       "      <td>{1: 25, 2: 43, 3: 17, 4: 60, 5: 855}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.4-1.json.gz</td>\n",
       "      <td>GRU</td>\n",
       "      <td>0.994549</td>\n",
       "      <td>0.990519</td>\n",
       "      <td>0.996507</td>\n",
       "      <td>0</td>\n",
       "      <td>0.992834</td>\n",
       "      <td>0.988215</td>\n",
       "      <td>{1: 2, 2: 432, 3: 365, 4: 57, 5: 144}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.4-1.json.gz</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{1: 432, 2: 1, 3: 366, 4: 144, 5: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.5-1.json.gz</td>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>0.322863</td>\n",
       "      <td>0.367457</td>\n",
       "      <td>0.505923</td>\n",
       "      <td>0</td>\n",
       "      <td>0.422728</td>\n",
       "      <td>0.324968</td>\n",
       "      <td>{1: 218, 2: 190, 3: 281, 4: 240, 5: 71}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.5-1.json.gz</td>\n",
       "      <td>TRACE2VEC</td>\n",
       "      <td>0.192318</td>\n",
       "      <td>0.347606</td>\n",
       "      <td>0.488021</td>\n",
       "      <td>0</td>\n",
       "      <td>0.389925</td>\n",
       "      <td>0.313573</td>\n",
       "      <td>{1: 202, 2: 139, 3: 320, 4: 48, 5: 291}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.5-1.json.gz</td>\n",
       "      <td>CASE2VEC E</td>\n",
       "      <td>0.335304</td>\n",
       "      <td>0.432354</td>\n",
       "      <td>0.561641</td>\n",
       "      <td>0</td>\n",
       "      <td>0.488254</td>\n",
       "      <td>0.38794</td>\n",
       "      <td>{1: 75, 2: 130, 3: 174, 4: 351, 5: 270}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.5-1.json.gz</td>\n",
       "      <td>CASE2VEC E+C</td>\n",
       "      <td>-0.015337</td>\n",
       "      <td>0.126334</td>\n",
       "      <td>0.532615</td>\n",
       "      <td>0</td>\n",
       "      <td>0.09385</td>\n",
       "      <td>0.193206</td>\n",
       "      <td>{1: 47, 2: 64, 3: 33, 4: 855, 5: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.5-1.json.gz</td>\n",
       "      <td>GRU</td>\n",
       "      <td>0.987258</td>\n",
       "      <td>0.979917</td>\n",
       "      <td>0.992072</td>\n",
       "      <td>0</td>\n",
       "      <td>0.980948</td>\n",
       "      <td>0.978888</td>\n",
       "      <td>{1: 428, 2: 1, 3: 369, 4: 58, 5: 144}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium_1000_10_20_5_3_1-0.5-1.json.gz</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.993326</td>\n",
       "      <td>0.983968</td>\n",
       "      <td>0.994042</td>\n",
       "      <td>0</td>\n",
       "      <td>0.984668</td>\n",
       "      <td>0.983269</td>\n",
       "      <td>{1: 433, 2: 1, 3: 364, 4: 58, 5: 144}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p2p_500_10_20_5_1_1-0.8-1.json.gz</td>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>0.280815</td>\n",
       "      <td>0.359237</td>\n",
       "      <td>0.475895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.387339</td>\n",
       "      <td>0.334937</td>\n",
       "      <td>{1: 50, 2: 116, 3: 97, 4: 102, 5: 135}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p2p_500_10_20_5_1_1-0.8-1.json.gz</td>\n",
       "      <td>TRACE2VEC</td>\n",
       "      <td>0.038423</td>\n",
       "      <td>0.208462</td>\n",
       "      <td>0.425062</td>\n",
       "      <td>0</td>\n",
       "      <td>0.204843</td>\n",
       "      <td>0.212211</td>\n",
       "      <td>{1: 57, 2: 43, 3: 49, 4: 78, 5: 273}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p2p_500_10_20_5_1_1-0.8-1.json.gz</td>\n",
       "      <td>CASE2VEC E</td>\n",
       "      <td>0.047411</td>\n",
       "      <td>0.064876</td>\n",
       "      <td>0.308444</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06731</td>\n",
       "      <td>0.062612</td>\n",
       "      <td>{1: 104, 2: 25, 3: 142, 4: 60, 5: 169}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p2p_500_10_20_5_1_1-0.8-1.json.gz</td>\n",
       "      <td>CASE2VEC E+C</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>0.102249</td>\n",
       "      <td>0.430611</td>\n",
       "      <td>0</td>\n",
       "      <td>0.082432</td>\n",
       "      <td>0.134612</td>\n",
       "      <td>{1: 22, 2: 11, 3: 8, 4: 93, 5: 366}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p2p_500_10_20_5_1_1-0.8-1.json.gz</td>\n",
       "      <td>GRU</td>\n",
       "      <td>0.934042</td>\n",
       "      <td>0.908895</td>\n",
       "      <td>0.942779</td>\n",
       "      <td>0</td>\n",
       "      <td>0.91707</td>\n",
       "      <td>0.900865</td>\n",
       "      <td>{1: 189, 2: 6, 3: 133, 4: 92, 5: 80}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p2p_500_10_20_5_1_1-0.8-1.json.gz</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.971303</td>\n",
       "      <td>0.949481</td>\n",
       "      <td>0.954468</td>\n",
       "      <td>0</td>\n",
       "      <td>0.973168</td>\n",
       "      <td>0.926921</td>\n",
       "      <td>{1: 100, 2: 35, 3: 37, 4: 194, 5: 134}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small_5000_10_20_5_1_1-0.5-1.json.gz</td>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>0.403938</td>\n",
       "      <td>0.414749</td>\n",
       "      <td>0.599211</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4731</td>\n",
       "      <td>0.369211</td>\n",
       "      <td>{1: 825, 2: 234, 3: 566, 4: 905, 5: 2470}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small_5000_10_20_5_1_1-0.5-1.json.gz</td>\n",
       "      <td>TRACE2VEC</td>\n",
       "      <td>0.896997</td>\n",
       "      <td>0.879324</td>\n",
       "      <td>0.905695</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998325</td>\n",
       "      <td>0.785672</td>\n",
       "      <td>{1: 1230, 2: 2422, 3: 619, 4: 293, 5: 436}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small_5000_10_20_5_1_1-0.5-1.json.gz</td>\n",
       "      <td>CASE2VEC E</td>\n",
       "      <td>0.896678</td>\n",
       "      <td>0.879065</td>\n",
       "      <td>0.905218</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998721</td>\n",
       "      <td>0.785013</td>\n",
       "      <td>{1: 1230, 2: 616, 3: 2420, 4: 431, 5: 303}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small_5000_10_20_5_1_1-0.5-1.json.gz</td>\n",
       "      <td>CASE2VEC E+C</td>\n",
       "      <td>0.058945</td>\n",
       "      <td>0.244741</td>\n",
       "      <td>0.455816</td>\n",
       "      <td>0</td>\n",
       "      <td>0.275525</td>\n",
       "      <td>0.220144</td>\n",
       "      <td>{1: 2685, 2: 720, 3: 659, 4: 318, 5: 618}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small_5000_10_20_5_1_1-0.5-1.json.gz</td>\n",
       "      <td>GRU</td>\n",
       "      <td>0.963811</td>\n",
       "      <td>0.943003</td>\n",
       "      <td>0.966646</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.892154</td>\n",
       "      <td>{1: 2421, 2: 85, 3: 1145, 4: 88, 5: 1261}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small_5000_10_20_5_1_1-0.5-1.json.gz</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.975325</td>\n",
       "      <td>0.96259</td>\n",
       "      <td>0.982494</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999146</td>\n",
       "      <td>0.928615</td>\n",
       "      <td>{1: 2389, 2: 33, 3: 1348, 4: 55, 5: 1175}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_10000_10_20_5_3_1-0.3-1.json.gz</td>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>0.180924</td>\n",
       "      <td>0.256322</td>\n",
       "      <td>0.377565</td>\n",
       "      <td>0</td>\n",
       "      <td>0.270308</td>\n",
       "      <td>0.243712</td>\n",
       "      <td>{1: 1848, 2: 1180, 3: 2387, 4: 3200, 5: 1385}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_10000_10_20_5_3_1-0.3-1.json.gz</td>\n",
       "      <td>TRACE2VEC</td>\n",
       "      <td>0.253679</td>\n",
       "      <td>0.381532</td>\n",
       "      <td>0.475459</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392013</td>\n",
       "      <td>0.371597</td>\n",
       "      <td>{1: 2730, 2: 3802, 3: 1169, 4: 1030, 5: 1269}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_10000_10_20_5_3_1-0.3-1.json.gz</td>\n",
       "      <td>CASE2VEC E</td>\n",
       "      <td>0.224693</td>\n",
       "      <td>0.373137</td>\n",
       "      <td>0.47008</td>\n",
       "      <td>0</td>\n",
       "      <td>0.378927</td>\n",
       "      <td>0.367521</td>\n",
       "      <td>{1: 2097, 2: 4433, 3: 1228, 4: 1043, 5: 1199}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_10000_10_20_5_3_1-0.3-1.json.gz</td>\n",
       "      <td>CASE2VEC E+C</td>\n",
       "      <td>0.047103</td>\n",
       "      <td>0.124818</td>\n",
       "      <td>0.332885</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124279</td>\n",
       "      <td>0.125362</td>\n",
       "      <td>{1: 858, 2: 1618, 3: 1082, 4: 1514, 5: 4928}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_10000_10_20_5_3_1-0.3-1.json.gz</td>\n",
       "      <td>GRU</td>\n",
       "      <td>0.992916</td>\n",
       "      <td>0.98599</td>\n",
       "      <td>0.994231</td>\n",
       "      <td>0</td>\n",
       "      <td>0.986133</td>\n",
       "      <td>0.985846</td>\n",
       "      <td>{1: 2023, 2: 36, 3: 2247, 4: 3043, 5: 2651}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_10000_10_20_5_3_1-0.3-1.json.gz</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.995483</td>\n",
       "      <td>0.990842</td>\n",
       "      <td>0.996411</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>0.990938</td>\n",
       "      <td>{1: 2248, 2: 2003, 3: 3053, 4: 36, 5: 2660}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_5000_10_20_5_1_1-1.0-1.json.gz</td>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>0.076511</td>\n",
       "      <td>0.124089</td>\n",
       "      <td>0.310927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.123286</td>\n",
       "      <td>0.124903</td>\n",
       "      <td>{1: 1605, 2: 1233, 3: 1162, 4: 309, 5: 691}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_5000_10_20_5_1_1-1.0-1.json.gz</td>\n",
       "      <td>TRACE2VEC</td>\n",
       "      <td>0.279342</td>\n",
       "      <td>0.418704</td>\n",
       "      <td>0.495557</td>\n",
       "      <td>0</td>\n",
       "      <td>0.412063</td>\n",
       "      <td>0.425562</td>\n",
       "      <td>{1: 566, 2: 537, 3: 622, 4: 1346, 5: 1929}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_5000_10_20_5_1_1-1.0-1.json.gz</td>\n",
       "      <td>CASE2VEC E</td>\n",
       "      <td>0.343456</td>\n",
       "      <td>0.501017</td>\n",
       "      <td>0.537663</td>\n",
       "      <td>0</td>\n",
       "      <td>0.501436</td>\n",
       "      <td>0.500599</td>\n",
       "      <td>{1: 489, 2: 1236, 3: 1634, 4: 577, 5: 1064}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_5000_10_20_5_1_1-1.0-1.json.gz</td>\n",
       "      <td>CASE2VEC E+C</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.003362</td>\n",
       "      <td>0.377732</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.045781</td>\n",
       "      <td>{1: 4959, 2: 14, 3: 17, 4: 4, 5: 6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_5000_10_20_5_1_1-1.0-1.json.gz</td>\n",
       "      <td>GRU</td>\n",
       "      <td>0.975716</td>\n",
       "      <td>0.963558</td>\n",
       "      <td>0.98106</td>\n",
       "      <td>0</td>\n",
       "      <td>0.963307</td>\n",
       "      <td>0.963809</td>\n",
       "      <td>{1: 1398, 2: 1446, 3: 968, 4: 865, 5: 323}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide_5000_10_20_5_1_1-1.0-1.json.gz</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.985307</td>\n",
       "      <td>0.976885</td>\n",
       "      <td>0.987783</td>\n",
       "      <td>0</td>\n",
       "      <td>0.97773</td>\n",
       "      <td>0.976041</td>\n",
       "      <td>{1: 1422, 2: 1401, 3: 866, 4: 980, 5: 331}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Filename        Method       ari       nmi  \\\n",
       "0  medium_1000_10_20_5_3_1-0.4-1.json.gz   Autoencoder  0.402615  0.423485   \n",
       "0  medium_1000_10_20_5_3_1-0.4-1.json.gz     TRACE2VEC  0.265702  0.393323   \n",
       "0  medium_1000_10_20_5_3_1-0.4-1.json.gz    CASE2VEC E  0.358569  0.406603   \n",
       "0  medium_1000_10_20_5_3_1-0.4-1.json.gz  CASE2VEC E+C -0.000939  0.171583   \n",
       "0  medium_1000_10_20_5_3_1-0.4-1.json.gz           GRU  0.994549  0.990519   \n",
       "0  medium_1000_10_20_5_3_1-0.4-1.json.gz          LSTM       1.0       1.0   \n",
       "0  medium_1000_10_20_5_3_1-0.5-1.json.gz   Autoencoder  0.322863  0.367457   \n",
       "0  medium_1000_10_20_5_3_1-0.5-1.json.gz     TRACE2VEC  0.192318  0.347606   \n",
       "0  medium_1000_10_20_5_3_1-0.5-1.json.gz    CASE2VEC E  0.335304  0.432354   \n",
       "0  medium_1000_10_20_5_3_1-0.5-1.json.gz  CASE2VEC E+C -0.015337  0.126334   \n",
       "0  medium_1000_10_20_5_3_1-0.5-1.json.gz           GRU  0.987258  0.979917   \n",
       "0  medium_1000_10_20_5_3_1-0.5-1.json.gz          LSTM  0.993326  0.983968   \n",
       "0      p2p_500_10_20_5_1_1-0.8-1.json.gz   Autoencoder  0.280815  0.359237   \n",
       "0      p2p_500_10_20_5_1_1-0.8-1.json.gz     TRACE2VEC  0.038423  0.208462   \n",
       "0      p2p_500_10_20_5_1_1-0.8-1.json.gz    CASE2VEC E  0.047411  0.064876   \n",
       "0      p2p_500_10_20_5_1_1-0.8-1.json.gz  CASE2VEC E+C  0.003359  0.102249   \n",
       "0      p2p_500_10_20_5_1_1-0.8-1.json.gz           GRU  0.934042  0.908895   \n",
       "0      p2p_500_10_20_5_1_1-0.8-1.json.gz          LSTM  0.971303  0.949481   \n",
       "0   small_5000_10_20_5_1_1-0.5-1.json.gz   Autoencoder  0.403938  0.414749   \n",
       "0   small_5000_10_20_5_1_1-0.5-1.json.gz     TRACE2VEC  0.896997  0.879324   \n",
       "0   small_5000_10_20_5_1_1-0.5-1.json.gz    CASE2VEC E  0.896678  0.879065   \n",
       "0   small_5000_10_20_5_1_1-0.5-1.json.gz  CASE2VEC E+C  0.058945  0.244741   \n",
       "0   small_5000_10_20_5_1_1-0.5-1.json.gz           GRU  0.963811  0.943003   \n",
       "0   small_5000_10_20_5_1_1-0.5-1.json.gz          LSTM  0.975325   0.96259   \n",
       "0   wide_10000_10_20_5_3_1-0.3-1.json.gz   Autoencoder  0.180924  0.256322   \n",
       "0   wide_10000_10_20_5_3_1-0.3-1.json.gz     TRACE2VEC  0.253679  0.381532   \n",
       "0   wide_10000_10_20_5_3_1-0.3-1.json.gz    CASE2VEC E  0.224693  0.373137   \n",
       "0   wide_10000_10_20_5_3_1-0.3-1.json.gz  CASE2VEC E+C  0.047103  0.124818   \n",
       "0   wide_10000_10_20_5_3_1-0.3-1.json.gz           GRU  0.992916   0.98599   \n",
       "0   wide_10000_10_20_5_3_1-0.3-1.json.gz          LSTM  0.995483  0.990842   \n",
       "0    wide_5000_10_20_5_1_1-1.0-1.json.gz   Autoencoder  0.076511  0.124089   \n",
       "0    wide_5000_10_20_5_1_1-1.0-1.json.gz     TRACE2VEC  0.279342  0.418704   \n",
       "0    wide_5000_10_20_5_1_1-1.0-1.json.gz    CASE2VEC E  0.343456  0.501017   \n",
       "0    wide_5000_10_20_5_1_1-1.0-1.json.gz  CASE2VEC E+C -0.000091  0.003362   \n",
       "0    wide_5000_10_20_5_1_1-1.0-1.json.gz           GRU  0.975716  0.963558   \n",
       "0    wide_5000_10_20_5_1_1-1.0-1.json.gz          LSTM  0.985307  0.976885   \n",
       "\n",
       "         b3  0 homogeneity completeness  \\\n",
       "0  0.573741  0    0.475172     0.381939   \n",
       "0  0.515302  0     0.45508     0.346325   \n",
       "0  0.542741  0    0.467833     0.359546   \n",
       "0   0.54921  0     0.12939     0.254606   \n",
       "0  0.996507  0    0.992834     0.988215   \n",
       "0       1.0  0         1.0          1.0   \n",
       "0  0.505923  0    0.422728     0.324968   \n",
       "0  0.488021  0    0.389925     0.313573   \n",
       "0  0.561641  0    0.488254      0.38794   \n",
       "0  0.532615  0     0.09385     0.193206   \n",
       "0  0.992072  0    0.980948     0.978888   \n",
       "0  0.994042  0    0.984668     0.983269   \n",
       "0  0.475895  0    0.387339     0.334937   \n",
       "0  0.425062  0    0.204843     0.212211   \n",
       "0  0.308444  0     0.06731     0.062612   \n",
       "0  0.430611  0    0.082432     0.134612   \n",
       "0  0.942779  0     0.91707     0.900865   \n",
       "0  0.954468  0    0.973168     0.926921   \n",
       "0  0.599211  0      0.4731     0.369211   \n",
       "0  0.905695  0    0.998325     0.785672   \n",
       "0  0.905218  0    0.998721     0.785013   \n",
       "0  0.455816  0    0.275525     0.220144   \n",
       "0  0.966646  0         1.0     0.892154   \n",
       "0  0.982494  0    0.999146     0.928615   \n",
       "0  0.377565  0    0.270308     0.243712   \n",
       "0  0.475459  0    0.392013     0.371597   \n",
       "0   0.47008  0    0.378927     0.367521   \n",
       "0  0.332885  0    0.124279     0.125362   \n",
       "0  0.994231  0    0.986133     0.985846   \n",
       "0  0.996411  0    0.990746     0.990938   \n",
       "0  0.310927  0    0.123286     0.124903   \n",
       "0  0.495557  0    0.412063     0.425562   \n",
       "0  0.537663  0    0.501436     0.500599   \n",
       "0  0.377732  0    0.001745     0.045781   \n",
       "0   0.98106  0    0.963307     0.963809   \n",
       "0  0.987783  0     0.97773     0.976041   \n",
       "\n",
       "                                    distribution  \n",
       "0        {1: 60, 2: 264, 3: 208, 4: 119, 5: 349}  \n",
       "0        {1: 220, 2: 165, 3: 255, 4: 91, 5: 269}  \n",
       "0        {1: 169, 2: 81, 3: 201, 4: 256, 5: 293}  \n",
       "0           {1: 25, 2: 43, 3: 17, 4: 60, 5: 855}  \n",
       "0          {1: 2, 2: 432, 3: 365, 4: 57, 5: 144}  \n",
       "0          {1: 432, 2: 1, 3: 366, 4: 144, 5: 57}  \n",
       "0        {1: 218, 2: 190, 3: 281, 4: 240, 5: 71}  \n",
       "0        {1: 202, 2: 139, 3: 320, 4: 48, 5: 291}  \n",
       "0        {1: 75, 2: 130, 3: 174, 4: 351, 5: 270}  \n",
       "0            {1: 47, 2: 64, 3: 33, 4: 855, 5: 1}  \n",
       "0          {1: 428, 2: 1, 3: 369, 4: 58, 5: 144}  \n",
       "0          {1: 433, 2: 1, 3: 364, 4: 58, 5: 144}  \n",
       "0         {1: 50, 2: 116, 3: 97, 4: 102, 5: 135}  \n",
       "0           {1: 57, 2: 43, 3: 49, 4: 78, 5: 273}  \n",
       "0         {1: 104, 2: 25, 3: 142, 4: 60, 5: 169}  \n",
       "0            {1: 22, 2: 11, 3: 8, 4: 93, 5: 366}  \n",
       "0           {1: 189, 2: 6, 3: 133, 4: 92, 5: 80}  \n",
       "0         {1: 100, 2: 35, 3: 37, 4: 194, 5: 134}  \n",
       "0      {1: 825, 2: 234, 3: 566, 4: 905, 5: 2470}  \n",
       "0     {1: 1230, 2: 2422, 3: 619, 4: 293, 5: 436}  \n",
       "0     {1: 1230, 2: 616, 3: 2420, 4: 431, 5: 303}  \n",
       "0      {1: 2685, 2: 720, 3: 659, 4: 318, 5: 618}  \n",
       "0      {1: 2421, 2: 85, 3: 1145, 4: 88, 5: 1261}  \n",
       "0      {1: 2389, 2: 33, 3: 1348, 4: 55, 5: 1175}  \n",
       "0  {1: 1848, 2: 1180, 3: 2387, 4: 3200, 5: 1385}  \n",
       "0  {1: 2730, 2: 3802, 3: 1169, 4: 1030, 5: 1269}  \n",
       "0  {1: 2097, 2: 4433, 3: 1228, 4: 1043, 5: 1199}  \n",
       "0   {1: 858, 2: 1618, 3: 1082, 4: 1514, 5: 4928}  \n",
       "0    {1: 2023, 2: 36, 3: 2247, 4: 3043, 5: 2651}  \n",
       "0    {1: 2248, 2: 2003, 3: 3053, 4: 36, 5: 2660}  \n",
       "0    {1: 1605, 2: 1233, 3: 1162, 4: 309, 5: 691}  \n",
       "0     {1: 566, 2: 537, 3: 622, 4: 1346, 5: 1929}  \n",
       "0    {1: 489, 2: 1236, 3: 1634, 4: 577, 5: 1064}  \n",
       "0            {1: 4959, 2: 14, 3: 17, 4: 4, 5: 6}  \n",
       "0     {1: 1398, 2: 1446, 3: 968, 4: 865, 5: 323}  \n",
       "0     {1: 1422, 2: 1401, 3: 866, 4: 980, 5: 331}  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc5aba863efa4f95ce0f31a1349eb9f064ab108411f4556c2db85ccef09bb8f8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
